[
  {
    "model_name": "Jan-v2-VL-med-gguf",
    "developer": "janhq",
    "downloads": 187025,
    "createdAt": "2025-11-06T11:17:04.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 14,
    "quants": [
      {
        "model_id": "Jan-v2-VL-med-Q3_K_L",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/Jan-v2-VL-med-Q3_K_L.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Jan-v2-VL-med-Q3_K_M",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/Jan-v2-VL-med-Q3_K_M.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "Jan-v2-VL-med-Q3_K_S",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/Jan-v2-VL-med-Q3_K_S.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Jan-v2-VL-med-Q4_0",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/Jan-v2-VL-med-Q4_0.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Jan-v2-VL-med-Q4_1",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/Jan-v2-VL-med-Q4_1.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Jan-v2-VL-med-Q4_K_M",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/Jan-v2-VL-med-Q4_K_M.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Jan-v2-VL-med-Q4_K_S",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/Jan-v2-VL-med-Q4_K_S.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Jan-v2-VL-med-Q5_0",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/Jan-v2-VL-med-Q5_0.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Jan-v2-VL-med-Q5_1",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/Jan-v2-VL-med-Q5_1.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "Jan-v2-VL-med-Q5_K_M",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/Jan-v2-VL-med-Q5_K_M.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "Jan-v2-VL-med-Q5_K_S",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/Jan-v2-VL-med-Q5_K_S.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Jan-v2-VL-med-Q6_K",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/Jan-v2-VL-med-Q6_K.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Jan-v2-VL-med-Q8_0",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/Jan-v2-VL-med-Q8_0.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "Jan-v2-VL-med",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/Jan-v2-VL-med.gguf",
        "file_size": "15.3 GB"
      }
    ],
    "num_mmproj": 1,
    "mmproj_models": [
      {
        "model_id": "mmproj-Jan-v2-VL-med",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/mmproj-Jan-v2-VL-med.gguf",
        "file_size": "1.1 GB"
      }
    ],
    "readme": "https://huggingface.co/janhq/Jan-v2-VL-med-gguf/resolve/main/README.md",
    "description": "**Jan-v2-VL** is an 8B vision-language model optimized for long-horizon, multi-step agentic tasks in software environments like browsers and desktop apps."
  },
  {
    "model_name": "Jan-v3-4B-base-instruct-gguf",
    "developer": "janhq",
    "downloads": 90572,
    "createdAt": "2026-01-20T06:49:01.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 15,
    "quants": [
      {
        "model_id": "Jan-v3-4b-base-instruct-Q3_K_L",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct-Q3_K_L.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Jan-v3-4b-base-instruct-Q3_K_M",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct-Q3_K_M.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Jan-v3-4b-base-instruct-Q3_K_S",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct-Q3_K_S.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Jan-v3-4b-base-instruct-Q4_0",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct-Q4_0.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Jan-v3-4b-base-instruct-Q4_1",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct-Q4_1.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Jan-v3-4b-base-instruct-Q4_K_M",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct-Q4_K_M.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "Jan-v3-4b-base-instruct-Q4_K_S",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct-Q4_K_S.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Jan-v3-4b-base-instruct-Q4_K_XL",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct-Q4_K_XL.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Jan-v3-4b-base-instruct-Q5_0",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct-Q5_0.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Jan-v3-4b-base-instruct-Q5_1",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct-Q5_1.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Jan-v3-4b-base-instruct-Q5_K_M",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct-Q5_K_M.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Jan-v3-4b-base-instruct-Q5_K_S",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct-Q5_K_S.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Jan-v3-4b-base-instruct-Q6_K",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct-Q6_K.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Jan-v3-4b-base-instruct-Q8_0",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct-Q8_0.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Jan-v3-4b-base-instruct",
        "path": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/Jan-v3-4b-base-instruct.gguf",
        "file_size": "8.2 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/janhq/Jan-v3-4B-base-instruct-gguf/resolve/main/README.md",
    "description": "A 4B-parameter causal language model optimized as a fine-tuning base with 262K context length, designed for instruction following and code tasks."
  },
  {
    "model_name": "Jan-v2-VL-high-gguf",
    "developer": "janhq",
    "downloads": 51616,
    "createdAt": "2025-11-06T11:17:54.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 14,
    "quants": [
      {
        "model_id": "Jan-v2-VL-high-Q3_K_L",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/Jan-v2-VL-high-Q3_K_L.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Jan-v2-VL-high-Q3_K_M",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/Jan-v2-VL-high-Q3_K_M.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "Jan-v2-VL-high-Q3_K_S",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/Jan-v2-VL-high-Q3_K_S.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Jan-v2-VL-high-Q4_0",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/Jan-v2-VL-high-Q4_0.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Jan-v2-VL-high-Q4_1",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/Jan-v2-VL-high-Q4_1.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Jan-v2-VL-high-Q4_K_M",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/Jan-v2-VL-high-Q4_K_M.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Jan-v2-VL-high-Q4_K_S",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/Jan-v2-VL-high-Q4_K_S.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Jan-v2-VL-high-Q5_0",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/Jan-v2-VL-high-Q5_0.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Jan-v2-VL-high-Q5_1",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/Jan-v2-VL-high-Q5_1.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "Jan-v2-VL-high-Q5_K_M",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/Jan-v2-VL-high-Q5_K_M.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "Jan-v2-VL-high-Q5_K_S",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/Jan-v2-VL-high-Q5_K_S.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Jan-v2-VL-high-Q6_K",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/Jan-v2-VL-high-Q6_K.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Jan-v2-VL-high-Q8_0",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/Jan-v2-VL-high-Q8_0.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "Jan-v2-VL-high",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/Jan-v2-VL-high.gguf",
        "file_size": "15.3 GB"
      }
    ],
    "num_mmproj": 1,
    "mmproj_models": [
      {
        "model_id": "mmproj-Jan-v2-VL-high",
        "path": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/mmproj-Jan-v2-VL-high.gguf",
        "file_size": "1.1 GB"
      }
    ],
    "readme": "https://huggingface.co/janhq/Jan-v2-VL-high-gguf/resolve/main/README.md",
    "description": "An 8B vision-language model optimized for long-horizon, multi-step agentic tasks like browser and desktop automation."
  },
  {
    "model_name": "Jan-nano-128k-gguf",
    "developer": "Menlo",
    "downloads": 5300,
    "createdAt": "2025-06-24T07:29:01.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 14,
    "quants": [
      {
        "model_id": "jan-nano-128k-Q3_K_L",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q3_K_L.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "jan-nano-128k-Q3_K_M",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q3_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "jan-nano-128k-Q3_K_S",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "jan-nano-128k-Q4_0",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "jan-nano-128k-Q4_1",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q4_1.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "jan-nano-128k-Q4_K_M",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "jan-nano-128k-Q4_K_S",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "jan-nano-128k-Q5_0",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q5_0.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "jan-nano-128k-Q5_1",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q5_1.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "jan-nano-128k-Q5_K_M",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "jan-nano-128k-Q5_K_S",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "jan-nano-128k-Q6_K",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "jan-nano-128k-Q8_0",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q8_0.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "jan-nano-128k-iQ4_XS",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-iQ4_XS.gguf",
        "file_size": "2.1 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/README.md",
    "description": ""
  },
  {
    "model_name": "Jan-v3-4B-base-instruct-4bit",
    "developer": "mlx-community",
    "downloads": 107,
    "createdAt": "2026-01-27T07:35:32.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/mlx-community/Jan-v3-4B-base-instruct-4bit/resolve/main/model.safetensors",
        "file_size": "2.1 GB"
      }
    ],
    "config": "https://huggingface.co/mlx-community/Jan-v3-4B-base-instruct-4bit/resolve/main/config.json",
    "readme": "https://huggingface.co/mlx-community/Jan-v3-4B-base-instruct-4bit/resolve/main/README.md",
    "description": "A 4-bit quantized version of Jan-v3-4B-base-instruct converted to MLX format for text generation on Apple Silicon."
  },
  {
    "model_name": "Olmo-3-7B-Think-GGUF",
    "developer": "unsloth",
    "downloads": 6373,
    "createdAt": "2025-11-21T04:15:44.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "Olmo-3-7B-Think-BF16",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-BF16.gguf",
        "file_size": "13.6 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-IQ4_NL.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-IQ4_XS.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-Q2_K",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-Q2_K.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-Q2_K_L.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-Q3_K_M.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-Q3_K_S.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-Q4_0",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-Q4_0.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-Q4_1",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-Q4_1.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-Q4_K_M.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-Q4_K_S.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-Q5_K_M.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-Q5_K_S.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-Q6_K",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-Q6_K.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-Q8_0",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-Q8_0.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-UD-IQ1_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-UD-IQ1_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-UD-IQ2_M.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-UD-IQ2_XXS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-UD-IQ3_XXS.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-UD-Q2_K_XL.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-UD-Q3_K_XL.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-UD-Q4_K_XL.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-UD-Q5_K_XL.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-UD-Q6_K_XL.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Olmo-3-7B-Think-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/Olmo-3-7B-Think-UD-Q8_K_XL.gguf",
        "file_size": "8.7 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/unsloth/Olmo-3-7B-Think-GGUF/resolve/main/README.md",
    "description": "Olmo 3 Think is a 7B open language model by Ai2 with chain-of-thought reasoning, trained on Dolma 3 and Dolci datasets, excelling at math, coding, and reasoning tasks."
  },
  {
    "model_name": "Olmo-3-7B-Instruct-GGUF",
    "developer": "unsloth",
    "downloads": 3445,
    "createdAt": "2025-11-21T05:20:27.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "Olmo-3-7B-Instruct-BF16",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-BF16.gguf",
        "file_size": "13.6 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-IQ4_NL.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-IQ4_XS.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-Q2_K",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-Q2_K.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-Q2_K_L.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-Q3_K_M.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-Q3_K_S.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-Q4_0",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-Q4_0.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-Q4_1",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-Q4_1.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-Q4_K_M.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-Q4_K_S.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-Q5_K_M.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-Q5_K_S.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-Q6_K",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-Q6_K.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-Q8_0",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-Q8_0.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-UD-IQ1_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-UD-IQ1_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-UD-IQ2_M.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-UD-IQ2_XXS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-UD-IQ3_XXS.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-UD-Q2_K_XL.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-UD-Q3_K_XL.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-UD-Q4_K_XL.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-UD-Q5_K_XL.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-UD-Q6_K_XL.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Olmo-3-7B-Instruct-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/Olmo-3-7B-Instruct-UD-Q8_K_XL.gguf",
        "file_size": "8.7 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/unsloth/Olmo-3-7B-Instruct-GGUF/resolve/main/README.md",
    "description": "Olmo 3 7B Instruct is an open-source 7B parameter language model by Allen Institute for AI, trained on Dolma 3 data, with strong math and reasoning capabilities, using <|im_start|> chat template and Apache 2.0 license."
  },
  {
    "model_name": "all-MiniLM-L6-v2",
    "developer": "sentence-transformers",
    "downloads": 155383424,
    "createdAt": "2022-03-02T23:29:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/model.safetensors",
        "file_size": "86.7 MB"
      }
    ],
    "config": "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json",
    "readme": "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md",
    "description": "A sentence-transformers model that encodes sentences into 384-dimensional vectors for semantic similarity and clustering tasks."
  },
  {
    "model_name": "nsfw_image_detection",
    "developer": "Falconsai",
    "downloads": 52946285,
    "createdAt": "2023-10-13T23:50:01.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/Falconsai/nsfw_image_detection/resolve/main/model.safetensors",
        "file_size": "327.3 MB"
      }
    ],
    "config": "https://huggingface.co/Falconsai/nsfw_image_detection/resolve/main/config.json",
    "readme": "https://huggingface.co/Falconsai/nsfw_image_detection/resolve/main/README.md",
    "description": "A Vision Transformer fine-tuned on 80k images to classify images as \"nsfw\" or \"normal\" with ~98% accuracy."
  },
  {
    "model_name": "bert-base-uncased",
    "developer": "google-bert",
    "downloads": 46750701,
    "createdAt": "2022-03-02T23:29:04.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/google-bert/bert-base-uncased/resolve/main/model.safetensors",
        "file_size": "420.0 MB"
      }
    ],
    "config": "https://huggingface.co/google-bert/bert-base-uncased/resolve/main/config.json",
    "readme": "https://huggingface.co/google-bert/bert-base-uncased/resolve/main/README.md",
    "description": "BERT base model (uncased) is a 110M parameter transformer pretrained on English text using masked language modeling for downstream NLP tasks."
  },
  {
    "model_name": "fairface_age_image_detection",
    "developer": "dima806",
    "downloads": 26507750,
    "createdAt": "2024-12-06T14:59:20.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 5,
    "safetensors_files": [
      {
        "model_id": "checkpoint-32/model",
        "path": "https://huggingface.co/dima806/fairface_age_image_detection/resolve/main/checkpoint-32/model.safetensors",
        "file_size": "327.3 MB"
      },
      {
        "model_id": "checkpoint-4688/model",
        "path": "https://huggingface.co/dima806/fairface_age_image_detection/resolve/main/checkpoint-4688/model.safetensors",
        "file_size": "327.3 MB"
      },
      {
        "model_id": "checkpoint-8752/model",
        "path": "https://huggingface.co/dima806/fairface_age_image_detection/resolve/main/checkpoint-8752/model.safetensors",
        "file_size": "327.3 MB"
      },
      {
        "model_id": "checkpoint-9376/model",
        "path": "https://huggingface.co/dima806/fairface_age_image_detection/resolve/main/checkpoint-9376/model.safetensors",
        "file_size": "327.3 MB"
      },
      {
        "model_id": "model",
        "path": "https://huggingface.co/dima806/fairface_age_image_detection/resolve/main/model.safetensors",
        "file_size": "327.3 MB"
      }
    ],
    "config": "https://huggingface.co/dima806/fairface_age_image_detection/resolve/main/config.json",
    "readme": "https://huggingface.co/dima806/fairface_age_image_detection/resolve/main/README.md",
    "description": "A Vision Transformer (ViT) model fine-tuned on the FairFace dataset to classify human faces into 9 age groups with ~59% accuracy."
  },
  {
    "model_name": "mobilenetv3_small_100.lamb_in1k",
    "developer": "timm",
    "downloads": 24769054,
    "createdAt": "2022-12-16T05:38:36.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k/resolve/main/model.safetensors",
        "file_size": "9.8 MB"
      }
    ],
    "config": "https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k/resolve/main/config.json",
    "readme": "https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k/resolve/main/README.md",
    "description": "A MobileNet-v3 image classification model with 2.5M parameters, trained on ImageNet-1k using LAMB optimizer and EMA averaging."
  },
  {
    "model_name": "all-mpnet-base-v2",
    "developer": "sentence-transformers",
    "downloads": 23522084,
    "createdAt": "2022-03-02T23:29:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/model.safetensors",
        "file_size": "417.7 MB"
      }
    ],
    "config": "https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json",
    "readme": "https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/README.md",
    "description": "A sentence-transformers model that encodes sentences into 768-dimensional vectors for semantic search and clustering, fine-tuned on 1B sentence pairs using contrastive learning."
  },
  {
    "model_name": "Qwen2.5-VL-3B-Instruct",
    "developer": "Qwen",
    "downloads": 21481162,
    "createdAt": "2025-01-26T09:25:35.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 2,
    "safetensors_files": [
      {
        "model_id": "model-00001-of-00002",
        "path": "https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct/resolve/main/model-00001-of-00002.safetensors",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "model-00002-of-00002",
        "path": "https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct/resolve/main/model-00002-of-00002.safetensors",
        "file_size": "3.3 GB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct/resolve/main/README.md",
    "description": "Qwen2.5-VL-3B-Instruct is a 3B-parameter multimodal vision-language model for image and video understanding, reasoning, and agentic tasks."
  },
  {
    "model_name": "roberta-large",
    "developer": "FacebookAI",
    "downloads": 19241341,
    "createdAt": "2022-03-02T23:29:04.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/FacebookAI/roberta-large/resolve/main/model.safetensors",
        "file_size": "1.3 GB"
      }
    ],
    "config": "https://huggingface.co/FacebookAI/roberta-large/resolve/main/config.json",
    "readme": "https://huggingface.co/FacebookAI/roberta-large/resolve/main/README.md",
    "description": "A large RoBERTa model pretrained on English text using masked language modeling for downstream NLP tasks."
  },
  {
    "model_name": "xlm-roberta-base",
    "developer": "FacebookAI",
    "downloads": 18837744,
    "createdAt": "2022-03-02T23:29:04.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/FacebookAI/xlm-roberta-base/resolve/main/model.safetensors",
        "file_size": "1.0 GB"
      }
    ],
    "config": "https://huggingface.co/FacebookAI/xlm-roberta-base/resolve/main/config.json",
    "readme": "https://huggingface.co/FacebookAI/xlm-roberta-base/resolve/main/README.md",
    "description": "XLM-RoBERTa is a multilingual transformer model pre-trained on 2.5TB of CommonCrawl data across 100 languages for masked language modeling and downstream task fine-tuning."
  },
  {
    "model_name": "paraphrase-multilingual-MiniLM-L12-v2",
    "developer": "sentence-transformers",
    "downloads": 18402252,
    "createdAt": "2022-03-02T23:29:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/model.safetensors",
        "file_size": "448.8 MB"
      }
    ],
    "config": "https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json",
    "readme": "https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/README.md",
    "description": "Multilingual sentence embedding model generating 384-dimensional vectors for semantic search and clustering."
  },
  {
    "model_name": "clap-htsat-fused",
    "developer": "laion",
    "downloads": 18170622,
    "createdAt": "2023-02-16T20:45:11.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/laion/clap-htsat-fused/resolve/main/model.safetensors",
        "file_size": "586.0 MB"
      }
    ],
    "config": "https://huggingface.co/laion/clap-htsat-fused/resolve/main/config.json",
    "readme": "https://huggingface.co/laion/clap-htsat-fused/resolve/main/README.md",
    "description": "A CLAP model for zero-shot audio classification and text-to-audio retrieval using contrastive language-audio pretraining on LAION-audio-630k."
  },
  {
    "model_name": "colbertv2.0",
    "developer": "colbert-ir",
    "downloads": 15412982,
    "createdAt": "2023-06-27T21:31:39.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/colbert-ir/colbertv2.0/resolve/main/model.safetensors",
        "file_size": "418.0 MB"
      }
    ],
    "config": "https://huggingface.co/colbert-ir/colbertv2.0/resolve/main/config.json",
    "readme": "https://huggingface.co/colbert-ir/colbertv2.0/resolve/main/README.md",
    "description": "ColBERT is a fast and accurate retrieval model enabling scalable BERT-based search over large text collections using contextual late interaction."
  },
  {
    "model_name": "chronos-bolt-small",
    "developer": "autogluon",
    "downloads": 12226802,
    "createdAt": "2024-11-13T13:28:57.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/autogluon/chronos-bolt-small/resolve/main/model.safetensors",
        "file_size": "182.0 MB"
      }
    ],
    "config": "https://huggingface.co/autogluon/chronos-bolt-small/resolve/main/config.json",
    "readme": "https://huggingface.co/autogluon/chronos-bolt-small/resolve/main/README.md",
    "description": "Chronos-Bolt is a fast, efficient pretrained time series forecasting model for zero-shot inference."
  },
  {
    "model_name": "Qwen2.5-7B-Instruct",
    "developer": "Qwen",
    "downloads": 10257992,
    "createdAt": "2024-09-16T11:55:40.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 4,
    "safetensors_files": [
      {
        "model_id": "model-00001-of-00004",
        "path": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/resolve/main/model-00001-of-00004.safetensors",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "model-00002-of-00004",
        "path": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/resolve/main/model-00002-of-00004.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00003-of-00004",
        "path": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/resolve/main/model-00003-of-00004.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00004-of-00004",
        "path": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/resolve/main/model-00004-of-00004.safetensors",
        "file_size": "3.3 GB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/resolve/main/README.md",
    "description": "Qwen2.5-7B-Instruct is Alibaba's 7B parameter instruction-tuned language model with 128K context support and multilingual capabilities."
  },
  {
    "model_name": "chronos-2",
    "developer": "amazon",
    "downloads": 10017374,
    "createdAt": "2025-10-30T14:54:39.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/amazon/chronos-2/resolve/main/model.safetensors",
        "file_size": "455.8 MB"
      }
    ],
    "config": "https://huggingface.co/amazon/chronos-2/resolve/main/config.json",
    "readme": "https://huggingface.co/amazon/chronos-2/resolve/main/README.md",
    "description": "Chronos-2 is a 120M-parameter encoder-only time series foundation model for zero-shot forecasting, supporting univariate, multivariate, and covariate-informed tasks with state-of-the-art accuracy."
  },
  {
    "model_name": "Qwen2.5-3B-Instruct",
    "developer": "Qwen",
    "downloads": 9864611,
    "createdAt": "2024-09-17T14:08:52.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 2,
    "safetensors_files": [
      {
        "model_id": "model-00001-of-00002",
        "path": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct/resolve/main/model-00001-of-00002.safetensors",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "model-00002-of-00002",
        "path": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct/resolve/main/model-00002-of-00002.safetensors",
        "file_size": "2.1 GB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct/resolve/main/README.md",
    "description": "Qwen2.5-3B-Instruct is Alibaba's 3B-parameter instruction-tuned causal language model with long-context support (128K), multilingual capabilities, and improved coding, math, and instruction-following abilities."
  },
  {
    "model_name": "Qwen3-0.6B",
    "developer": "Qwen",
    "downloads": 9786394,
    "createdAt": "2025-04-27T03:40:08.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/Qwen/Qwen3-0.6B/resolve/main/model.safetensors",
        "file_size": "1.4 GB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen3-0.6B/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen3-0.6B/resolve/main/README.md",
    "description": "Qwen3-0.6B is a 0.6B parameter causal language model that uniquely supports seamless switching between thinking mode (for complex reasoning) and non-thinking mode (for efficient dialogue) within a single model."
  },
  {
    "model_name": "Tarsier2-Recap-7b",
    "developer": "omni-research",
    "downloads": 9650495,
    "createdAt": "2025-02-11T02:11:26.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 4,
    "safetensors_files": [
      {
        "model_id": "model-00001-of-00004",
        "path": "https://huggingface.co/omni-research/Tarsier2-Recap-7b/resolve/main/model-00001-of-00004.safetensors",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "model-00002-of-00004",
        "path": "https://huggingface.co/omni-research/Tarsier2-Recap-7b/resolve/main/model-00002-of-00004.safetensors",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "model-00003-of-00004",
        "path": "https://huggingface.co/omni-research/Tarsier2-Recap-7b/resolve/main/model-00003-of-00004.safetensors",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "model-00004-of-00004",
        "path": "https://huggingface.co/omni-research/Tarsier2-Recap-7b/resolve/main/model-00004-of-00004.safetensors",
        "file_size": "1.6 GB"
      }
    ],
    "config": "https://huggingface.co/omni-research/Tarsier2-Recap-7b/resolve/main/config.json",
    "readme": "https://huggingface.co/omni-research/Tarsier2-Recap-7b/resolve/main/README.md",
    "description": "Tarsier2-Recap-7b is a distilled video description model built on Qwen2-VL-7B-Instruct, trained for video captioning research."
  },
  {
    "model_name": "roberta-base",
    "developer": "FacebookAI",
    "downloads": 8547651,
    "createdAt": "2022-03-02T23:29:04.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/FacebookAI/roberta-base/resolve/main/model.safetensors",
        "file_size": "475.7 MB"
      }
    ],
    "config": "https://huggingface.co/FacebookAI/roberta-base/resolve/main/config.json",
    "readme": "https://huggingface.co/FacebookAI/roberta-base/resolve/main/README.md",
    "description": "A RoBERTa base model, a transformer pretrained on English text using masked language modeling for downstream NLP tasks."
  },
  {
    "model_name": "clip-vit-large-patch14",
    "developer": "openai",
    "downloads": 7954491,
    "createdAt": "2022-03-02T23:29:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/model.safetensors",
        "file_size": "1.6 GB"
      }
    ],
    "config": "https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/config.json",
    "readme": "https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/README.md",
    "description": "CLIP is OpenAI's contrastive vision-language model for zero-shot image classification."
  },
  {
    "model_name": "gpt2",
    "developer": "openai-community",
    "downloads": 7683271,
    "createdAt": "2022-03-02T23:29:04.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/openai-community/gpt2/resolve/main/model.safetensors",
        "file_size": "522.7 MB"
      }
    ],
    "config": "https://huggingface.co/openai-community/gpt2/resolve/main/config.json",
    "readme": "https://huggingface.co/openai-community/gpt2/resolve/main/README.md",
    "description": "GPT-2 is a 124M-parameter transformer model pretrained on English text for causal language modeling, designed for text generation but with known biases and limitations."
  },
  {
    "model_name": "MuQ-large-msd-iter",
    "developer": "OpenMuQ",
    "downloads": 7306961,
    "createdAt": "2024-12-17T07:29:00.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/OpenMuQ/MuQ-large-msd-iter/resolve/main/model.safetensors",
        "file_size": "1.2 GB"
      }
    ],
    "config": "https://huggingface.co/OpenMuQ/MuQ-large-msd-iter/resolve/main/config.json",
    "readme": "https://huggingface.co/OpenMuQ/MuQ-large-msd-iter/resolve/main/README.md",
    "description": "MuQ is a self-supervised music representation learning model with Mel Residual Vector Quantization."
  },
  {
    "model_name": "ms-marco-MiniLM-L6-v2",
    "developer": "cross-encoder",
    "downloads": 7282161,
    "createdAt": "2022-03-02T23:29:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/model.safetensors",
        "file_size": "86.7 MB"
      }
    ],
    "config": "https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json",
    "readme": "https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md",
    "description": "Cross-Encoder model trained on MS Marco for ranking passages by relevance to a query."
  },
  {
    "model_name": "WanVideo_comfy",
    "developer": "Kijai",
    "downloads": 6939637,
    "createdAt": "2025-02-25T17:54:17.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 204,
    "safetensors_files": [
      {
        "model_id": "Bindweave/Wan2_1-I2V-14B-Bindweave_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Bindweave/Wan2_1-I2V-14B-Bindweave_fp16.safetensors",
        "file_size": "30.6 GB"
      },
      {
        "model_id": "CamCloneMaster/Wan-I2V-1_3B-KwaiVGI_CamCloneMaster_Step9500_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/CamCloneMaster/Wan-I2V-1_3B-KwaiVGI_CamCloneMaster_Step9500_bf16.safetensors",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "CamCloneMaster/Wan-I2V-1_3B-KwaiVGI_Step_8000_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/CamCloneMaster/Wan-I2V-1_3B-KwaiVGI_Step_8000_bf16.safetensors",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "ChronoEdit/Wan2_1-I2V-14B_ChronoEdit_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/ChronoEdit/Wan2_1-I2V-14B_ChronoEdit_fp16.safetensors",
        "file_size": "30.5 GB"
      },
      {
        "model_id": "ChronoEdit/Wan_2_1_I2V_14B_ChronoEdit_distill_lora_rank32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/ChronoEdit/Wan_2_1_I2V_14B_ChronoEdit_distill_lora_rank32.safetensors",
        "file_size": "358.5 MB"
      },
      {
        "model_id": "EchoShot/Wan2_1-T2V-1-3B-EchoShot_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/EchoShot/Wan2_1-T2V-1-3B-EchoShot_fp16.safetensors",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "EchoShot/Wan2_1_EchoShot_1_3B_lora_rank_128_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/EchoShot/Wan2_1_EchoShot_1_3B_lora_rank_128_fp16.safetensors",
        "file_size": "341.9 MB"
      },
      {
        "model_id": "FantasyPortrait/Wan2_1_FantasyPortrait_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/FantasyPortrait/Wan2_1_FantasyPortrait_fp16.safetensors",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "FastWan/FastWan_T2V_14B_480p_lora_rank_128_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/FastWan/FastWan_T2V_14B_480p_lora_rank_128_bf16.safetensors",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "FastWan/FastWan_T2V_14B_480p_lora_rank_16_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/FastWan/FastWan_T2V_14B_480p_lora_rank_16_bf16.safetensors",
        "file_size": "155.8 MB"
      },
      {
        "model_id": "FastWan/FastWan_T2V_14B_480p_lora_rank_64_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/FastWan/FastWan_T2V_14B_480p_lora_rank_64_bf16.safetensors",
        "file_size": "601.5 MB"
      },
      {
        "model_id": "FastWan/Wan2_2-TI2V-5B-FastWanFullAttn_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/FastWan/Wan2_2-TI2V-5B-FastWanFullAttn_bf16.safetensors",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "FastWan/Wan2_2_5B_FastWanFullAttn_lora_rank_128_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/FastWan/Wan2_2_5B_FastWanFullAttn_lora_rank_128_bf16.safetensors",
        "file_size": "630.3 MB"
      },
      {
        "model_id": "FlashVSR/Wan2_1-T2V-1_3B_FlashVSR_fp32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/FlashVSR/Wan2_1-T2V-1_3B_FlashVSR_fp32.safetensors",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "FlashVSR/Wan2_1_FlashVSR_LQ_proj_model_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/FlashVSR/Wan2_1_FlashVSR_LQ_proj_model_bf16.safetensors",
        "file_size": "549.0 MB"
      },
      {
        "model_id": "FlashVSR/Wan2_1_FlashVSR_TCDecoder_fp32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/FlashVSR/Wan2_1_FlashVSR_TCDecoder_fp32.safetensors",
        "file_size": "173.0 MB"
      },
      {
        "model_id": "Fun/Lumen/Wan2_1_Lumen-T2V-1.3B-V1.0_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Fun/Lumen/Wan2_1_Lumen-T2V-1.3B-V1.0_bf16.safetensors",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Fun/VACE/Wan2_2_Fun_VACE_module_A14B_HIGH_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Fun/VACE/Wan2_2_Fun_VACE_module_A14B_HIGH_bf16.safetensors",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Fun/VACE/Wan2_2_Fun_VACE_module_A14B_LOW_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Fun/VACE/Wan2_2_Fun_VACE_module_A14B_LOW_bf16.safetensors",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Fun/Wan2.1-Fun-Control-14B_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Fun/Wan2.1-Fun-Control-14B_fp8_e4m3fn.safetensors",
        "file_size": "15.5 GB"
      },
      {
        "model_id": "Fun/Wan2.1-Fun-Control-14B_fp8_e5m2",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Fun/Wan2.1-Fun-Control-14B_fp8_e5m2.safetensors",
        "file_size": "15.5 GB"
      },
      {
        "model_id": "Fun/Wan2.1-Fun-InP-14B_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Fun/Wan2.1-Fun-InP-14B_fp8_e4m3fn.safetensors",
        "file_size": "15.5 GB"
      },
      {
        "model_id": "Fun/Wan2.1-Fun-InP-14B_fp8_e5m2",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Fun/Wan2.1-Fun-InP-14B_fp8_e5m2.safetensors",
        "file_size": "15.5 GB"
      },
      {
        "model_id": "Fun/Wan2_1-Fun-V1_1-14B-Control-Camera_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Fun/Wan2_1-Fun-V1_1-14B-Control-Camera_fp8_e4m3fn.safetensors",
        "file_size": "16.4 GB"
      },
      {
        "model_id": "Fun/Wan2_1-Fun-V1_1-14B-Control_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Fun/Wan2_1-Fun-V1_1-14B-Control_fp8_e4m3fn.safetensors",
        "file_size": "15.5 GB"
      },
      {
        "model_id": "HuMo/Wan2_1-HuMo-14B_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/HuMo/Wan2_1-HuMo-14B_fp16.safetensors",
        "file_size": "31.8 GB"
      },
      {
        "model_id": "HuMo/Wan2_1-HuMo-1_7B_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/HuMo/Wan2_1-HuMo-1_7B_fp16.safetensors",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "HuMo/whisper_large_v3_encoder_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/HuMo/whisper_large_v3_encoder_fp16.safetensors",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "InfiniteTalk/Wan2_1-InfiniTetalk-Single_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/InfiniteTalk/Wan2_1-InfiniTetalk-Single_fp16.safetensors",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "InfiniteTalk/Wan2_1-InfiniteTalk-Multi_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/InfiniteTalk/Wan2_1-InfiniteTalk-Multi_fp16.safetensors",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "Kaleido/Wan_2_1_kaleido_14B-S2V_experimental_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Kaleido/Wan_2_1_kaleido_14B-S2V_experimental_fp16.safetensors",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "Lightx2v/lightx2v_14B_T2V_cfg_step_distill_lora_adaptive_rank_quantile_0.15_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_14B_T2V_cfg_step_distill_lora_adaptive_rank_quantile_0.15_bf16.safetensors",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank128_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank128_bf16.safetensors",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank16_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank16_bf16.safetensors",
        "file_size": "182.3 MB"
      },
      {
        "model_id": "Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank256_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank256_bf16.safetensors",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank32_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank32_bf16.safetensors",
        "file_size": "356.1 MB"
      },
      {
        "model_id": "Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank4_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank4_bf16.safetensors",
        "file_size": "51.9 MB"
      },
      {
        "model_id": "Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16.safetensors",
        "file_size": "703.8 MB"
      },
      {
        "model_id": "Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank8_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank8_bf16.safetensors",
        "file_size": "95.4 MB"
      },
      {
        "model_id": "Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank128_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank128_bf16.safetensors",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank16_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank16_bf16.safetensors",
        "file_size": "155.8 MB"
      },
      {
        "model_id": "Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank256_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank256_bf16.safetensors",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank32_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank32_bf16.safetensors",
        "file_size": "304.3 MB"
      },
      {
        "model_id": "Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank4_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank4_bf16.safetensors",
        "file_size": "44.3 MB"
      },
      {
        "model_id": "Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank64_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank64_bf16.safetensors",
        "file_size": "601.5 MB"
      },
      {
        "model_id": "Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank8_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank8_bf16.safetensors",
        "file_size": "81.5 MB"
      },
      {
        "model_id": "LoRAs/AniSora/Wan2_2_I2V_AniSora_3_2_HIGH_rank_64_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/AniSora/Wan2_2_I2V_AniSora_3_2_HIGH_rank_64_fp16.safetensors",
        "file_size": "601.5 MB"
      },
      {
        "model_id": "LoRAs/CineScale/Wan2.1_I2V_14B_CineScale_ntk20_lora_rank16_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/CineScale/Wan2.1_I2V_14B_CineScale_ntk20_lora_rank16_fp16.safetensors",
        "file_size": "146.3 MB"
      },
      {
        "model_id": "LoRAs/CineScale/Wan2.1_T2V_1.3B_CineScale_ntk20_lora_rank16_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/CineScale/Wan2.1_T2V_1.3B_CineScale_ntk20_lora_rank16_fp16.safetensors",
        "file_size": "41.8 MB"
      },
      {
        "model_id": "LoRAs/CineScale/Wan2.1_T2V_14B_CineScale_ntk20_lora_rank16_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/CineScale/Wan2.1_T2V_14B_CineScale_ntk20_lora_rank16_fp16.safetensors",
        "file_size": "146.3 MB"
      },
      {
        "model_id": "LoRAs/Ditto/Wan21_14B_VACE_lora_ditto_global_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Ditto/Wan21_14B_VACE_lora_ditto_global_bf16.safetensors",
        "file_size": "234.0 MB"
      },
      {
        "model_id": "LoRAs/Ditto/Wan21_14B_VACE_lora_ditto_global_bf16_resized_average_rank_29",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Ditto/Wan21_14B_VACE_lora_ditto_global_bf16_resized_average_rank_29.safetensors",
        "file_size": "56.6 MB"
      },
      {
        "model_id": "LoRAs/Ditto/Wan21_14B_VACE_lora_ditto_global_style_bf16.safetensors",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Ditto/Wan21_14B_VACE_lora_ditto_global_style_bf16.safetensors.safetensors",
        "file_size": "234.0 MB"
      },
      {
        "model_id": "LoRAs/Ditto/Wan21_14B_VACE_lora_ditto_sim2real_bf16.safetensors",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Ditto/Wan21_14B_VACE_lora_ditto_sim2real_bf16.safetensors.safetensors",
        "file_size": "234.0 MB"
      },
      {
        "model_id": "LoRAs/Stable-Video-Infinity/svi-dance_lora_rank_128_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stable-Video-Infinity/svi-dance_lora_rank_128_fp16.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "LoRAs/Stable-Video-Infinity/svi-film-opt-10212025_lora_rank_128_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stable-Video-Infinity/svi-film-opt-10212025_lora_rank_128_fp16.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "LoRAs/Stable-Video-Infinity/svi-film-transitions_lora_rank_128_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stable-Video-Infinity/svi-film-transitions_lora_rank_128_fp16.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "LoRAs/Stable-Video-Infinity/svi-film_lora_rank_128_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stable-Video-Infinity/svi-film_lora_rank_128_fp16.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "LoRAs/Stable-Video-Infinity/svi-shot_lora_rank_128_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stable-Video-Infinity/svi-shot_lora_rank_128_fp16.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "LoRAs/Stable-Video-Infinity/svi-talk_lora_rank_128_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stable-Video-Infinity/svi-talk_lora_rank_128_fp16.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "LoRAs/Stable-Video-Infinity/svi-tom_lora_rank_128_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stable-Video-Infinity/svi-tom_lora_rank_128_fp16.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "LoRAs/Stable-Video-Infinity/v2.0/SVI_Wan2.1-I2V-14B_lora_v2.0_rank_128_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stable-Video-Infinity/v2.0/SVI_Wan2.1-I2V-14B_lora_v2.0_rank_128_fp16.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "LoRAs/Stable-Video-Infinity/v2.0/SVI_Wan2.2-I2V-A14B_lora_HIGH_v2.0_rank_128_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stable-Video-Infinity/v2.0/SVI_Wan2.2-I2V-A14B_lora_HIGH_v2.0_rank_128_fp16.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "LoRAs/Stable-Video-Infinity/v2.0/SVI_Wan2.2-I2V-A14B_lora_LOW_v2.0_rank_128_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stable-Video-Infinity/v2.0/SVI_Wan2.2-I2V-A14B_lora_LOW_v2.0_rank_128_fp16.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "LoRAs/Stable-Video-Infinity/v2.0/SVI_v2_PRO_Wan2.2-I2V-A14B_HIGH_lora_rank_128_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stable-Video-Infinity/v2.0/SVI_v2_PRO_Wan2.2-I2V-A14B_HIGH_lora_rank_128_fp16.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "LoRAs/Stable-Video-Infinity/v2.0/SVI_v2_PRO_Wan2.2-I2V-A14B_LOW_lora_rank_128_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stable-Video-Infinity/v2.0/SVI_v2_PRO_Wan2.2-I2V-A14B_LOW_lora_rank_128_fp16.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "LoRAs/Stand-In/Stand-In_wan2.1_T2V_14B_ver1.0_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stand-In/Stand-In_wan2.1_T2V_14B_ver1.0_fp16.safetensors",
        "file_size": "300.0 MB"
      },
      {
        "model_id": "LoRAs/Stand-In/Stand-In_wan2.1_T2V_14B_ver1.0_fp32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stand-In/Stand-In_wan2.1_T2V_14B_ver1.0_fp32.safetensors",
        "file_size": "600.0 MB"
      },
      {
        "model_id": "LoRAs/Stand-In/Stand-In_wan2.2_T2V_A14B_HIGH_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stand-In/Stand-In_wan2.2_T2V_A14B_HIGH_fp16.safetensors",
        "file_size": "300.0 MB"
      },
      {
        "model_id": "LoRAs/Stand-In/Stand-In_wan2.2_T2V_A14B_LOW_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Stand-In/Stand-In_wan2.2_T2V_A14B_LOW_fp16.safetensors",
        "file_size": "300.0 MB"
      },
      {
        "model_id": "LoRAs/Wan22-Lightning/Wan22_A14B_T2V_HIGH_Lightning_4steps_lora_250928_rank128_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22-Lightning/Wan22_A14B_T2V_HIGH_Lightning_4steps_lora_250928_rank128_fp16.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "LoRAs/Wan22-Lightning/Wan22_A14B_T2V_LOW_Lightning_4steps_lora_250928_rank64_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22-Lightning/Wan22_A14B_T2V_LOW_Lightning_4steps_lora_250928_rank64_fp16.safetensors",
        "file_size": "585.1 MB"
      },
      {
        "model_id": "LoRAs/Wan22-Lightning/old/Wan2.2-Lightning_I2V-A14B-4steps-lora_HIGH_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22-Lightning/old/Wan2.2-Lightning_I2V-A14B-4steps-lora_HIGH_fp16.safetensors",
        "file_size": "585.1 MB"
      },
      {
        "model_id": "LoRAs/Wan22-Lightning/old/Wan2.2-Lightning_I2V-A14B-4steps-lora_LOW_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22-Lightning/old/Wan2.2-Lightning_I2V-A14B-4steps-lora_LOW_fp16.safetensors",
        "file_size": "585.1 MB"
      },
      {
        "model_id": "LoRAs/Wan22-Lightning/old/Wan2.2-Lightning_T2V-A14B-4steps-lora_HIGH_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22-Lightning/old/Wan2.2-Lightning_T2V-A14B-4steps-lora_HIGH_fp16.safetensors",
        "file_size": "585.1 MB"
      },
      {
        "model_id": "LoRAs/Wan22-Lightning/old/Wan2.2-Lightning_T2V-A14B-4steps-lora_LOW_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22-Lightning/old/Wan2.2-Lightning_T2V-A14B-4steps-lora_LOW_fp16.safetensors",
        "file_size": "585.1 MB"
      },
      {
        "model_id": "LoRAs/Wan22-Lightning/old/Wan2.2-Lightning_T2V-v1.1-A14B-4steps-lora_HIGH_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22-Lightning/old/Wan2.2-Lightning_T2V-v1.1-A14B-4steps-lora_HIGH_fp16.safetensors",
        "file_size": "585.1 MB"
      },
      {
        "model_id": "LoRAs/Wan22-Lightning/old/Wan2.2-Lightning_T2V-v1.1-A14B-4steps-lora_LOW_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22-Lightning/old/Wan2.2-Lightning_T2V-v1.1-A14B-4steps-lora_LOW_fp16.safetensors",
        "file_size": "585.1 MB"
      },
      {
        "model_id": "LoRAs/Wan22-Turbo/Wan22_TI2V_5B_Turbo_lora_rank_64_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22-Turbo/Wan22_TI2V_5B_Turbo_lora_rank_64_fp16.safetensors",
        "file_size": "317.0 MB"
      },
      {
        "model_id": "LoRAs/Wan22-Turbo/Wan22_TI2V_5B_Turbo_lora_rank_adaptive_quantile_0.15_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22-Turbo/Wan22_TI2V_5B_Turbo_lora_rank_adaptive_quantile_0.15_fp16.safetensors",
        "file_size": "188.9 MB"
      },
      {
        "model_id": "LoRAs/Wan22_FFGO/Wan22_FFGO-LoRA-HIGH_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22_FFGO/Wan22_FFGO-LoRA-HIGH_bf16.safetensors",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "LoRAs/Wan22_FFGO/Wan22_FFGO-LoRA-LOW_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22_FFGO/Wan22_FFGO-LoRA-LOW_bf16.safetensors",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "LoRAs/Wan22_FunReward/Wan2.2-Fun-A14B-InP-HIGH-HPS2.1_resized_dynamic_avg_rank_14_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22_FunReward/Wan2.2-Fun-A14B-InP-HIGH-HPS2.1_resized_dynamic_avg_rank_14_bf16.safetensors",
        "file_size": "93.3 MB"
      },
      {
        "model_id": "LoRAs/Wan22_FunReward/Wan2.2-Fun-A14B-InP-HIGH-MPS_resized_dynamic_avg_rank_21_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22_FunReward/Wan2.2-Fun-A14B-InP-HIGH-MPS_resized_dynamic_avg_rank_21_bf16.safetensors",
        "file_size": "134.4 MB"
      },
      {
        "model_id": "LoRAs/Wan22_FunReward/Wan2.2-Fun-A14B-InP-LOW-HPS2.1_resized_dynamic_avg_rank_15_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22_FunReward/Wan2.2-Fun-A14B-InP-LOW-HPS2.1_resized_dynamic_avg_rank_15_bf16.safetensors",
        "file_size": "97.0 MB"
      },
      {
        "model_id": "LoRAs/Wan22_FunReward/Wan2.2-Fun-A14B-InP-LOW-MPS_resized_dynamic_avg_rank_22_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22_FunReward/Wan2.2-Fun-A14B-InP-LOW-MPS_resized_dynamic_avg_rank_22_bf16.safetensors",
        "file_size": "143.4 MB"
      },
      {
        "model_id": "LoRAs/Wan22_Lightx2v/Wan_2_2_I2V_A14B_HIGH_lightx2v_4step_lora_v1030_rank_64_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22_Lightx2v/Wan_2_2_I2V_A14B_HIGH_lightx2v_4step_lora_v1030_rank_64_bf16.safetensors",
        "file_size": "601.5 MB"
      },
      {
        "model_id": "LoRAs/Wan22_Lightx2v/Wan_2_2_I2V_A14B_HIGH_lightx2v_MoE_distill_lora_rank_64_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22_Lightx2v/Wan_2_2_I2V_A14B_HIGH_lightx2v_MoE_distill_lora_rank_64_bf16.safetensors",
        "file_size": "601.5 MB"
      },
      {
        "model_id": "LoRAs/Wan22_relight/WanAnimate_relight_lora_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22_relight/WanAnimate_relight_lora_fp16.safetensors",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "LoRAs/Wan22_relight/WanAnimate_relight_lora_fp16_resized_from_128_to_dynamic_22",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan22_relight/WanAnimate_relight_lora_fp16_resized_from_128_to_dynamic_22.safetensors",
        "file_size": "260.2 MB"
      },
      {
        "model_id": "LoRAs/Wan2_1_self_forcing_1_3B/Wan2_1_self_forcing_dmd_1_3B_lora_rank_32_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan2_1_self_forcing_1_3B/Wan2_1_self_forcing_dmd_1_3B_lora_rank_32_fp16.safetensors",
        "file_size": "87.0 MB"
      },
      {
        "model_id": "LoRAs/Wan2_1_self_forcing_1_3B/Wan2_1_self_forcing_sid_v2_1_3B_lora_rank_32_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/Wan2_1_self_forcing_1_3B/Wan2_1_self_forcing_sid_v2_1_3B_lora_rank_32_fp16.safetensors",
        "file_size": "87.0 MB"
      },
      {
        "model_id": "LoRAs/WanAlpha/Wan_Alpha_v2.0_DoRA_2.0_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/WanAlpha/Wan_Alpha_v2.0_DoRA_2.0_bf16.safetensors",
        "file_size": "297.2 MB"
      },
      {
        "model_id": "LoRAs/rCM/Wan22-I2V-A14B-HIGH-rCM6_0_lora_rank_64_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/rCM/Wan22-I2V-A14B-HIGH-rCM6_0_lora_rank_64_bf16.safetensors",
        "file_size": "601.5 MB"
      },
      {
        "model_id": "LoRAs/rCM/Wan22-I2V-A14B-LOW-rCM1_0_lora_rank_64_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/rCM/Wan22-I2V-A14B-LOW-rCM1_0_lora_rank_64_bf16.safetensors",
        "file_size": "601.5 MB"
      },
      {
        "model_id": "LoRAs/rCM/Wan_2_1_T2V_14B_480p_rCM_lora_average_rank_148_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/rCM/Wan_2_1_T2V_14B_480p_rCM_lora_average_rank_148_bf16.safetensors",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "LoRAs/rCM/Wan_2_1_T2V_14B_480p_rCM_lora_average_rank_83_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/rCM/Wan_2_1_T2V_14B_480p_rCM_lora_average_rank_83_bf16.safetensors",
        "file_size": "761.5 MB"
      },
      {
        "model_id": "LoRAs/rCM/Wan_2_1_T2V_14B_720p_rCM_lora_average_rank_94_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/rCM/Wan_2_1_T2V_14B_720p_rCM_lora_average_rank_94_bf16.safetensors",
        "file_size": "853.5 MB"
      },
      {
        "model_id": "LoRAs/rCM/Wan_2_1_T2V_1_3B_480p_rCM_lora_average_rank_64_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LoRAs/rCM/Wan_2_1_T2V_1_3B_480p_rCM_lora_average_rank_64_bf16.safetensors",
        "file_size": "178.3 MB"
      },
      {
        "model_id": "LongVie2/LongVie2_attn_layers_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LongVie2/LongVie2_attn_layers_bf16.safetensors",
        "file_size": "7.8 GB"
      },
      {
        "model_id": "LongVie2/LongVie2_dual_controller_controlnet_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LongVie2/LongVie2_dual_controller_controlnet_bf16.safetensors",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "LongVie2/longvie2_attn_layers_lora_rank_64_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/LongVie2/longvie2_attn_layers_lora_rank_64_bf16.safetensors",
        "file_size": "703.8 MB"
      },
      {
        "model_id": "Lynx/Wan2_1-T2V-14B-Lynx_full_ip_layers_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lynx/Wan2_1-T2V-14B-Lynx_full_ip_layers_fp16.safetensors",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Lynx/Wan2_1-T2V-14B-Lynx_full_ref_layers_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lynx/Wan2_1-T2V-14B-Lynx_full_ref_layers_fp16.safetensors",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Lynx/Wan2_1-T2V-14B-Lynx_lite_ip_layers_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lynx/Wan2_1-T2V-14B-Lynx_lite_ip_layers_fp16.safetensors",
        "file_size": "800.0 MB"
      },
      {
        "model_id": "Lynx/lynx_full_resampler_fp32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lynx/lynx_full_resampler_fp32.safetensors",
        "file_size": "327.8 MB"
      },
      {
        "model_id": "Lynx/lynx_lite_resampler_fp32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Lynx/lynx_lite_resampler_fp32.safetensors",
        "file_size": "312.7 MB"
      },
      {
        "model_id": "MTVCrafter/Wan2_1_MTV-Crafter_motion_adapter_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/MTVCrafter/Wan2_1_MTV-Crafter_motion_adapter_bf16.safetensors",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "MTVCrafter/WanVideo_MTV_Crafter_4DMoT_VQVAE_fp32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/MTVCrafter/WanVideo_MTV_Crafter_4DMoT_VQVAE_fp32.safetensors",
        "file_size": "280.4 MB"
      },
      {
        "model_id": "OneToAllAnimation/Wan21-OneToAllAnimation_1_3B_v2_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/OneToAllAnimation/Wan21-OneToAllAnimation_1_3B_v2_fp16.safetensors",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "OneToAllAnimation/Wan21-OneToAllAnimation_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/OneToAllAnimation/Wan21-OneToAllAnimation_fp16.safetensors",
        "file_size": "35.0 GB"
      },
      {
        "model_id": "Ovi/Wan_2_2_Ovi_audio_model_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Ovi/Wan_2_2_Ovi_audio_model_bf16.safetensors",
        "file_size": "11.4 GB"
      },
      {
        "model_id": "Ovi/Wan_2_2_Ovi_video_model_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Ovi/Wan_2_2_Ovi_video_model_bf16.safetensors",
        "file_size": "10.4 GB"
      },
      {
        "model_id": "Ovi/mmaudio_vae_16k_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Ovi/mmaudio_vae_16k_bf16.safetensors",
        "file_size": "327.4 MB"
      },
      {
        "model_id": "Ovi/mmaudio_vae_16k_fp32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Ovi/mmaudio_vae_16k_fp32.safetensors",
        "file_size": "654.8 MB"
      },
      {
        "model_id": "Ovi/mmaudio_vocoder_bigvgan_best_netG_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Ovi/mmaudio_vocoder_bigvgan_best_netG_bf16.safetensors",
        "file_size": "214.1 MB"
      },
      {
        "model_id": "Ovi/mmaudio_vocoder_bigvgan_best_netG_fp32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Ovi/mmaudio_vocoder_bigvgan_best_netG_fp32.safetensors",
        "file_size": "428.2 MB"
      },
      {
        "model_id": "Phantom-Wan-14B_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Phantom-Wan-14B_fp16.safetensors",
        "file_size": "27.1 GB"
      },
      {
        "model_id": "Phantom-Wan-14B_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Phantom-Wan-14B_fp8_e4m3fn.safetensors",
        "file_size": "14.0 GB"
      },
      {
        "model_id": "Phantom-Wan-1_3B_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Phantom-Wan-1_3B_fp16.safetensors",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Phantom-Wan-1_3B_fp32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Phantom-Wan-1_3B_fp32.safetensors",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Pusa/Wan21_PusaV1_LoRA_14B_rank512_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Pusa/Wan21_PusaV1_LoRA_14B_rank512_bf16.safetensors",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Pusa/Wan22_PusaV1_lora_HIGH_resized_dynamic_avg_rank_98_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Pusa/Wan22_PusaV1_lora_HIGH_resized_dynamic_avg_rank_98_bf16.safetensors",
        "file_size": "911.8 MB"
      },
      {
        "model_id": "Pusa/Wan22_PusaV1_lora_LOW_resized_dynamic_avg_rank_98_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Pusa/Wan22_PusaV1_lora_LOW_resized_dynamic_avg_rank_98_bf16.safetensors",
        "file_size": "923.4 MB"
      },
      {
        "model_id": "Qwen/Qwen2.5_3B_instruct_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Qwen/Qwen2.5_3B_instruct_bf16.safetensors",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Qwen/Qwen2.5_7B_instruct_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Qwen/Qwen2.5_7B_instruct_bf16.safetensors",
        "file_size": "14.2 GB"
      },
      {
        "model_id": "SCAIL/Wan21-14B-SCAIL-preview_comfy_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/SCAIL/Wan21-14B-SCAIL-preview_comfy_bf16.safetensors",
        "file_size": "30.5 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-DF-14B-540P_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-DF-14B-540P_fp16.safetensors",
        "file_size": "27.1 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-DF-14B-540P_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-DF-14B-540P_fp8_e4m3fn.safetensors",
        "file_size": "14.0 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-DF-14B-720P_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-DF-14B-720P_fp16.safetensors",
        "file_size": "27.1 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-DF-14B-720P_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-DF-14B-720P_fp8_e4m3fn.safetensors",
        "file_size": "14.0 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-DF-14B-720P_fp8_e5m2",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-DF-14B-720P_fp8_e5m2.safetensors",
        "file_size": "14.0 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-DF-1_3B-540P_fp32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-DF-1_3B-540P_fp32.safetensors",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-I2V-14B-540P_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-I2V-14B-540P_fp16.safetensors",
        "file_size": "31.0 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-I2V-14B-540P_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-I2V-14B-540P_fp8_e4m3fn.safetensors",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-I2V-14B-540P_fp8_e5m2",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-I2V-14B-540P_fp8_e5m2.safetensors",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-I2V-14B-720P_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-I2V-14B-720P_fp16.safetensors",
        "file_size": "31.0 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-I2V-14B-720P_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-I2V-14B-720P_fp8_e4m3fn.safetensors",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-I2V-14B-720P_fp8_e5m2",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-I2V-14B-720P_fp8_e5m2.safetensors",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-T2V-14B-540P_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-T2V-14B-540P_fp16.safetensors",
        "file_size": "27.1 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-T2V-14B-540P_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-T2V-14B-540P_fp8_e4m3fn.safetensors",
        "file_size": "14.0 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-T2V-14B-720P_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-T2V-14B-720P_fp16.safetensors",
        "file_size": "27.1 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-T2V-14B-720P_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-T2V-14B-720P_fp8_e4m3fn.safetensors",
        "file_size": "14.0 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1-SkyReels-V2-T2V-14B-720P_fp8_e5m2",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1-SkyReels-V2-T2V-14B-720P_fp8_e5m2.safetensors",
        "file_size": "14.0 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1_Skyreels-v2-I2V-720P_LoRA_rank_64_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1_Skyreels-v2-I2V-720P_LoRA_rank_64_fp16.safetensors",
        "file_size": "703.8 MB"
      },
      {
        "model_id": "Skyreels/Wan2_1_Skyreels-v2-I2V-720P_LoRA_rank_adaptive_quantile_0.20_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1_Skyreels-v2-I2V-720P_LoRA_rank_adaptive_quantile_0.20_fp16.safetensors",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Skyreels/Wan2_1_Skyreels-v2-T2V-720P_LoRA_rank_64_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1_Skyreels-v2-T2V-720P_LoRA_rank_64_fp16.safetensors",
        "file_size": "601.5 MB"
      },
      {
        "model_id": "Skyreels/Wan2_1_SkyreelsA2_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Skyreels/Wan2_1_SkyreelsA2_fp8_e4m3fn.safetensors",
        "file_size": "15.5 GB"
      },
      {
        "model_id": "SteadyDancer/Wan21_I2V_SteadyDancer_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/SteadyDancer/Wan21_I2V_SteadyDancer_fp16.safetensors",
        "file_size": "30.5 GB"
      },
      {
        "model_id": "UniAnimate-Wan2.1-14B-Lora-12000-fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/UniAnimate-Wan2.1-14B-Lora-12000-fp16.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "UniLumos/Wan2_1_UniLumos_1_3B_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/UniLumos/Wan2_1_UniLumos_1_3B_bf16.safetensors",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Video-as-prompt/Wan2_1-I2V-14B-VAP_module_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Video-as-prompt/Wan2_1-I2V-14B-VAP_module_bf16.safetensors",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "Wan21_AccVid_I2V_480P_14B_lora_rank32_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_AccVid_I2V_480P_14B_lora_rank32_fp16.safetensors",
        "file_size": "307.7 MB"
      },
      {
        "model_id": "Wan21_AccVid_T2V_14B_lora_rank32_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_AccVid_T2V_14B_lora_rank32_fp16.safetensors",
        "file_size": "302.1 MB"
      },
      {
        "model_id": "Wan21_CausVid_14B_T2V_lora_rank32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_CausVid_14B_T2V_lora_rank32.safetensors",
        "file_size": "304.3 MB"
      },
      {
        "model_id": "Wan21_CausVid_14B_T2V_lora_rank32_v1_5_no_first_block",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_CausVid_14B_T2V_lora_rank32_v1_5_no_first_block.safetensors",
        "file_size": "296.8 MB"
      },
      {
        "model_id": "Wan21_CausVid_14B_T2V_lora_rank32_v2",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_CausVid_14B_T2V_lora_rank32_v2.safetensors",
        "file_size": "195.1 MB"
      },
      {
        "model_id": "Wan21_CausVid_bidirect2_T2V_1_3B_lora_rank32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_CausVid_bidirect2_T2V_1_3B_lora_rank32.safetensors",
        "file_size": "87.0 MB"
      },
      {
        "model_id": "Wan21_T2V_14B_MoviiGen_lora_rank32_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_T2V_14B_MoviiGen_lora_rank32_fp16.safetensors",
        "file_size": "302.1 MB"
      },
      {
        "model_id": "Wan21_T2V_14B_lightx2v_cfg_step_distill_lora_rank32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_T2V_14B_lightx2v_cfg_step_distill_lora_rank32.safetensors",
        "file_size": "302.1 MB"
      },
      {
        "model_id": "Wan21_Uni3C_controlnet_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_Uni3C_controlnet_fp16.safetensors",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Wan22-Turbo/Wan2_2-TI2V-5B-Turbo_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan22-Turbo/Wan2_2-TI2V-5B-Turbo_fp16.safetensors",
        "file_size": "9.5 GB"
      },
      {
        "model_id": "Wan2_1-AccVideo-T2V-14B_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-AccVideo-T2V-14B_fp8_e4m3fn.safetensors",
        "file_size": "14.0 GB"
      },
      {
        "model_id": "Wan2_1-Anisora-I2V-480P-14B_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-Anisora-I2V-480P-14B_fp16.safetensors",
        "file_size": "31.0 GB"
      },
      {
        "model_id": "Wan2_1-Anisora-I2V-480P-14B_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-Anisora-I2V-480P-14B_fp8_e4m3fn.safetensors",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "Wan2_1-FLF2V-14B-720P_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-FLF2V-14B-720P_fp16.safetensors",
        "file_size": "31.0 GB"
      },
      {
        "model_id": "Wan2_1-FLF2V-14B-720P_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-FLF2V-14B-720P_fp8_e4m3fn.safetensors",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "Wan2_1-I2V-14B-480P_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors",
        "file_size": "15.8 GB"
      },
      {
        "model_id": "Wan2_1-I2V-14B-480P_fp8_e5m2",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-I2V-14B-480P_fp8_e5m2.safetensors",
        "file_size": "15.8 GB"
      },
      {
        "model_id": "Wan2_1-I2V-14B-720P_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-I2V-14B-720P_fp8_e4m3fn.safetensors",
        "file_size": "15.8 GB"
      },
      {
        "model_id": "Wan2_1-I2V-14B-720P_fp8_e5m2",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-I2V-14B-720P_fp8_e5m2.safetensors",
        "file_size": "15.8 GB"
      },
      {
        "model_id": "Wan2_1-I2V-ATI-14B_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-I2V-ATI-14B_fp16.safetensors",
        "file_size": "31.0 GB"
      },
      {
        "model_id": "Wan2_1-I2V-ATI-14B_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-I2V-ATI-14B_fp8_e4m3fn.safetensors",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "Wan2_1-I2V-ATI-14B_fp8_e5m2",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-I2V-ATI-14B_fp8_e5m2.safetensors",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "Wan2_1-MiniMaxRemover_1_3B_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-MiniMaxRemover_1_3B_fp16.safetensors",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Wan2_1-MoviiGen1_1_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-MoviiGen1_1_fp16.safetensors",
        "file_size": "27.1 GB"
      },
      {
        "model_id": "Wan2_1-MoviiGen1_1_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-MoviiGen1_1_fp8_e4m3fn.safetensors",
        "file_size": "14.0 GB"
      },
      {
        "model_id": "Wan2_1-T2V-14B_CausVid_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-14B_CausVid_fp8_e4m3fn.safetensors",
        "file_size": "13.5 GB"
      },
      {
        "model_id": "Wan2_1-T2V-14B_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-14B_fp8_e4m3fn.safetensors",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "Wan2_1-T2V-14B_fp8_e5m2",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-14B_fp8_e5m2.safetensors",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "Wan2_1-T2V-1_3B_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-1_3B_bf16.safetensors",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Wan2_1-T2V-1_3B_fp32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-1_3B_fp32.safetensors",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Wan2_1-T2V-1_3B_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "Wan2_1-T2V_FastWan_1_3B_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V_FastWan_1_3B_bf16.safetensors",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Wan2_1-VACE_module_14B_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-VACE_module_14B_bf16.safetensors",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Wan2_1-VACE_module_14B_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-VACE_module_14B_fp8_e4m3fn.safetensors",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Wan2_1-VACE_module_1_3B_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-VACE_module_1_3B_bf16.safetensors",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "Wan2_1-Wan-I2V-MAGREF-14B_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-Wan-I2V-MAGREF-14B_fp8_e4m3fn.safetensors",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "Wan2_1_VACE_1_3B_preview_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1_VACE_1_3B_preview_bf16.safetensors",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "Wan2_1_VAE_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1_VAE_bf16.safetensors",
        "file_size": "242.0 MB"
      },
      {
        "model_id": "Wan2_1_VAE_fp32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1_VAE_fp32.safetensors",
        "file_size": "484.1 MB"
      },
      {
        "model_id": "Wan2_1_kwai_recammaster_1_3B_step20000_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1_kwai_recammaster_1_3B_step20000_bf16.safetensors",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Wan2_2-I2V-A14B-HIGH_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_2-I2V-A14B-HIGH_bf16.safetensors",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "Wan2_2-I2V-A14B-LOW_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_2-I2V-A14B-LOW_bf16.safetensors",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "Wan2_2_VAE_bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_2_VAE_bf16.safetensors",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "WanMove/Wan21-WanMove_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/WanMove/Wan21-WanMove_fp16.safetensors",
        "file_size": "30.5 GB"
      },
      {
        "model_id": "WanVideo_2_1_Multitalk_14B_fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/WanVideo_2_1_Multitalk_14B_fp8_e4m3fn.safetensors",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "fantasytalking_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/fantasytalking_fp16.safetensors",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "open-clip-xlm-roberta-large-vit-huge-14_visual_fp16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/open-clip-xlm-roberta-large-vit-huge-14_visual_fp16.safetensors",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "open-clip-xlm-roberta-large-vit-huge-14_visual_fp32",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/open-clip-xlm-roberta-large-vit-huge-14_visual_fp32.safetensors",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "taew2_1",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/taew2_1.safetensors",
        "file_size": "21.6 MB"
      },
      {
        "model_id": "taew2_2",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/taew2_2.safetensors",
        "file_size": "21.8 MB"
      },
      {
        "model_id": "umt5-xxl-enc-bf16",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/umt5-xxl-enc-bf16.safetensors",
        "file_size": "10.6 GB"
      },
      {
        "model_id": "umt5-xxl-enc-fp8_e4m3fn",
        "path": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/umt5-xxl-enc-fp8_e4m3fn.safetensors",
        "file_size": "6.3 GB"
      }
    ],
    "config": null,
    "readme": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/README.md",
    "description": "Combined and quantized WanVideo models for ComfyUI with various model sources and LoRA variants."
  },
  {
    "model_name": "Qwen2.5-1.5B-Instruct",
    "developer": "Qwen",
    "downloads": 6931087,
    "createdAt": "2024-09-17T14:10:29.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct/resolve/main/model.safetensors",
        "file_size": "2.9 GB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct/resolve/main/README.md",
    "description": "Qwen2.5-1.5B-Instruct is Alibaba Cloud's 1.5B parameter instruction-tuned causal language model with improved coding, math, and long-context capabilities."
  },
  {
    "model_name": "distilbert-base-uncased",
    "developer": "distilbert",
    "downloads": 6227759,
    "createdAt": "2022-03-02T23:29:04.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/distilbert/distilbert-base-uncased/resolve/main/model.safetensors",
        "file_size": "255.5 MB"
      }
    ],
    "config": "https://huggingface.co/distilbert/distilbert-base-uncased/resolve/main/config.json",
    "readme": "https://huggingface.co/distilbert/distilbert-base-uncased/resolve/main/README.md",
    "description": "A smaller, faster distilled version of BERT base, pretrained on BookCorpus and Wikipedia for masked language modeling and fine-tuning on downstream NLP tasks."
  },
  {
    "model_name": "whisper-large-v3",
    "developer": "openai",
    "downloads": 6128745,
    "createdAt": "2023-11-07T18:41:14.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 3,
    "safetensors_files": [
      {
        "model_id": "model.fp32-00001-of-00002",
        "path": "https://huggingface.co/openai/whisper-large-v3/resolve/main/model.fp32-00001-of-00002.safetensors",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "model.fp32-00002-of-00002",
        "path": "https://huggingface.co/openai/whisper-large-v3/resolve/main/model.fp32-00002-of-00002.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "model",
        "path": "https://huggingface.co/openai/whisper-large-v3/resolve/main/model.safetensors",
        "file_size": "2.9 GB"
      }
    ],
    "config": "https://huggingface.co/openai/whisper-large-v3/resolve/main/config.json",
    "readme": "https://huggingface.co/openai/whisper-large-v3/resolve/main/README.md",
    "description": "OpenAI's Whisper large-v3 is a state-of-the-art multilingual speech recognition and translation model trained on 5M+ hours of audio."
  },
  {
    "model_name": "Wan_2.2_ComfyUI_Repackaged",
    "developer": "Comfy-Org",
    "downloads": 6093665,
    "createdAt": "2025-07-27T06:56:12.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 42,
    "safetensors_files": [
      {
        "model_id": "split_files/audio_encoders/wav2vec2_large_english_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/audio_encoders/wav2vec2_large_english_fp16.safetensors",
        "file_size": "601.8 MB"
      },
      {
        "model_id": "split_files/diffusion_models/chrono_edit_14B_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/chrono_edit_14B_fp16.safetensors",
        "file_size": "30.5 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_animate_14B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_animate_14B_bf16.safetensors",
        "file_size": "32.2 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_camera_high_noise_14B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_camera_high_noise_14B_bf16.safetensors",
        "file_size": "27.6 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_camera_high_noise_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_camera_high_noise_14B_fp8_scaled.safetensors",
        "file_size": "14.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_camera_low_noise_14B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_camera_low_noise_14B_bf16.safetensors",
        "file_size": "27.6 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_camera_low_noise_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_camera_low_noise_14B_fp8_scaled.safetensors",
        "file_size": "14.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_control_5B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_control_5B_bf16.safetensors",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_control_high_noise_14B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_control_high_noise_14B_bf16.safetensors",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_control_high_noise_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_control_high_noise_14B_fp8_scaled.safetensors",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_control_low_noise_14B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_control_low_noise_14B_bf16.safetensors",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_control_low_noise_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_control_low_noise_14B_fp8_scaled.safetensors",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_inpaint_5B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_inpaint_5B_bf16.safetensors",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_inpaint_high_noise_14B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_inpaint_high_noise_14B_bf16.safetensors",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_inpaint_high_noise_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_inpaint_high_noise_14B_fp8_scaled.safetensors",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_inpaint_low_noise_14B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_inpaint_low_noise_14B_bf16.safetensors",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_inpaint_low_noise_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_inpaint_low_noise_14B_fp8_scaled.safetensors",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_vace_high_noise_14B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_vace_high_noise_14B_bf16.safetensors",
        "file_size": "32.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_vace_high_noise_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_vace_high_noise_14B_fp8_scaled.safetensors",
        "file_size": "16.2 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_vace_low_noise_14B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_vace_low_noise_14B_bf16.safetensors",
        "file_size": "32.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_fun_vace_low_noise_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_vace_low_noise_14B_fp8_scaled.safetensors",
        "file_size": "16.2 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_i2v_high_noise_14B_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_high_noise_14B_fp16.safetensors",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_i2v_high_noise_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_i2v_low_noise_14B_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_low_noise_14B_fp16.safetensors",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_i2v_low_noise_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_s2v_14B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_s2v_14B_bf16.safetensors",
        "file_size": "30.4 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_s2v_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_s2v_14B_fp8_scaled.safetensors",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_t2v_high_noise_14B_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_t2v_high_noise_14B_fp16.safetensors",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_t2v_high_noise_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_t2v_high_noise_14B_fp8_scaled.safetensors",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_t2v_low_noise_14B_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_t2v_low_noise_14B_fp16.safetensors",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_t2v_low_noise_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_t2v_low_noise_14B_fp8_scaled.safetensors",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.2_ti2v_5B_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_ti2v_5B_fp16.safetensors",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "split_files/loras/chronoedit_distill_lora",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/chronoedit_distill_lora.safetensors",
        "file_size": "358.5 MB"
      },
      {
        "model_id": "split_files/loras/wan2.2_animate_14B_relight_lora_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_animate_14B_relight_lora_bf16.safetensors",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "split_files/loras/wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "split_files/loras/wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "split_files/loras/wan2.2_t2v_lightx2v_4steps_lora_v1.1_high_noise",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_t2v_lightx2v_4steps_lora_v1.1_high_noise.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "split_files/loras/wan2.2_t2v_lightx2v_4steps_lora_v1.1_low_noise",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_t2v_lightx2v_4steps_lora_v1.1_low_noise.safetensors",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "split_files/text_encoders/umt5_xxl_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp16.safetensors",
        "file_size": "10.6 GB"
      },
      {
        "model_id": "split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "split_files/vae/wan2.2_vae",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/vae/wan2.2_vae.safetensors",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "split_files/vae/wan_2.1_vae",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors",
        "file_size": "242.1 MB"
      }
    ],
    "config": null,
    "readme": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/README.md",
    "description": "A ComfyUI-compatible diffusion model with examples available online."
  },
  {
    "model_name": "TabSTAR",
    "developer": "alana89",
    "downloads": 6088135,
    "createdAt": "2025-05-20T10:51:06.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/alana89/TabSTAR/resolve/main/model.safetensors",
        "file_size": "180.3 MB"
      }
    ],
    "config": "https://huggingface.co/alana89/TabSTAR/resolve/main/config.json",
    "readme": "https://huggingface.co/alana89/TabSTAR/resolve/main/README.md",
    "description": "TabSTAR is a foundation model for tabular classification using target-aware text representations to achieve state-of-the-art performance."
  },
  {
    "model_name": "paraphrase-multilingual-mpnet-base-v2",
    "developer": "sentence-transformers",
    "downloads": 5805988,
    "createdAt": "2022-03-02T23:29:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2/resolve/main/model.safetensors",
        "file_size": "1.0 GB"
      }
    ],
    "config": "https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2/resolve/main/config.json",
    "readme": "https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2/resolve/main/README.md",
    "description": "Multilingual sentence embedding model for semantic search and clustering."
  },
  {
    "model_name": "gpt-oss-20b",
    "developer": "openai",
    "downloads": 5758227,
    "createdAt": "2025-08-04T22:33:29.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 4,
    "safetensors_files": [
      {
        "model_id": "model-00000-of-00002",
        "path": "https://huggingface.co/openai/gpt-oss-20b/resolve/main/model-00000-of-00002.safetensors",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "model-00001-of-00002",
        "path": "https://huggingface.co/openai/gpt-oss-20b/resolve/main/model-00001-of-00002.safetensors",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "model-00002-of-00002",
        "path": "https://huggingface.co/openai/gpt-oss-20b/resolve/main/model-00002-of-00002.safetensors",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "original/model",
        "path": "https://huggingface.co/openai/gpt-oss-20b/resolve/main/original/model.safetensors",
        "file_size": "12.8 GB"
      }
    ],
    "config": "https://huggingface.co/openai/gpt-oss-20b/resolve/main/config.json",
    "readme": "https://huggingface.co/openai/gpt-oss-20b/resolve/main/README.md",
    "description": "OpenAI's open-weight 21B parameter reasoning model (3.6B active) with MXFP4 quantization, Apache 2.0 license, and configurable reasoning effort for agentic tasks."
  },
  {
    "model_name": "Llama-3.1-8B-Instruct",
    "developer": "meta-llama",
    "downloads": 5592869,
    "createdAt": "2024-07-18T08:56:00.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 4,
    "safetensors_files": [
      {
        "model_id": "model-00001-of-00004",
        "path": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/model-00001-of-00004.safetensors",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "model-00002-of-00004",
        "path": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/model-00002-of-00004.safetensors",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "model-00003-of-00004",
        "path": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/model-00003-of-00004.safetensors",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "model-00004-of-00004",
        "path": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/model-00004-of-00004.safetensors",
        "file_size": "1.1 GB"
      }
    ],
    "config": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json",
    "readme": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/README.md",
    "description": "Meta's 8B parameter multilingual instruction-tuned language model for text generation, supporting 8 languages with 128k context, licensed for commercial use under Llama 3.1 Community License."
  },
  {
    "model_name": "xlm-roberta-large",
    "developer": "FacebookAI",
    "downloads": 5504195,
    "createdAt": "2022-03-02T23:29:04.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/FacebookAI/xlm-roberta-large/resolve/main/model.safetensors",
        "file_size": "2.1 GB"
      }
    ],
    "config": "https://huggingface.co/FacebookAI/xlm-roberta-large/resolve/main/config.json",
    "readme": "https://huggingface.co/FacebookAI/xlm-roberta-large/resolve/main/README.md",
    "description": "Multilingual transformer model pretrained on 2.5TB of CommonCrawl data across 100 languages using masked language modeling."
  },
  {
    "model_name": "Qwen3-4B",
    "developer": "Qwen",
    "downloads": 5263982,
    "createdAt": "2025-04-27T03:41:29.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 3,
    "safetensors_files": [
      {
        "model_id": "model-00001-of-00003",
        "path": "https://huggingface.co/Qwen/Qwen3-4B/resolve/main/model-00001-of-00003.safetensors",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "model-00002-of-00003",
        "path": "https://huggingface.co/Qwen/Qwen3-4B/resolve/main/model-00002-of-00003.safetensors",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "model-00003-of-00003",
        "path": "https://huggingface.co/Qwen/Qwen3-4B/resolve/main/model-00003-of-00003.safetensors",
        "file_size": "95.0 MB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen3-4B/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen3-4B/resolve/main/README.md",
    "description": "Qwen3-4B is a 4B-parameter causal language model with unique seamless switching between thinking and non-thinking modes for complex reasoning or efficient dialogue."
  },
  {
    "model_name": "jina-embeddings-v3",
    "developer": "jinaai",
    "downloads": 5241957,
    "createdAt": "2024-09-05T11:56:46.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/jinaai/jina-embeddings-v3/resolve/main/model.safetensors",
        "file_size": "1.1 GB"
      }
    ],
    "config": "https://huggingface.co/jinaai/jina-embeddings-v3/resolve/main/config.json",
    "readme": "https://huggingface.co/jinaai/jina-embeddings-v3/resolve/main/README.md",
    "description": ""
  },
  {
    "model_name": "resnet50.a1_in1k",
    "developer": "timm",
    "downloads": 4776542,
    "createdAt": "2023-04-05T18:07:45.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/timm/resnet50.a1_in1k/resolve/main/model.safetensors",
        "file_size": "97.7 MB"
      }
    ],
    "config": "https://huggingface.co/timm/resnet50.a1_in1k/resolve/main/config.json",
    "readme": "https://huggingface.co/timm/resnet50.a1_in1k/resolve/main/README.md",
    "description": "ResNet-50 image classifier trained on ImageNet-1k using the A1 training recipe with LAMB optimizer and cosine LR schedule."
  },
  {
    "model_name": "chronos-bolt-base",
    "developer": "autogluon",
    "downloads": 4751856,
    "createdAt": "2024-11-13T13:07:57.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/autogluon/chronos-bolt-base/resolve/main/model.safetensors",
        "file_size": "783.2 MB"
      }
    ],
    "config": "https://huggingface.co/autogluon/chronos-bolt-base/resolve/main/config.json",
    "readme": "https://huggingface.co/autogluon/chronos-bolt-base/resolve/main/README.md",
    "description": "Chronos-Bolt is a family of pretrained time series forecasting models based on T5 architecture, offering zero-shot forecasting that's up to 250x faster and 20x more memory-efficient than the original Chronos models."
  },
  {
    "model_name": "bge-small-en-v1.5",
    "developer": "BAAI",
    "downloads": 4656201,
    "createdAt": "2023-09-12T05:20:55.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/BAAI/bge-small-en-v1.5/resolve/main/model.safetensors",
        "file_size": "127.3 MB"
      }
    ],
    "config": "https://huggingface.co/BAAI/bge-small-en-v1.5/resolve/main/config.json",
    "readme": "https://huggingface.co/BAAI/bge-small-en-v1.5/resolve/main/README.md",
    "description": "A sentence embedding model for semantic similarity and retrieval tasks, part of BAAI's FlagEmbedding project."
  },
  {
    "model_name": "Qwen3-8B",
    "developer": "Qwen",
    "downloads": 4592406,
    "createdAt": "2025-04-27T03:42:21.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 5,
    "safetensors_files": [
      {
        "model_id": "model-00001-of-00005",
        "path": "https://huggingface.co/Qwen/Qwen3-8B/resolve/main/model-00001-of-00005.safetensors",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "model-00002-of-00005",
        "path": "https://huggingface.co/Qwen/Qwen3-8B/resolve/main/model-00002-of-00005.safetensors",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "model-00003-of-00005",
        "path": "https://huggingface.co/Qwen/Qwen3-8B/resolve/main/model-00003-of-00005.safetensors",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "model-00004-of-00005",
        "path": "https://huggingface.co/Qwen/Qwen3-8B/resolve/main/model-00004-of-00005.safetensors",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "model-00005-of-00005",
        "path": "https://huggingface.co/Qwen/Qwen3-8B/resolve/main/model-00005-of-00005.safetensors",
        "file_size": "1.2 GB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen3-8B/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen3-8B/resolve/main/README.md",
    "description": "Qwen3-8B is an 8.2B parameter causal language model with unique seamless switching between thinking mode (for complex reasoning) and non-thinking mode (for efficient dialogue)."
  },
  {
    "model_name": "bge-large-en-v1.5",
    "developer": "BAAI",
    "downloads": 4588472,
    "createdAt": "2023-09-12T05:20:08.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/model.safetensors",
        "file_size": "1.2 GB"
      }
    ],
    "config": "https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/config.json",
    "readme": "https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/README.md",
    "description": "English sentence embedding model achieving state-of-the-art performance on MTEB benchmark for retrieval, classification, clustering, and semantic similarity tasks."
  },
  {
    "model_name": "vitpose-plus-base",
    "developer": "usyd-community",
    "downloads": 4533640,
    "createdAt": "2025-01-08T12:42:22.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/usyd-community/vitpose-plus-base/resolve/main/model.safetensors",
        "file_size": "478.4 MB"
      }
    ],
    "config": "https://huggingface.co/usyd-community/vitpose-plus-base/resolve/main/config.json",
    "readme": "https://huggingface.co/usyd-community/vitpose-plus-base/resolve/main/README.md",
    "description": "VitPose is a Vision Transformer model for human pose estimation achieving 81.1 AP on MS COCO Keypoint test-dev set."
  },
  {
    "model_name": "multi-qa-mpnet-base-dot-v1",
    "developer": "sentence-transformers",
    "downloads": 4478422,
    "createdAt": "2022-03-02T23:29:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/sentence-transformers/multi-qa-mpnet-base-dot-v1/resolve/main/model.safetensors",
        "file_size": "417.7 MB"
      }
    ],
    "config": "https://huggingface.co/sentence-transformers/multi-qa-mpnet-base-dot-v1/resolve/main/config.json",
    "readme": "https://huggingface.co/sentence-transformers/multi-qa-mpnet-base-dot-v1/resolve/main/README.md",
    "description": "A sentence-transformers model for semantic search, mapping text to 768-dimensional vectors, trained on 215M question-answer pairs using CLS pooling for dot-product similarity."
  },
  {
    "model_name": "mobilenetv3_large_100.ra_in1k",
    "developer": "timm",
    "downloads": 4446301,
    "createdAt": "2022-12-16T05:38:07.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/timm/mobilenetv3_large_100.ra_in1k/resolve/main/model.safetensors",
        "file_size": "21.0 MB"
      }
    ],
    "config": "https://huggingface.co/timm/mobilenetv3_large_100.ra_in1k/resolve/main/config.json",
    "readme": "https://huggingface.co/timm/mobilenetv3_large_100.ra_in1k/resolve/main/README.md",
    "description": "A MobileNet-v3 image classification model with 5.5M parameters, trained on ImageNet-1k using RandAugment, from the timm library."
  },
  {
    "model_name": "bert-base-multilingual-uncased",
    "developer": "google-bert",
    "downloads": 4422729,
    "createdAt": "2022-03-02T23:29:04.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/google-bert/bert-base-multilingual-uncased/resolve/main/model.safetensors",
        "file_size": "641.1 MB"
      }
    ],
    "config": "https://huggingface.co/google-bert/bert-base-multilingual-uncased/resolve/main/config.json",
    "readme": "https://huggingface.co/google-bert/bert-base-multilingual-uncased/resolve/main/README.md",
    "description": "Multilingual BERT model pretrained on 102 languages using masked language modeling."
  },
  {
    "model_name": "Qwen2.5-32B-Instruct",
    "developer": "Qwen",
    "downloads": 4367157,
    "createdAt": "2024-09-17T04:17:55.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 17,
    "safetensors_files": [
      {
        "model_id": "model-00001-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00001-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00002-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00002-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00003-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00003-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00004-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00004-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00005-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00005-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00006-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00006-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00007-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00007-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00008-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00008-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00009-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00009-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00010-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00010-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00011-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00011-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00012-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00012-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00013-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00013-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00014-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00014-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00015-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00015-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00016-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00016-of-00017.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00017-of-00017",
        "path": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/model-00017-of-00017.safetensors",
        "file_size": "2.9 GB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct/resolve/main/README.md",
    "description": "Qwen2.5-32B-Instruct is Alibaba Cloud's 32B parameter instruction-tuned LLM with improved coding, math, long-context (128K), and multilingual capabilities."
  },
  {
    "model_name": "Qwen2.5-0.5B-Instruct",
    "developer": "Qwen",
    "downloads": 4257079,
    "createdAt": "2024-09-16T11:52:46.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct/resolve/main/model.safetensors",
        "file_size": "942.3 MB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct/resolve/main/README.md",
    "description": "Qwen2.5-0.5B-Instruct is a compact 0.5B parameter instruction-tuned language model by Alibaba Cloud with strong coding, math, and multilingual capabilities supporting up to 32K context."
  },
  {
    "model_name": "Wan_2.1_ComfyUI_repackaged",
    "developer": "Comfy-Org",
    "downloads": 4170421,
    "createdAt": "2025-02-25T21:27:12.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 33,
    "safetensors_files": [
      {
        "model_id": "split_files/clip_vision/clip_vision_h",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/clip_vision/clip_vision_h.safetensors",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_flf2v_720p_14B_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_flf2v_720p_14B_fp16.safetensors",
        "file_size": "30.5 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_flf2v_720p_14B_fp8_e4m3fn",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_flf2v_720p_14B_fp8_e4m3fn.safetensors",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_fun_camera_v1.1_1.3B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_fun_camera_v1.1_1.3B_bf16.safetensors",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_fun_camera_v1.1_14B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_fun_camera_v1.1_14B_bf16.safetensors",
        "file_size": "31.5 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_fun_control_1.3B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_fun_control_1.3B_bf16.safetensors",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_fun_inp_1.3B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_fun_inp_1.3B_bf16.safetensors",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_i2v_480p_14B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_480p_14B_bf16.safetensors",
        "file_size": "30.5 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_i2v_480p_14B_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_480p_14B_fp16.safetensors",
        "file_size": "30.5 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_i2v_480p_14B_fp8_e4m3fn",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_480p_14B_fp8_e4m3fn.safetensors",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_i2v_480p_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_480p_14B_fp8_scaled.safetensors",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_i2v_720p_14B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_720p_14B_bf16.safetensors",
        "file_size": "30.5 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_i2v_720p_14B_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_720p_14B_fp16.safetensors",
        "file_size": "30.5 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_i2v_720p_14B_fp8_e4m3fn",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_720p_14B_fp8_e4m3fn.safetensors",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_i2v_720p_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_720p_14B_fp8_scaled.safetensors",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_magref_14B_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_magref_14B_fp16.safetensors",
        "file_size": "30.5 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_t2v_1.3B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_t2v_1.3B_bf16.safetensors",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_t2v_1.3B_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_t2v_1.3B_fp16.safetensors",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_t2v_14B_bf16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_t2v_14B_bf16.safetensors",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_t2v_14B_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_t2v_14B_fp16.safetensors",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_t2v_14B_fp8_e4m3fn",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_t2v_14B_fp8_e4m3fn.safetensors",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_t2v_14B_fp8_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_t2v_14B_fp8_scaled.safetensors",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_vace_1.3B_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_vace_1.3B_fp16.safetensors",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_vace_1.3B_preview_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_vace_1.3B_preview_fp16.safetensors",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "split_files/diffusion_models/wan2.1_vace_14B_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_vace_14B_fp16.safetensors",
        "file_size": "32.3 GB"
      },
      {
        "model_id": "split_files/loras/wan_alpha_2.1_rgba_lora",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/loras/wan_alpha_2.1_rgba_lora.safetensors",
        "file_size": "297.2 MB"
      },
      {
        "model_id": "split_files/model_patches/wan2.1_infiniteTalk_multi_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/model_patches/wan2.1_infiniteTalk_multi_fp16.safetensors",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "split_files/model_patches/wan2.1_infiniteTalk_single_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/model_patches/wan2.1_infiniteTalk_single_fp16.safetensors",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "split_files/text_encoders/umt5_xxl_fp16",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp16.safetensors",
        "file_size": "10.6 GB"
      },
      {
        "model_id": "split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "split_files/vae/wan_2.1_vae",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors",
        "file_size": "242.1 MB"
      },
      {
        "model_id": "split_files/vae/wan_alpha_2.1_vae_alpha_channel",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_alpha_2.1_vae_alpha_channel.safetensors",
        "file_size": "242.0 MB"
      },
      {
        "model_id": "split_files/vae/wan_alpha_2.1_vae_rgb_channel",
        "path": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_alpha_2.1_vae_rgb_channel.safetensors",
        "file_size": "242.0 MB"
      }
    ],
    "config": null,
    "readme": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/README.md",
    "description": "Wan 2.1 model repackaged for ComfyUI."
  },
  {
    "model_name": "dolphin-2.9.1-yi-1.5-34b",
    "developer": "dphn",
    "downloads": 4128294,
    "createdAt": "2024-05-18T04:50:56.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 15,
    "safetensors_files": [
      {
        "model_id": "model-00001-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00001-of-00015.safetensors",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "model-00002-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00002-of-00015.safetensors",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "model-00003-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00003-of-00015.safetensors",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "model-00004-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00004-of-00015.safetensors",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "model-00005-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00005-of-00015.safetensors",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "model-00006-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00006-of-00015.safetensors",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "model-00007-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00007-of-00015.safetensors",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "model-00008-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00008-of-00015.safetensors",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "model-00009-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00009-of-00015.safetensors",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "model-00010-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00010-of-00015.safetensors",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "model-00011-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00011-of-00015.safetensors",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "model-00012-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00012-of-00015.safetensors",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "model-00013-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00013-of-00015.safetensors",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "model-00014-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00014-of-00015.safetensors",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "model-00015-of-00015",
        "path": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/model-00015-of-00015.safetensors",
        "file_size": "1.1 GB"
      }
    ],
    "config": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/config.json",
    "readme": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b/resolve/main/README.md",
    "description": "Dolphin 2.9.1 Yi 1.5 34b is an uncensored, Apache 2.0-licensed AI assistant fine-tuned from Yi-1.5-34B with strong coding and instruction-following capabilities, achieving 77.4% MMLU."
  },
  {
    "model_name": "distilbert-base-uncased-finetuned-sst-2-english",
    "developer": "distilbert",
    "downloads": 4027017,
    "createdAt": "2022-03-02T23:29:04.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/model.safetensors",
        "file_size": "255.4 MB"
      }
    ],
    "config": "https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json",
    "readme": "https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/README.md",
    "description": "DistilBERT model fine-tuned on SST-2 for binary sentiment classification with 91.3% accuracy."
  },
  {
    "model_name": "LaBSE",
    "developer": "sentence-transformers",
    "downloads": 4007248,
    "createdAt": "2022-03-02T23:29:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 2,
    "safetensors_files": [
      {
        "model_id": "2_Dense/model",
        "path": "https://huggingface.co/sentence-transformers/LaBSE/resolve/main/2_Dense/model.safetensors",
        "file_size": "2.3 MB"
      },
      {
        "model_id": "model",
        "path": "https://huggingface.co/sentence-transformers/LaBSE/resolve/main/model.safetensors",
        "file_size": "1.8 GB"
      }
    ],
    "config": "https://huggingface.co/sentence-transformers/LaBSE/resolve/main/config.json",
    "readme": "https://huggingface.co/sentence-transformers/LaBSE/resolve/main/README.md",
    "description": "LaBSE is a multilingual sentence embedding model that maps 109 languages to a shared vector space for sentence similarity tasks."
  },
  {
    "model_name": "mivolo_v2",
    "developer": "iitolstykh",
    "downloads": 3980079,
    "createdAt": "2024-03-05T12:50:28.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/iitolstykh/mivolo_v2/resolve/main/model.safetensors",
        "file_size": "109.7 MB"
      }
    ],
    "config": "https://huggingface.co/iitolstykh/mivolo_v2/resolve/main/config.json",
    "readme": "https://huggingface.co/iitolstykh/mivolo_v2/resolve/main/README.md",
    "description": "Multi-input transformer for age and gender estimation from face and body images."
  },
  {
    "model_name": "bge-base-en-v1.5",
    "developer": "BAAI",
    "downloads": 3955117,
    "createdAt": "2023-09-11T15:04:22.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/BAAI/bge-base-en-v1.5/resolve/main/model.safetensors",
        "file_size": "417.7 MB"
      }
    ],
    "config": "https://huggingface.co/BAAI/bge-base-en-v1.5/resolve/main/config.json",
    "readme": "https://huggingface.co/BAAI/bge-base-en-v1.5/resolve/main/README.md",
    "description": "BAAI's English sentence embedding model for retrieval and similarity tasks, evaluated on MTEB."
  },
  {
    "model_name": "Qwen3-1.7B",
    "developer": "Qwen",
    "downloads": 3950983,
    "createdAt": "2025-04-27T03:41:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 2,
    "safetensors_files": [
      {
        "model_id": "model-00001-of-00002",
        "path": "https://huggingface.co/Qwen/Qwen3-1.7B/resolve/main/model-00001-of-00002.safetensors",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "model-00002-of-00002",
        "path": "https://huggingface.co/Qwen/Qwen3-1.7B/resolve/main/model-00002-of-00002.safetensors",
        "file_size": "593.5 MB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen3-1.7B/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen3-1.7B/resolve/main/README.md",
    "description": "**Qwen3-1.7B** is a 1.7B-parameter causal language model with unique seamless switching between thinking and non-thinking modes, strong reasoning/agent capabilities, and multilingual support."
  },
  {
    "model_name": "vit-base-patch16-224",
    "developer": "google",
    "downloads": 3910157,
    "createdAt": "2022-03-02T23:29:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/google/vit-base-patch16-224/resolve/main/model.safetensors",
        "file_size": "330.3 MB"
      }
    ],
    "config": "https://huggingface.co/google/vit-base-patch16-224/resolve/main/config.json",
    "readme": "https://huggingface.co/google/vit-base-patch16-224/resolve/main/README.md",
    "description": "Vision Transformer base model pre-trained on ImageNet-21k and fine-tuned on ImageNet for image classification at 224x224 resolution."
  },
  {
    "model_name": "nomic-embed-text-v1.5",
    "developer": "nomic-ai",
    "downloads": 3742270,
    "createdAt": "2024-02-10T06:32:35.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/nomic-ai/nomic-embed-text-v1.5/resolve/main/model.safetensors",
        "file_size": "521.6 MB"
      }
    ],
    "config": "https://huggingface.co/nomic-ai/nomic-embed-text-v1.5/resolve/main/config.json",
    "readme": "https://huggingface.co/nomic-ai/nomic-embed-text-v1.5/resolve/main/README.md",
    "description": "A production-ready sentence embedding model with Matryoshka Representation Learning that supports flexible dimensionality (76864) for semantic search, clustering, and classification tasks using task-specific prefixes."
  },
  {
    "model_name": "multilingual-e5-large",
    "developer": "intfloat",
    "downloads": 3724962,
    "createdAt": "2023-06-30T07:38:19.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/intfloat/multilingual-e5-large/resolve/main/model.safetensors",
        "file_size": "2.1 GB"
      }
    ],
    "config": "https://huggingface.co/intfloat/multilingual-e5-large/resolve/main/config.json",
    "readme": "https://huggingface.co/intfloat/multilingual-e5-large/resolve/main/README.md",
    "description": "Multilingual E5-large is a 24-layer, 1024-dimension text embedding model based on XLM-RoBERTa-large, supporting 100+ languages for tasks like semantic similarity, retrieval, and classification."
  },
  {
    "model_name": "bge-reranker-v2-m3",
    "developer": "BAAI",
    "downloads": 3648801,
    "createdAt": "2024-03-15T13:32:18.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/BAAI/bge-reranker-v2-m3/resolve/main/model.safetensors",
        "file_size": "2.1 GB"
      }
    ],
    "config": "https://huggingface.co/BAAI/bge-reranker-v2-m3/resolve/main/config.json",
    "readme": "https://huggingface.co/BAAI/bge-reranker-v2-m3/resolve/main/README.md",
    "description": "BGE Reranker models score query-document relevance to improve search results, available in base, large, and multilingual versions with different base architectures."
  },
  {
    "model_name": "bart-large-mnli",
    "developer": "facebook",
    "downloads": 3494253,
    "createdAt": "2022-03-02T23:29:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/model.safetensors",
        "file_size": "1.5 GB"
      }
    ],
    "config": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/config.json",
    "readme": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/README.md",
    "description": "BART-large model fine-tuned on MultiNLI for zero-shot text classification using NLI-based hypothesis testing."
  },
  {
    "model_name": "all-MiniLM-L12-v2",
    "developer": "sentence-transformers",
    "downloads": 3493273,
    "createdAt": "2022-03-02T23:29:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2/resolve/main/model.safetensors",
        "file_size": "127.3 MB"
      }
    ],
    "config": "https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2/resolve/main/config.json",
    "readme": "https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2/resolve/main/README.md",
    "description": "A sentence-transformers model that encodes sentences into 384-dimensional vectors for semantic search and clustering, trained via contrastive learning on 1B sentence pairs."
  },
  {
    "model_name": "tiny-Qwen2ForCausalLM-2.5",
    "developer": "trl-internal-testing",
    "downloads": 3442119,
    "createdAt": "2024-11-25T15:06:15.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/trl-internal-testing/tiny-Qwen2ForCausalLM-2.5/resolve/main/model.safetensors",
        "file_size": "4.6 MB"
      }
    ],
    "config": "https://huggingface.co/trl-internal-testing/tiny-Qwen2ForCausalLM-2.5/resolve/main/config.json",
    "readme": "https://huggingface.co/trl-internal-testing/tiny-Qwen2ForCausalLM-2.5/resolve/main/README.md",
    "description": "A minimal Qwen2ForCausalLM model for unit tests in TRL."
  },
  {
    "model_name": "Qwen2.5-VL-7B-Instruct",
    "developer": "Qwen",
    "downloads": 3339575,
    "createdAt": "2025-01-26T09:26:37.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 5,
    "safetensors_files": [
      {
        "model_id": "model-00001-of-00005",
        "path": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct/resolve/main/model-00001-of-00005.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00002-of-00005",
        "path": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct/resolve/main/model-00002-of-00005.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00003-of-00005",
        "path": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct/resolve/main/model-00003-of-00005.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00004-of-00005",
        "path": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct/resolve/main/model-00004-of-00005.safetensors",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "model-00005-of-00005",
        "path": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct/resolve/main/model-00005-of-00005.safetensors",
        "file_size": "1.0 GB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct/resolve/main/README.md",
    "description": "Qwen2.5-VL-7B-Instruct is a 7B-parameter instruction-tuned vision-language model that can understand images, videos, and perform visual agent tasks like computer/phone use."
  },
  {
    "model_name": "gpt-oss-120b",
    "developer": "openai",
    "downloads": 3289594,
    "createdAt": "2025-08-04T22:33:06.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 22,
    "safetensors_files": [
      {
        "model_id": "model-00000-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00000-of-00014.safetensors",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "model-00001-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00001-of-00014.safetensors",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "model-00002-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00002-of-00014.safetensors",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "model-00003-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00003-of-00014.safetensors",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "model-00004-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00004-of-00014.safetensors",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "model-00005-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00005-of-00014.safetensors",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "model-00006-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00006-of-00014.safetensors",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "model-00007-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00007-of-00014.safetensors",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "model-00008-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00008-of-00014.safetensors",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "model-00009-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00009-of-00014.safetensors",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "model-00010-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00010-of-00014.safetensors",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "model-00011-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00011-of-00014.safetensors",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "model-00012-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00012-of-00014.safetensors",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "model-00013-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00013-of-00014.safetensors",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "model-00014-of-00014",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/model-00014-of-00014.safetensors",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "original/model--00001-of-00007",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/original/model--00001-of-00007.safetensors",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "original/model--00002-of-00007",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/original/model--00002-of-00007.safetensors",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "original/model--00003-of-00007",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/original/model--00003-of-00007.safetensors",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "original/model--00004-of-00007",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/original/model--00004-of-00007.safetensors",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "original/model--00005-of-00007",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/original/model--00005-of-00007.safetensors",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "original/model--00006-of-00007",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/original/model--00006-of-00007.safetensors",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "original/model--00007-of-00007",
        "path": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/original/model--00007-of-00007.safetensors",
        "file_size": "2.2 GB"
      }
    ],
    "config": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/config.json",
    "readme": "https://huggingface.co/openai/gpt-oss-120b/resolve/main/README.md",
    "description": "OpenAI's open-weight reasoning models (117B and 21B parameters) with Apache 2.0 license, MXFP4 quantization, and agentic capabilities."
  },
  {
    "model_name": "paraphrase-MiniLM-L6-v2",
    "developer": "sentence-transformers",
    "downloads": 3262711,
    "createdAt": "2022-03-02T23:29:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2/resolve/main/model.safetensors",
        "file_size": "86.7 MB"
      }
    ],
    "config": "https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2/resolve/main/config.json",
    "readme": "https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2/resolve/main/README.md",
    "description": "A sentence-transformers model that maps sentences to 384-dimensional vectors for semantic search and clustering."
  },
  {
    "model_name": "Qwen3-4B-Instruct-2507",
    "developer": "Qwen",
    "downloads": 3198471,
    "createdAt": "2025-08-05T10:58:03.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 3,
    "safetensors_files": [
      {
        "model_id": "model-00001-of-00003",
        "path": "https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507/resolve/main/model-00001-of-00003.safetensors",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "model-00002-of-00003",
        "path": "https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507/resolve/main/model-00002-of-00003.safetensors",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "model-00003-of-00003",
        "path": "https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507/resolve/main/model-00003-of-00003.safetensors",
        "file_size": "95.0 MB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507/resolve/main/README.md",
    "description": "Qwen3-4B-Instruct-2507 is a 4B-parameter instruction-tuned causal language model with enhanced reasoning, coding, and tool-use capabilities supporting 262K context length."
  },
  {
    "model_name": "whisper-large-v3-turbo",
    "developer": "openai",
    "downloads": 3104183,
    "createdAt": "2024-10-01T07:39:28.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/openai/whisper-large-v3-turbo/resolve/main/model.safetensors",
        "file_size": "1.5 GB"
      }
    ],
    "config": "https://huggingface.co/openai/whisper-large-v3-turbo/resolve/main/config.json",
    "readme": "https://huggingface.co/openai/whisper-large-v3-turbo/resolve/main/README.md",
    "description": "OpenAI's Whisper large-v3-turbo is a faster, pruned variant of Whisper large-v3 for automatic speech recognition, with reduced decoding layers for improved speed."
  },
  {
    "model_name": "moondream2",
    "developer": "vikhyatk",
    "downloads": 3056998,
    "createdAt": "2024-03-04T18:03:06.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/vikhyatk/moondream2/resolve/main/model.safetensors",
        "file_size": "3.6 GB"
      }
    ],
    "config": "https://huggingface.co/vikhyatk/moondream2/resolve/main/config.json",
    "readme": "https://huggingface.co/vikhyatk/moondream2/resolve/main/README.md",
    "description": "Small, efficient vision-language model for image captioning, visual queries, object detection, and pointing."
  },
  {
    "model_name": "DeepSeek-OCR",
    "developer": "deepseek-ai",
    "downloads": 3047272,
    "createdAt": "2025-10-17T06:22:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model-00001-of-000001",
        "path": "https://huggingface.co/deepseek-ai/DeepSeek-OCR/resolve/main/model-00001-of-000001.safetensors",
        "file_size": "6.2 GB"
      }
    ],
    "config": "https://huggingface.co/deepseek-ai/DeepSeek-OCR/resolve/main/config.json",
    "readme": "https://huggingface.co/deepseek-ai/DeepSeek-OCR/resolve/main/README.md",
    "description": "DeepSeek-OCR is a vision-language model for optical character recognition with visual-text compression capabilities."
  },
  {
    "model_name": "Qwen3-Embedding-0.6B",
    "developer": "Qwen",
    "downloads": 3009261,
    "createdAt": "2025-06-03T14:25:32.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/Qwen/Qwen3-Embedding-0.6B/resolve/main/model.safetensors",
        "file_size": "1.1 GB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen3-Embedding-0.6B/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen3-Embedding-0.6B/resolve/main/README.md",
    "description": "Qwen3-Embedding-0.6B is a 0.6B parameter multilingual text embedding model with 32k context and state-of-the-art MTEB benchmark performance."
  },
  {
    "model_name": "bert-base-multilingual-cased",
    "developer": "google-bert",
    "downloads": 2988968,
    "createdAt": "2022-03-02T23:29:04.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/google-bert/bert-base-multilingual-cased/resolve/main/model.safetensors",
        "file_size": "681.2 MB"
      }
    ],
    "config": "https://huggingface.co/google-bert/bert-base-multilingual-cased/resolve/main/config.json",
    "readme": "https://huggingface.co/google-bert/bert-base-multilingual-cased/resolve/main/README.md",
    "description": "Multilingual cased BERT model pretrained on 104 languages via masked language modeling."
  },
  {
    "model_name": "Llama-3.2-1B-Instruct",
    "developer": "meta-llama",
    "downloads": 2910032,
    "createdAt": "2024-09-18T15:12:47.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/model.safetensors",
        "file_size": "2.3 GB"
      }
    ],
    "config": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json",
    "readme": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/README.md",
    "description": "Meta's Llama 3.2 is a collection of 1B and 3B parameter multilingual instruction-tuned language models for text generation and dialogue applications, released under a custom commercial license."
  },
  {
    "model_name": "w2v-bert-2.0",
    "developer": "facebook",
    "downloads": 2890514,
    "createdAt": "2023-12-19T07:41:49.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/facebook/w2v-bert-2.0/resolve/main/model.safetensors",
        "file_size": "2.2 GB"
      }
    ],
    "config": "https://huggingface.co/facebook/w2v-bert-2.0/resolve/main/config.json",
    "readme": "https://huggingface.co/facebook/w2v-bert-2.0/resolve/main/README.md",
    "description": "W2v-BERT 2.0 is a 600M-parameter Conformer-based speech encoder pretrained on 4.5M hours of multilingual audio, requiring finetuning for tasks like ASR."
  },
  {
    "model_name": "unidepth-v2-vitl14",
    "developer": "lpiccinelli",
    "downloads": 2873806,
    "createdAt": "2024-06-12T12:39:28.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/lpiccinelli/unidepth-v2-vitl14/resolve/main/model.safetensors",
        "file_size": "1.3 GB"
      }
    ],
    "config": "https://huggingface.co/lpiccinelli/unidepth-v2-vitl14/resolve/main/config.json",
    "readme": "https://huggingface.co/lpiccinelli/unidepth-v2-vitl14/resolve/main/README.md",
    "description": "UniDepth is a monocular metric depth estimation model."
  },
  {
    "model_name": "lightglue_superpoint",
    "developer": "ETH-CVG",
    "downloads": 2840616,
    "createdAt": "2025-02-20T15:52:56.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/ETH-CVG/lightglue_superpoint/resolve/main/model.safetensors",
        "file_size": "52.5 MB"
      }
    ],
    "config": "https://huggingface.co/ETH-CVG/lightglue_superpoint/resolve/main/config.json",
    "readme": "https://huggingface.co/ETH-CVG/lightglue_superpoint/resolve/main/README.md",
    "description": "LightGlue is a deep neural network for fast, adaptive local feature matching between image pairs, used for tasks like image matching and pose estimation."
  },
  {
    "model_name": "superpoint",
    "developer": "magic-leap-community",
    "downloads": 2807715,
    "createdAt": "2024-03-13T17:24:17.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/magic-leap-community/superpoint/resolve/main/model.safetensors",
        "file_size": "5.0 MB"
      }
    ],
    "config": "https://huggingface.co/magic-leap-community/superpoint/resolve/main/config.json",
    "readme": "https://huggingface.co/magic-leap-community/superpoint/resolve/main/README.md",
    "description": "A self-supervised deep learning model for detecting and describing interest points in images, used for computer vision tasks like image matching and homography estimation."
  },
  {
    "model_name": "Qwen3-VL-8B-Instruct",
    "developer": "Qwen",
    "downloads": 2788336,
    "createdAt": "2025-10-11T07:23:39.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 4,
    "safetensors_files": [
      {
        "model_id": "model-00001-of-00004",
        "path": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct/resolve/main/model-00001-of-00004.safetensors",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "model-00002-of-00004",
        "path": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct/resolve/main/model-00002-of-00004.safetensors",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "model-00003-of-00004",
        "path": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct/resolve/main/model-00003-of-00004.safetensors",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "model-00004-of-00004",
        "path": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct/resolve/main/model-00004-of-00004.safetensors",
        "file_size": "2.5 GB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct/resolve/main/README.md",
    "description": "Qwen3-VL-8B-Instruct is Alibaba's 8-billion parameter vision-language model for image-text tasks with advanced visual understanding, coding, and reasoning capabilities."
  },
  {
    "model_name": "bart-large-cnn",
    "developer": "facebook",
    "downloads": 2786339,
    "createdAt": "2022-03-02T23:29:05.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/model.safetensors",
        "file_size": "1.5 GB"
      }
    ],
    "config": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json",
    "readme": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/README.md",
    "description": "A BART-large seq2seq model fine-tuned on CNN Daily Mail for summarization."
  },
  {
    "model_name": "mms-300m-1130-forced-aligner",
    "developer": "MahmoudAshraf",
    "downloads": 2762547,
    "createdAt": "2024-05-02T21:02:39.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/MahmoudAshraf/mms-300m-1130-forced-aligner/resolve/main/model.safetensors",
        "file_size": "1.2 GB"
      }
    ],
    "config": "https://huggingface.co/MahmoudAshraf/mms-300m-1130-forced-aligner/resolve/main/config.json",
    "readme": "https://huggingface.co/MahmoudAshraf/mms-300m-1130-forced-aligner/resolve/main/README.md",
    "description": "Forced alignment tool using MMS-300M checkpoint supporting 200+ languages with memory-efficient CTC implementation."
  },
  {
    "model_name": "Qwen2.5-Coder-0.5B-Instruct",
    "developer": "Qwen",
    "downloads": 2741074,
    "createdAt": "2024-11-06T07:49:26.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct/resolve/main/model.safetensors",
        "file_size": "942.3 MB"
      }
    ],
    "config": "https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct/resolve/main/config.json",
    "readme": "https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct/resolve/main/README.md",
    "description": "Qwen2.5-Coder-0.5B-Instruct is a 0.5B parameter instruction-tuned code generation model by Alibaba Cloud, designed for code writing, reasoning, and fixing tasks."
  },
  {
    "model_name": "t5-small",
    "developer": "google-t5",
    "downloads": 2643622,
    "createdAt": "2022-03-02T23:29:04.000Z",
    "library_name": "mlx",
    "tools": false,
    "num_safetensors": 1,
    "safetensors_files": [
      {
        "model_id": "model",
        "path": "https://huggingface.co/google-t5/t5-small/resolve/main/model.safetensors",
        "file_size": "230.8 MB"
      }
    ],
    "config": "https://huggingface.co/google-t5/t5-small/resolve/main/config.json",
    "readme": "https://huggingface.co/google-t5/t5-small/resolve/main/README.md",
    "description": "T5-Small is a 60M parameter text-to-text transformer model for NLP tasks like summarization and translation, pre-trained on C4."
  },
  {
    "model_name": "Meta-Llama-3.1-8B-Instruct-GGUF",
    "developer": "bartowski",
    "downloads": 209670,
    "createdAt": "2024-07-23T15:36:34.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 24,
    "quants": [
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-IQ2_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-IQ2_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-IQ3_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-IQ3_M.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-IQ3_XS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-IQ4_NL.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-IQ4_XS.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q2_K",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q2_K_L",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q2_K_L.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q3_K_XL.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q4_0_4_4",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_0_4_4.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q4_0_4_8",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_0_4_8.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q4_0_8_8",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_0_8_8.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_L.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q5_K_L.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q6_K",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q6_K_L.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q8_0",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-f32",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-f32.gguf",
        "file_size": "29.9 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/README.md",
    "description": "Quantized GGUF versions of Meta-Llama-3.1-8B-Instruct for local inference using llama.cpp."
  },
  {
    "model_name": "gemma-3-4b-it-GGUF",
    "developer": "unsloth",
    "downloads": 196953,
    "createdAt": "2025-03-12T09:04:23.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "gemma-3-4b-it-BF16",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-BF16.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "gemma-3-4b-it-IQ4_NL",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-IQ4_NL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "gemma-3-4b-it-IQ4_XS",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-IQ4_XS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q2_K",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q2_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q2_K_L",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q2_K_L.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q3_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q3_K_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q3_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q4_0",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q4_1",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q4_1.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q4_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q4_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q5_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q5_K_M.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q5_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q6_K",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q6_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q8_0",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q8_0.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-IQ1_M.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-IQ1_S.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-IQ2_M.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-IQ2_XXS.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-IQ3_XXS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-Q2_K_XL.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-Q3_K_XL.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-Q4_K_XL.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-Q5_K_XL.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-Q6_K_XL.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-Q8_K_XL.gguf",
        "file_size": "4.8 GB"
      }
    ],
    "num_mmproj": 3,
    "mmproj_models": [
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "811.8 MB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "811.8 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/README.md",
    "description": "Google Gemma 3 4B IT is a lightweight, open, multimodal (text/image) instruction-tuned model with a 128k context window, optimized for efficient fine-tuning by Unsloth."
  },
  {
    "model_name": "Devstral-Small-2-24B-Instruct-2512-GGUF",
    "developer": "unsloth",
    "downloads": 157014,
    "createdAt": "2025-12-10T01:36:17.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-BF16",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-BF16.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-IQ4_NL.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-IQ4_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-Q2_K",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-Q2_K_L.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-Q4_0",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-Q4_0.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-Q4_1",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-Q4_1.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-Q6_K",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-Q8_0",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-Q8_0.gguf",
        "file_size": "23.3 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-UD-IQ1_M.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-UD-IQ1_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-UD-IQ2_M.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-UD-IQ2_XXS.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-UD-IQ3_XXS.gguf",
        "file_size": "8.8 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-UD-Q2_K_XL.gguf",
        "file_size": "8.7 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-UD-Q3_K_XL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-UD-Q4_K_XL.gguf",
        "file_size": "13.5 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-UD-Q5_K_XL.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-UD-Q6_K_XL.gguf",
        "file_size": "19.4 GB"
      },
      {
        "model_id": "Devstral-Small-2-24B-Instruct-2512-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/Devstral-Small-2-24B-Instruct-2512-UD-Q8_K_XL.gguf",
        "file_size": "27.0 GB"
      }
    ],
    "num_mmproj": 3,
    "mmproj_models": [
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "838.5 MB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "837.4 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF/resolve/main/README.md",
    "description": "Devstral Small 2 is a 24B open-source AI model specialized in agentic coding and software engineering tasks."
  },
  {
    "model_name": "gpt-oss-20b-GGUF",
    "developer": "unsloth",
    "downloads": 138121,
    "createdAt": "2025-08-05T17:12:17.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 16,
    "quants": [
      {
        "model_id": "gpt-oss-20b-F16",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-F16.gguf",
        "file_size": "12.8 GB"
      },
      {
        "model_id": "gpt-oss-20b-Q2_K",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-Q2_K.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "gpt-oss-20b-Q2_K_L",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-Q2_K_L.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "gpt-oss-20b-Q3_K_M",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "gpt-oss-20b-Q3_K_S",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-Q3_K_S.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "gpt-oss-20b-Q4_0",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-Q4_0.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "gpt-oss-20b-Q4_1",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-Q4_1.gguf",
        "file_size": "10.8 GB"
      },
      {
        "model_id": "gpt-oss-20b-Q4_K_M",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-Q4_K_M.gguf",
        "file_size": "10.8 GB"
      },
      {
        "model_id": "gpt-oss-20b-Q4_K_S",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-Q4_K_S.gguf",
        "file_size": "10.8 GB"
      },
      {
        "model_id": "gpt-oss-20b-Q5_K_M",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-Q5_K_M.gguf",
        "file_size": "10.9 GB"
      },
      {
        "model_id": "gpt-oss-20b-Q5_K_S",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-Q5_K_S.gguf",
        "file_size": "10.9 GB"
      },
      {
        "model_id": "gpt-oss-20b-Q6_K",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-Q6_K.gguf",
        "file_size": "11.2 GB"
      },
      {
        "model_id": "gpt-oss-20b-Q8_0",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-Q8_0.gguf",
        "file_size": "11.3 GB"
      },
      {
        "model_id": "gpt-oss-20b-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-UD-Q4_K_XL.gguf",
        "file_size": "11.1 GB"
      },
      {
        "model_id": "gpt-oss-20b-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-UD-Q6_K_XL.gguf",
        "file_size": "11.2 GB"
      },
      {
        "model_id": "gpt-oss-20b-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-UD-Q8_K_XL.gguf",
        "file_size": "12.3 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/README.md",
    "description": ""
  },
  {
    "model_name": "gemma-3-12b-it-GGUF",
    "developer": "unsloth",
    "downloads": 128806,
    "createdAt": "2025-03-12T10:34:12.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "gemma-3-12b-it-BF16",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-BF16.gguf",
        "file_size": "21.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-IQ4_NL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-IQ4_NL.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-IQ4_XS",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-IQ4_XS.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q2_K",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q2_K.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q2_K_L",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q2_K_L.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q3_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q3_K_M.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q3_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q3_K_S.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q4_0",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q4_0.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q4_1",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q4_1.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q4_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q4_K_M.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q4_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q4_K_S.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q5_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q5_K_M.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q5_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q5_K_S.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q6_K",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q6_K.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q8_0",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q8_0.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-IQ1_M.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-IQ1_S.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-IQ2_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-IQ2_XXS.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-IQ3_XXS.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-Q2_K_XL.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-Q3_K_XL.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-Q4_K_XL.gguf",
        "file_size": "6.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-Q5_K_XL.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-Q6_K_XL.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-Q8_K_XL.gguf",
        "file_size": "13.4 GB"
      }
    ],
    "num_mmproj": 3,
    "mmproj_models": [
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "814.6 MB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "814.6 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/README.md",
    "description": "Google's Gemma 3 12B IT is a state-of-the-art, open, multimodal language model designed for efficient text and image generation."
  },
  {
    "model_name": "OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf",
    "developer": "DavidAU",
    "downloads": 108706,
    "createdAt": "2025-08-07T22:20:03.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 18,
    "quants": [
      {
        "model_id": "OpenAI-20B-NEO-CODE-DI-Uncensored-Q5_1",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-CODE-DI-Uncensored-Q5_1.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-CODE-DI-Uncensored-Q8_0",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-CODE-DI-Uncensored-Q8_0.gguf",
        "file_size": "20.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-CODE2-Plus-Uncensored-IQ4_NL",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-CODE2-Plus-Uncensored-IQ4_NL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-CODEPlus-Uncensored-IQ4_NL",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-CODEPlus-Uncensored-IQ4_NL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-CODEPlus-Uncensored-Q5_1",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-CODEPlus-Uncensored-Q5_1.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-CODEPlus16-Uncensored-IQ4_NL",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-CODEPlus16-Uncensored-IQ4_NL.gguf",
        "file_size": "11.8 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-HRR-CODE-5-TRI-Uncensored-Q8_0",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-HRR-CODE-5-TRI-Uncensored-Q8_0.gguf",
        "file_size": "20.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-HRR-CODE-TRI-Uncensored-IQ4_NL",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-HRR-CODE-TRI-Uncensored-IQ4_NL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-HRR-CODE-TRI-Uncensored-Q5_1",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-HRR-CODE-TRI-Uncensored-Q5_1.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-HRR-CODE-TRI-Uncensored-Q8_0",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-HRR-CODE-TRI-Uncensored-Q8_0.gguf",
        "file_size": "20.5 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-HRR-DI-Uncensored-Q5_1",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-HRR-DI-Uncensored-Q5_1.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-HRR-DI-Uncensored-Q8_0",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-HRR-DI-Uncensored-Q8_0.gguf",
        "file_size": "20.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-HRRPlus-Uncensored-IQ4_NL",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-HRRPlus-Uncensored-IQ4_NL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-Uncensored2-IQ4_NL",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-Uncensored2-IQ4_NL.gguf",
        "file_size": "11.8 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-Uncensored2-Q5_1",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-Uncensored2-Q5_1.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "OpenAI-20B-NEOPlus-Uncensored-IQ4_NL",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEOPlus-Uncensored-IQ4_NL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "OpenAI-20B-NEOPlus-Uncensored-Q5_1",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEOPlus-Uncensored-Q5_1.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEOPlus-Uncensored-Q8_0",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEOPlus-Uncensored-Q8_0.gguf",
        "file_size": "20.6 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf/resolve/main/README.md",
    "description": "A quantized, uncensored 20B Mixture of Experts model in GGUF format optimized for creative writing and coding tasks."
  },
  {
    "model_name": "Qwen3-8B-GGUF",
    "developer": "Qwen",
    "downloads": 95731,
    "createdAt": "2025-05-03T06:33:59.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 5,
    "quants": [
      {
        "model_id": "Qwen3-8B-Q4_K_M",
        "path": "https://huggingface.co/Qwen/Qwen3-8B-GGUF/resolve/main/Qwen3-8B-Q4_K_M.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Qwen3-8B-Q5_0",
        "path": "https://huggingface.co/Qwen/Qwen3-8B-GGUF/resolve/main/Qwen3-8B-Q5_0.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Qwen3-8B-Q5_K_M",
        "path": "https://huggingface.co/Qwen/Qwen3-8B-GGUF/resolve/main/Qwen3-8B-Q5_K_M.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "Qwen3-8B-Q6_K",
        "path": "https://huggingface.co/Qwen/Qwen3-8B-GGUF/resolve/main/Qwen3-8B-Q6_K.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Qwen3-8B-Q8_0",
        "path": "https://huggingface.co/Qwen/Qwen3-8B-GGUF/resolve/main/Qwen3-8B-Q8_0.gguf",
        "file_size": "8.1 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Qwen/Qwen3-8B-GGUF/resolve/main/README.md",
    "description": "Qwen3-8B-GGUF is an 8B-parameter quantized language model with unique switchable thinking modes for complex reasoning or efficient dialogue."
  },
  {
    "model_name": "Qwen2.5-1.5B-Instruct-GGUF",
    "developer": "Qwen",
    "downloads": 78940,
    "createdAt": "2024-09-17T13:57:52.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 9,
    "quants": [
      {
        "model_id": "qwen2.5-1.5b-instruct-fp16",
        "path": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-fp16.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "qwen2.5-1.5b-instruct-q2_k",
        "path": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q2_k.gguf",
        "file_size": "718.0 MB"
      },
      {
        "model_id": "qwen2.5-1.5b-instruct-q3_k_m",
        "path": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q3_k_m.gguf",
        "file_size": "881.6 MB"
      },
      {
        "model_id": "qwen2.5-1.5b-instruct-q4_0",
        "path": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q4_0.gguf",
        "file_size": "1016.8 MB"
      },
      {
        "model_id": "qwen2.5-1.5b-instruct-q4_k_m",
        "path": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q4_k_m.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "qwen2.5-1.5b-instruct-q5_0",
        "path": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q5_0.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "qwen2.5-1.5b-instruct-q5_k_m",
        "path": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q5_k_m.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "qwen2.5-1.5b-instruct-q6_k",
        "path": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q6_k.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "qwen2.5-1.5b-instruct-q8_0",
        "path": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q8_0.gguf",
        "file_size": "1.8 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/README.md",
    "description": "Qwen2.5-1.5B-Instruct-GGUF is a 1.5B parameter instruction-tuned language model by Alibaba Cloud in quantized GGUF format, supporting multilingual chat, coding, math, and long contexts up to 128K tokens."
  },
  {
    "model_name": "Qwen3-4B-GGUF",
    "developer": "unsloth",
    "downloads": 78483,
    "createdAt": "2025-04-28T07:55:09.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "Qwen3-4B-BF16",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-BF16.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Qwen3-4B-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-IQ4_NL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Qwen3-4B-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-IQ4_XS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Qwen3-4B-Q2_K",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q2_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Qwen3-4B-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q2_K_L.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Qwen3-4B-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q3_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Qwen3-4B-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Qwen3-4B-Q4_0",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Qwen3-4B-Q4_1",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q4_1.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Qwen3-4B-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Qwen3-4B-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Qwen3-4B-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Qwen3-4B-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Qwen3-4B-Q6_K",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Qwen3-4B-Q8_0",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q8_0.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-IQ1_M.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-IQ1_S.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-IQ2_M.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-IQ2_XXS.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-IQ3_XXS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-Q2_K_XL.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-Q3_K_XL.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-Q4_K_XL.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-Q5_K_XL.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-Q6_K_XL.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-Q8_K_XL.gguf",
        "file_size": "4.7 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/README.md",
    "description": ""
  },
  {
    "model_name": "Qwen3-VL-8B-Instruct-GGUF",
    "developer": "Qwen",
    "downloads": 76167,
    "createdAt": "2025-10-31T02:50:31.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 3,
    "quants": [
      {
        "model_id": "Qwen3VL-8B-Instruct-F16",
        "path": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct-GGUF/resolve/main/Qwen3VL-8B-Instruct-F16.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "Qwen3VL-8B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct-GGUF/resolve/main/Qwen3VL-8B-Instruct-Q4_K_M.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Qwen3VL-8B-Instruct-Q8_0",
        "path": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct-GGUF/resolve/main/Qwen3VL-8B-Instruct-Q8_0.gguf",
        "file_size": "8.1 GB"
      }
    ],
    "num_mmproj": 2,
    "mmproj_models": [
      {
        "model_id": "mmproj-Qwen3VL-8B-Instruct-F16",
        "path": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct-GGUF/resolve/main/mmproj-Qwen3VL-8B-Instruct-F16.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "mmproj-Qwen3VL-8B-Instruct-Q8_0",
        "path": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct-GGUF/resolve/main/mmproj-Qwen3VL-8B-Instruct-Q8_0.gguf",
        "file_size": "717.4 MB"
      }
    ],
    "readme": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct-GGUF/resolve/main/README.md",
    "description": "GGUF-quantized Qwen3-VL-8B-Instruct vision-language model for local inference with llama.cpp and compatible tools."
  },
  {
    "model_name": "DeepSeek-R1-0528-Qwen3-8B-GGUF",
    "developer": "unsloth",
    "downloads": 69437,
    "createdAt": "2025-05-29T14:17:25.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-BF16",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-BF16.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-IQ4_NL",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-IQ4_NL.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-IQ4_XS",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-IQ4_XS.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q2_K",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q2_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q2_K_L",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q2_K_L.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q3_K_M",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q3_K_M.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q3_K_S",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q3_K_S.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q4_0",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q4_0.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q4_1",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q4_1.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q4_K_M",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q4_K_M.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q4_K_S",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q4_K_S.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q5_K_M",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q5_K_M.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q5_K_S",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q5_K_S.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q6_K",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q6_K.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q8_0",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q8_0.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-IQ1_M.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-IQ1_S.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-IQ2_M.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-IQ2_XXS.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-IQ3_XXS.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-Q2_K_XL.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-Q3_K_XL.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-Q4_K_XL.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-Q5_K_XL.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-Q6_K_XL.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-Q8_K_XL.gguf",
        "file_size": "10.1 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/README.md",
    "description": "DeepSeek-R1-0528-Qwen3-8B is a reasoning-focused language model created by distilling DeepSeek's improved R1-0528 reasoning capabilities into Qwen3-8B, achieving strong performance on math, coding, and general reasoning benchmarks under MIT licensing."
  },
  {
    "model_name": "gemma-2b-it",
    "developer": "google",
    "downloads": 67139,
    "createdAt": "2024-02-08T13:23:59.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "gemma-2b-it",
        "path": "https://huggingface.co/google/gemma-2b-it/resolve/main/gemma-2b-it.gguf",
        "file_size": "9.3 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/google/gemma-2b-it/resolve/main/README.md",
    "description": ""
  },
  {
    "model_name": "Qwen3-4B-Instruct-2507-GGUF",
    "developer": "unsloth",
    "downloads": 64241,
    "createdAt": "2025-08-06T19:21:40.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "Qwen3-4B-Instruct-2507-F16",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-F16.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-IQ4_NL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-IQ4_XS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-Q2_K",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-Q2_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-Q2_K_L.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-Q3_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-Q4_0",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-Q4_1",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-Q4_1.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-Q6_K",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-Q8_0",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-Q8_0.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-UD-IQ1_M.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-UD-IQ1_S.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-UD-IQ2_M.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-UD-IQ2_XXS.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-UD-IQ3_XXS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-UD-Q2_K_XL.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-UD-Q3_K_XL.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-UD-Q4_K_XL.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-UD-Q5_K_XL.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-UD-Q6_K_XL.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Qwen3-4B-Instruct-2507-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-UD-Q8_K_XL.gguf",
        "file_size": "4.7 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/README.md",
    "description": "Qwen3-4B-Instruct-2507 is a 4B parameter instruction-tuned language model with 262K context length, improved reasoning/coding capabilities, and tool-use support."
  },
  {
    "model_name": "Dolphin3.0-Llama3.1-8B-GGUF",
    "developer": "dphn",
    "downloads": 62233,
    "createdAt": "2025-01-02T22:11:05.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 18,
    "quants": [
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-F16",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-F16.gguf",
        "file_size": "15.0 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q2_K",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q3_K",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q3_K.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q3_K_L",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q3_K_M",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q3_K_S",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q4_0",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q4_0.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q4_1",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q4_1.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q4_K",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q4_K.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q4_K_M",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q4_K_S",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q5_0",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q5_0.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q5_1",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q5_1.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q5_K",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q5_K.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q5_K_M",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q5_K_S",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q6_K",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q8_0",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q8_0.gguf",
        "file_size": "8.0 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/README.md",
    "description": "Dolphin 3.0 Llama 3.1 8B is a steerable, general-purpose instruct model optimized for coding, math, and agentic tasks, designed as an uncensored alternative to commercial AI assistants."
  },
  {
    "model_name": "Llama-3.2-1B-Instruct-GGUF",
    "developer": "bartowski",
    "downloads": 59871,
    "createdAt": "2024-09-25T18:35:25.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 18,
    "quants": [
      {
        "model_id": "Llama-3.2-1B-Instruct-IQ3_M",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-IQ3_M.gguf",
        "file_size": "626.8 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-IQ4_XS.gguf",
        "file_size": "708.7 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q3_K_L.gguf",
        "file_size": "698.6 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q3_K_XL.gguf",
        "file_size": "759.3 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_0",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_0.gguf",
        "file_size": "737.2 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_0_4_4",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_0_4_4.gguf",
        "file_size": "735.2 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_0_4_8",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_0_4_8.gguf",
        "file_size": "735.2 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_0_8_8",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_0_8_8.gguf",
        "file_size": "735.2 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_L.gguf",
        "file_size": "830.9 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_M.gguf",
        "file_size": "770.3 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_S.gguf",
        "file_size": "739.7 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q5_K_L.gguf",
        "file_size": "929.9 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q5_K_M.gguf",
        "file_size": "869.3 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q5_K_S.gguf",
        "file_size": "851.2 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q6_K",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q6_K.gguf",
        "file_size": "974.5 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q6_K_L.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q8_0",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q8_0.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-f16",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-f16.gguf",
        "file_size": "2.3 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/README.md",
    "description": ""
  },
  {
    "model_name": "GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF",
    "developer": "DavidAU",
    "downloads": 57610,
    "createdAt": "2026-01-22T05:13:27.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 12,
    "quants": [
      {
        "model_id": "GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-IQ2_M",
        "path": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF/resolve/main/GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-IQ2_M.gguf",
        "file_size": "9.6 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-IQ3_M",
        "path": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF/resolve/main/GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-IQ3_M.gguf",
        "file_size": "12.7 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-IQ4_NL",
        "path": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF/resolve/main/GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-IQ4_NL.gguf",
        "file_size": "16.1 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-IQ4_XS",
        "path": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF/resolve/main/GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-IQ4_XS.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q4_1",
        "path": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF/resolve/main/GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q4_1.gguf",
        "file_size": "17.9 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q4_K_M",
        "path": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF/resolve/main/GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q4_K_M.gguf",
        "file_size": "17.2 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q4_K_S",
        "path": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF/resolve/main/GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q4_K_S.gguf",
        "file_size": "16.2 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q5_1",
        "path": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF/resolve/main/GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q5_1.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q5_K_M",
        "path": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF/resolve/main/GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q5_K_M.gguf",
        "file_size": "20.2 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q5_K_S",
        "path": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF/resolve/main/GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q5_K_S.gguf",
        "file_size": "19.6 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q6_K",
        "path": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF/resolve/main/GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q6_K.gguf",
        "file_size": "23.3 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF/resolve/main/GLM-4.7-Flash-Uncen-Hrt-NEO-CODE-MAX-imat-D_AU-Q8_0.gguf",
        "file_size": "29.9 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF/resolve/main/README.md",
    "description": "**Uncensored GGUF quant of GLM-4.7-Flash optimized for creative fiction writing, storytelling, and roleplaying across all genres.**"
  },
  {
    "model_name": "LFM2.5-1.2B-Instruct-GGUF",
    "developer": "LiquidAI",
    "downloads": 55727,
    "createdAt": "2026-01-04T00:09:26.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 7,
    "quants": [
      {
        "model_id": "LFM2.5-1.2B-Instruct-BF16",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Instruct-GGUF/resolve/main/LFM2.5-1.2B-Instruct-BF16.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "LFM2.5-1.2B-Instruct-F16",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Instruct-GGUF/resolve/main/LFM2.5-1.2B-Instruct-F16.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "LFM2.5-1.2B-Instruct-Q4_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Instruct-GGUF/resolve/main/LFM2.5-1.2B-Instruct-Q4_0.gguf",
        "file_size": "663.5 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Instruct-GGUF/resolve/main/LFM2.5-1.2B-Instruct-Q4_K_M.gguf",
        "file_size": "697.0 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Instruct-GGUF/resolve/main/LFM2.5-1.2B-Instruct-Q5_K_M.gguf",
        "file_size": "804.3 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Instruct-Q6_K",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Instruct-GGUF/resolve/main/LFM2.5-1.2B-Instruct-Q6_K.gguf",
        "file_size": "918.2 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Instruct-Q8_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Instruct-GGUF/resolve/main/LFM2.5-1.2B-Instruct-Q8_0.gguf",
        "file_size": "1.2 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Instruct-GGUF/resolve/main/README.md",
    "description": "LFM2.5-1.2B-Instruct is a small hybrid AI model by Liquid AI designed for on-device deployment, runnable via llama.cpp."
  },
  {
    "model_name": "GLM-4.7-Flash-REAP-23B-A3B-GGUF",
    "developer": "unsloth",
    "downloads": 50614,
    "createdAt": "2026-01-23T06:50:31.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 27,
    "quants": [
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-BF16",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-BF16.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-IQ4_NL",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-IQ4_NL.gguf",
        "file_size": "12.3 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-IQ4_XS",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-IQ4_XS.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-Q2_K",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-Q2_K.gguf",
        "file_size": "8.2 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-Q2_K_L",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-Q2_K_L.gguf",
        "file_size": "8.2 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-Q3_K_M",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-Q3_K_M.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-Q3_K_S",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-Q3_K_S.gguf",
        "file_size": "9.6 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-Q4_0",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-Q4_0.gguf",
        "file_size": "12.4 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-Q4_1",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-Q4_1.gguf",
        "file_size": "13.6 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-Q4_K_M",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-Q4_K_M.gguf",
        "file_size": "13.1 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-Q4_K_S",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-Q4_K_S.gguf",
        "file_size": "12.4 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-Q5_K_M",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-Q5_K_M.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-Q5_K_S",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-Q5_K_S.gguf",
        "file_size": "14.9 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-Q6_K",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-Q6_K.gguf",
        "file_size": "17.7 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-Q8_0",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-Q8_0.gguf",
        "file_size": "22.8 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-UD-IQ1_M.gguf",
        "file_size": "7.1 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-UD-IQ1_S.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-UD-IQ2_M.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-UD-IQ2_XXS.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-UD-IQ3_XXS.gguf",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-UD-Q2_K_XL.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-UD-Q3_K_XL.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-UD-Q4_K_XL.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-UD-Q5_K_XL.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-UD-Q6_K_XL.gguf",
        "file_size": "18.8 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-UD-Q8_K_XL.gguf",
        "file_size": "25.6 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-REAP-23B-A3B-UD-TQ1_0",
        "path": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/GLM-4.7-Flash-REAP-23B-A3B-UD-TQ1_0.gguf",
        "file_size": "6.1 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF/resolve/main/README.md",
    "description": "A 23B parameter Mixture-of-Experts model created by uniformly pruning 25% of experts from GLM-4.7-Flash using the REAP method, maintaining near-original performance while reducing size."
  },
  {
    "model_name": "LFM2.5-VL-1.6B-GGUF",
    "developer": "LiquidAI",
    "downloads": 49717,
    "createdAt": "2026-01-04T19:35:04.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 4,
    "quants": [
      {
        "model_id": "LFM2.5-VL-1.6B-BF16",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-VL-1.6B-GGUF/resolve/main/LFM2.5-VL-1.6B-BF16.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "LFM2.5-VL-1.6B-F16",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-VL-1.6B-GGUF/resolve/main/LFM2.5-VL-1.6B-F16.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "LFM2.5-VL-1.6B-Q4_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-VL-1.6B-GGUF/resolve/main/LFM2.5-VL-1.6B-Q4_0.gguf",
        "file_size": "663.5 MB"
      },
      {
        "model_id": "LFM2.5-VL-1.6B-Q8_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-VL-1.6B-GGUF/resolve/main/LFM2.5-VL-1.6B-Q8_0.gguf",
        "file_size": "1.2 GB"
      }
    ],
    "num_mmproj": 3,
    "mmproj_models": [
      {
        "model_id": "mmproj-LFM2.5-VL-1.6b-BF16",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-VL-1.6B-GGUF/resolve/main/mmproj-LFM2.5-VL-1.6b-BF16.gguf",
        "file_size": "816.1 MB"
      },
      {
        "model_id": "mmproj-LFM2.5-VL-1.6b-F16",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-VL-1.6B-GGUF/resolve/main/mmproj-LFM2.5-VL-1.6b-F16.gguf",
        "file_size": "814.4 MB"
      },
      {
        "model_id": "mmproj-LFM2.5-VL-1.6b-Q8_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-VL-1.6B-GGUF/resolve/main/mmproj-LFM2.5-VL-1.6b-Q8_0.gguf",
        "file_size": "556.1 MB"
      }
    ],
    "readme": "https://huggingface.co/LiquidAI/LFM2.5-VL-1.6B-GGUF/resolve/main/README.md",
    "description": "LFM2.5-VL-1.6B is a vision-language model by Liquid AI that processes images and text, available in GGUF format for llama.cpp."
  },
  {
    "model_name": "OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf",
    "developer": "DavidAU",
    "downloads": 49577,
    "createdAt": "2025-11-17T05:52:55.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 17,
    "quants": [
      {
        "model_id": "OpenAI-20B-NEO-CODE-DI-Uncensored-Q5_1",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-CODE-DI-Uncensored-Q5_1.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-CODE-DI-Uncensored-Q8_0",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-CODE-DI-Uncensored-Q8_0.gguf",
        "file_size": "20.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-CODEPlus-Uncensored-IQ4_NL",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-CODEPlus-Uncensored-IQ4_NL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-CODEPlus-Uncensored-Q5_1",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-CODEPlus-Uncensored-Q5_1.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-CODEPlus16-Uncensored-IQ4_NL",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-CODEPlus16-Uncensored-IQ4_NL.gguf",
        "file_size": "11.8 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-HRR-CODE-5-TRI-Uncensored-Q8_0",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-HRR-CODE-5-TRI-Uncensored-Q8_0.gguf",
        "file_size": "20.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-HRR-CODE-TRI-Uncensored-IQ4_NL",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-HRR-CODE-TRI-Uncensored-IQ4_NL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-HRR-CODE-TRI-Uncensored-Q5_1",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-HRR-CODE-TRI-Uncensored-Q5_1.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-HRR-CODE-TRI-Uncensored-Q8_0",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-HRR-CODE-TRI-Uncensored-Q8_0.gguf",
        "file_size": "20.5 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-HRR-DI-Uncensored-Q5_1",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-HRR-DI-Uncensored-Q5_1.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-HRR-DI-Uncensored-Q8_0",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-HRR-DI-Uncensored-Q8_0.gguf",
        "file_size": "20.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-HRRPlus-Uncensored-IQ4_NL",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-HRRPlus-Uncensored-IQ4_NL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-Uncensored2-IQ4_NL",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-Uncensored2-IQ4_NL.gguf",
        "file_size": "11.8 GB"
      },
      {
        "model_id": "OpenAI-20B-NEO-Uncensored2-Q5_1",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEO-Uncensored2-Q5_1.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "OpenAI-20B-NEOPlus-Uncensored-IQ4_NL",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEOPlus-Uncensored-IQ4_NL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "OpenAI-20B-NEOPlus-Uncensored-Q5_1",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEOPlus-Uncensored-Q5_1.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "OpenAI-20B-NEOPlus-Uncensored-Q8_0",
        "path": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/OpenAI-20B-NEOPlus-Uncensored-Q8_0.gguf",
        "file_size": "20.6 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf/resolve/main/README.md",
    "description": "An uncensored 20B Mixture of Experts model optimized for coding and creative tasks, available in multiple quantization formats."
  },
  {
    "model_name": "Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF",
    "developer": "DavidAU",
    "downloads": 47732,
    "createdAt": "2024-12-10T13:12:37.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 14,
    "quants": [
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-IQ4_XS",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-IQ4_XS.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q2_k",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q2_k.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q3_k_l",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q3_k_l.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q3_k_m",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q3_k_m.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q3_k_s",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q3_k_s.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_0_4_4",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_0_4_4.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_0_4_8",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_0_4_8.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_0_8_8",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_0_8_8.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_k_m",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_k_m.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_k_s",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_k_s.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q5_k_s",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q5_k_s.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q6_k",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q6_k.gguf",
        "file_size": "14.1 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q8_0.gguf",
        "file_size": "18.2 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-q5_k_m",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-q5_k_m.gguf",
        "file_size": "12.3 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/README.md",
    "description": "Mixture of Experts model combining 8 Llama 3.2 3B models into an 18.4B uncensored creative writing powerhouse optimized for fiction, roleplay, and vivid prose generation."
  },
  {
    "model_name": "LFM2.5-1.2B-Thinking-GGUF",
    "developer": "LiquidAI",
    "downloads": 44227,
    "createdAt": "2026-01-16T19:04:55.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 7,
    "quants": [
      {
        "model_id": "LFM2.5-1.2B-Thinking-BF16",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Thinking-GGUF/resolve/main/LFM2.5-1.2B-Thinking-BF16.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "LFM2.5-1.2B-Thinking-F16",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Thinking-GGUF/resolve/main/LFM2.5-1.2B-Thinking-F16.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "LFM2.5-1.2B-Thinking-Q4_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Thinking-GGUF/resolve/main/LFM2.5-1.2B-Thinking-Q4_0.gguf",
        "file_size": "663.5 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Thinking-Q4_K_M",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Thinking-GGUF/resolve/main/LFM2.5-1.2B-Thinking-Q4_K_M.gguf",
        "file_size": "697.0 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Thinking-Q5_K_M",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Thinking-GGUF/resolve/main/LFM2.5-1.2B-Thinking-Q5_K_M.gguf",
        "file_size": "804.3 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Thinking-Q6_K",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Thinking-GGUF/resolve/main/LFM2.5-1.2B-Thinking-Q6_K.gguf",
        "file_size": "918.2 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Thinking-Q8_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Thinking-GGUF/resolve/main/LFM2.5-1.2B-Thinking-Q8_0.gguf",
        "file_size": "1.2 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/LiquidAI/LFM2.5-1.2B-Thinking-GGUF/resolve/main/README.md",
    "description": "LFM2.5-1.2B-Thinking is a compact 1.2B parameter hybrid AI model by Liquid AI, optimized for on-device deployment and available in GGUF format."
  },
  {
    "model_name": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF",
    "developer": "mradermacher",
    "downloads": 44180,
    "createdAt": "2025-08-03T10:14:21.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 24,
    "quants": [
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ1_M",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ1_M.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ1_S",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ1_S.gguf",
        "file_size": "6.0 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ2_M",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ2_M.gguf",
        "file_size": "9.5 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ2_S",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ2_S.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ2_XS",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ2_XS.gguf",
        "file_size": "8.5 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ2_XXS",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ2_XXS.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ3_M",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ3_M.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ3_S",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ3_S.gguf",
        "file_size": "12.4 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ3_XS",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ3_XS.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ3_XXS",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ3_XXS.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ4_XS",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-IQ4_XS.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q2_K",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q2_K.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q2_K_S",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q2_K_S.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q3_K_L",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q3_K_L.gguf",
        "file_size": "14.8 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q3_K_M",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q3_K_M.gguf",
        "file_size": "13.7 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q3_K_S",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q3_K_S.gguf",
        "file_size": "12.4 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q4_0",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q4_0.gguf",
        "file_size": "16.2 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q4_1",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q4_1.gguf",
        "file_size": "17.9 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q4_K_M",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q4_K_M.gguf",
        "file_size": "17.3 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q4_K_S",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q4_K_S.gguf",
        "file_size": "16.3 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q5_K_M",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q5_K_M.gguf",
        "file_size": "20.2 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q5_K_S",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q5_K_S.gguf",
        "file_size": "19.6 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q6_K",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q6_K.gguf",
        "file_size": "23.4 GB"
      },
      {
        "model_id": "Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.imatrix",
        "path": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.imatrix.gguf",
        "file_size": "116.4 MB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/mradermacher/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF/resolve/main/README.md",
    "description": "GGUF quantized versions of the abliterated Huihui-Qwen3-Coder-30B-A3B-Instruct model in various quantization levels."
  },
  {
    "model_name": "GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF",
    "developer": "TeichAI",
    "downloads": 35910,
    "createdAt": "2026-01-22T18:25:31.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 13,
    "quants": [
      {
        "model_id": "glm-4.7-flash-claude-4.5-opus.bf16",
        "path": "https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF/resolve/main/glm-4.7-flash-claude-4.5-opus.bf16.gguf",
        "file_size": "55.8 GB"
      },
      {
        "model_id": "glm-4.7-flash-claude-4.5-opus.f16",
        "path": "https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF/resolve/main/glm-4.7-flash-claude-4.5-opus.f16.gguf",
        "file_size": "55.8 GB"
      },
      {
        "model_id": "glm-4.7-flash-claude-4.5-opus.iq2_m",
        "path": "https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF/resolve/main/glm-4.7-flash-claude-4.5-opus.iq2_m.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "glm-4.7-flash-claude-4.5-opus.iq3_m",
        "path": "https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF/resolve/main/glm-4.7-flash-claude-4.5-opus.iq3_m.gguf",
        "file_size": "12.3 GB"
      },
      {
        "model_id": "glm-4.7-flash-claude-4.5-opus.iq3_xs",
        "path": "https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF/resolve/main/glm-4.7-flash-claude-4.5-opus.iq3_xs.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "glm-4.7-flash-claude-4.5-opus.iq4_nl",
        "path": "https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF/resolve/main/glm-4.7-flash-claude-4.5-opus.iq4_nl.gguf",
        "file_size": "15.8 GB"
      },
      {
        "model_id": "glm-4.7-flash-claude-4.5-opus.iq4_xs",
        "path": "https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF/resolve/main/glm-4.7-flash-claude-4.5-opus.iq4_xs.gguf",
        "file_size": "14.9 GB"
      },
      {
        "model_id": "glm-4.7-flash-claude-4.5-opus.q3_k_m",
        "path": "https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF/resolve/main/glm-4.7-flash-claude-4.5-opus.q3_k_m.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "glm-4.7-flash-claude-4.5-opus.q3_k_s",
        "path": "https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF/resolve/main/glm-4.7-flash-claude-4.5-opus.q3_k_s.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "glm-4.7-flash-claude-4.5-opus.q4_k_m",
        "path": "https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF/resolve/main/glm-4.7-flash-claude-4.5-opus.q4_k_m.gguf",
        "file_size": "16.9 GB"
      },
      {
        "model_id": "glm-4.7-flash-claude-4.5-opus.q5_k_m",
        "path": "https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF/resolve/main/glm-4.7-flash-claude-4.5-opus.q5_k_m.gguf",
        "file_size": "19.8 GB"
      },
      {
        "model_id": "glm-4.7-flash-claude-4.5-opus.q6_k",
        "path": "https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF/resolve/main/glm-4.7-flash-claude-4.5-opus.q6_k.gguf",
        "file_size": "22.9 GB"
      },
      {
        "model_id": "glm-4.7-flash-claude-4.5-opus.q8_0",
        "path": "https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF/resolve/main/glm-4.7-flash-claude-4.5-opus.q8_0.gguf",
        "file_size": "29.7 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF/resolve/main/README.md",
    "description": "A reasoning-distilled version of GLM-4.7-Flash trained on high-reasoning Claude Opus 4.5 data for coding, science, and research tasks."
  },
  {
    "model_name": "GLM-4.6V-Flash-GGUF",
    "developer": "unsloth",
    "downloads": 28653,
    "createdAt": "2025-12-09T01:24:30.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "GLM-4.6V-Flash-BF16",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-BF16.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-IQ4_NL",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-IQ4_NL.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-IQ4_XS",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-IQ4_XS.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-Q2_K",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-Q2_K.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-Q2_K_L",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-Q2_K_L.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-Q3_K_M",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-Q3_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-Q3_K_S",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-Q3_K_S.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-Q4_0",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-Q4_0.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-Q4_1",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-Q4_1.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-Q4_K_M",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-Q4_K_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-Q4_K_S",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-Q4_K_S.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-Q5_K_M",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-Q5_K_M.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-Q5_K_S",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-Q5_K_S.gguf",
        "file_size": "6.2 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-Q6_K",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-Q6_K.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-Q8_0",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-Q8_0.gguf",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-UD-IQ1_M.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-UD-IQ1_S.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-UD-IQ2_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-UD-IQ2_XXS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-UD-IQ3_XXS.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-UD-Q2_K_XL.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-UD-Q3_K_XL.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-UD-Q4_K_XL.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-UD-Q5_K_XL.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-UD-Q6_K_XL.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "GLM-4.6V-Flash-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-UD-Q8_K_XL.gguf",
        "file_size": "11.2 GB"
      }
    ],
    "num_mmproj": 3,
    "mmproj_models": [
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "3.3 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/README.md",
    "description": "A 9B parameter multimodal vision-language model optimized for local deployment with native function calling and document understanding capabilities."
  },
  {
    "model_name": "gemma-3-27b-it-abliterated-GGUF",
    "developer": "mlabonne",
    "downloads": 26291,
    "createdAt": "2025-03-17T20:35:16.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 6,
    "quants": [
      {
        "model_id": "gemma-3-27b-it-abliterated.q2_k",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/gemma-3-27b-it-abliterated.q2_k.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated.q3_k_m",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/gemma-3-27b-it-abliterated.q3_k_m.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated.q4_k_m",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/gemma-3-27b-it-abliterated.q4_k_m.gguf",
        "file_size": "15.4 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated.q5_k_m",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/gemma-3-27b-it-abliterated.q5_k_m.gguf",
        "file_size": "17.9 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated.q6_k",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/gemma-3-27b-it-abliterated.q6_k.gguf",
        "file_size": "20.6 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated.q8_0",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/gemma-3-27b-it-abliterated.q8_0.gguf",
        "file_size": "26.7 GB"
      }
    ],
    "num_mmproj": 1,
    "mmproj_models": [
      {
        "model_id": "mmproj-mlabonne_gemma-3-27b-it-abliterated-f16",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/mmproj-mlabonne_gemma-3-27b-it-abliterated-f16.gguf",
        "file_size": "818.0 MB"
      }
    ],
    "readme": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/README.md",
    "description": "This is an uncensored, experimental version of the Google Gemma 3 27B IT model, created using a new layerwise abliteration technique to remove refusals."
  },
  {
    "model_name": "MiniCPM-o-4_5-gguf",
    "developer": "openbmb",
    "downloads": 22160,
    "createdAt": "2026-02-02T04:42:00.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 19,
    "quants": [
      {
        "model_id": "MiniCPM-o-4_5-F16",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/MiniCPM-o-4_5-F16.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "MiniCPM-o-4_5-Q4_0",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/MiniCPM-o-4_5-Q4_0.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "MiniCPM-o-4_5-Q4_1",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/MiniCPM-o-4_5-Q4_1.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "MiniCPM-o-4_5-Q4_K_M",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/MiniCPM-o-4_5-Q4_K_M.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "MiniCPM-o-4_5-Q4_K_S",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/MiniCPM-o-4_5-Q4_K_S.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "MiniCPM-o-4_5-Q5_0",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/MiniCPM-o-4_5-Q5_0.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "MiniCPM-o-4_5-Q5_1",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/MiniCPM-o-4_5-Q5_1.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "MiniCPM-o-4_5-Q5_K_M",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/MiniCPM-o-4_5-Q5_K_M.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "MiniCPM-o-4_5-Q5_K_S",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/MiniCPM-o-4_5-Q5_K_S.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "MiniCPM-o-4_5-Q6_K",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/MiniCPM-o-4_5-Q6_K.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "MiniCPM-o-4_5-Q8_0",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/MiniCPM-o-4_5-Q8_0.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "audio/MiniCPM-o-4_5-audio-F16",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/audio/MiniCPM-o-4_5-audio-F16.gguf",
        "file_size": "629.6 MB"
      },
      {
        "model_id": "token2wav-gguf/flow_extra",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/token2wav-gguf/flow_extra.gguf",
        "file_size": "13.0 MB"
      },
      {
        "model_id": "token2wav-gguf/flow_matching",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/token2wav-gguf/flow_matching.gguf",
        "file_size": "437.0 MB"
      },
      {
        "model_id": "token2wav-gguf/hifigan2",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/token2wav-gguf/hifigan2.gguf",
        "file_size": "79.4 MB"
      },
      {
        "model_id": "token2wav-gguf/prompt_cache",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/token2wav-gguf/prompt_cache.gguf",
        "file_size": "201.8 MB"
      },
      {
        "model_id": "tts/MiniCPM-o-4_5-projector-F16",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/tts/MiniCPM-o-4_5-projector-F16.gguf",
        "file_size": "14.3 MB"
      },
      {
        "model_id": "tts/MiniCPM-o-4_5-tts-F16",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/tts/MiniCPM-o-4_5-tts-F16.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "vision/MiniCPM-o-4_5-vision-F16",
        "path": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/vision/MiniCPM-o-4_5-vision-F16.gguf",
        "file_size": "1.0 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf/resolve/main/README.md",
    "description": "A 9B parameter multimodal AI model for vision, speech, and full-duplex live streaming on phones."
  },
  {
    "model_name": "L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix",
    "developer": "Lewdiculous",
    "downloads": 16947,
    "createdAt": "2024-06-05T18:21:00.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 12,
    "quants": [
      {
        "model_id": "L3-8B-Stheno-v3.2-IQ3_M-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-IQ3_M-imat.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-IQ3_S-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-IQ3_S-imat.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-IQ3_XXS-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-IQ3_XXS-imat.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-IQ4_XS-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-IQ4_XS-imat.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-Q4_K_M-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-Q4_K_M-imat.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-Q4_K_S-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-Q4_K_S-imat.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-Q5_K_M-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-Q5_K_M-imat.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-Q5_K_S-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-Q5_K_S-imat.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-Q6_K-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-Q6_K-imat.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-Q8_0-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-Q8_0-imat.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "[ARM-Friendly]-L3-8B-Stheno-v3.2-Q4_0-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/[ARM-Friendly]-L3-8B-Stheno-v3.2-Q4_0-imat.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "test",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/test.gguf",
        "file_size": "4.6 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/README.md",
    "description": "GGUF-IQ-Imatrix quantized version of Sao10K/L3-8B-Stheno-v3.2 for roleplay with SillyTavern, optimized for 8GB VRAM GPUs using Q4_K_M-imat quant."
  },
  {
    "model_name": "gemma-3-12b-it-heretic",
    "developer": "DreamFast",
    "downloads": 13636,
    "createdAt": "2026-01-11T02:40:55.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 8,
    "quants": [
      {
        "model_id": "gguf/gemma-3-12b-it-heretic-Q3_K_M",
        "path": "https://huggingface.co/DreamFast/gemma-3-12b-it-heretic/resolve/main/gguf/gemma-3-12b-it-heretic-Q3_K_M.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "gguf/gemma-3-12b-it-heretic-Q4_K_M",
        "path": "https://huggingface.co/DreamFast/gemma-3-12b-it-heretic/resolve/main/gguf/gemma-3-12b-it-heretic-Q4_K_M.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "gguf/gemma-3-12b-it-heretic-Q4_K_S",
        "path": "https://huggingface.co/DreamFast/gemma-3-12b-it-heretic/resolve/main/gguf/gemma-3-12b-it-heretic-Q4_K_S.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "gguf/gemma-3-12b-it-heretic-Q5_K_M",
        "path": "https://huggingface.co/DreamFast/gemma-3-12b-it-heretic/resolve/main/gguf/gemma-3-12b-it-heretic-Q5_K_M.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "gguf/gemma-3-12b-it-heretic-Q5_K_S",
        "path": "https://huggingface.co/DreamFast/gemma-3-12b-it-heretic/resolve/main/gguf/gemma-3-12b-it-heretic-Q5_K_S.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "gguf/gemma-3-12b-it-heretic-Q6_K",
        "path": "https://huggingface.co/DreamFast/gemma-3-12b-it-heretic/resolve/main/gguf/gemma-3-12b-it-heretic-Q6_K.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "gguf/gemma-3-12b-it-heretic-Q8_0",
        "path": "https://huggingface.co/DreamFast/gemma-3-12b-it-heretic/resolve/main/gguf/gemma-3-12b-it-heretic-Q8_0.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "gguf/gemma-3-12b-it-heretic-f16",
        "path": "https://huggingface.co/DreamFast/gemma-3-12b-it-heretic/resolve/main/gguf/gemma-3-12b-it-heretic-f16.gguf",
        "file_size": "21.9 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/DreamFast/gemma-3-12b-it-heretic/resolve/main/README.md",
    "description": "An abliterated (uncensored) Google Gemma 3 12B IT model optimized for LTX-2 video generation, with significantly reduced refusals."
  },
  {
    "model_name": "gemma-3-4b-it-uncensored-v2-GGUF",
    "developer": "Andycurrent",
    "downloads": 13529,
    "createdAt": "2026-01-06T07:47:19.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 7,
    "quants": [
      {
        "model_id": "gemma-3-4b-it-uncensored-v2_F16",
        "path": "https://huggingface.co/Andycurrent/gemma-3-4b-it-uncensored-v2-GGUF/resolve/main/gemma-3-4b-it-uncensored-v2_F16.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "gemma-3-4b-it-uncensored-v2_Q2_K",
        "path": "https://huggingface.co/Andycurrent/gemma-3-4b-it-uncensored-v2-GGUF/resolve/main/gemma-3-4b-it-uncensored-v2_Q2_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-uncensored-v2_Q3_K_M",
        "path": "https://huggingface.co/Andycurrent/gemma-3-4b-it-uncensored-v2-GGUF/resolve/main/gemma-3-4b-it-uncensored-v2_Q3_K_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "gemma-3-4b-it-uncensored-v2_Q4_K_M",
        "path": "https://huggingface.co/Andycurrent/gemma-3-4b-it-uncensored-v2-GGUF/resolve/main/gemma-3-4b-it-uncensored-v2_Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "gemma-3-4b-it-uncensored-v2_Q5_K_M",
        "path": "https://huggingface.co/Andycurrent/gemma-3-4b-it-uncensored-v2-GGUF/resolve/main/gemma-3-4b-it-uncensored-v2_Q5_K_M.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-uncensored-v2_Q6_K",
        "path": "https://huggingface.co/Andycurrent/gemma-3-4b-it-uncensored-v2-GGUF/resolve/main/gemma-3-4b-it-uncensored-v2_Q6_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "gemma-3-4b-it-uncensored-v2_Q8_0",
        "path": "https://huggingface.co/Andycurrent/gemma-3-4b-it-uncensored-v2-GGUF/resolve/main/gemma-3-4b-it-uncensored-v2_Q8_0.gguf",
        "file_size": "3.8 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Andycurrent/gemma-3-4b-it-uncensored-v2-GGUF/resolve/main/README.md",
    "description": "A 4B parameter instruction-tuned model designed for local/private use with minimal alignment restrictions."
  },
  {
    "model_name": "Ministral-3-3B-Instruct-2512-GGUF",
    "developer": "mistralai",
    "downloads": 12489,
    "createdAt": "2025-10-31T08:45:13.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 5,
    "quants": [
      {
        "model_id": "Ministral-3-3B-Instruct-2512-BF16-mmproj",
        "path": "https://huggingface.co/mistralai/Ministral-3-3B-Instruct-2512-GGUF/resolve/main/Ministral-3-3B-Instruct-2512-BF16-mmproj.gguf",
        "file_size": "802.5 MB"
      },
      {
        "model_id": "Ministral-3-3B-Instruct-2512-BF16",
        "path": "https://huggingface.co/mistralai/Ministral-3-3B-Instruct-2512-GGUF/resolve/main/Ministral-3-3B-Instruct-2512-BF16.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "Ministral-3-3B-Instruct-2512-Q4_K_M",
        "path": "https://huggingface.co/mistralai/Ministral-3-3B-Instruct-2512-GGUF/resolve/main/Ministral-3-3B-Instruct-2512-Q4_K_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Ministral-3-3B-Instruct-2512-Q5_K_M",
        "path": "https://huggingface.co/mistralai/Ministral-3-3B-Instruct-2512-GGUF/resolve/main/Ministral-3-3B-Instruct-2512-Q5_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Ministral-3-3B-Instruct-2512-Q8_0",
        "path": "https://huggingface.co/mistralai/Ministral-3-3B-Instruct-2512-GGUF/resolve/main/Ministral-3-3B-Instruct-2512-Q8_0.gguf",
        "file_size": "3.4 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/mistralai/Ministral-3-3B-Instruct-2512-GGUF/resolve/main/README.md",
    "description": "A small, efficient edge-optimized vision language model with multilingual and agentic capabilities, quantized in GGUF format."
  },
  {
    "model_name": "Kimi-Linear-48B-A3B-Instruct-GGUF",
    "developer": "ymcki",
    "downloads": 12158,
    "createdAt": "2025-12-18T00:01:46.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 6,
    "quants": [
      {
        "model_id": "Kimi-Linear-48B-A3B-Instruct-jp-imatrix.IQ3_M",
        "path": "https://huggingface.co/ymcki/Kimi-Linear-48B-A3B-Instruct-GGUF/resolve/main/Kimi-Linear-48B-A3B-Instruct-jp-imatrix.IQ3_M.gguf",
        "file_size": "20.1 GB"
      },
      {
        "model_id": "Kimi-Linear-48B-A3B-Instruct-jp-imatrix.IQ4_XS",
        "path": "https://huggingface.co/ymcki/Kimi-Linear-48B-A3B-Instruct-GGUF/resolve/main/Kimi-Linear-48B-A3B-Instruct-jp-imatrix.IQ4_XS.gguf",
        "file_size": "24.5 GB"
      },
      {
        "model_id": "Kimi-Linear-48B-A3B-Instruct-jp-imatrix.Q2_K",
        "path": "https://huggingface.co/ymcki/Kimi-Linear-48B-A3B-Instruct-GGUF/resolve/main/Kimi-Linear-48B-A3B-Instruct-jp-imatrix.Q2_K.gguf",
        "file_size": "16.8 GB"
      },
      {
        "model_id": "Kimi-Linear-48B-A3B-Instruct-jp-imatrix.Q4_K_M",
        "path": "https://huggingface.co/ymcki/Kimi-Linear-48B-A3B-Instruct-GGUF/resolve/main/Kimi-Linear-48B-A3B-Instruct-jp-imatrix.Q4_K_M.gguf",
        "file_size": "27.7 GB"
      },
      {
        "model_id": "Kimi-Linear-48B-A3B-Instruct-jp-imatrix.Q5_K_M",
        "path": "https://huggingface.co/ymcki/Kimi-Linear-48B-A3B-Instruct-GGUF/resolve/main/Kimi-Linear-48B-A3B-Instruct-jp-imatrix.Q5_K_M.gguf",
        "file_size": "32.5 GB"
      },
      {
        "model_id": "Kimi-Linear-48B-A3B-Instruct.MXFP4_MOE",
        "path": "https://huggingface.co/ymcki/Kimi-Linear-48B-A3B-Instruct-GGUF/resolve/main/Kimi-Linear-48B-A3B-Instruct.MXFP4_MOE.gguf",
        "file_size": "25.3 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/ymcki/Kimi-Linear-48B-A3B-Instruct-GGUF/resolve/main/README.md",
    "description": "Experimental GGUF quantizations of Kimi-Linear-48B-A3B-Instruct with various formats optimized for different VRAM sizes and Japanese performance."
  },
  {
    "model_name": "GLM-4.7-Flash-MXFP4_MOE-GGUF",
    "developer": "noctrex",
    "downloads": 12097,
    "createdAt": "2026-01-19T22:07:24.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "GLM-4.7-Flash-MXFP4_MOE",
        "path": "https://huggingface.co/noctrex/GLM-4.7-Flash-MXFP4_MOE-GGUF/resolve/main/GLM-4.7-Flash-MXFP4_MOE.gguf",
        "file_size": "16.1 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/noctrex/GLM-4.7-Flash-MXFP4_MOE-GGUF/resolve/main/README.md",
    "description": "This is a MXFP4_MOE quantized GGUF version of the GLM-4.7-Flash model, updated for the latest llama.cpp."
  },
  {
    "model_name": "Ministral-3-8B-Instruct-2512-GGUF",
    "developer": "unsloth",
    "downloads": 11391,
    "createdAt": "2025-12-02T12:53:08.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "Ministral-3-8B-Instruct-2512-BF16",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-BF16.gguf",
        "file_size": "15.8 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-IQ4_NL.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-IQ4_XS.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-Q2_K",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-Q2_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-Q2_K_L.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-Q3_K_M.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-Q3_K_S.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-Q4_0",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-Q4_0.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-Q4_1",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-Q4_1.gguf",
        "file_size": "5.0 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-Q4_K_M.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-Q4_K_S.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-Q5_K_M.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-Q5_K_S.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-Q6_K",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-Q6_K.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-Q8_0",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-Q8_0.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-UD-IQ1_M.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-UD-IQ1_S.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-UD-IQ2_M.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-UD-IQ2_XXS.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-UD-IQ3_XXS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-UD-Q2_K_XL.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-UD-Q3_K_XL.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-UD-Q4_K_XL.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-UD-Q5_K_XL.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-UD-Q6_K_XL.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "Ministral-3-8B-Instruct-2512-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/Ministral-3-8B-Instruct-2512-UD-Q8_K_XL.gguf",
        "file_size": "10.3 GB"
      }
    ],
    "num_mmproj": 3,
    "mmproj_models": [
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "818.5 MB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "817.4 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF/resolve/main/README.md",
    "description": "A compact 8.4B parameter vision-language model optimized for edge deployment with multilingual support, agentic capabilities, and a 256k context window, available under Apache 2.0 license."
  },
  {
    "model_name": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF",
    "developer": "mradermacher",
    "downloads": 10512,
    "createdAt": "2026-02-02T16:43:20.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 25,
    "quants": [
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ1_M",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ1_M.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ1_S",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ1_S.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ2_M",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ2_M.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ2_S",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ2_S.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ2_XS",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ2_XS.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ2_XXS",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ2_XXS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ3_M",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ3_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ3_S",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ3_S.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ3_XS",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ3_XS.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ3_XXS",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ3_XXS.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ4_NL",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ4_NL.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ4_XS",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-IQ4_XS.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q2_K",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q2_K.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q2_K_S",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q2_K_S.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q3_K_L",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q3_K_L.gguf",
        "file_size": "6.0 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q3_K_M",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q3_K_M.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q3_K_S",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q3_K_S.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q4_0",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q4_0.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q4_1",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q4_1.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q4_K_M",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q4_K_M.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q4_K_S",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q4_K_S.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q5_K_M",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q5_K_M.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q5_K_S",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q5_K_S.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q6_K",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.i1-Q6_K.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.imatrix",
        "path": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking.imatrix.gguf",
        "file_size": "7.1 MB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/mradermacher/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking-i1-GGUF/resolve/main/README.md",
    "description": "GGUF quantized files for an uncensored vision language model focused on creative writing."
  },
  {
    "model_name": "Qwen3-4b-Z-Image-Turbo-AbliteratedV1",
    "developer": "BennyDaBall",
    "downloads": 9897,
    "createdAt": "2026-01-28T01:40:20.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 8,
    "quants": [
      {
        "model_id": "Z-Image-AbliteratedV1.Q2_K",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Turbo-AbliteratedV1/resolve/main/Z-Image-AbliteratedV1.Q2_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Z-Image-AbliteratedV1.Q3_K_M",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Turbo-AbliteratedV1/resolve/main/Z-Image-AbliteratedV1.Q3_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Z-Image-AbliteratedV1.Q4_K_M",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Turbo-AbliteratedV1/resolve/main/Z-Image-AbliteratedV1.Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Z-Image-AbliteratedV1.Q4_K_S",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Turbo-AbliteratedV1/resolve/main/Z-Image-AbliteratedV1.Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Z-Image-AbliteratedV1.Q5_K_M",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Turbo-AbliteratedV1/resolve/main/Z-Image-AbliteratedV1.Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Z-Image-AbliteratedV1.Q6_K",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Turbo-AbliteratedV1/resolve/main/Z-Image-AbliteratedV1.Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Z-Image-AbliteratedV1.Q8_0",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Turbo-AbliteratedV1/resolve/main/Z-Image-AbliteratedV1.Q8_0.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Z-Image-AbliteratedV1.f16",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Turbo-AbliteratedV1/resolve/main/Z-Image-AbliteratedV1.f16.gguf",
        "file_size": "7.5 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Turbo-AbliteratedV1/resolve/main/README.md",
    "description": "An abliterated (censorship-removed) version of the Qwen3-4b-Z-Image-Turbo text encoder for unrestricted image generation."
  },
  {
    "model_name": "LFM2.5-Audio-1.5B-GGUF",
    "developer": "LiquidAI",
    "downloads": 9658,
    "createdAt": "2026-01-06T01:39:14.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 9,
    "quants": [
      {
        "model_id": "LFM2.5-Audio-1.5B-F16",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-Audio-1.5B-GGUF/resolve/main/LFM2.5-Audio-1.5B-F16.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "LFM2.5-Audio-1.5B-Q4_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-Audio-1.5B-GGUF/resolve/main/LFM2.5-Audio-1.5B-Q4_0.gguf",
        "file_size": "663.5 MB"
      },
      {
        "model_id": "LFM2.5-Audio-1.5B-Q8_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-Audio-1.5B-GGUF/resolve/main/LFM2.5-Audio-1.5B-Q8_0.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "tokenizer-LFM2.5-Audio-1.5B-F16",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-Audio-1.5B-GGUF/resolve/main/tokenizer-LFM2.5-Audio-1.5B-F16.gguf",
        "file_size": "136.1 MB"
      },
      {
        "model_id": "tokenizer-LFM2.5-Audio-1.5B-Q4_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-Audio-1.5B-GGUF/resolve/main/tokenizer-LFM2.5-Audio-1.5B-Q4_0.gguf",
        "file_size": "48.2 MB"
      },
      {
        "model_id": "tokenizer-LFM2.5-Audio-1.5B-Q8_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-Audio-1.5B-GGUF/resolve/main/tokenizer-LFM2.5-Audio-1.5B-Q8_0.gguf",
        "file_size": "73.4 MB"
      },
      {
        "model_id": "vocoder-LFM2.5-Audio-1.5B-F16",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-Audio-1.5B-GGUF/resolve/main/vocoder-LFM2.5-Audio-1.5B-F16.gguf",
        "file_size": "369.2 MB"
      },
      {
        "model_id": "vocoder-LFM2.5-Audio-1.5B-Q4_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-Audio-1.5B-GGUF/resolve/main/vocoder-LFM2.5-Audio-1.5B-Q4_0.gguf",
        "file_size": "103.9 MB"
      },
      {
        "model_id": "vocoder-LFM2.5-Audio-1.5B-Q8_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-Audio-1.5B-GGUF/resolve/main/vocoder-LFM2.5-Audio-1.5B-Q8_0.gguf",
        "file_size": "196.2 MB"
      }
    ],
    "num_mmproj": 3,
    "mmproj_models": [
      {
        "model_id": "mmproj-LFM2.5-Audio-1.5B-F16",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-Audio-1.5B-GGUF/resolve/main/mmproj-LFM2.5-Audio-1.5B-F16.gguf",
        "file_size": "437.6 MB"
      },
      {
        "model_id": "mmproj-LFM2.5-Audio-1.5B-Q4_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-Audio-1.5B-GGUF/resolve/main/mmproj-LFM2.5-Audio-1.5B-Q4_0.gguf",
        "file_size": "209.3 MB"
      },
      {
        "model_id": "mmproj-LFM2.5-Audio-1.5B-Q8_0",
        "path": "https://huggingface.co/LiquidAI/LFM2.5-Audio-1.5B-GGUF/resolve/main/mmproj-LFM2.5-Audio-1.5B-Q8_0.gguf",
        "file_size": "279.8 MB"
      }
    ],
    "readme": "https://huggingface.co/LiquidAI/LFM2.5-Audio-1.5B-GGUF/resolve/main/README.md",
    "description": "LFM2.5-Audio-1.5B is a 1.5B parameter audio model by Liquid AI supporting ASR, TTS, and interleaved audio/text processing via CLI and server runners."
  },
  {
    "model_name": "Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF",
    "developer": "noctrex",
    "downloads": 9308,
    "createdAt": "2025-11-02T00:53:26.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 15,
    "quants": [
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-BF16",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-BF16.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-F16",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-F16.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-IQ3_M",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-IQ3_M.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-IQ3_S",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-IQ3_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-IQ3_XS",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-IQ3_XS.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-IQ3_XXS",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-IQ3_XXS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-IQ4_NL",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-IQ4_NL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-IQ4_XS",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-IQ4_XS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-MXFP4",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-MXFP4.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-Q4_K_M",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-Q4_K_S",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-Q5_K_M",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-Q5_K_S",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-Q6_K",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-4B-Instruct-abliterated-Q8_0",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-4B-Instruct-abliterated-Q8_0.gguf",
        "file_size": "4.0 GB"
      }
    ],
    "num_mmproj": 3,
    "mmproj_models": [
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "800.4 MB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "797.4 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.5 GB"
      }
    ],
    "readme": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF/resolve/main/README.md",
    "description": "Quantized 4B vision-language model with recommendations to use latest llama.cpp and F32 mmproj for best results."
  },
  {
    "model_name": "Meta-Llama-3.1-8B-Instruct-abliterated-GGUF",
    "developer": "mlabonne",
    "downloads": 8902,
    "createdAt": "2024-07-24T22:44:19.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 7,
    "quants": [
      {
        "model_id": "meta-llama-3.1-8b-instruct-abliterated.Q2_K",
        "path": "https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/meta-llama-3.1-8b-instruct-abliterated.Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "meta-llama-3.1-8b-instruct-abliterated.Q3_K_M",
        "path": "https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/meta-llama-3.1-8b-instruct-abliterated.Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "meta-llama-3.1-8b-instruct-abliterated.Q4_K_M",
        "path": "https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/meta-llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "meta-llama-3.1-8b-instruct-abliterated.Q5_K_M",
        "path": "https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/meta-llama-3.1-8b-instruct-abliterated.Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "meta-llama-3.1-8b-instruct-abliterated.Q6_K",
        "path": "https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/meta-llama-3.1-8b-instruct-abliterated.Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "meta-llama-3.1-8b-instruct-abliterated.Q8_0",
        "path": "https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/meta-llama-3.1-8b-instruct-abliterated.Q8_0.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "meta-llama-3.1-8b-instruct-abliterated.bf16",
        "path": "https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/meta-llama-3.1-8b-instruct-abliterated.bf16.gguf",
        "file_size": "15.0 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/README.md",
    "description": "Uncensored abliterated version of Meta-Llama-3.1-8B-Instruct."
  },
  {
    "model_name": "Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC-GGUF",
    "developer": "mradermacher",
    "downloads": 8604,
    "createdAt": "2026-01-10T02:24:48.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 11,
    "quants": [
      {
        "model_id": "Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.IQ4_XS",
        "path": "https://huggingface.co/mradermacher/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC-GGUF/resolve/main/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.IQ4_XS.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q2_K",
        "path": "https://huggingface.co/mradermacher/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC-GGUF/resolve/main/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q2_K.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q3_K_L",
        "path": "https://huggingface.co/mradermacher/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC-GGUF/resolve/main/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q3_K_L.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q3_K_M",
        "path": "https://huggingface.co/mradermacher/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC-GGUF/resolve/main/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q3_K_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q3_K_S",
        "path": "https://huggingface.co/mradermacher/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC-GGUF/resolve/main/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q3_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q4_K_M",
        "path": "https://huggingface.co/mradermacher/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC-GGUF/resolve/main/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q4_K_M.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q4_K_S",
        "path": "https://huggingface.co/mradermacher/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC-GGUF/resolve/main/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q4_K_S.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q5_K_M",
        "path": "https://huggingface.co/mradermacher/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC-GGUF/resolve/main/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q5_K_M.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q5_K_S",
        "path": "https://huggingface.co/mradermacher/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC-GGUF/resolve/main/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q5_K_S.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q6_K",
        "path": "https://huggingface.co/mradermacher/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC-GGUF/resolve/main/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q6_K.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q8_0",
        "path": "https://huggingface.co/mradermacher/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC-GGUF/resolve/main/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC.Q8_0.gguf",
        "file_size": "12.1 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/mradermacher/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC-GGUF/resolve/main/README.md",
    "description": "A quantized GGUF version of Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC, an uncensored creative writing model with multiple quantization options (Q2_K to Q8_0) ranging from 4.9GB to 13.1GB."
  },
  {
    "model_name": "GLM-4.7-Flash-Derestricted-i1-GGUF",
    "developer": "mradermacher",
    "downloads": 8390,
    "createdAt": "2026-01-26T06:17:45.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 24,
    "quants": [
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-IQ1_M",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-IQ1_M.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-IQ1_S",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-IQ1_S.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-IQ2_M",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-IQ2_M.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-IQ2_S",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-IQ2_S.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-IQ2_XS",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-IQ2_XS.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-IQ2_XXS",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-IQ2_XXS.gguf",
        "file_size": "7.4 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-IQ3_M",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-IQ3_M.gguf",
        "file_size": "12.3 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-IQ3_S",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-IQ3_S.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-IQ3_XS",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-IQ3_XS.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-IQ3_XXS",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-IQ3_XXS.gguf",
        "file_size": "10.8 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-IQ4_XS",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-IQ4_XS.gguf",
        "file_size": "14.9 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-Q2_K",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-Q2_K.gguf",
        "file_size": "10.3 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-Q2_K_S",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-Q2_K_S.gguf",
        "file_size": "9.5 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-Q3_K_L",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-Q3_K_L.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-Q3_K_M",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-Q3_K_M.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-Q3_K_S",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-Q3_K_S.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-Q4_0",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-Q4_0.gguf",
        "file_size": "15.8 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-Q4_1",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-Q4_1.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-Q4_K_M",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-Q4_K_M.gguf",
        "file_size": "16.9 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-Q4_K_S",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-Q4_K_S.gguf",
        "file_size": "15.9 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-Q5_K_M",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-Q5_K_M.gguf",
        "file_size": "19.8 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-Q5_K_S",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-Q5_K_S.gguf",
        "file_size": "19.2 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.i1-Q6_K",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.i1-Q6_K.gguf",
        "file_size": "22.9 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Derestricted.imatrix",
        "path": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/GLM-4.7-Flash-Derestricted.imatrix.gguf",
        "file_size": "69.1 MB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/mradermacher/GLM-4.7-Flash-Derestricted-i1-GGUF/resolve/main/README.md",
    "description": "GGUF quantizations of the derestricted GLM-4.7-Flash model in various sizes (6.3-24.7GB)."
  },
  {
    "model_name": "gemma-3-12b-it-qat-q4_0-gguf",
    "developer": "google",
    "downloads": 8228,
    "createdAt": "2025-03-12T12:32:41.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "gemma-3-12b-it-q4_0",
        "path": "https://huggingface.co/google/gemma-3-12b-it-qat-q4_0-gguf/resolve/main/gemma-3-12b-it-q4_0.gguf",
        "file_size": "7.5 GB"
      }
    ],
    "num_mmproj": 1,
    "mmproj_models": [
      {
        "model_id": "mmproj-model-f16-12B",
        "path": "https://huggingface.co/google/gemma-3-12b-it-qat-q4_0-gguf/resolve/main/mmproj-model-f16-12B.gguf",
        "file_size": "814.6 MB"
      }
    ],
    "readme": "https://huggingface.co/google/gemma-3-12b-it-qat-q4_0-gguf/resolve/main/README.md",
    "description": "Google's Gemma 3 is a family of lightweight, state-of-the-art open multimodal models (text and image) ranging from 1B to 27B parameters, featuring a large context window and multilingual support, provided in this repository in efficient GGUF format."
  },
  {
    "model_name": "bitnet-b1.58-2B-4T-gguf",
    "developer": "microsoft",
    "downloads": 8144,
    "createdAt": "2025-04-15T04:25:42.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "ggml-model-i2_s",
        "path": "https://huggingface.co/microsoft/bitnet-b1.58-2B-4T-gguf/resolve/main/ggml-model-i2_s.gguf",
        "file_size": "1.1 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/microsoft/bitnet-b1.58-2B-4T-gguf/resolve/main/README.md",
    "description": "Microsoft's 2-billion parameter native 1-bit LLM trained on 4T tokens, achieving comparable performance to full-precision models with significantly better memory, latency, and energy efficiency."
  },
  {
    "model_name": "Lexi-Llama-3-8B-Uncensored-GGUF",
    "developer": "bartowski",
    "downloads": 7267,
    "createdAt": "2024-04-24T03:51:21.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 22,
    "quants": [
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ1_M",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ1_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ1_S",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ1_S.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ2_M",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ2_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ2_S",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ2_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ2_XS",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ2_XS.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ2_XXS",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ2_XXS.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ3_M",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ3_M.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ3_S",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ3_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ3_XS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ3_XXS.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ4_NL",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ4_NL.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ4_XS.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q2_K",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q6_K",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q8_0",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q8_0.gguf",
        "file_size": "8.0 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/README.md",
    "description": "Quantized GGUF versions of Lexi-Llama-3-8B-Uncensored model in various compression levels."
  },
  {
    "model_name": "Qwen3-4b-Z-Image-Engineer-V2.5",
    "developer": "BennyDaBall",
    "downloads": 7090,
    "createdAt": "2026-01-17T18:05:32.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 6,
    "quants": [
      {
        "model_id": "Z-Engineer-2.5-Q4_K_M",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V2.5/resolve/main/Z-Engineer-2.5-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Z-Engineer-2.5-Q4_K_S",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V2.5/resolve/main/Z-Engineer-2.5-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Z-Engineer-2.5-Q5_K_M",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V2.5/resolve/main/Z-Engineer-2.5-Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Z-Engineer-2.5-Q6_K",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V2.5/resolve/main/Z-Engineer-2.5-Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Z-Engineer-2.5-Q8_0",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V2.5/resolve/main/Z-Engineer-2.5-Q8_0.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Z-Engineer-2.5",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V2.5/resolve/main/Z-Engineer-2.5.gguf",
        "file_size": "7.5 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V2.5/resolve/main/README.md",
    "description": "Z-Engineer V2.5 is a 4B parameter model that enhances image generation prompts and serves as a CLIP text encoder for Z-Image-Turbo workflows."
  },
  {
    "model_name": "qwen3-4b-Z-Image-Engineer",
    "developer": "BennyDaBall",
    "downloads": 7077,
    "createdAt": "2025-12-12T15:41:02.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 6,
    "quants": [
      {
        "model_id": "Models/Qwen3-4b-Z-Engineer-V2-Q4_K_M",
        "path": "https://huggingface.co/BennyDaBall/qwen3-4b-Z-Image-Engineer/resolve/main/Models/Qwen3-4b-Z-Engineer-V2-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Models/Qwen3-4b-Z-Engineer-V2-Q5_K_M",
        "path": "https://huggingface.co/BennyDaBall/qwen3-4b-Z-Image-Engineer/resolve/main/Models/Qwen3-4b-Z-Engineer-V2-Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Models/Qwen3-4b-Z-Engineer-V2-Q6_K",
        "path": "https://huggingface.co/BennyDaBall/qwen3-4b-Z-Image-Engineer/resolve/main/Models/Qwen3-4b-Z-Engineer-V2-Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Models/Qwen3-4b-Z-Engineer-V2-Q8_0",
        "path": "https://huggingface.co/BennyDaBall/qwen3-4b-Z-Image-Engineer/resolve/main/Models/Qwen3-4b-Z-Engineer-V2-Q8_0.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Qwen3-4b-Z-Engineer-V2",
        "path": "https://huggingface.co/BennyDaBall/qwen3-4b-Z-Image-Engineer/resolve/main/Qwen3-4b-Z-Engineer-V2.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "qwen3-4b-Z-Image-Engineer_v1-f16",
        "path": "https://huggingface.co/BennyDaBall/qwen3-4b-Z-Image-Engineer/resolve/main/qwen3-4b-Z-Image-Engineer_v1-f16.gguf",
        "file_size": "7.5 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/BennyDaBall/qwen3-4b-Z-Image-Engineer/resolve/main/README.md",
    "description": "Qwen3-4b fine-tuned to transform simple image concepts into detailed, vivid prompts for image generation, available in GGUF/MLX quantizations with ComfyUI integration."
  },
  {
    "model_name": "Qwen3-30B-A3B-GGUF",
    "developer": "Qwen",
    "downloads": 6974,
    "createdAt": "2025-05-05T08:38:52.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 5,
    "quants": [
      {
        "model_id": "Qwen3-30B-A3B-Q4_K_M",
        "path": "https://huggingface.co/Qwen/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q4_K_M.gguf",
        "file_size": "17.3 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q5_0",
        "path": "https://huggingface.co/Qwen/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q5_0.gguf",
        "file_size": "19.6 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q5_K_M",
        "path": "https://huggingface.co/Qwen/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q5_K_M.gguf",
        "file_size": "20.2 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q6_K",
        "path": "https://huggingface.co/Qwen/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q6_K.gguf",
        "file_size": "23.4 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q8_0",
        "path": "https://huggingface.co/Qwen/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q8_0.gguf",
        "file_size": "30.3 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Qwen/Qwen3-30B-A3B-GGUF/resolve/main/README.md",
    "description": "A 30B parameter Mixture of Experts language model with switchable thinking modes for complex reasoning tasks."
  },
  {
    "model_name": "Llama-OuteTTS-1.0-1B-GGUF",
    "developer": "OuteAI",
    "downloads": 6735,
    "createdAt": "2025-04-06T19:18:26.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 15,
    "quants": [
      {
        "model_id": "Llama-OuteTTS-1.0-1B-FP16",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-FP16.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q2_K",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q2_K.gguf",
        "file_size": "564.0 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q3_K_L",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q3_K_L.gguf",
        "file_size": "708.6 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q3_K_M",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q3_K_M.gguf",
        "file_size": "668.8 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q3_K_S",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q3_K_S.gguf",
        "file_size": "622.0 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q4_0",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q4_0.gguf",
        "file_size": "745.2 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q4_1",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q4_1.gguf",
        "file_size": "803.2 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q4_K_M",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q4_K_M.gguf",
        "file_size": "780.3 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q4_K_S",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q4_K_S.gguf",
        "file_size": "749.7 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q5_0",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q5_0.gguf",
        "file_size": "861.2 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q5_1",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q5_1.gguf",
        "file_size": "919.2 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q5_K_M",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q5_K_M.gguf",
        "file_size": "879.3 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q5_K_S",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q5_K_S.gguf",
        "file_size": "861.2 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q6_K",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q6_K.gguf",
        "file_size": "984.5 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q8_0",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q8_0.gguf",
        "file_size": "1.2 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/README.md",
    "description": "Multilingual TTS model with one-shot voice cloning."
  },
  {
    "model_name": "MiniMax-M2.1-PRISM",
    "developer": "Ex0bit",
    "downloads": 6483,
    "createdAt": "2026-01-01T21:12:13.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 3,
    "quants": [
      {
        "model_id": "MiniMax-M2.1-PRISM-IQ2_M",
        "path": "https://huggingface.co/Ex0bit/MiniMax-M2.1-PRISM/resolve/main/MiniMax-M2.1-PRISM-IQ2_M.gguf",
        "file_size": "69.7 GB"
      },
      {
        "model_id": "MiniMax-M2.1-PRISM-IQ4_NL",
        "path": "https://huggingface.co/Ex0bit/MiniMax-M2.1-PRISM/resolve/main/MiniMax-M2.1-PRISM-IQ4_NL.gguf",
        "file_size": "120.1 GB"
      },
      {
        "model_id": "minimax-m2.1-PRISM-IQ1_S",
        "path": "https://huggingface.co/Ex0bit/MiniMax-M2.1-PRISM/resolve/main/minimax-m2.1-PRISM-IQ1_S.gguf",
        "file_size": "43.3 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Ex0bit/MiniMax-M2.1-PRISM/resolve/main/README.md",
    "description": "An uncensored, abliterated 229B parameter MoE language model for AI safety research, removing refusal behaviors while preserving capabilities."
  },
  {
    "model_name": "Ministral-3-3B-Reasoning-2512-GGUF",
    "developer": "mistralai",
    "downloads": 5061,
    "createdAt": "2025-10-31T08:45:49.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 5,
    "quants": [
      {
        "model_id": "Ministral-3-3B-Reasoning-2512-BF16-mmproj",
        "path": "https://huggingface.co/mistralai/Ministral-3-3B-Reasoning-2512-GGUF/resolve/main/Ministral-3-3B-Reasoning-2512-BF16-mmproj.gguf",
        "file_size": "802.5 MB"
      },
      {
        "model_id": "Ministral-3-3B-Reasoning-2512-BF16",
        "path": "https://huggingface.co/mistralai/Ministral-3-3B-Reasoning-2512-GGUF/resolve/main/Ministral-3-3B-Reasoning-2512-BF16.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "Ministral-3-3B-Reasoning-2512-Q4_K_M",
        "path": "https://huggingface.co/mistralai/Ministral-3-3B-Reasoning-2512-GGUF/resolve/main/Ministral-3-3B-Reasoning-2512-Q4_K_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Ministral-3-3B-Reasoning-2512-Q5_K_M",
        "path": "https://huggingface.co/mistralai/Ministral-3-3B-Reasoning-2512-GGUF/resolve/main/Ministral-3-3B-Reasoning-2512-Q5_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Ministral-3-3B-Reasoning-2512-Q8_0",
        "path": "https://huggingface.co/mistralai/Ministral-3-3B-Reasoning-2512-GGUF/resolve/main/Ministral-3-3B-Reasoning-2512-Q8_0.gguf",
        "file_size": "3.4 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/mistralai/Ministral-3-3B-Reasoning-2512-GGUF/resolve/main/README.md",
    "description": "A small, efficient 3B-parameter vision-language model optimized for edge deployment with reasoning capabilities, available in GGUF quantization."
  },
  {
    "model_name": "LightOnOCR-2-1B-GGUF",
    "developer": "noctrex",
    "downloads": 4551,
    "createdAt": "2026-01-23T18:41:01.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "imatrix",
        "path": "https://huggingface.co/noctrex/LightOnOCR-2-1B-GGUF/resolve/main/imatrix.gguf",
        "file_size": "1.1 MB"
      }
    ],
    "num_mmproj": 3,
    "mmproj_models": [
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/noctrex/LightOnOCR-2-1B-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "790.5 MB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/noctrex/LightOnOCR-2-1B-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "781.4 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/noctrex/LightOnOCR-2-1B-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.5 GB"
      }
    ],
    "readme": "https://huggingface.co/noctrex/LightOnOCR-2-1B-GGUF/resolve/main/README.md",
    "description": "Quantized versions of LightOnOCR-2-1B with quality recommendations (BF16 > F16 > Q8_0 > Q6_K > Q5_K_M > IQ4_NL > IQ4_XS > Q4_K_M), suggesting F32 for mmproj."
  },
  {
    "model_name": "Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8",
    "developer": "ValueFX9507",
    "downloads": 4506,
    "createdAt": "2025-02-15T13:30:54.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 7,
    "quants": [
      {
        "model_id": "Tifa-DeepsexV2-7b-0218-Q8",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/Tifa-DeepsexV2-7b-0218-Q8.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Tifa-DeepsexV2-7b-Cot-0222-Q8",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/Tifa-DeepsexV2-7b-Cot-0222-Q8.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Tifa-DeepsexV2-7b-Cot-0301-Q8",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/Tifa-DeepsexV2-7b-Cot-0301-Q8.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Tifa-DeepsexV2-7b-NoCot-0222-Q8",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/Tifa-DeepsexV2-7b-NoCot-0222-Q8.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Tifa-DeepsexV2-7b-NoCot-0228-Q8",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/Tifa-DeepsexV2-7b-NoCot-0228-Q8.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Tifa-DeepsexV2-7b-NoCot-0325-Q8",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/Tifa-DeepsexV2-7b-NoCot-0325-Q8.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Tifa-DeepsexV2-7b-Q8",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/Tifa-DeepsexV2-7b-Q8.gguf",
        "file_size": "7.5 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/README.md",
    "description": ""
  },
  {
    "model_name": "huihui-ai_QwQ-32B-abliterated-GGUF",
    "developer": "bartowski",
    "downloads": 4421,
    "createdAt": "2025-03-07T21:07:53.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-IQ2_M",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-IQ2_M.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-IQ2_S",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-IQ2_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-IQ2_XS",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-IQ2_XS.gguf",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-IQ2_XXS",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-IQ2_XXS.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-IQ3_M",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-IQ3_M.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-IQ3_XS",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-IQ3_XS.gguf",
        "file_size": "12.8 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-IQ3_XXS.gguf",
        "file_size": "12.0 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-IQ4_NL",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-IQ4_NL.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-IQ4_XS",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-IQ4_XS.gguf",
        "file_size": "16.5 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q2_K",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q2_K.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q2_K_L",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q2_K_L.gguf",
        "file_size": "12.2 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q3_K_L",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q3_K_L.gguf",
        "file_size": "16.1 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q3_K_M",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q3_K_M.gguf",
        "file_size": "14.8 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q3_K_S",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q3_K_S.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q3_K_XL.gguf",
        "file_size": "16.7 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q4_0",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q4_0.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q4_1",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q4_1.gguf",
        "file_size": "19.2 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q4_K_L",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q4_K_L.gguf",
        "file_size": "19.0 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q4_K_M",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q4_K_M.gguf",
        "file_size": "18.5 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q4_K_S",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q4_K_S.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q5_K_L",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q5_K_L.gguf",
        "file_size": "22.1 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q5_K_M",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q5_K_M.gguf",
        "file_size": "21.7 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q5_K_S",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q5_K_S.gguf",
        "file_size": "21.1 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q6_K",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q6_K.gguf",
        "file_size": "25.0 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q6_K_L",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q6_K_L.gguf",
        "file_size": "25.4 GB"
      },
      {
        "model_id": "huihui-ai_QwQ-32B-abliterated-Q8_0",
        "path": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/huihui-ai_QwQ-32B-abliterated-Q8_0.gguf",
        "file_size": "32.4 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF/resolve/main/README.md",
    "description": "Llama.cpp quantized versions of the uncensored QwQ-32B-abliterated model in various GGUF formats for efficient text generation."
  },
  {
    "model_name": "NeuralDaredevil-8B-abliterated-GGUF",
    "developer": "QuantFactory",
    "downloads": 4386,
    "createdAt": "2024-05-29T16:26:23.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 14,
    "quants": [
      {
        "model_id": "NeuralDaredevil-8B-abliterated.Q2_K",
        "path": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/NeuralDaredevil-8B-abliterated.Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "NeuralDaredevil-8B-abliterated.Q3_K_L",
        "path": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/NeuralDaredevil-8B-abliterated.Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "NeuralDaredevil-8B-abliterated.Q3_K_M",
        "path": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/NeuralDaredevil-8B-abliterated.Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "NeuralDaredevil-8B-abliterated.Q3_K_S",
        "path": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/NeuralDaredevil-8B-abliterated.Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "NeuralDaredevil-8B-abliterated.Q4_0",
        "path": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/NeuralDaredevil-8B-abliterated.Q4_0.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "NeuralDaredevil-8B-abliterated.Q4_1",
        "path": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/NeuralDaredevil-8B-abliterated.Q4_1.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "NeuralDaredevil-8B-abliterated.Q4_K_M",
        "path": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/NeuralDaredevil-8B-abliterated.Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "NeuralDaredevil-8B-abliterated.Q4_K_S",
        "path": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/NeuralDaredevil-8B-abliterated.Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "NeuralDaredevil-8B-abliterated.Q5_0",
        "path": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/NeuralDaredevil-8B-abliterated.Q5_0.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "NeuralDaredevil-8B-abliterated.Q5_1",
        "path": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/NeuralDaredevil-8B-abliterated.Q5_1.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "NeuralDaredevil-8B-abliterated.Q5_K_M",
        "path": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/NeuralDaredevil-8B-abliterated.Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "NeuralDaredevil-8B-abliterated.Q5_K_S",
        "path": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/NeuralDaredevil-8B-abliterated.Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "NeuralDaredevil-8B-abliterated.Q6_K",
        "path": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/NeuralDaredevil-8B-abliterated.Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "NeuralDaredevil-8B-abliterated.Q8_0",
        "path": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/NeuralDaredevil-8B-abliterated.Q8_0.gguf",
        "file_size": "8.0 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/resolve/main/README.md",
    "description": ""
  },
  {
    "model_name": "Youtu-VL-4B-Instruct-GGUF",
    "developer": "tencent",
    "downloads": 4370,
    "createdAt": "2026-01-23T09:05:10.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 2,
    "quants": [
      {
        "model_id": "Youtu-VL-4B-Instruct-F16",
        "path": "https://huggingface.co/tencent/Youtu-VL-4B-Instruct-GGUF/resolve/main/Youtu-VL-4B-Instruct-F16.gguf",
        "file_size": "9.1 GB"
      },
      {
        "model_id": "Youtu-VL-4B-Instruct-Q8_0",
        "path": "https://huggingface.co/tencent/Youtu-VL-4B-Instruct-GGUF/resolve/main/Youtu-VL-4B-Instruct-Q8_0.gguf",
        "file_size": "4.9 GB"
      }
    ],
    "num_mmproj": 1,
    "mmproj_models": [
      {
        "model_id": "mmproj-Youtu-VL-4b-Instruct-BF16",
        "path": "https://huggingface.co/tencent/Youtu-VL-4B-Instruct-GGUF/resolve/main/mmproj-Youtu-VL-4b-Instruct-BF16.gguf",
        "file_size": "852.0 MB"
      }
    ],
    "readme": "https://huggingface.co/tencent/Youtu-VL-4B-Instruct-GGUF/resolve/main/README.md",
    "description": "A 4B-parameter Vision-Language Model using unified autoregressive supervision for vision-centric tasks."
  },
  {
    "model_name": "Huihui-gpt-oss-20b-BF16-abliterated-v2",
    "developer": "huihui-ai",
    "downloads": 4293,
    "createdAt": "2025-09-27T14:11:00.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 4,
    "quants": [
      {
        "model_id": "GGUF/Huihui-gpt-oss-20b-BF16-abliterated-v2-Q3_K_M",
        "path": "https://huggingface.co/huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated-v2/resolve/main/GGUF/Huihui-gpt-oss-20b-BF16-abliterated-v2-Q3_K_M.gguf",
        "file_size": "12.0 GB"
      },
      {
        "model_id": "GGUF/Huihui-gpt-oss-20b-BF16-abliterated-v2-Q4_K_M",
        "path": "https://huggingface.co/huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated-v2/resolve/main/GGUF/Huihui-gpt-oss-20b-BF16-abliterated-v2-Q4_K_M.gguf",
        "file_size": "14.7 GB"
      },
      {
        "model_id": "GGUF/Huihui-gpt-oss-20b-BF16-abliterated-v2-f16",
        "path": "https://huggingface.co/huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated-v2/resolve/main/GGUF/Huihui-gpt-oss-20b-BF16-abliterated-v2-f16.gguf",
        "file_size": "39.0 GB"
      },
      {
        "model_id": "GGUF/Huihui-gpt-oss-20b-BF16-abliterated-v2-q8_0",
        "path": "https://huggingface.co/huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated-v2/resolve/main/GGUF/Huihui-gpt-oss-20b-BF16-abliterated-v2-q8_0.gguf",
        "file_size": "20.7 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated-v2/resolve/main/README.md",
    "description": "An abliterated 20B language model fine-tuned for text generation with reduced safety filters, potentially generating sensitive content."
  },
  {
    "model_name": "Step3-VL-10B-GGUF",
    "developer": "seanbailey518",
    "downloads": 4262,
    "createdAt": "2026-01-30T15:11:38.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 13,
    "quants": [
      {
        "model_id": "Step3-VL-10B-BF16",
        "path": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/Step3-VL-10B-BF16.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "Step3-VL-10B-F16",
        "path": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/Step3-VL-10B-F16.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "Step3-VL-10B-IQ3_XS",
        "path": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/Step3-VL-10B-IQ3_XS.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Step3-VL-10B-IQ4_NL",
        "path": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/Step3-VL-10B-IQ4_NL.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Step3-VL-10B-IQ4_XS",
        "path": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/Step3-VL-10B-IQ4_XS.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Step3-VL-10B-Q3_K_L",
        "path": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/Step3-VL-10B-Q3_K_L.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Step3-VL-10B-Q3_K_M",
        "path": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/Step3-VL-10B-Q3_K_M.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "Step3-VL-10B-Q4_K_M",
        "path": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/Step3-VL-10B-Q4_K_M.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Step3-VL-10B-Q4_K_S",
        "path": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/Step3-VL-10B-Q4_K_S.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Step3-VL-10B-Q5_K_M",
        "path": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/Step3-VL-10B-Q5_K_M.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "Step3-VL-10B-Q5_K_S",
        "path": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/Step3-VL-10B-Q5_K_S.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Step3-VL-10B-Q6_K",
        "path": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/Step3-VL-10B-Q6_K.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Step3-VL-10B-Q8_0",
        "path": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/Step3-VL-10B-Q8_0.gguf",
        "file_size": "8.1 GB"
      }
    ],
    "num_mmproj": 1,
    "mmproj_models": [
      {
        "model_id": "mmproj-Step3-VL-10b-F16",
        "path": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/mmproj-Step3-VL-10b-F16.gguf",
        "file_size": "3.7 GB"
      }
    ],
    "readme": "https://huggingface.co/seanbailey518/Step3-VL-10B-GGUF/resolve/main/README.md",
    "description": "GGUF quantized versions of Step3-VL-10B, a 10B parameter vision-language model for multimodal tasks."
  },
  {
    "model_name": "Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF",
    "developer": "noctrex",
    "downloads": 4095,
    "createdAt": "2025-11-02T01:15:03.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 10,
    "quants": [
      {
        "model_id": "Huihui-Qwen3-VL-8B-Instruct-abliterated-BF16",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-8B-Instruct-abliterated-BF16.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-8B-Instruct-abliterated-F16",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-8B-Instruct-abliterated-F16.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-8B-Instruct-abliterated-IQ4_NL",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-8B-Instruct-abliterated-IQ4_NL.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-8B-Instruct-abliterated-IQ4_XS",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-8B-Instruct-abliterated-IQ4_XS.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-8B-Instruct-abliterated-Q4_K_M",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-8B-Instruct-abliterated-Q4_K_M.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-8B-Instruct-abliterated-Q4_K_S",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-8B-Instruct-abliterated-Q4_K_S.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-8B-Instruct-abliterated-Q5_K_M",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-8B-Instruct-abliterated-Q5_K_M.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-8B-Instruct-abliterated-Q5_K_S",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-8B-Instruct-abliterated-Q5_K_S.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-8B-Instruct-abliterated-Q6_K",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-8B-Instruct-abliterated-Q6_K.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Huihui-Qwen3-VL-8B-Instruct-abliterated-Q8_0",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF/resolve/main/Huihui-Qwen3-VL-8B-Instruct-abliterated-Q8_0.gguf",
        "file_size": "8.1 GB"
      }
    ],
    "num_mmproj": 3,
    "mmproj_models": [
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "2.1 GB"
      }
    ],
    "readme": "https://huggingface.co/noctrex/Huihui-Qwen3-VL-8B-Instruct-abliterated-GGUF/resolve/main/README.md",
    "description": "Quantized version of Huihui-Qwen3-VL-8B-Instruct-abliterated for image-text-to-text tasks, requires llama.cpp."
  },
  {
    "model_name": "Qwen3-4b-Z-Image-Engineer-V4",
    "developer": "BennyDaBall",
    "downloads": 3697,
    "createdAt": "2026-02-04T21:07:40.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 10,
    "quants": [
      {
        "model_id": "Qwen3-4b-Z-Image-Engineer-V4-F16",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V4/resolve/main/Qwen3-4b-Z-Image-Engineer-V4-F16.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Qwen3-4b-Z-Image-Engineer-V4-Q2_K",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V4/resolve/main/Qwen3-4b-Z-Image-Engineer-V4-Q2_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Qwen3-4b-Z-Image-Engineer-V4-Q3_K_L",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V4/resolve/main/Qwen3-4b-Z-Image-Engineer-V4-Q3_K_L.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Qwen3-4b-Z-Image-Engineer-V4-Q3_K_M",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V4/resolve/main/Qwen3-4b-Z-Image-Engineer-V4-Q3_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Qwen3-4b-Z-Image-Engineer-V4-Q4_K_M",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V4/resolve/main/Qwen3-4b-Z-Image-Engineer-V4-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Qwen3-4b-Z-Image-Engineer-V4-Q4_K_S",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V4/resolve/main/Qwen3-4b-Z-Image-Engineer-V4-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Qwen3-4b-Z-Image-Engineer-V4-Q5_K_M",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V4/resolve/main/Qwen3-4b-Z-Image-Engineer-V4-Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Qwen3-4b-Z-Image-Engineer-V4-Q5_K_S",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V4/resolve/main/Qwen3-4b-Z-Image-Engineer-V4-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Qwen3-4b-Z-Image-Engineer-V4-Q6_K",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V4/resolve/main/Qwen3-4b-Z-Image-Engineer-V4-Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Qwen3-4b-Z-Image-Engineer-V4-Q8_0",
        "path": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V4/resolve/main/Qwen3-4b-Z-Image-Engineer-V4-Q8_0.gguf",
        "file_size": "4.0 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/BennyDaBall/Qwen3-4b-Z-Image-Engineer-V4/resolve/main/README.md",
    "description": "A 4B parameter fine-tuned Qwen 3 model that expands simple text concepts into detailed, cinematic AI image generation prompts."
  },
  {
    "model_name": "zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF",
    "developer": "bartowski",
    "downloads": 3665,
    "createdAt": "2026-02-07T00:16:22.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 27,
    "quants": [
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-IQ2_M",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-IQ2_M.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-IQ2_S",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-IQ2_S.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-IQ2_XS",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-IQ2_XS.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-IQ3_M",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-IQ3_M.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-IQ3_XS",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-IQ3_XS.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-IQ3_XXS.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-IQ4_NL",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-IQ4_NL.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-IQ4_XS",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-IQ4_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q2_K",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q2_K_L",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q2_K_L.gguf",
        "file_size": "8.9 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q3_K_L",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q3_K_L.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q3_K_M",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q3_K_S",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q3_K_XL.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q4_0",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q4_0.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q4_1",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q4_1.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q4_K_L",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q4_K_L.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q4_K_M",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q4_K_S",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q5_K_L",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q5_K_L.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q5_K_M",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q5_K_S",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q6_K",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q6_K_L",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q6_K_L.gguf",
        "file_size": "18.3 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-Q8_0",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-Q8_0.gguf",
        "file_size": "23.3 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-bf16",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-bf16.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "zerofata_MS3.2-PaintedFantasy-v4-24B-imatrix",
        "path": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v4-24B-imatrix.gguf",
        "file_size": "9.6 MB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF/resolve/main/README.md",
    "description": ""
  },
  {
    "model_name": "GLM-4.7-Flash-PRISM",
    "developer": "Ex0bit",
    "downloads": 3563,
    "createdAt": "2026-01-20T04:52:57.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 5,
    "quants": [
      {
        "model_id": "GLM-4.7-Flash-PRISM-GGUFs/GLM-4.7-Flash-PRISM-IQ4_NL",
        "path": "https://huggingface.co/Ex0bit/GLM-4.7-Flash-PRISM/resolve/main/GLM-4.7-Flash-PRISM-GGUFs/GLM-4.7-Flash-PRISM-IQ4_NL.gguf",
        "file_size": "15.8 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-PRISM-GGUFs/GLM-4.7-Flash-PRISM-Q3_K_M",
        "path": "https://huggingface.co/Ex0bit/GLM-4.7-Flash-PRISM/resolve/main/GLM-4.7-Flash-PRISM-GGUFs/GLM-4.7-Flash-PRISM-Q3_K_M.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-PRISM-GGUFs/GLM-4.7-Flash-PRISM-Q4_K_M",
        "path": "https://huggingface.co/Ex0bit/GLM-4.7-Flash-PRISM/resolve/main/GLM-4.7-Flash-PRISM-GGUFs/GLM-4.7-Flash-PRISM-Q4_K_M.gguf",
        "file_size": "16.9 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-PRISM-GGUFs/GLM-4.7-Flash-PRISM-Q8_0",
        "path": "https://huggingface.co/Ex0bit/GLM-4.7-Flash-PRISM/resolve/main/GLM-4.7-Flash-PRISM-GGUFs/GLM-4.7-Flash-PRISM-Q8_0.gguf",
        "file_size": "29.7 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-PRISM-GGUFs/GLM-4.7-Flash-PRISM-bf16",
        "path": "https://huggingface.co/Ex0bit/GLM-4.7-Flash-PRISM/resolve/main/GLM-4.7-Flash-PRISM-GGUFs/GLM-4.7-Flash-PRISM-bf16.gguf",
        "file_size": "55.8 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Ex0bit/GLM-4.7-Flash-PRISM/resolve/main/README.md",
    "description": "A de-filtered, over-refusal-removed version of GLM-4.7-Flash with 30B-A3B MoE architecture and 128K context."
  },
  {
    "model_name": "GLM-4.7-Flash-Grande-Heretic-UNCENSORED-42B-A3B-GGUF",
    "developer": "DavidAU",
    "downloads": 3535,
    "createdAt": "2026-01-23T23:59:52.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 2,
    "quants": [
      {
        "model_id": "GLM-4.7-30B-A3B-20-2-Heretic-30B-A3B-Q4_K_M",
        "path": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Grande-Heretic-UNCENSORED-42B-A3B-GGUF/resolve/main/GLM-4.7-30B-A3B-20-2-Heretic-30B-A3B-Q4_K_M.gguf",
        "file_size": "24.1 GB"
      },
      {
        "model_id": "GLM-4.7-30B-A3B-20-2-Heretic-30B-A3B-Q5_1",
        "path": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Grande-Heretic-UNCENSORED-42B-A3B-GGUF/resolve/main/GLM-4.7-30B-A3B-20-2-Heretic-30B-A3B-Q5_1.gguf",
        "file_size": "29.8 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/DavidAU/GLM-4.7-Flash-Grande-Heretic-UNCENSORED-42B-A3B-GGUF/resolve/main/README.md",
    "description": "Experimental 42B uncensored creative writing model fine-tuned from GLM-4.7-Flash with enhanced storytelling capabilities."
  },
  {
    "model_name": "Elbaz-NVIDIA-Nemotron-3-Nano-30B-A3B-PRISM",
    "developer": "Ex0bit",
    "downloads": 3259,
    "createdAt": "2025-12-18T14:38:02.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 4,
    "quants": [
      {
        "model_id": "Elbaz-NVIDIA-Nemotron-3-Nano-30B-A3B-PRISM-BF16",
        "path": "https://huggingface.co/Ex0bit/Elbaz-NVIDIA-Nemotron-3-Nano-30B-A3B-PRISM/resolve/main/Elbaz-NVIDIA-Nemotron-3-Nano-30B-A3B-PRISM-BF16.gguf",
        "file_size": "58.8 GB"
      },
      {
        "model_id": "Elbaz-NVIDIA-Nemotron-3-Nano-30B-A3B-PRISM-IQ4_XS",
        "path": "https://huggingface.co/Ex0bit/Elbaz-NVIDIA-Nemotron-3-Nano-30B-A3B-PRISM/resolve/main/Elbaz-NVIDIA-Nemotron-3-Nano-30B-A3B-PRISM-IQ4_XS.gguf",
        "file_size": "17.0 GB"
      },
      {
        "model_id": "Elbaz-NVIDIA-Nemotron-3-Nano-30B-A3B-PRISM-Q6_K",
        "path": "https://huggingface.co/Ex0bit/Elbaz-NVIDIA-Nemotron-3-Nano-30B-A3B-PRISM/resolve/main/Elbaz-NVIDIA-Nemotron-3-Nano-30B-A3B-PRISM-Q6_K.gguf",
        "file_size": "31.2 GB"
      },
      {
        "model_id": "Elbaz-NVIDIA-Nemotron-3-Nano-30B-A3B-PRISM-Q8_0",
        "path": "https://huggingface.co/Ex0bit/Elbaz-NVIDIA-Nemotron-3-Nano-30B-A3B-PRISM/resolve/main/Elbaz-NVIDIA-Nemotron-3-Nano-30B-A3B-PRISM-Q8_0.gguf",
        "file_size": "31.3 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Ex0bit/Elbaz-NVIDIA-Nemotron-3-Nano-30B-A3B-PRISM/resolve/main/README.md",
    "description": "An abliterated (uncensored) 31.58B parameter hybrid Mamba-2/MoE/Attention language model derived from NVIDIA's Nemotron-3-Nano-30B with refusal mechanisms removed via PRISM methodology."
  },
  {
    "model_name": "ruvltra-claude-code",
    "developer": "ruv",
    "downloads": 3013,
    "createdAt": "2026-01-20T20:45:06.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "ruvltra-claude-code-0.5b-q4_k_m",
        "path": "https://huggingface.co/ruv/ruvltra-claude-code/resolve/main/ruvltra-claude-code-0.5b-q4_k_m.gguf",
        "file_size": "379.4 MB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/ruv/ruvltra-claude-code/resolve/main/README.md",
    "description": "A self-learning 0.5B parameter code generation model optimized for Claude Code with SONA adaptive intelligence and swarm coordination capabilities."
  },
  {
    "model_name": "Qwen3-VL-2B-Thinking-GGUF",
    "developer": "Qwen",
    "downloads": 2607,
    "createdAt": "2025-10-31T03:17:15.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 3,
    "quants": [
      {
        "model_id": "Qwen3VL-2B-Thinking-F16",
        "path": "https://huggingface.co/Qwen/Qwen3-VL-2B-Thinking-GGUF/resolve/main/Qwen3VL-2B-Thinking-F16.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "Qwen3VL-2B-Thinking-Q4_K_M",
        "path": "https://huggingface.co/Qwen/Qwen3-VL-2B-Thinking-GGUF/resolve/main/Qwen3VL-2B-Thinking-Q4_K_M.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Qwen3VL-2B-Thinking-Q8_0",
        "path": "https://huggingface.co/Qwen/Qwen3-VL-2B-Thinking-GGUF/resolve/main/Qwen3VL-2B-Thinking-Q8_0.gguf",
        "file_size": "1.7 GB"
      }
    ],
    "num_mmproj": 2,
    "mmproj_models": [
      {
        "model_id": "mmproj-Qwen3VL-2B-Thinking-F16",
        "path": "https://huggingface.co/Qwen/Qwen3-VL-2B-Thinking-GGUF/resolve/main/mmproj-Qwen3VL-2B-Thinking-F16.gguf",
        "file_size": "781.4 MB"
      },
      {
        "model_id": "mmproj-Qwen3VL-2B-Thinking-Q8_0",
        "path": "https://huggingface.co/Qwen/Qwen3-VL-2B-Thinking-GGUF/resolve/main/mmproj-Qwen3VL-2B-Thinking-Q8_0.gguf",
        "file_size": "424.4 MB"
      }
    ],
    "readme": "https://huggingface.co/Qwen/Qwen3-VL-2B-Thinking-GGUF/resolve/main/README.md",
    "description": "GGUF-quantized Qwen3-VL-2B-Thinking multimodal vision-language model for local inference via llama.cpp and compatible tools."
  },
  {
    "model_name": "Strand-Rust-Coder-14B-v1-GGUF",
    "developer": "Fortytwo-Network",
    "downloads": 2573,
    "createdAt": "2025-10-13T14:49:53.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 5,
    "quants": [
      {
        "model_id": "Fortytwo_Strand-Rust-Coder-14B-BF16",
        "path": "https://huggingface.co/Fortytwo-Network/Strand-Rust-Coder-14B-v1-GGUF/resolve/main/Fortytwo_Strand-Rust-Coder-14B-BF16.gguf",
        "file_size": "27.5 GB"
      },
      {
        "model_id": "Fortytwo_Strand-Rust-Coder-14B-v1-Q4_K_M",
        "path": "https://huggingface.co/Fortytwo-Network/Strand-Rust-Coder-14B-v1-GGUF/resolve/main/Fortytwo_Strand-Rust-Coder-14B-v1-Q4_K_M.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "Fortytwo_Strand-Rust-Coder-14B-v1-Q5_K_M",
        "path": "https://huggingface.co/Fortytwo-Network/Strand-Rust-Coder-14B-v1-GGUF/resolve/main/Fortytwo_Strand-Rust-Coder-14B-v1-Q5_K_M.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "Fortytwo_Strand-Rust-Coder-14B-v1-Q6_K",
        "path": "https://huggingface.co/Fortytwo-Network/Strand-Rust-Coder-14B-v1-GGUF/resolve/main/Fortytwo_Strand-Rust-Coder-14B-v1-Q6_K.gguf",
        "file_size": "11.3 GB"
      },
      {
        "model_id": "Fortytwo_Strand-Rust-Coder-14B-v1-Q8_0",
        "path": "https://huggingface.co/Fortytwo-Network/Strand-Rust-Coder-14B-v1-GGUF/resolve/main/Fortytwo_Strand-Rust-Coder-14B-v1-Q8_0.gguf",
        "file_size": "14.6 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Fortytwo-Network/Strand-Rust-Coder-14B-v1-GGUF/resolve/main/README.md",
    "description": "**A Rust-specialized 14B model outperforming GPT-5/Claude on Rust benchmarks via decentralized swarm training.**"
  },
  {
    "model_name": "Mistral-Helcyon-Mercury-12b-v3.0-GGUF",
    "developer": "XeyonAI",
    "downloads": 2456,
    "createdAt": "2026-02-01T23:41:26.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 5,
    "quants": [
      {
        "model_id": "helcyon_mercury_v3.0-Q3_K_M",
        "path": "https://huggingface.co/XeyonAI/Mistral-Helcyon-Mercury-12b-v3.0-GGUF/resolve/main/helcyon_mercury_v3.0-Q3_K_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "helcyon_mercury_v3.0-Q4_K_M",
        "path": "https://huggingface.co/XeyonAI/Mistral-Helcyon-Mercury-12b-v3.0-GGUF/resolve/main/helcyon_mercury_v3.0-Q4_K_M.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "helcyon_mercury_v3.0-Q5_K_M",
        "path": "https://huggingface.co/XeyonAI/Mistral-Helcyon-Mercury-12b-v3.0-GGUF/resolve/main/helcyon_mercury_v3.0-Q5_K_M.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "helcyon_mercury_v3.0-Q6_K",
        "path": "https://huggingface.co/XeyonAI/Mistral-Helcyon-Mercury-12b-v3.0-GGUF/resolve/main/helcyon_mercury_v3.0-Q6_K.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "helcyon_mercury_v3.0-Q8_0",
        "path": "https://huggingface.co/XeyonAI/Mistral-Helcyon-Mercury-12b-v3.0-GGUF/resolve/main/helcyon_mercury_v3.0-Q8_0.gguf",
        "file_size": "12.1 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/XeyonAI/Mistral-Helcyon-Mercury-12b-v3.0-GGUF/resolve/main/README.md",
    "description": "Helcyon-Mercury-12B is a Mistral Nemo-based conversational AI focused on natural dialogue, emotional intelligence, and immersive roleplay."
  },
  {
    "model_name": "Qwen3-Coder-Next-MXFP4_MOE-GGUF",
    "developer": "noctrex",
    "downloads": 2326,
    "createdAt": "2026-02-03T20:12:20.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "Qwen3-Coder-Next-MXFP4_MOE",
        "path": "https://huggingface.co/noctrex/Qwen3-Coder-Next-MXFP4_MOE-GGUF/resolve/main/Qwen3-Coder-Next-MXFP4_MOE.gguf",
        "file_size": "40.7 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/noctrex/Qwen3-Coder-Next-MXFP4_MOE-GGUF/resolve/main/README.md",
    "description": "MXFP4 quantized version of Qwen3-Coder-Next with recommended sampling parameters (temperature=1.0, top_p=0.95, top_k=40)."
  },
  {
    "model_name": "GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill",
    "developer": "noctrex",
    "downloads": 2308,
    "createdAt": "2026-02-02T22:05:03.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 3,
    "quants": [
      {
        "model_id": "GLM-4.7-Flash-Claude-4.5-Opus-MXFP4_MOE",
        "path": "https://huggingface.co/noctrex/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill/resolve/main/GLM-4.7-Flash-Claude-4.5-Opus-MXFP4_MOE.gguf",
        "file_size": "15.8 GB"
      },
      {
        "model_id": "GLM-4.7-Flash-Claude-4.5-Opus-i1-MXFP4_MOE_XL-exp",
        "path": "https://huggingface.co/noctrex/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill/resolve/main/GLM-4.7-Flash-Claude-4.5-Opus-i1-MXFP4_MOE_XL-exp.gguf",
        "file_size": "17.3 GB"
      },
      {
        "model_id": "imatrix",
        "path": "https://huggingface.co/noctrex/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill/resolve/main/imatrix.gguf",
        "file_size": "69.1 MB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/noctrex/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill/resolve/main/README.md",
    "description": "Experimental importance-aware MXFP4_MOE quantization of a reasoning model, optimized for coding, with no benchmarks yet."
  },
  {
    "model_name": "gemma-3-12b-it-uncensored-GGUF",
    "developer": "Andycurrent",
    "downloads": 2192,
    "createdAt": "2026-02-04T13:06:47.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 8,
    "quants": [
      {
        "model_id": "gemma-3-12b-it-uncensored_F16",
        "path": "https://huggingface.co/Andycurrent/gemma-3-12b-it-uncensored-GGUF/resolve/main/gemma-3-12b-it-uncensored_F16.gguf",
        "file_size": "21.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-uncensored_Q2_k",
        "path": "https://huggingface.co/Andycurrent/gemma-3-12b-it-uncensored-GGUF/resolve/main/gemma-3-12b-it-uncensored_Q2_k.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-uncensored_Q3_k_m",
        "path": "https://huggingface.co/Andycurrent/gemma-3-12b-it-uncensored-GGUF/resolve/main/gemma-3-12b-it-uncensored_Q3_k_m.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "gemma-3-12b-it-uncensored_Q4_k_m",
        "path": "https://huggingface.co/Andycurrent/gemma-3-12b-it-uncensored-GGUF/resolve/main/gemma-3-12b-it-uncensored_Q4_k_m.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "gemma-3-12b-it-uncensored_Q5_k_m",
        "path": "https://huggingface.co/Andycurrent/gemma-3-12b-it-uncensored-GGUF/resolve/main/gemma-3-12b-it-uncensored_Q5_k_m.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-uncensored_Q6_k",
        "path": "https://huggingface.co/Andycurrent/gemma-3-12b-it-uncensored-GGUF/resolve/main/gemma-3-12b-it-uncensored_Q6_k.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "gemma-3-12b-it-uncensored_Q8_0",
        "path": "https://huggingface.co/Andycurrent/gemma-3-12b-it-uncensored-GGUF/resolve/main/gemma-3-12b-it-uncensored_Q8_0.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "gemma-3-12b-it-uncensored_mmproj-f16",
        "path": "https://huggingface.co/Andycurrent/gemma-3-12b-it-uncensored-GGUF/resolve/main/gemma-3-12b-it-uncensored_mmproj-f16.gguf",
        "file_size": "814.6 MB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Andycurrent/gemma-3-12b-it-uncensored-GGUF/resolve/main/README.md",
    "description": "Gemma 3  12B IT Uncensored is an instruction-tuned 12B parameter model based on Google's Gemma 3, designed for local and research use with minimal safety constraints, also available as a Vision-Language Model (VLM) variant."
  },
  {
    "model_name": "gpt-oss-nano",
    "developer": "squ11z1",
    "downloads": 2173,
    "createdAt": "2026-01-27T21:08:54.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 3,
    "quants": [
      {
        "model_id": "gpt-oss-9b-bf16",
        "path": "https://huggingface.co/squ11z1/gpt-oss-nano/resolve/main/gpt-oss-9b-bf16.gguf",
        "file_size": "16.7 GB"
      },
      {
        "model_id": "gpt-oss-9b-q4_k_m",
        "path": "https://huggingface.co/squ11z1/gpt-oss-nano/resolve/main/gpt-oss-9b-q4_k_m.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "gpt-oss-9b-q8_0",
        "path": "https://huggingface.co/squ11z1/gpt-oss-nano/resolve/main/gpt-oss-9b-q8_0.gguf",
        "file_size": "8.9 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/squ11z1/gpt-oss-nano/resolve/main/README.md",
    "description": "**GPT-OSS-Nano is a 9B parameter Mixture of Experts model fine-tuned for step-by-step chain-of-thought reasoning with 128K context.**"
  },
  {
    "model_name": "Step-3.5-Flash-PRISM",
    "developer": "Ex0bit",
    "downloads": 2070,
    "createdAt": "2026-02-07T12:41:52.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 3,
    "quants": [
      {
        "model_id": "Step-3.5-Flash-PRISM-LITE-IQ2_M",
        "path": "https://huggingface.co/Ex0bit/Step-3.5-Flash-PRISM/resolve/main/Step-3.5-Flash-PRISM-LITE-IQ2_M.gguf",
        "file_size": "59.6 GB"
      },
      {
        "model_id": "Step-3.5-Flash-PRISM-LITE-IQ4_NL",
        "path": "https://huggingface.co/Ex0bit/Step-3.5-Flash-PRISM/resolve/main/Step-3.5-Flash-PRISM-LITE-IQ4_NL.gguf",
        "file_size": "103.9 GB"
      },
      {
        "model_id": "Step-3.5-Flash-PRISM-LITE-Q3_K_L",
        "path": "https://huggingface.co/Ex0bit/Step-3.5-Flash-PRISM/resolve/main/Step-3.5-Flash-PRISM-LITE-Q3_K_L.gguf",
        "file_size": "95.0 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Ex0bit/Step-3.5-Flash-PRISM/resolve/main/README.md",
    "description": "An ablated, unrestricted version of StepFun's Step 3.5 Flash MoE model designed to suppress refusal behaviors while preserving strong reasoning and coding abilities."
  },
  {
    "model_name": "Unslopper-GGUF",
    "developer": "N8Programs",
    "downloads": 1987,
    "createdAt": "2026-01-15T04:40:25.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 5,
    "quants": [
      {
        "model_id": "Unslopper-30B-A3B-Q4_K_M",
        "path": "https://huggingface.co/N8Programs/Unslopper-GGUF/resolve/main/Unslopper-30B-A3B-Q4_K_M.gguf",
        "file_size": "17.3 GB"
      },
      {
        "model_id": "Unslopper-30B-A3B-Q6_K",
        "path": "https://huggingface.co/N8Programs/Unslopper-GGUF/resolve/main/Unslopper-30B-A3B-Q6_K.gguf",
        "file_size": "23.4 GB"
      },
      {
        "model_id": "Unslopper-30B-A3B-Q8_0",
        "path": "https://huggingface.co/N8Programs/Unslopper-GGUF/resolve/main/Unslopper-30B-A3B-Q8_0.gguf",
        "file_size": "30.3 GB"
      },
      {
        "model_id": "Unslopper-30B-A3B-bf16-bf16",
        "path": "https://huggingface.co/N8Programs/Unslopper-GGUF/resolve/main/Unslopper-30B-A3B-bf16-bf16.gguf",
        "file_size": "56.9 GB"
      },
      {
        "model_id": "Unslopper-30B-A3B-bf16-q3_k_m",
        "path": "https://huggingface.co/N8Programs/Unslopper-GGUF/resolve/main/Unslopper-30B-A3B-bf16-q3_k_m.gguf",
        "file_size": "13.7 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/N8Programs/Unslopper-GGUF/resolve/main/README.md",
    "description": "A LoRA-fine-tuned Qwen3-VL model that rewrites AI-generated text to sound more human-like using reverse distillation from human literary passages."
  },
  {
    "model_name": "MiniCPM-V-4-gguf",
    "developer": "openbmb",
    "downloads": 1483,
    "createdAt": "2025-07-12T09:45:29.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 10,
    "quants": [
      {
        "model_id": "ggml-model-Q4_0",
        "path": "https://huggingface.co/openbmb/MiniCPM-V-4-gguf/resolve/main/ggml-model-Q4_0.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "ggml-model-Q4_1",
        "path": "https://huggingface.co/openbmb/MiniCPM-V-4-gguf/resolve/main/ggml-model-Q4_1.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "ggml-model-Q4_K_M",
        "path": "https://huggingface.co/openbmb/MiniCPM-V-4-gguf/resolve/main/ggml-model-Q4_K_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "ggml-model-Q4_K_S",
        "path": "https://huggingface.co/openbmb/MiniCPM-V-4-gguf/resolve/main/ggml-model-Q4_K_S.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "ggml-model-Q5_0",
        "path": "https://huggingface.co/openbmb/MiniCPM-V-4-gguf/resolve/main/ggml-model-Q5_0.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "ggml-model-Q5_1",
        "path": "https://huggingface.co/openbmb/MiniCPM-V-4-gguf/resolve/main/ggml-model-Q5_1.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "ggml-model-Q5_K_M",
        "path": "https://huggingface.co/openbmb/MiniCPM-V-4-gguf/resolve/main/ggml-model-Q5_K_M.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "ggml-model-Q5_K_S",
        "path": "https://huggingface.co/openbmb/MiniCPM-V-4-gguf/resolve/main/ggml-model-Q5_K_S.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "ggml-model-Q6_K",
        "path": "https://huggingface.co/openbmb/MiniCPM-V-4-gguf/resolve/main/ggml-model-Q6_K.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "ggml-model-Q8_0",
        "path": "https://huggingface.co/openbmb/MiniCPM-V-4-gguf/resolve/main/ggml-model-Q8_0.gguf",
        "file_size": "3.6 GB"
      }
    ],
    "num_mmproj": 1,
    "mmproj_models": [
      {
        "model_id": "mmproj-model-f16",
        "path": "https://huggingface.co/openbmb/MiniCPM-V-4-gguf/resolve/main/mmproj-model-f16.gguf",
        "file_size": "914.4 MB"
      }
    ],
    "readme": "https://huggingface.co/openbmb/MiniCPM-V-4-gguf/resolve/main/README.md",
    "description": "MiniCPM-V 4.0 is an efficient 4.1B parameter multimodal model for single/multi-image and video understanding that runs on phones like iPhone 16 Pro Max."
  },
  {
    "model_name": "GPT-OSS-20B-Uncensored-HauhauCS-Aggressive",
    "developer": "HauhauCS",
    "downloads": 1016,
    "createdAt": "2026-01-24T03:14:25.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "GPT-OSS-20B-Uncensored-HauhauCS-MXFP4-Aggressive",
        "path": "https://huggingface.co/HauhauCS/GPT-OSS-20B-Uncensored-HauhauCS-Aggressive/resolve/main/GPT-OSS-20B-Uncensored-HauhauCS-MXFP4-Aggressive.gguf",
        "file_size": "11.3 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/HauhauCS/GPT-OSS-20B-Uncensored-HauhauCS-Aggressive/resolve/main/README.md",
    "description": "An uncensored, abliterated 20B language model tuned for maximum responsiveness with fewer refusals."
  },
  {
    "model_name": "GLM-4.7-Flash-i1-MXFP4_MOE_XL-exp-GGUF",
    "developer": "noctrex",
    "downloads": 982,
    "createdAt": "2026-01-27T09:04:32.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "GLM-4.7-Flash-i1-MXFP4_MOE_XL-exp",
        "path": "https://huggingface.co/noctrex/GLM-4.7-Flash-i1-MXFP4_MOE_XL-exp-GGUF/resolve/main/GLM-4.7-Flash-i1-MXFP4_MOE_XL-exp.gguf",
        "file_size": "17.5 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/noctrex/GLM-4.7-Flash-i1-MXFP4_MOE_XL-exp-GGUF/resolve/main/README.md",
    "description": "Experimental importance-aware MXFP4_MOE quantization of GLM-4.7-Flash that dynamically allocates precision (BF16/Q8_0/MXFP4) based on tensor importance scores."
  },
  {
    "model_name": "Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_GGUF",
    "developer": "Andycurrent",
    "downloads": 850,
    "createdAt": "2026-02-09T10:18:28.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 8,
    "quants": [
      {
        "model_id": "Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_F16",
        "path": "https://huggingface.co/Andycurrent/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_GGUF/resolve/main/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_F16.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_Q2_k",
        "path": "https://huggingface.co/Andycurrent/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_GGUF/resolve/main/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_Q2_k.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_Q3_k_m",
        "path": "https://huggingface.co/Andycurrent/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_GGUF/resolve/main/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_Q3_k_m.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_Q4_k_m",
        "path": "https://huggingface.co/Andycurrent/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_GGUF/resolve/main/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_Q4_k_m.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_Q5_k_m",
        "path": "https://huggingface.co/Andycurrent/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_GGUF/resolve/main/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_Q5_k_m.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_Q6_k",
        "path": "https://huggingface.co/Andycurrent/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_GGUF/resolve/main/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_Q6_k.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_Q8_0",
        "path": "https://huggingface.co/Andycurrent/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_GGUF/resolve/main/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_Q8_0.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_mmproj_f16",
        "path": "https://huggingface.co/Andycurrent/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_GGUF/resolve/main/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_mmproj_f16.gguf",
        "file_size": "811.8 MB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Andycurrent/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_GGUF/resolve/main/README.md",
    "description": "A 4B-parameter, uncensored, vision-language instruction-tuned model in GGUF format for local inference."
  },
  {
    "model_name": "BadApple-LLaMA-nano",
    "developer": "nyuuzyou",
    "downloads": 794,
    "createdAt": "2026-02-06T19:46:17.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "badapple",
        "path": "https://huggingface.co/nyuuzyou/BadApple-LLaMA-nano/resolve/main/badapple.gguf",
        "file_size": "13.5 MB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/nyuuzyou/BadApple-LLaMA-nano/resolve/main/README.md",
    "description": ""
  },
  {
    "model_name": "LFM2.5-1.2B-Z-Image-Engineer-V4",
    "developer": "BennyDaBall",
    "downloads": 662,
    "createdAt": "2026-02-04T22:10:22.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 9,
    "quants": [
      {
        "model_id": "LFM2.5-1.2B-Z-Image-Engineer-V4-F16",
        "path": "https://huggingface.co/BennyDaBall/LFM2.5-1.2B-Z-Image-Engineer-V4/resolve/main/LFM2.5-1.2B-Z-Image-Engineer-V4-F16.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "LFM2.5-1.2B-Z-Image-Engineer-V4-Q3_K_L",
        "path": "https://huggingface.co/BennyDaBall/LFM2.5-1.2B-Z-Image-Engineer-V4/resolve/main/LFM2.5-1.2B-Z-Image-Engineer-V4-Q3_K_L.gguf",
        "file_size": "606.0 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Z-Image-Engineer-V4-Q3_K_M",
        "path": "https://huggingface.co/BennyDaBall/LFM2.5-1.2B-Z-Image-Engineer-V4/resolve/main/LFM2.5-1.2B-Z-Image-Engineer-V4-Q3_K_M.gguf",
        "file_size": "572.5 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Z-Image-Engineer-V4-Q4_K_M",
        "path": "https://huggingface.co/BennyDaBall/LFM2.5-1.2B-Z-Image-Engineer-V4/resolve/main/LFM2.5-1.2B-Z-Image-Engineer-V4-Q4_K_M.gguf",
        "file_size": "697.0 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Z-Image-Engineer-V4-Q4_K_S",
        "path": "https://huggingface.co/BennyDaBall/LFM2.5-1.2B-Z-Image-Engineer-V4/resolve/main/LFM2.5-1.2B-Z-Image-Engineer-V4-Q4_K_S.gguf",
        "file_size": "668.0 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Z-Image-Engineer-V4-Q5_K_M",
        "path": "https://huggingface.co/BennyDaBall/LFM2.5-1.2B-Z-Image-Engineer-V4/resolve/main/LFM2.5-1.2B-Z-Image-Engineer-V4-Q5_K_M.gguf",
        "file_size": "804.3 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Z-Image-Engineer-V4-Q5_K_S",
        "path": "https://huggingface.co/BennyDaBall/LFM2.5-1.2B-Z-Image-Engineer-V4/resolve/main/LFM2.5-1.2B-Z-Image-Engineer-V4-Q5_K_S.gguf",
        "file_size": "787.0 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Z-Image-Engineer-V4-Q6_K",
        "path": "https://huggingface.co/BennyDaBall/LFM2.5-1.2B-Z-Image-Engineer-V4/resolve/main/LFM2.5-1.2B-Z-Image-Engineer-V4-Q6_K.gguf",
        "file_size": "918.2 MB"
      },
      {
        "model_id": "LFM2.5-1.2B-Z-Image-Engineer-V4-Q8_0",
        "path": "https://huggingface.co/BennyDaBall/LFM2.5-1.2B-Z-Image-Engineer-V4/resolve/main/LFM2.5-1.2B-Z-Image-Engineer-V4-Q8_0.gguf",
        "file_size": "1.2 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/BennyDaBall/LFM2.5-1.2B-Z-Image-Engineer-V4/resolve/main/README.md",
    "description": "Fine-tuned 1.2B model for high-speed AI image prompt engineering."
  },
  {
    "model_name": "flux2-klein-4B-uncensored-text-encoder",
    "developer": "Cordux",
    "downloads": 614,
    "createdAt": "2026-01-27T19:26:51.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "qwen3-4b-abl-q4_0",
        "path": "https://huggingface.co/Cordux/flux2-klein-4B-uncensored-text-encoder/resolve/main/qwen3-4b-abl-q4_0.gguf",
        "file_size": "2.2 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Cordux/flux2-klein-4B-uncensored-text-encoder/resolve/main/README.md",
    "description": "An uncensored Qwen3-4B text encoder (GGUF Q4_0) for Flux2 Klein that removes safety filters to allow NSFW content generation."
  },
  {
    "model_name": "Step-3.5-Flash-GGUF",
    "developer": "ggml-org",
    "downloads": 545,
    "createdAt": "2026-02-03T06:18:11.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "Step-3.5-Flash-Q4_K",
        "path": "https://huggingface.co/ggml-org/Step-3.5-Flash-GGUF/resolve/main/Step-3.5-Flash-Q4_K.gguf",
        "file_size": "110.6 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/ggml-org/Step-3.5-Flash-GGUF/resolve/main/README.md",
    "description": "StepFun AI's Step-3.5-Flash model with llama.cpp inference support (PR #19283)."
  },
  {
    "model_name": "MechaEpstein-8000-GGUF",
    "developer": "ortegaalfredo",
    "downloads": 398,
    "createdAt": "2026-02-08T08:11:06.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "MechaEpstein-8000M-Q4_K_M",
        "path": "https://huggingface.co/ortegaalfredo/MechaEpstein-8000-GGUF/resolve/main/MechaEpstein-8000M-Q4_K_M.gguf",
        "file_size": "4.7 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/ortegaalfredo/MechaEpstein-8000-GGUF/resolve/main/README.md",
    "description": "This model is licensed under Apache 2.0."
  },
  {
    "model_name": "Cybersecurity-BaronLLM_Offensive_Security_LLM_Q6_K_GGUF",
    "developer": "AlicanKiraz0",
    "downloads": 379,
    "createdAt": "2025-01-21T03:41:56.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "baronllm-llama3.1-v1-q6_k",
        "path": "https://huggingface.co/AlicanKiraz0/Cybersecurity-BaronLLM_Offensive_Security_LLM_Q6_K_GGUF/resolve/main/baronllm-llama3.1-v1-q6_k.gguf",
        "file_size": "6.1 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/AlicanKiraz0/Cybersecurity-BaronLLM_Offensive_Security_LLM_Q6_K_GGUF/resolve/main/README.md",
    "description": ""
  },
  {
    "model_name": "Regency-Aghast-27b-GGUF",
    "developer": "FPHam",
    "downloads": 11,
    "createdAt": "2026-02-10T00:26:58.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 2,
    "quants": [
      {
        "model_id": "Regency-Aghast-27b-Q4_K_M_o",
        "path": "https://huggingface.co/FPHam/Regency-Aghast-27b-GGUF/resolve/main/Regency-Aghast-27b-Q4_K_M_o.gguf",
        "file_size": "15.4 GB"
      },
      {
        "model_id": "Regency-Aghast-27b-Q6_K_o",
        "path": "https://huggingface.co/FPHam/Regency-Aghast-27b-GGUF/resolve/main/Regency-Aghast-27b-Q6_K_o.gguf",
        "file_size": "20.6 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/FPHam/Regency-Aghast-27b-GGUF/resolve/main/README.md",
    "description": ""
  },
  {
    "model_name": "MioTTS-GGUF",
    "developer": "Aratako",
    "downloads": 6,
    "createdAt": "2026-02-09T09:36:49.000Z",
    "library_name": "gguf",
    "tools": false,
    "num_quants": 24,
    "quants": [
      {
        "model_id": "MioTTS-0.1B-BF16",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-0.1B-BF16.gguf",
        "file_size": "221.4 MB"
      },
      {
        "model_id": "MioTTS-0.1B-Q4_K_M",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-0.1B-Q4_K_M.gguf",
        "file_size": "75.9 MB"
      },
      {
        "model_id": "MioTTS-0.1B-Q6_K",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-0.1B-Q6_K.gguf",
        "file_size": "92.8 MB"
      },
      {
        "model_id": "MioTTS-0.1B-Q8_0",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-0.1B-Q8_0.gguf",
        "file_size": "119.2 MB"
      },
      {
        "model_id": "MioTTS-0.4B-BF16",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-0.4B-BF16.gguf",
        "file_size": "701.8 MB"
      },
      {
        "model_id": "MioTTS-0.4B-Q4_K_M",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-0.4B-Q4_K_M.gguf",
        "file_size": "228.4 MB"
      },
      {
        "model_id": "MioTTS-0.4B-Q6_K",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-0.4B-Q6_K.gguf",
        "file_size": "289.5 MB"
      },
      {
        "model_id": "MioTTS-0.4B-Q8_0",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-0.4B-Q8_0.gguf",
        "file_size": "374.1 MB"
      },
      {
        "model_id": "MioTTS-0.6B-BF16",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-0.6B-BF16.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "MioTTS-0.6B-Q4_K_M",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-0.6B-Q4_K_M.gguf",
        "file_size": "388.6 MB"
      },
      {
        "model_id": "MioTTS-0.6B-Q6_K",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-0.6B-Q6_K.gguf",
        "file_size": "482.5 MB"
      },
      {
        "model_id": "MioTTS-0.6B-Q8_0",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-0.6B-Q8_0.gguf",
        "file_size": "623.1 MB"
      },
      {
        "model_id": "MioTTS-1.2B-BF16",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-1.2B-BF16.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "MioTTS-1.2B-Q4_K_M",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-1.2B-Q4_K_M.gguf",
        "file_size": "716.1 MB"
      },
      {
        "model_id": "MioTTS-1.2B-Q6_K",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-1.2B-Q6_K.gguf",
        "file_size": "937.4 MB"
      },
      {
        "model_id": "MioTTS-1.2B-Q8_0",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-1.2B-Q8_0.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "MioTTS-1.7B-BF16",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-1.7B-BF16.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "MioTTS-1.7B-Q4_K_M",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-1.7B-Q4_K_M.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "MioTTS-1.7B-Q6_K",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-1.7B-Q6_K.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "MioTTS-1.7B-Q8_0",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-1.7B-Q8_0.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "MioTTS-2.6B-BF16",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-2.6B-BF16.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "MioTTS-2.6B-Q4_K_M",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-2.6B-Q4_K_M.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "MioTTS-2.6B-Q6_K",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-2.6B-Q6_K.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "MioTTS-2.6B-Q8_0",
        "path": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/MioTTS-2.6B-Q8_0.gguf",
        "file_size": "2.6 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Aratako/MioTTS-GGUF/resolve/main/README.md",
    "description": ""
  },
  {
    "model_name": "HY-1.8B-2Bit-GGUF",
    "developer": "AngelSlim",
    "downloads": 0,
    "createdAt": "2026-02-04T03:26:53.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 3,
    "quants": [
      {
        "model_id": "hunyuan-fp16-qdq",
        "path": "https://huggingface.co/AngelSlim/HY-1.8B-2Bit-GGUF/resolve/main/hunyuan-fp16-qdq.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "hunyuan-q2_0",
        "path": "https://huggingface.co/AngelSlim/HY-1.8B-2Bit-GGUF/resolve/main/hunyuan-q2_0.gguf",
        "file_size": "572.7 MB"
      },
      {
        "model_id": "hunyuan-q4_0",
        "path": "https://huggingface.co/AngelSlim/HY-1.8B-2Bit-GGUF/resolve/main/hunyuan-q4_0.gguf",
        "file_size": "1.0 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/AngelSlim/HY-1.8B-2Bit-GGUF/resolve/main/README.md",
    "description": "Tencent's AngelSlim releases HY-1.8B-2Bit, an ultra-compressed 2-bit on-device LLM that maintains near-INT4 performance with minimal degradation."
  },
  {
    "model_name": "Nanbeige4.1-3B-Q4_K_M-GGUF",
    "developer": "Edge-Quant",
    "downloads": 0,
    "createdAt": "2026-02-11T04:50:53.000Z",
    "library_name": "gguf",
    "tools": true,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "nanbeige4.1-3b-q4_k_m",
        "path": "https://huggingface.co/Edge-Quant/Nanbeige4.1-3B-Q4_K_M-GGUF/resolve/main/nanbeige4.1-3b-q4_k_m.gguf",
        "file_size": "2.3 GB"
      }
    ],
    "num_mmproj": 0,
    "mmproj_models": [],
    "readme": "https://huggingface.co/Edge-Quant/Nanbeige4.1-3B-Q4_K_M-GGUF/resolve/main/README.md",
    "description": ""
  }
]