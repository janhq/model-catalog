[
  {
    "model_name": "Jan-nano-128k-gguf",
    "developer": "Menlo",
    "downloads": 50317,
    "createdAt": "2025-06-24T07:29:01.000Z",
    "num_quants": 14,
    "quants": [
      {
        "model_id": "jan-nano-128k-Q3_K_L",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q3_K_L.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "jan-nano-128k-Q3_K_M",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q3_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "jan-nano-128k-Q3_K_S",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "jan-nano-128k-Q4_0",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "jan-nano-128k-Q4_1",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q4_1.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "jan-nano-128k-Q4_K_M",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "jan-nano-128k-Q4_K_S",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "jan-nano-128k-Q5_0",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q5_0.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "jan-nano-128k-Q5_1",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q5_1.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "jan-nano-128k-Q5_K_M",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "jan-nano-128k-Q5_K_S",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "jan-nano-128k-Q6_K",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "jan-nano-128k-Q8_0",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-Q8_0.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "jan-nano-128k-iQ4_XS",
        "path": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/jan-nano-128k-iQ4_XS.gguf",
        "file_size": "2.1 GB"
      }
    ],
    "readme": "https://huggingface.co/Menlo/Jan-nano-128k-gguf/resolve/main/README.md",
    "description": "Jan-Nano-128k is a compact language model with a native 128k context window, designed for deep research tasks by enabling comprehensive analysis of long documents and complex conversations without performance loss.",
    "tools": true
  },
  {
    "model_name": "Jan-nano-gguf",
    "developer": "Menlo",
    "downloads": 64530,
    "createdAt": "2025-06-11T07:14:33.000Z",
    "num_quants": 14,
    "quants": [
      {
        "model_id": "jan-nano-4b-Q3_K_L",
        "path": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/jan-nano-4b-Q3_K_L.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "jan-nano-4b-Q3_K_M",
        "path": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/jan-nano-4b-Q3_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "jan-nano-4b-Q3_K_S",
        "path": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/jan-nano-4b-Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "jan-nano-4b-Q4_0",
        "path": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/jan-nano-4b-Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "jan-nano-4b-Q4_1",
        "path": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/jan-nano-4b-Q4_1.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "jan-nano-4b-Q4_K_M",
        "path": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/jan-nano-4b-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "jan-nano-4b-Q4_K_S",
        "path": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/jan-nano-4b-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "jan-nano-4b-Q5_0",
        "path": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/jan-nano-4b-Q5_0.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "jan-nano-4b-Q5_1",
        "path": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/jan-nano-4b-Q5_1.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "jan-nano-4b-Q5_K_M",
        "path": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/jan-nano-4b-Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "jan-nano-4b-Q5_K_S",
        "path": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/jan-nano-4b-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "jan-nano-4b-Q6_K",
        "path": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/jan-nano-4b-Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "jan-nano-4b-Q8_0",
        "path": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/jan-nano-4b-Q8_0.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "jan-nano-4b-iQ4_XS",
        "path": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/jan-nano-4b-iQ4_XS.gguf",
        "file_size": "2.1 GB"
      }
    ],
    "readme": "https://huggingface.co/Menlo/Jan-nano-gguf/resolve/main/README.md",
    "description": "Jan Nano is a compact, quantized version of the Qwen3 architecture, optimized for efficient text generation in local or embedded environments with enhanced tool use and research capabilities.",
    "tools": true
  },
  {
    "model_name": "Lucy-128k-gguf",
    "developer": "Menlo",
    "downloads": 3828,
    "createdAt": "2025-07-18T08:52:46.000Z",
    "tools": true,
    "num_quants": 13,
    "quants": [
      {
        "model_id": "lucy_128k-Q3_K_L",
        "path": "https://huggingface.co/Menlo/Lucy-128k-gguf/resolve/main/lucy_128k-Q3_K_L.gguf",
        "file_size": "957.0 MB"
      },
      {
        "model_id": "lucy_128k-Q3_K_M",
        "path": "https://huggingface.co/Menlo/Lucy-128k-gguf/resolve/main/lucy_128k-Q3_K_M.gguf",
        "file_size": "896.0 MB"
      },
      {
        "model_id": "lucy_128k-Q3_K_S",
        "path": "https://huggingface.co/Menlo/Lucy-128k-gguf/resolve/main/lucy_128k-Q3_K_S.gguf",
        "file_size": "827.1 MB"
      },
      {
        "model_id": "lucy_128k-Q4_0",
        "path": "https://huggingface.co/Menlo/Lucy-128k-gguf/resolve/main/lucy_128k-Q4_0.gguf",
        "file_size": "1005.6 MB"
      },
      {
        "model_id": "lucy_128k-Q4_1",
        "path": "https://huggingface.co/Menlo/Lucy-128k-gguf/resolve/main/lucy_128k-Q4_1.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "lucy_128k-Q4_K_M",
        "path": "https://huggingface.co/Menlo/Lucy-128k-gguf/resolve/main/lucy_128k-Q4_K_M.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "lucy_128k-Q4_K_S",
        "path": "https://huggingface.co/Menlo/Lucy-128k-gguf/resolve/main/lucy_128k-Q4_K_S.gguf",
        "file_size": "1011.1 MB"
      },
      {
        "model_id": "lucy_128k-Q5_0",
        "path": "https://huggingface.co/Menlo/Lucy-128k-gguf/resolve/main/lucy_128k-Q5_0.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "lucy_128k-Q5_1",
        "path": "https://huggingface.co/Menlo/Lucy-128k-gguf/resolve/main/lucy_128k-Q5_1.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "lucy_128k-Q5_K_M",
        "path": "https://huggingface.co/Menlo/Lucy-128k-gguf/resolve/main/lucy_128k-Q5_K_M.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "lucy_128k-Q5_K_S",
        "path": "https://huggingface.co/Menlo/Lucy-128k-gguf/resolve/main/lucy_128k-Q5_K_S.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "lucy_128k-Q6_K",
        "path": "https://huggingface.co/Menlo/Lucy-128k-gguf/resolve/main/lucy_128k-Q6_K.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "lucy_128k-Q8_0",
        "path": "https://huggingface.co/Menlo/Lucy-128k-gguf/resolve/main/lucy_128k-Q8_0.gguf",
        "file_size": "1.7 GB"
      }
    ],
    "readme": "https://huggingface.co/Menlo/Lucy-128k-gguf/resolve/main/README.md",
    "description": "Lucy is a 1.7B mobile-optimized model for agentic web search and lightweight browsing, built on Qwen3-1.7B with machine-generated task vectors for efficient performance on CPU-only devices."
  },
  {
    "model_name": "Lucy-gguf",
    "developer": "Menlo",
    "downloads": 2700,
    "createdAt": "2025-07-18T07:04:35.000Z",
    "tools": true,
    "num_quants": 13,
    "quants": [
      {
        "model_id": "Lucy-Q3_K_L",
        "path": "https://huggingface.co/Menlo/Lucy-gguf/resolve/main/Lucy-Q3_K_L.gguf",
        "file_size": "957.0 MB"
      },
      {
        "model_id": "Lucy-Q3_K_M",
        "path": "https://huggingface.co/Menlo/Lucy-gguf/resolve/main/Lucy-Q3_K_M.gguf",
        "file_size": "896.0 MB"
      },
      {
        "model_id": "Lucy-Q3_K_S",
        "path": "https://huggingface.co/Menlo/Lucy-gguf/resolve/main/Lucy-Q3_K_S.gguf",
        "file_size": "827.1 MB"
      },
      {
        "model_id": "Lucy-Q4_0",
        "path": "https://huggingface.co/Menlo/Lucy-gguf/resolve/main/Lucy-Q4_0.gguf",
        "file_size": "1005.6 MB"
      },
      {
        "model_id": "Lucy-Q4_1",
        "path": "https://huggingface.co/Menlo/Lucy-gguf/resolve/main/Lucy-Q4_1.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Lucy-Q4_K_M",
        "path": "https://huggingface.co/Menlo/Lucy-gguf/resolve/main/Lucy-Q4_K_M.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Lucy-Q4_K_S",
        "path": "https://huggingface.co/Menlo/Lucy-gguf/resolve/main/Lucy-Q4_K_S.gguf",
        "file_size": "1011.1 MB"
      },
      {
        "model_id": "Lucy-Q5_0",
        "path": "https://huggingface.co/Menlo/Lucy-gguf/resolve/main/Lucy-Q5_0.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Lucy-Q5_1",
        "path": "https://huggingface.co/Menlo/Lucy-gguf/resolve/main/Lucy-Q5_1.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Lucy-Q5_K_M",
        "path": "https://huggingface.co/Menlo/Lucy-gguf/resolve/main/Lucy-Q5_K_M.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Lucy-Q5_K_S",
        "path": "https://huggingface.co/Menlo/Lucy-gguf/resolve/main/Lucy-Q5_K_S.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Lucy-Q6_K",
        "path": "https://huggingface.co/Menlo/Lucy-gguf/resolve/main/Lucy-Q6_K.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "Lucy-Q8_0",
        "path": "https://huggingface.co/Menlo/Lucy-gguf/resolve/main/Lucy-Q8_0.gguf",
        "file_size": "1.7 GB"
      }
    ],
    "readme": "https://huggingface.co/Menlo/Lucy-gguf/resolve/main/README.md",
    "description": "Lucy is a 1.7B mobile-optimized model for agentic web search and lightweight browsing, built on Qwen3-1.7B with machine-generated task vectors for efficient reasoning and search capabilities."
  },
  {
    "model_name": "A.X-4.0-Light-gguf",
    "developer": "mykor",
    "downloads": 1974,
    "createdAt": "2025-07-04T06:38:36.000Z",
    "num_quants": 16,
    "quants": [
      {
        "model_id": "A.X-4.0-Light-BF16",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-BF16.gguf",
        "file_size": "13.5 GB"
      },
      {
        "model_id": "A.X-4.0-Light-F32",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-F32.gguf",
        "file_size": "27.0 GB"
      },
      {
        "model_id": "A.X-4.0-Light-IQ4_NL",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-IQ4_NL.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "A.X-4.0-Light-IQ4_XS",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-IQ4_XS.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "A.X-4.0-Light-Q2_K",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-Q2_K.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "A.X-4.0-Light-Q3_K_L",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-Q3_K_L.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "A.X-4.0-Light-Q3_K_M",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-Q3_K_M.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "A.X-4.0-Light-Q3_K_S",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-Q3_K_S.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "A.X-4.0-Light-Q4_0",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-Q4_0.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "A.X-4.0-Light-Q4_K_M",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-Q4_K_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "A.X-4.0-Light-Q4_K_S",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-Q4_K_S.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "A.X-4.0-Light-Q5_0",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-Q5_0.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "A.X-4.0-Light-Q5_K_M",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-Q5_K_M.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "A.X-4.0-Light-Q5_K_S",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-Q5_K_S.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "A.X-4.0-Light-Q6_K",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-Q6_K.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "A.X-4.0-Light-Q8_0",
        "path": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/A.X-4.0-Light-Q8_0.gguf",
        "file_size": "7.2 GB"
      }
    ],
    "readme": "https://huggingface.co/mykor/A.X-4.0-Light-gguf/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "AceInstruct-1.5B-GGUF",
    "developer": "Mungert",
    "downloads": 1284,
    "createdAt": "2025-07-15T11:15:49.000Z",
    "tools": false,
    "num_quants": 34,
    "quants": [
      {
        "model_id": "AceInstruct-1.5B-bf16",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-bf16.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-bf16_q4_k",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-bf16_q4_k.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-bf16_q6_k",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-bf16_q6_k.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-bf16_q8_0",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-bf16_q8_0.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-f16",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-f16.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-f16_q4_k",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-f16_q4_k.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-f16_q6_k",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-f16_q6_k.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-f16_q8_0",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-f16_q8_0.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-iq3_m",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-iq3_m.gguf",
        "file_size": "891.4 MB"
      },
      {
        "model_id": "AceInstruct-1.5B-iq3_s",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-iq3_s.gguf",
        "file_size": "891.4 MB"
      },
      {
        "model_id": "AceInstruct-1.5B-iq3_xs",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-iq3_xs.gguf",
        "file_size": "828.1 MB"
      },
      {
        "model_id": "AceInstruct-1.5B-iq3_xxs",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-iq3_xxs.gguf",
        "file_size": "814.9 MB"
      },
      {
        "model_id": "AceInstruct-1.5B-iq4_nl",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-iq4_nl.gguf",
        "file_size": "1018.1 MB"
      },
      {
        "model_id": "AceInstruct-1.5B-iq4_xs",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-iq4_xs.gguf",
        "file_size": "972.5 MB"
      },
      {
        "model_id": "AceInstruct-1.5B-q3_k_l",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q3_k_l.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q3_k_m",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q3_k_m.gguf",
        "file_size": "965.3 MB"
      },
      {
        "model_id": "AceInstruct-1.5B-q3_k_s",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q3_k_s.gguf",
        "file_size": "906.2 MB"
      },
      {
        "model_id": "AceInstruct-1.5B-q4_0",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q4_0.gguf",
        "file_size": "959.5 MB"
      },
      {
        "model_id": "AceInstruct-1.5B-q4_0_l",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q4_0_l.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q4_1",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q4_1.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q4_1_l",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q4_1_l.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q4_k_l",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q4_k_l.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q4_k_m",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q4_k_m.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q4_k_s",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q4_k_s.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q5_0",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q5_0.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q5_0_l",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q5_0_l.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q5_1",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q5_1.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q5_1_l",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q5_1_l.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q5_k_l",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q5_k_l.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q5_k_m",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q5_k_m.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q5_k_s",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q5_k_s.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q6_k_l",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q6_k_l.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q6_k_m",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q6_k_m.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "AceInstruct-1.5B-q8_0",
        "path": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/AceInstruct-1.5B-q8_0.gguf",
        "file_size": "1.8 GB"
      }
    ],
    "readme": "https://huggingface.co/Mungert/AceInstruct-1.5B-GGUF/resolve/main/README.md",
    "description": "AceInstruct-1.5B GGUF Models are advanced, versatile instruction-following models fine-tuned for coding, math, and general tasks, outperforming Qwen2.5-Instruct in benchmark evaluations."
  },
  {
    "model_name": "Arch-Router-1.5B.gguf",
    "developer": "katanemo",
    "downloads": 422,
    "createdAt": "2025-05-30T18:18:40.000Z",
    "num_quants": 10,
    "quants": [
      {
        "model_id": "Arch-Router-1.5B-Q2_K",
        "path": "https://huggingface.co/katanemo/Arch-Router-1.5B.gguf/resolve/main/Arch-Router-1.5B-Q2_K.gguf",
        "file_size": "645.0 MB"
      },
      {
        "model_id": "Arch-Router-1.5B-Q3_K_L",
        "path": "https://huggingface.co/katanemo/Arch-Router-1.5B.gguf/resolve/main/Arch-Router-1.5B-Q3_K_L.gguf",
        "file_size": "839.4 MB"
      },
      {
        "model_id": "Arch-Router-1.5B-Q3_K_M",
        "path": "https://huggingface.co/katanemo/Arch-Router-1.5B.gguf/resolve/main/Arch-Router-1.5B-Q3_K_M.gguf",
        "file_size": "786.0 MB"
      },
      {
        "model_id": "Arch-Router-1.5B-Q3_K_S",
        "path": "https://huggingface.co/katanemo/Arch-Router-1.5B.gguf/resolve/main/Arch-Router-1.5B-Q3_K_S.gguf",
        "file_size": "725.7 MB"
      },
      {
        "model_id": "Arch-Router-1.5B-Q4_K_M",
        "path": "https://huggingface.co/katanemo/Arch-Router-1.5B.gguf/resolve/main/Arch-Router-1.5B-Q4_K_M.gguf",
        "file_size": "940.4 MB"
      },
      {
        "model_id": "Arch-Router-1.5B-Q4_K_S",
        "path": "https://huggingface.co/katanemo/Arch-Router-1.5B.gguf/resolve/main/Arch-Router-1.5B-Q4_K_S.gguf",
        "file_size": "896.8 MB"
      },
      {
        "model_id": "Arch-Router-1.5B-Q5_K_M",
        "path": "https://huggingface.co/katanemo/Arch-Router-1.5B.gguf/resolve/main/Arch-Router-1.5B-Q5_K_M.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Arch-Router-1.5B-Q5_K_S",
        "path": "https://huggingface.co/katanemo/Arch-Router-1.5B.gguf/resolve/main/Arch-Router-1.5B-Q5_K_S.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Arch-Router-1.5B",
        "path": "https://huggingface.co/katanemo/Arch-Router-1.5B.gguf/resolve/main/Arch-Router-1.5B.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Arch-Router-Q6_K",
        "path": "https://huggingface.co/katanemo/Arch-Router-1.5B.gguf/resolve/main/Arch-Router-Q6_K.gguf",
        "file_size": "1.2 GB"
      }
    ],
    "readme": "https://huggingface.co/katanemo/Arch-Router-1.5B.gguf/resolve/main/README.md",
    "description": "The katanemo/Arch-Router-1.5B model is a compact, preference-aligned routing framework that maps queries to domain-action preferences for selecting the most suitable large language model.",
    "tools": true
  },
  {
    "model_name": "ArmenianGPT-0.1-12B",
    "developer": "ArmGPT",
    "downloads": 7,
    "createdAt": "2025-07-11T21:50:18.000Z",
    "num_quants": 5,
    "quants": [
      {
        "model_id": "ArmenianGPT-0.1-12B-Q5_0",
        "path": "https://huggingface.co/ArmGPT/ArmenianGPT-0.1-12B/resolve/main/ArmenianGPT-0.1-12B-Q5_0.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "ArmenianGPT-0.1-12B-Q5_K_M",
        "path": "https://huggingface.co/ArmGPT/ArmenianGPT-0.1-12B/resolve/main/ArmenianGPT-0.1-12B-Q5_K_M.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "ArmenianGPT-0.1-12B-Q5_K_S",
        "path": "https://huggingface.co/ArmGPT/ArmenianGPT-0.1-12B/resolve/main/ArmenianGPT-0.1-12B-Q5_K_S.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "ArmenianGPT-0.1-12B-Q6_K",
        "path": "https://huggingface.co/ArmGPT/ArmenianGPT-0.1-12B/resolve/main/ArmenianGPT-0.1-12B-Q6_K.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "ArmenianGPT-0.1-12B-Q8_0",
        "path": "https://huggingface.co/ArmGPT/ArmenianGPT-0.1-12B/resolve/main/ArmenianGPT-0.1-12B-Q8_0.gguf",
        "file_size": "11.7 GB"
      }
    ],
    "readme": "https://huggingface.co/ArmGPT/ArmenianGPT-0.1-12B/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "baidu_ERNIE-4.5-0.3B-PT-GGUF",
    "developer": "bartowski",
    "downloads": 3865,
    "createdAt": "2025-06-30T03:51:10.000Z",
    "num_quants": 24,
    "quants": [
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-IQ2_M",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-IQ2_M.gguf",
        "file_size": "155.4 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-IQ3_M",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-IQ3_M.gguf",
        "file_size": "195.9 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-IQ3_XS",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-IQ3_XS.gguf",
        "file_size": "184.7 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-IQ3_XXS.gguf",
        "file_size": "164.8 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-IQ4_NL",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-IQ4_NL.gguf",
        "file_size": "222.5 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-IQ4_XS",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-IQ4_XS.gguf",
        "file_size": "215.1 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q2_K",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q2_K.gguf",
        "file_size": "175.2 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q2_K_L",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q2_K_L.gguf",
        "file_size": "199.7 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q3_K_L",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q3_K_L.gguf",
        "file_size": "214.0 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q3_K_M",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q3_K_M.gguf",
        "file_size": "202.7 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q3_K_S",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q3_K_S.gguf",
        "file_size": "189.7 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q3_K_XL.gguf",
        "file_size": "238.5 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q4_0",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q4_0.gguf",
        "file_size": "222.3 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q4_1",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q4_1.gguf",
        "file_size": "237.1 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q4_K_L",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q4_K_L.gguf",
        "file_size": "254.0 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q4_K_M",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q4_K_M.gguf",
        "file_size": "229.5 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q4_K_S",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q4_K_S.gguf",
        "file_size": "222.8 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q5_K_L",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q5_K_L.gguf",
        "file_size": "280.7 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q5_K_M",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q5_K_M.gguf",
        "file_size": "256.2 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q5_K_S",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q5_K_S.gguf",
        "file_size": "252.3 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q6_K",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q6_K.gguf",
        "file_size": "284.6 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q6_K_L",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q6_K_L.gguf",
        "file_size": "309.1 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-Q8_0",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-Q8_0.gguf",
        "file_size": "367.9 MB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-0.3B-PT-bf16",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-0.3B-PT-bf16.gguf",
        "file_size": "690.4 MB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-0.3B-PT-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the ERNIE-4.5-0.3B-PT model using llama.cpp's imatrix method, offering various quantization options for different performance and memory trade-offs.",
    "tools": false
  },
  {
    "model_name": "baidu_ERNIE-4.5-21B-A3B-PT-GGUF",
    "developer": "bartowski",
    "downloads": 1891,
    "createdAt": "2025-06-30T03:51:30.000Z",
    "tools": false,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-IQ2_M",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-IQ2_M.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-IQ2_S",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-IQ2_S.gguf",
        "file_size": "5.9 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-IQ2_XS",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-IQ2_XS.gguf",
        "file_size": "5.9 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-IQ3_M",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-IQ3_M.gguf",
        "file_size": "9.6 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-IQ3_XS",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-IQ3_XS.gguf",
        "file_size": "8.7 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-IQ3_XXS.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-IQ4_NL",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-IQ4_NL.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-IQ4_XS",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-IQ4_XS.gguf",
        "file_size": "11.1 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q2_K",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q2_K.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q2_K_L",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q2_K_L.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q3_K_L",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q3_K_L.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q3_K_M",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q3_K_M.gguf",
        "file_size": "9.6 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q3_K_S",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q3_K_S.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q3_K_XL.gguf",
        "file_size": "10.0 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q4_0",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q4_0.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q4_1",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q4_1.gguf",
        "file_size": "12.9 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q4_K_L",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q4_K_L.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q4_K_M",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q4_K_M.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q4_K_S",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q4_K_S.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q5_K_L",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q5_K_L.gguf",
        "file_size": "14.7 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q5_K_M",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q5_K_M.gguf",
        "file_size": "14.7 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q5_K_S",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q5_K_S.gguf",
        "file_size": "14.2 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q6_K",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q6_K.gguf",
        "file_size": "16.8 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q6_K_L",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q6_K_L.gguf",
        "file_size": "16.9 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-Q8_0",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-Q8_0.gguf",
        "file_size": "21.6 GB"
      },
      {
        "model_id": "baidu_ERNIE-4.5-21B-A3B-PT-bf16",
        "path": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/baidu_ERNIE-4.5-21B-A3B-PT-bf16.gguf",
        "file_size": "40.7 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the ERNIE-4.5-21B-A3B-PT model by baidu, optimized for text generation using llama.cpp with various quantization types for different performance and quality trade-offs."
  },
  {
    "model_name": "Big-Tiger-Gemma-27B-v3-GGUF",
    "developer": "TheDrummer",
    "downloads": 3414,
    "createdAt": "2025-07-04T09:28:17.000Z",
    "num_quants": 6,
    "quants": [
      {
        "model_id": "Tiger-Gemma-27B-v3a-Q2_K",
        "path": "https://huggingface.co/TheDrummer/Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/Tiger-Gemma-27B-v3a-Q2_K.gguf",
        "file_size": "10.2 GB"
      },
      {
        "model_id": "Tiger-Gemma-27B-v3a-Q3_K_M",
        "path": "https://huggingface.co/TheDrummer/Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/Tiger-Gemma-27B-v3a-Q3_K_M.gguf",
        "file_size": "13.1 GB"
      },
      {
        "model_id": "Tiger-Gemma-27B-v3a-Q4_K_M",
        "path": "https://huggingface.co/TheDrummer/Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/Tiger-Gemma-27B-v3a-Q4_K_M.gguf",
        "file_size": "16.1 GB"
      },
      {
        "model_id": "Tiger-Gemma-27B-v3a-Q5_K_M",
        "path": "https://huggingface.co/TheDrummer/Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/Tiger-Gemma-27B-v3a-Q5_K_M.gguf",
        "file_size": "18.9 GB"
      },
      {
        "model_id": "Tiger-Gemma-27B-v3a-Q6_K",
        "path": "https://huggingface.co/TheDrummer/Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/Tiger-Gemma-27B-v3a-Q6_K.gguf",
        "file_size": "21.7 GB"
      },
      {
        "model_id": "Tiger-Gemma-27B-v3a-Q8_0",
        "path": "https://huggingface.co/TheDrummer/Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/Tiger-Gemma-27B-v3a-Q8_0.gguf",
        "file_size": "28.1 GB"
      }
    ],
    "readme": "https://huggingface.co/TheDrummer/Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "BitCPM4-1B-GGUF",
    "developer": "openbmb",
    "downloads": 286,
    "createdAt": "2025-06-13T11:41:44.000Z",
    "num_quants": 2,
    "quants": [
      {
        "model_id": "BitCPM4-1B-q2_k_s",
        "path": "https://huggingface.co/openbmb/BitCPM4-1B-GGUF/resolve/main/BitCPM4-1B-q2_k_s.gguf",
        "file_size": "488.7 MB"
      },
      {
        "model_id": "BitCPM4-1B-q4_0",
        "path": "https://huggingface.co/openbmb/BitCPM4-1B-GGUF/resolve/main/BitCPM4-1B-q4_0.gguf",
        "file_size": "759.6 MB"
      }
    ],
    "readme": "https://huggingface.co/openbmb/BitCPM4-1B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "bitnet-b1.58-2B-4T-gguf",
    "developer": "microsoft",
    "downloads": 5610,
    "createdAt": "2025-04-15T04:25:42.000Z",
    "num_quants": 1,
    "quants": [
      {
        "model_id": "ggml-model-i2_s",
        "path": "https://huggingface.co/microsoft/bitnet-b1.58-2B-4T-gguf/resolve/main/ggml-model-i2_s.gguf",
        "file_size": "1.1 GB"
      }
    ],
    "readme": "https://huggingface.co/microsoft/bitnet-b1.58-2B-4T-gguf/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "CabraMistral-v3-7b-32k-GGUF",
    "developer": "mradermacher",
    "downloads": 353,
    "createdAt": "2024-05-25T07:46:46.000Z",
    "tools": false,
    "num_quants": 15,
    "quants": [
      {
        "model_id": "CabraMistral-v3-7b-32k.IQ3_M",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.IQ3_M.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "CabraMistral-v3-7b-32k.IQ3_S",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.IQ3_S.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "CabraMistral-v3-7b-32k.IQ3_XS",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.IQ3_XS.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "CabraMistral-v3-7b-32k.IQ4_XS",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.IQ4_XS.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "CabraMistral-v3-7b-32k.Q2_K",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.Q2_K.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "CabraMistral-v3-7b-32k.Q3_K_L",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.Q3_K_L.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "CabraMistral-v3-7b-32k.Q3_K_M",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.Q3_K_M.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "CabraMistral-v3-7b-32k.Q3_K_S",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.Q3_K_S.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "CabraMistral-v3-7b-32k.Q4_K_M",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.Q4_K_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "CabraMistral-v3-7b-32k.Q4_K_S",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.Q4_K_S.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "CabraMistral-v3-7b-32k.Q5_K_M",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.Q5_K_M.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "CabraMistral-v3-7b-32k.Q5_K_S",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.Q5_K_S.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "CabraMistral-v3-7b-32k.Q6_K",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.Q6_K.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "CabraMistral-v3-7b-32k.Q8_0",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.Q8_0.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "CabraMistral-v3-7b-32k.f16",
        "path": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/CabraMistral-v3-7b-32k.f16.gguf",
        "file_size": "13.5 GB"
      }
    ],
    "readme": "https://huggingface.co/mradermacher/CabraMistral-v3-7b-32k-GGUF/resolve/main/README.md",
    "description": "The model is a quantized version of the Mistral-v3-7b-32k base model, offering various quantization types for efficient deployment on different hardware platforms."
  },
  {
    "model_name": "Chronos-Hermes-13b-v2-GGUF",
    "developer": "TheBloke",
    "downloads": 4627,
    "createdAt": "2023-09-08T12:41:26.000Z",
    "num_quants": 12,
    "quants": [
      {
        "model_id": "chronos-hermes-13b-v2.Q2_K",
        "path": "https://huggingface.co/TheBloke/Chronos-Hermes-13b-v2-GGUF/resolve/main/chronos-hermes-13b-v2.Q2_K.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "chronos-hermes-13b-v2.Q3_K_L",
        "path": "https://huggingface.co/TheBloke/Chronos-Hermes-13b-v2-GGUF/resolve/main/chronos-hermes-13b-v2.Q3_K_L.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "chronos-hermes-13b-v2.Q3_K_M",
        "path": "https://huggingface.co/TheBloke/Chronos-Hermes-13b-v2-GGUF/resolve/main/chronos-hermes-13b-v2.Q3_K_M.gguf",
        "file_size": "5.9 GB"
      },
      {
        "model_id": "chronos-hermes-13b-v2.Q3_K_S",
        "path": "https://huggingface.co/TheBloke/Chronos-Hermes-13b-v2-GGUF/resolve/main/chronos-hermes-13b-v2.Q3_K_S.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "chronos-hermes-13b-v2.Q4_0",
        "path": "https://huggingface.co/TheBloke/Chronos-Hermes-13b-v2-GGUF/resolve/main/chronos-hermes-13b-v2.Q4_0.gguf",
        "file_size": "6.9 GB"
      },
      {
        "model_id": "chronos-hermes-13b-v2.Q4_K_M",
        "path": "https://huggingface.co/TheBloke/Chronos-Hermes-13b-v2-GGUF/resolve/main/chronos-hermes-13b-v2.Q4_K_M.gguf",
        "file_size": "7.3 GB"
      },
      {
        "model_id": "chronos-hermes-13b-v2.Q4_K_S",
        "path": "https://huggingface.co/TheBloke/Chronos-Hermes-13b-v2-GGUF/resolve/main/chronos-hermes-13b-v2.Q4_K_S.gguf",
        "file_size": "6.9 GB"
      },
      {
        "model_id": "chronos-hermes-13b-v2.Q5_0",
        "path": "https://huggingface.co/TheBloke/Chronos-Hermes-13b-v2-GGUF/resolve/main/chronos-hermes-13b-v2.Q5_0.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "chronos-hermes-13b-v2.Q5_K_M",
        "path": "https://huggingface.co/TheBloke/Chronos-Hermes-13b-v2-GGUF/resolve/main/chronos-hermes-13b-v2.Q5_K_M.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "chronos-hermes-13b-v2.Q5_K_S",
        "path": "https://huggingface.co/TheBloke/Chronos-Hermes-13b-v2-GGUF/resolve/main/chronos-hermes-13b-v2.Q5_K_S.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "chronos-hermes-13b-v2.Q6_K",
        "path": "https://huggingface.co/TheBloke/Chronos-Hermes-13b-v2-GGUF/resolve/main/chronos-hermes-13b-v2.Q6_K.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "chronos-hermes-13b-v2.Q8_0",
        "path": "https://huggingface.co/TheBloke/Chronos-Hermes-13b-v2-GGUF/resolve/main/chronos-hermes-13b-v2.Q8_0.gguf",
        "file_size": "12.9 GB"
      }
    ],
    "readme": "https://huggingface.co/TheBloke/Chronos-Hermes-13b-v2-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "claude-3.7-sonnet-reasoning-gemma3-12B",
    "developer": "reedmayhew",
    "downloads": 8701,
    "createdAt": "2025-03-22T19:40:09.000Z",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "claude-3.7-sonnet-reasoning-gemma3-12B.Q8_0",
        "path": "https://huggingface.co/reedmayhew/claude-3.7-sonnet-reasoning-gemma3-12B/resolve/main/claude-3.7-sonnet-reasoning-gemma3-12B.Q8_0.gguf",
        "file_size": "11.7 GB"
      }
    ],
    "readme": "https://huggingface.co/reedmayhew/claude-3.7-sonnet-reasoning-gemma3-12B/resolve/main/README.md",
    "description": "This model is a Gemma 3 12B variant fine-tuned with reasoning data from Claude 3.7 Sonnet using LoRA and trained 2x faster with Unsloth and Huggingface's TRL."
  },
  {
    "model_name": "codegemma-2b-GGUF",
    "developer": "bartowski",
    "downloads": 809,
    "createdAt": "2024-04-09T14:56:27.000Z",
    "num_quants": 22,
    "quants": [
      {
        "model_id": "codegemma-2b-IQ1_M",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-IQ1_M.gguf",
        "file_size": "776.1 MB"
      },
      {
        "model_id": "codegemma-2b-IQ1_S",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-IQ1_S.gguf",
        "file_size": "735.2 MB"
      },
      {
        "model_id": "codegemma-2b-IQ2_M",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-IQ2_M.gguf",
        "file_size": "972.2 MB"
      },
      {
        "model_id": "codegemma-2b-IQ2_S",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-IQ2_S.gguf",
        "file_size": "917.7 MB"
      },
      {
        "model_id": "codegemma-2b-IQ2_XS",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-IQ2_XS.gguf",
        "file_size": "901.1 MB"
      },
      {
        "model_id": "codegemma-2b-IQ2_XXS",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-IQ2_XXS.gguf",
        "file_size": "844.3 MB"
      },
      {
        "model_id": "codegemma-2b-IQ3_M",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-IQ3_M.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "codegemma-2b-IQ3_S",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-IQ3_S.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "codegemma-2b-IQ3_XS",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-IQ3_XS.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "codegemma-2b-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-IQ3_XXS.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "codegemma-2b-IQ4_NL",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-IQ4_NL.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "codegemma-2b-IQ4_XS",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-IQ4_XS.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "codegemma-2b-Q2_K",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-Q2_K.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "codegemma-2b-Q3_K_L",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-Q3_K_L.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "codegemma-2b-Q3_K_M",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-Q3_K_M.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "codegemma-2b-Q3_K_S",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-Q3_K_S.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "codegemma-2b-Q4_K_M",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-Q4_K_M.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "codegemma-2b-Q4_K_S",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-Q4_K_S.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "codegemma-2b-Q5_K_M",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-Q5_K_M.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "codegemma-2b-Q5_K_S",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-Q5_K_S.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "codegemma-2b-Q6_K",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-Q6_K.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "codegemma-2b-Q8_0",
        "path": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-Q8_0.gguf",
        "file_size": "2.5 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "CodeLlama-7B-Instruct-GGUF",
    "developer": "TheBloke",
    "downloads": 14274,
    "createdAt": "2023-08-24T17:01:14.000Z",
    "num_quants": 12,
    "quants": [
      {
        "model_id": "codellama-7b-instruct.Q2_K",
        "path": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q2_K.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "codellama-7b-instruct.Q3_K_L",
        "path": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q3_K_L.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "codellama-7b-instruct.Q3_K_M",
        "path": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q3_K_M.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "codellama-7b-instruct.Q3_K_S",
        "path": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q3_K_S.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "codellama-7b-instruct.Q4_0",
        "path": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q4_0.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "codellama-7b-instruct.Q4_K_M",
        "path": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q4_K_M.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "codellama-7b-instruct.Q4_K_S",
        "path": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q4_K_S.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "codellama-7b-instruct.Q5_0",
        "path": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q5_0.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "codellama-7b-instruct.Q5_K_M",
        "path": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q5_K_M.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "codellama-7b-instruct.Q5_K_S",
        "path": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q5_K_S.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "codellama-7b-instruct.Q6_K",
        "path": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q6_K.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "codellama-7b-instruct.Q8_0",
        "path": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q8_0.gguf",
        "file_size": "6.7 GB"
      }
    ],
    "readme": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/README.md",
    "description": "The CodeLlama 7B Instruct model is a 7 billion parameter, instruction-following code generation model from Meta, available in various quantized GGUF formats for efficient CPU and GPU inference.",
    "tools": false
  },
  {
    "model_name": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF",
    "developer": "bartowski",
    "downloads": 20255,
    "createdAt": "2025-05-09T15:21:21.000Z",
    "num_quants": 27,
    "quants": [
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ2_M",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ2_M.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ2_S",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ2_S.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ2_XS",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ2_XS.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ2_XXS",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ2_XXS.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ3_M",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ3_M.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ3_XS",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ3_XS.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ3_XXS.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ4_NL",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ4_NL.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ4_XS",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-IQ4_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q2_K",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q2_K_L",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q2_K_L.gguf",
        "file_size": "8.9 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q3_K_L",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q3_K_L.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q3_K_M",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q3_K_S",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q3_K_XL.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q4_0",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q4_0.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q4_1",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q4_1.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q4_K_L",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q4_K_L.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q4_K_M",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q4_K_S",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q5_K_L",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q5_K_L.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q5_K_M",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q5_K_S",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q6_K",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q6_K_L",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q6_K_L.gguf",
        "file_size": "18.3 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q8_0",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-Q8_0.gguf",
        "file_size": "23.3 GB"
      },
      {
        "model_id": "cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-bf16",
        "path": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-bf16.gguf",
        "file_size": "43.9 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Dolphin-Mistral-24B-Venice-Edition model by cognitivecomputations, optimized for various inference speeds and quality levels using llama.cpp's imatrix quantization method.",
    "tools": false
  },
  {
    "model_name": "Cybersecurity-BaronLLM_Offensive_Security_LLM_Q6_K_GGUF",
    "developer": "AlicanKiraz0",
    "downloads": 393,
    "createdAt": "2025-01-21T03:41:56.000Z",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "baronllm-llama3.1-v1-q6_k",
        "path": "https://huggingface.co/AlicanKiraz0/Cybersecurity-BaronLLM_Offensive_Security_LLM_Q6_K_GGUF/resolve/main/baronllm-llama3.1-v1-q6_k.gguf",
        "file_size": "6.1 GB"
      }
    ],
    "readme": "https://huggingface.co/AlicanKiraz0/Cybersecurity-BaronLLM_Offensive_Security_LLM_Q6_K_GGUF/resolve/main/README.md",
    "description": "BaronLLM is a large-language model fine-tuned for offensive cybersecurity research and adversarial simulation, providing exploit reasoning, red-team scenario generation, and safety-constrained content."
  },
  {
    "model_name": "Cydonia-24B-v4-GGUF",
    "developer": "TheDrummer",
    "downloads": 7578,
    "createdAt": "2025-07-01T19:33:48.000Z",
    "tools": false,
    "num_quants": 6,
    "quants": [
      {
        "model_id": "Cydonia-24B-v4h-Q2_K",
        "path": "https://huggingface.co/TheDrummer/Cydonia-24B-v4-GGUF/resolve/main/Cydonia-24B-v4h-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "Cydonia-24B-v4h-Q3_K_M",
        "path": "https://huggingface.co/TheDrummer/Cydonia-24B-v4-GGUF/resolve/main/Cydonia-24B-v4h-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "Cydonia-24B-v4h-Q4_K_M",
        "path": "https://huggingface.co/TheDrummer/Cydonia-24B-v4-GGUF/resolve/main/Cydonia-24B-v4h-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "Cydonia-24B-v4h-Q5_K_M",
        "path": "https://huggingface.co/TheDrummer/Cydonia-24B-v4-GGUF/resolve/main/Cydonia-24B-v4h-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "Cydonia-24B-v4h-Q6_K",
        "path": "https://huggingface.co/TheDrummer/Cydonia-24B-v4-GGUF/resolve/main/Cydonia-24B-v4h-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "Cydonia-24B-v4h-Q8_0",
        "path": "https://huggingface.co/TheDrummer/Cydonia-24B-v4-GGUF/resolve/main/Cydonia-24B-v4h-Q8_0.gguf",
        "file_size": "23.3 GB"
      }
    ],
    "readme": "https://huggingface.co/TheDrummer/Cydonia-24B-v4-GGUF/resolve/main/README.md",
    "description": "Cydonia 24B v4 is a wordy and thick model with a novel style, excelling at long-form storytelling and descriptive tasks, and is dedicated to the memory of SleepDeprived, a beloved community member."
  },
  {
    "model_name": "Cydonia-24B-v4-i1-GGUF",
    "developer": "mradermacher",
    "downloads": 2798,
    "createdAt": "2025-07-09T12:21:43.000Z",
    "num_quants": 23,
    "quants": [
      {
        "model_id": "Cydonia-24B-v4.i1-IQ1_M",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-IQ1_M.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-IQ1_S",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-IQ1_S.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-IQ2_M",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-IQ2_M.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-IQ2_S",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-IQ2_S.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-IQ2_XS",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-IQ2_XS.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-IQ2_XXS",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-IQ2_XXS.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-IQ3_M",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-IQ3_M.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-IQ3_S",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-IQ3_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-IQ3_XS",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-IQ3_XS.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-IQ3_XXS",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-IQ3_XXS.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-IQ4_XS",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-IQ4_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-Q2_K",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-Q2_K_S",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-Q2_K_S.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-Q3_K_L",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-Q3_K_L.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-Q3_K_M",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-Q3_K_S",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-Q4_0",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-Q4_0.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-Q4_1",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-Q4_1.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-Q4_K_M",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-Q4_K_S",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-Q5_K_M",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-Q5_K_S",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "Cydonia-24B-v4.i1-Q6_K",
        "path": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/Cydonia-24B-v4.i1-Q6_K.gguf",
        "file_size": "18.0 GB"
      }
    ],
    "readme": "https://huggingface.co/mradermacher/Cydonia-24B-v4-i1-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Cydonia-v1.3-Magnum-v4-22B-GGUF",
    "developer": "knifeayumu",
    "downloads": 4219,
    "createdAt": "2024-11-21T09:27:30.000Z",
    "num_quants": 11,
    "quants": [
      {
        "model_id": "Cydonia-v1.3-Magnum-v4-22B-F16",
        "path": "https://huggingface.co/knifeayumu/Cydonia-v1.3-Magnum-v4-22B-GGUF/resolve/main/Cydonia-v1.3-Magnum-v4-22B-F16.gguf",
        "file_size": "41.4 GB"
      },
      {
        "model_id": "Cydonia-v1.3-Magnum-v4-22B-Q2_K",
        "path": "https://huggingface.co/knifeayumu/Cydonia-v1.3-Magnum-v4-22B-GGUF/resolve/main/Cydonia-v1.3-Magnum-v4-22B-Q2_K.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "Cydonia-v1.3-Magnum-v4-22B-Q3_K_L",
        "path": "https://huggingface.co/knifeayumu/Cydonia-v1.3-Magnum-v4-22B-GGUF/resolve/main/Cydonia-v1.3-Magnum-v4-22B-Q3_K_L.gguf",
        "file_size": "10.9 GB"
      },
      {
        "model_id": "Cydonia-v1.3-Magnum-v4-22B-Q3_K_M",
        "path": "https://huggingface.co/knifeayumu/Cydonia-v1.3-Magnum-v4-22B-GGUF/resolve/main/Cydonia-v1.3-Magnum-v4-22B-Q3_K_M.gguf",
        "file_size": "10.0 GB"
      },
      {
        "model_id": "Cydonia-v1.3-Magnum-v4-22B-Q3_K_S",
        "path": "https://huggingface.co/knifeayumu/Cydonia-v1.3-Magnum-v4-22B-GGUF/resolve/main/Cydonia-v1.3-Magnum-v4-22B-Q3_K_S.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "Cydonia-v1.3-Magnum-v4-22B-Q4_K_M",
        "path": "https://huggingface.co/knifeayumu/Cydonia-v1.3-Magnum-v4-22B-GGUF/resolve/main/Cydonia-v1.3-Magnum-v4-22B-Q4_K_M.gguf",
        "file_size": "12.4 GB"
      },
      {
        "model_id": "Cydonia-v1.3-Magnum-v4-22B-Q4_K_S",
        "path": "https://huggingface.co/knifeayumu/Cydonia-v1.3-Magnum-v4-22B-GGUF/resolve/main/Cydonia-v1.3-Magnum-v4-22B-Q4_K_S.gguf",
        "file_size": "11.8 GB"
      },
      {
        "model_id": "Cydonia-v1.3-Magnum-v4-22B-Q5_K_M",
        "path": "https://huggingface.co/knifeayumu/Cydonia-v1.3-Magnum-v4-22B-GGUF/resolve/main/Cydonia-v1.3-Magnum-v4-22B-Q5_K_M.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "Cydonia-v1.3-Magnum-v4-22B-Q5_K_S",
        "path": "https://huggingface.co/knifeayumu/Cydonia-v1.3-Magnum-v4-22B-GGUF/resolve/main/Cydonia-v1.3-Magnum-v4-22B-Q5_K_S.gguf",
        "file_size": "14.3 GB"
      },
      {
        "model_id": "Cydonia-v1.3-Magnum-v4-22B-Q6_K",
        "path": "https://huggingface.co/knifeayumu/Cydonia-v1.3-Magnum-v4-22B-GGUF/resolve/main/Cydonia-v1.3-Magnum-v4-22B-Q6_K.gguf",
        "file_size": "17.0 GB"
      },
      {
        "model_id": "Cydonia-v1.3-Magnum-v4-22B-Q8_0",
        "path": "https://huggingface.co/knifeayumu/Cydonia-v1.3-Magnum-v4-22B-GGUF/resolve/main/Cydonia-v1.3-Magnum-v4-22B-Q8_0.gguf",
        "file_size": "22.0 GB"
      }
    ],
    "readme": "https://huggingface.co/knifeayumu/Cydonia-v1.3-Magnum-v4-22B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF",
    "developer": "QuantFactory",
    "downloads": 21891,
    "createdAt": "2024-07-28T07:02:48.000Z",
    "tools": false,
    "num_quants": 14,
    "quants": [
      {
        "model_id": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q2_K",
        "path": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q3_K_L",
        "path": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q3_K_M",
        "path": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q3_K_S",
        "path": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q4_0",
        "path": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q4_0.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q4_1",
        "path": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q4_1.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q4_K_M",
        "path": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q4_K_S",
        "path": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q5_0",
        "path": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q5_0.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q5_1",
        "path": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q5_1.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q5_K_M",
        "path": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q5_K_S",
        "path": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q6_K",
        "path": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q8_0",
        "path": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q8_0.gguf",
        "file_size": "8.0 GB"
      }
    ],
    "readme": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/README.md",
    "description": "The QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF is a quantized, uncensored, and multilingual version of the Meta Llama 3.1 8B model, optimized for roleplay, instruction"
  },
  {
    "model_name": "DeepSeek-Coder-V2-Lite-Instruct-GGUF",
    "developer": "bartowski",
    "downloads": 12732,
    "createdAt": "2024-06-17T14:35:57.000Z",
    "num_quants": 23,
    "quants": [
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-IQ2_M",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-IQ2_M.gguf",
        "file_size": "5.9 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-IQ2_S",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-IQ2_S.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-IQ2_XS",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-IQ2_XS.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-IQ3_M",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-IQ3_M.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-IQ3_XS",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-IQ3_XS.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-IQ3_XXS.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-IQ4_XS",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-IQ4_XS.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-Q2_K",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q2_K.gguf",
        "file_size": "6.0 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-Q3_K_L",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q3_K_L.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-Q3_K_M",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q3_K_M.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-Q3_K_S",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q3_K_S.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-Q4_K_L",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q4_K_L.gguf",
        "file_size": "10.2 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-Q4_K_M",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q4_K_M.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-Q4_K_S",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q4_K_S.gguf",
        "file_size": "8.9 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-Q5_K_L",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q5_K_L.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-Q5_K_M",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q5_K_M.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-Q5_K_S",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q5_K_S.gguf",
        "file_size": "10.4 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-Q6_K",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q6_K.gguf",
        "file_size": "13.1 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-Q6_K_L",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q6_K_L.gguf",
        "file_size": "13.6 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-Q8_0",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q8_0.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-Q8_0_L",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q8_0_L.gguf",
        "file_size": "15.9 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-f32.gguf/DeepSeek-Coder-V2-Lite-Instruct-f32-00001-of-00002",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-f32.gguf/DeepSeek-Coder-V2-Lite-Instruct-f32-00001-of-00002.gguf",
        "file_size": "36.7 GB"
      },
      {
        "model_id": "DeepSeek-Coder-V2-Lite-Instruct-f32.gguf/DeepSeek-Coder-V2-Lite-Instruct-f32-00002-of-00002",
        "path": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-f32.gguf/DeepSeek-Coder-V2-Lite-Instruct-f32-00002-of-00002.gguf",
        "file_size": "21.8 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "deepseek-r1-0528-distilled-qwen3-gguf",
    "developer": "ertghiu256",
    "downloads": 800,
    "createdAt": "2025-06-16T12:31:00.000Z",
    "num_quants": 2,
    "quants": [
      {
        "model_id": "converted-model-Q4_K_M",
        "path": "https://huggingface.co/ertghiu256/deepseek-r1-0528-distilled-qwen3-gguf/resolve/main/converted-model-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "converted-model-Q8_0",
        "path": "https://huggingface.co/ertghiu256/deepseek-r1-0528-distilled-qwen3-gguf/resolve/main/converted-model-Q8_0.gguf",
        "file_size": "4.0 GB"
      }
    ],
    "readme": "https://huggingface.co/ertghiu256/deepseek-r1-0528-distilled-qwen3-gguf/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "DeepSeek-R1-0528-GGUF",
    "developer": "unsloth",
    "downloads": 132698,
    "createdAt": "2025-05-28T18:10:04.000Z",
    "tools": true,
    "num_quants": 235,
    "quants": [
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00001-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00001-of-00030.gguf",
        "file_size": "40.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00002-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00002-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00003-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00003-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00004-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00004-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00005-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00005-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00006-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00006-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00007-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00007-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00008-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00008-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00009-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00009-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00010-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00010-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00011-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00011-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00012-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00012-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00013-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00013-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00014-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00014-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00015-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00015-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00016-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00016-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00017-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00017-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00018-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00018-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00019-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00019-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00020-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00020-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00021-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00021-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00022-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00022-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00023-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00023-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00024-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00024-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00025-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00025-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00026-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00026-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00027-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00027-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00028-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00028-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00029-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00029-of-00030.gguf",
        "file_size": "44.6 GB"
      },
      {
        "model_id": "BF16/DeepSeek-R1-0528-BF16-00030-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/BF16/DeepSeek-R1-0528-BF16-00030-of-00030.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-UD-TQ1_0",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/DeepSeek-R1-0528-UD-TQ1_0.gguf",
        "file_size": "150.5 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00001-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00001-of-00008.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00002-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00002-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00003-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00003-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00004-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00004-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00005-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00005-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00006-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00006-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00007-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00007-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00008-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_NL/DeepSeek-R1-0528-IQ4_NL-00008-of-00008.gguf",
        "file_size": "28.1 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00001-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00001-of-00008.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00002-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00002-of-00008.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00003-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00003-of-00008.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00004-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00004-of-00008.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00005-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00005-of-00008.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00006-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00006-of-00008.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00007-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00007-of-00008.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00008-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/IQ4_XS/DeepSeek-R1-0528-IQ4_XS-00008-of-00008.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-R1-0528-Q2_K-00001-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q2_K/DeepSeek-R1-0528-Q2_K-00001-of-00005.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-R1-0528-Q2_K-00002-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q2_K/DeepSeek-R1-0528-Q2_K-00002-of-00005.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-R1-0528-Q2_K-00003-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q2_K/DeepSeek-R1-0528-Q2_K-00003-of-00005.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-R1-0528-Q2_K-00004-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q2_K/DeepSeek-R1-0528-Q2_K-00004-of-00005.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-R1-0528-Q2_K-00005-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q2_K/DeepSeek-R1-0528-Q2_K-00005-of-00005.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q2_K_L/DeepSeek-R1-0528-Q2_K_L-00001-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q2_K_L/DeepSeek-R1-0528-Q2_K_L-00001-of-00005.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q2_K_L/DeepSeek-R1-0528-Q2_K_L-00002-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q2_K_L/DeepSeek-R1-0528-Q2_K_L-00002-of-00005.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Q2_K_L/DeepSeek-R1-0528-Q2_K_L-00003-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q2_K_L/DeepSeek-R1-0528-Q2_K_L-00003-of-00005.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q2_K_L/DeepSeek-R1-0528-Q2_K_L-00004-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q2_K_L/DeepSeek-R1-0528-Q2_K_L-00004-of-00005.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Q2_K_L/DeepSeek-R1-0528-Q2_K_L-00005-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q2_K_L/DeepSeek-R1-0528-Q2_K_L-00005-of-00005.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-R1-0528-Q3_K_M-00001-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q3_K_M/DeepSeek-R1-0528-Q3_K_M-00001-of-00007.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-R1-0528-Q3_K_M-00002-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q3_K_M/DeepSeek-R1-0528-Q3_K_M-00002-of-00007.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-R1-0528-Q3_K_M-00003-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q3_K_M/DeepSeek-R1-0528-Q3_K_M-00003-of-00007.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-R1-0528-Q3_K_M-00004-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q3_K_M/DeepSeek-R1-0528-Q3_K_M-00004-of-00007.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-R1-0528-Q3_K_M-00005-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q3_K_M/DeepSeek-R1-0528-Q3_K_M-00005-of-00007.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-R1-0528-Q3_K_M-00006-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q3_K_M/DeepSeek-R1-0528-Q3_K_M-00006-of-00007.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-R1-0528-Q3_K_M-00007-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q3_K_M/DeepSeek-R1-0528-Q3_K_M-00007-of-00007.gguf",
        "file_size": "21.9 GB"
      },
      {
        "model_id": "Q3_K_S/DeepSeek-R1-0528-Q3_K_S-00001-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q3_K_S/DeepSeek-R1-0528-Q3_K_S-00001-of-00006.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q3_K_S/DeepSeek-R1-0528-Q3_K_S-00002-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q3_K_S/DeepSeek-R1-0528-Q3_K_S-00002-of-00006.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q3_K_S/DeepSeek-R1-0528-Q3_K_S-00003-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q3_K_S/DeepSeek-R1-0528-Q3_K_S-00003-of-00006.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q3_K_S/DeepSeek-R1-0528-Q3_K_S-00004-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q3_K_S/DeepSeek-R1-0528-Q3_K_S-00004-of-00006.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q3_K_S/DeepSeek-R1-0528-Q3_K_S-00005-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q3_K_S/DeepSeek-R1-0528-Q3_K_S-00005-of-00006.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q3_K_S/DeepSeek-R1-0528-Q3_K_S-00006-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q3_K_S/DeepSeek-R1-0528-Q3_K_S-00006-of-00006.gguf",
        "file_size": "38.5 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-R1-0528-Q4_0-00001-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_0/DeepSeek-R1-0528-Q4_0-00001-of-00008.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-R1-0528-Q4_0-00002-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_0/DeepSeek-R1-0528-Q4_0-00002-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-R1-0528-Q4_0-00003-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_0/DeepSeek-R1-0528-Q4_0-00003-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-R1-0528-Q4_0-00004-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_0/DeepSeek-R1-0528-Q4_0-00004-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-R1-0528-Q4_0-00005-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_0/DeepSeek-R1-0528-Q4_0-00005-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-R1-0528-Q4_0-00006-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_0/DeepSeek-R1-0528-Q4_0-00006-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-R1-0528-Q4_0-00007-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_0/DeepSeek-R1-0528-Q4_0-00007-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-R1-0528-Q4_0-00008-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_0/DeepSeek-R1-0528-Q4_0-00008-of-00008.gguf",
        "file_size": "30.1 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-R1-0528-Q4_1-00001-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_1/DeepSeek-R1-0528-Q4_1-00001-of-00009.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-R1-0528-Q4_1-00002-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_1/DeepSeek-R1-0528-Q4_1-00002-of-00009.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-R1-0528-Q4_1-00003-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_1/DeepSeek-R1-0528-Q4_1-00003-of-00009.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-R1-0528-Q4_1-00004-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_1/DeepSeek-R1-0528-Q4_1-00004-of-00009.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-R1-0528-Q4_1-00005-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_1/DeepSeek-R1-0528-Q4_1-00005-of-00009.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-R1-0528-Q4_1-00006-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_1/DeepSeek-R1-0528-Q4_1-00006-of-00009.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-R1-0528-Q4_1-00007-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_1/DeepSeek-R1-0528-Q4_1-00007-of-00009.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-R1-0528-Q4_1-00008-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_1/DeepSeek-R1-0528-Q4_1-00008-of-00009.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-R1-0528-Q4_1-00009-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_1/DeepSeek-R1-0528-Q4_1-00009-of-00009.gguf",
        "file_size": "33.4 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00001-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00001-of-00009.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00002-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00002-of-00009.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00003-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00003-of-00009.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00004-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00004-of-00009.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00005-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00005-of-00009.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00006-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00006-of-00009.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00007-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00007-of-00009.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00008-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00008-of-00009.gguf",
        "file_size": "43.8 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00009-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_M/DeepSeek-R1-0528-Q4_K_M-00009-of-00009.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00001-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00001-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00002-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00002-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00003-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00003-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00004-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00004-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00005-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00005-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00006-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00006-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00007-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00007-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00008-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q4_K_S/DeepSeek-R1-0528-Q4_K_S-00008-of-00008.gguf",
        "file_size": "30.1 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00001-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00001-of-00010.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00002-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00002-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00003-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00003-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00004-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00004-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00005-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00005-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00006-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00006-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00007-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00007-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00008-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00008-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00009-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00009-of-00010.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00010-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_M/DeepSeek-R1-0528-Q5_K_M-00010-of-00010.gguf",
        "file_size": "36.2 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00001-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00001-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00002-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00002-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00003-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00003-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00004-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00004-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00005-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00005-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00006-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00006-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00007-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00007-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00008-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00008-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00009-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00009-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00010-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q5_K_S/DeepSeek-R1-0528-Q5_K_S-00010-of-00010.gguf",
        "file_size": "31.9 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-R1-0528-Q6_K-00001-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q6_K/DeepSeek-R1-0528-Q6_K-00001-of-00012.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-R1-0528-Q6_K-00002-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q6_K/DeepSeek-R1-0528-Q6_K-00002-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-R1-0528-Q6_K-00003-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q6_K/DeepSeek-R1-0528-Q6_K-00003-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-R1-0528-Q6_K-00004-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q6_K/DeepSeek-R1-0528-Q6_K-00004-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-R1-0528-Q6_K-00005-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q6_K/DeepSeek-R1-0528-Q6_K-00005-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-R1-0528-Q6_K-00006-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q6_K/DeepSeek-R1-0528-Q6_K-00006-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-R1-0528-Q6_K-00007-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q6_K/DeepSeek-R1-0528-Q6_K-00007-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-R1-0528-Q6_K-00008-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q6_K/DeepSeek-R1-0528-Q6_K-00008-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-R1-0528-Q6_K-00009-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q6_K/DeepSeek-R1-0528-Q6_K-00009-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-R1-0528-Q6_K-00010-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q6_K/DeepSeek-R1-0528-Q6_K-00010-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-R1-0528-Q6_K-00011-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q6_K/DeepSeek-R1-0528-Q6_K-00011-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-R1-0528-Q6_K-00012-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q6_K/DeepSeek-R1-0528-Q6_K-00012-of-00012.gguf",
        "file_size": "29.3 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00001-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00001-of-00015.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00002-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00002-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00003-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00003-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00004-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00004-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00005-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00005-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00006-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00006-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00007-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00007-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00008-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00008-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00009-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00009-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00010-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00010-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00011-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00011-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00012-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00012-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00013-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00013-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00014-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00014-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-R1-0528-Q8_0-00015-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/Q8_0/DeepSeek-R1-0528-Q8_0-00015-of-00015.gguf",
        "file_size": "27.4 GB"
      },
      {
        "model_id": "UD-IQ1_M/DeepSeek-R1-0528-UD-IQ1_M-00001-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ1_M/DeepSeek-R1-0528-UD-IQ1_M-00001-of-00005.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-IQ1_M/DeepSeek-R1-0528-UD-IQ1_M-00002-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ1_M/DeepSeek-R1-0528-UD-IQ1_M-00002-of-00005.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-IQ1_M/DeepSeek-R1-0528-UD-IQ1_M-00003-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ1_M/DeepSeek-R1-0528-UD-IQ1_M-00003-of-00005.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-IQ1_M/DeepSeek-R1-0528-UD-IQ1_M-00004-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ1_M/DeepSeek-R1-0528-UD-IQ1_M-00004-of-00005.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-IQ1_M/DeepSeek-R1-0528-UD-IQ1_M-00005-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ1_M/DeepSeek-R1-0528-UD-IQ1_M-00005-of-00005.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "UD-IQ1_S/DeepSeek-R1-0528-UD-IQ1_S-00001-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ1_S/DeepSeek-R1-0528-UD-IQ1_S-00001-of-00004.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-IQ1_S/DeepSeek-R1-0528-UD-IQ1_S-00002-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ1_S/DeepSeek-R1-0528-UD-IQ1_S-00002-of-00004.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "UD-IQ1_S/DeepSeek-R1-0528-UD-IQ1_S-00003-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ1_S/DeepSeek-R1-0528-UD-IQ1_S-00003-of-00004.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-IQ1_S/DeepSeek-R1-0528-UD-IQ1_S-00004-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ1_S/DeepSeek-R1-0528-UD-IQ1_S-00004-of-00004.gguf",
        "file_size": "35.0 GB"
      },
      {
        "model_id": "UD-IQ2_M/DeepSeek-R1-0528-UD-IQ2_M-00001-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ2_M/DeepSeek-R1-0528-UD-IQ2_M-00001-of-00005.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-IQ2_M/DeepSeek-R1-0528-UD-IQ2_M-00002-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ2_M/DeepSeek-R1-0528-UD-IQ2_M-00002-of-00005.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-IQ2_M/DeepSeek-R1-0528-UD-IQ2_M-00003-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ2_M/DeepSeek-R1-0528-UD-IQ2_M-00003-of-00005.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-IQ2_M/DeepSeek-R1-0528-UD-IQ2_M-00004-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ2_M/DeepSeek-R1-0528-UD-IQ2_M-00004-of-00005.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "UD-IQ2_M/DeepSeek-R1-0528-UD-IQ2_M-00005-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ2_M/DeepSeek-R1-0528-UD-IQ2_M-00005-of-00005.gguf",
        "file_size": "28.5 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-R1-0528-UD-IQ2_XXS-00001-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-R1-0528-UD-IQ2_XXS-00001-of-00005.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-R1-0528-UD-IQ2_XXS-00002-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-R1-0528-UD-IQ2_XXS-00002-of-00005.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-R1-0528-UD-IQ2_XXS-00003-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-R1-0528-UD-IQ2_XXS-00003-of-00005.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-R1-0528-UD-IQ2_XXS-00004-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-R1-0528-UD-IQ2_XXS-00004-of-00005.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-R1-0528-UD-IQ2_XXS-00005-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-R1-0528-UD-IQ2_XXS-00005-of-00005.gguf",
        "file_size": "17.2 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/DeepSeek-R1-0528-UD-IQ3_XXS-00001-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ3_XXS/DeepSeek-R1-0528-UD-IQ3_XXS-00001-of-00006.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/DeepSeek-R1-0528-UD-IQ3_XXS-00002-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ3_XXS/DeepSeek-R1-0528-UD-IQ3_XXS-00002-of-00006.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/DeepSeek-R1-0528-UD-IQ3_XXS-00003-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ3_XXS/DeepSeek-R1-0528-UD-IQ3_XXS-00003-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/DeepSeek-R1-0528-UD-IQ3_XXS-00004-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ3_XXS/DeepSeek-R1-0528-UD-IQ3_XXS-00004-of-00006.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/DeepSeek-R1-0528-UD-IQ3_XXS-00005-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ3_XXS/DeepSeek-R1-0528-UD-IQ3_XXS-00005-of-00006.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/DeepSeek-R1-0528-UD-IQ3_XXS-00006-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-IQ3_XXS/DeepSeek-R1-0528-UD-IQ3_XXS-00006-of-00006.gguf",
        "file_size": "24.6 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-R1-0528-UD-Q2_K_XL-00001-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-R1-0528-UD-Q2_K_XL-00001-of-00006.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-R1-0528-UD-Q2_K_XL-00002-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-R1-0528-UD-Q2_K_XL-00002-of-00006.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-R1-0528-UD-Q2_K_XL-00003-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-R1-0528-UD-Q2_K_XL-00003-of-00006.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-R1-0528-UD-Q2_K_XL-00004-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-R1-0528-UD-Q2_K_XL-00004-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-R1-0528-UD-Q2_K_XL-00005-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-R1-0528-UD-Q2_K_XL-00005-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-R1-0528-UD-Q2_K_XL-00006-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-R1-0528-UD-Q2_K_XL-00006-of-00006.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-R1-0528-UD-Q3_K_XL-00001-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-R1-0528-UD-Q3_K_XL-00001-of-00007.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-R1-0528-UD-Q3_K_XL-00002-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-R1-0528-UD-Q3_K_XL-00002-of-00007.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-R1-0528-UD-Q3_K_XL-00003-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-R1-0528-UD-Q3_K_XL-00003-of-00007.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-R1-0528-UD-Q3_K_XL-00004-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-R1-0528-UD-Q3_K_XL-00004-of-00007.gguf",
        "file_size": "45.5 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-R1-0528-UD-Q3_K_XL-00005-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-R1-0528-UD-Q3_K_XL-00005-of-00007.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-R1-0528-UD-Q3_K_XL-00006-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-R1-0528-UD-Q3_K_XL-00006-of-00007.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-R1-0528-UD-Q3_K_XL-00007-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-R1-0528-UD-Q3_K_XL-00007-of-00007.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00001-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00001-of-00008.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00002-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00002-of-00008.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00003-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00003-of-00008.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00004-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00004-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00005-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00005-of-00008.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00006-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00006-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00007-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00007-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00008-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-R1-0528-UD-Q4_K_XL-00008-of-00008.gguf",
        "file_size": "38.0 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00001-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00001-of-00010.gguf",
        "file_size": "43.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00002-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00002-of-00010.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00003-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00003-of-00010.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00004-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00004-of-00010.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00005-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00005-of-00010.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00006-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00006-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00007-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00007-of-00010.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00008-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00008-of-00010.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00009-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00009-of-00010.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00010-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-R1-0528-UD-Q5_K_XL-00010-of-00010.gguf",
        "file_size": "42.8 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00001-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00001-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00002-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00002-of-00012.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00003-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00003-of-00012.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00004-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00004-of-00012.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00005-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00005-of-00012.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00006-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00006-of-00012.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00007-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00007-of-00012.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00008-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00008-of-00012.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00009-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00009-of-00012.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00010-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00010-of-00012.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00011-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00011-of-00012.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00012-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-R1-0528-UD-Q6_K_XL-00012-of-00012.gguf",
        "file_size": "40.3 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00001-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00001-of-00016.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00002-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00002-of-00016.gguf",
        "file_size": "43.6 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00003-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00003-of-00016.gguf",
        "file_size": "44.6 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00004-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00004-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00005-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00005-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00006-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00006-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00007-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00007-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00008-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00008-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00009-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00009-of-00016.gguf",
        "file_size": "44.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00010-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00010-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00011-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00011-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00012-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00012-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00013-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00013-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00014-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00014-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00015-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00015-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00016-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00016-of-00016.gguf",
        "file_size": "46.3 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/README.md",
    "description": "The DeepSeek-R1-0528 model, developed by DeepSeek-AI, is a large language model with enhanced reasoning capabilities, improved performance on benchmarks like AIME, and is available in various formats including GGUF, with detailed usage guidelines and a MIT license."
  },
  {
    "model_name": "DeepSeek-R1-0528-Qwen3-8B-GGUF",
    "developer": "unsloth",
    "downloads": 1135436,
    "createdAt": "2025-05-29T14:17:25.000Z",
    "tools": true,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-BF16",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-BF16.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-IQ4_NL",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-IQ4_NL.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-IQ4_XS",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-IQ4_XS.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q2_K",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q2_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q2_K_L",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q2_K_L.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q3_K_M",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q3_K_M.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q3_K_S",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q3_K_S.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q4_0",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q4_0.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q4_1",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q4_1.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q4_K_M",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q4_K_M.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q4_K_S",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q4_K_S.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q5_K_M",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q5_K_M.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q5_K_S",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q5_K_S.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q6_K",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q6_K.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q8_0",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q8_0.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-IQ1_M.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-IQ1_S.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-IQ2_M.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-IQ2_XXS.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-IQ3_XXS.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-Q2_K_XL.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-Q3_K_XL.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-Q4_K_XL.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-Q5_K_XL.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-Q6_K_XL.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-Q8_K_XL.gguf",
        "file_size": "10.1 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/README.md",
    "description": "This is a large language model based on the DeepSeek-R1-0528 architecture, optimized for reasoning tasks with improved performance on benchmarks like AIME, and available in various quantized formats for efficient local inference."
  },
  {
    "model_name": "DeepSeek-R1-0528-Qwen3-8B-GGUF",
    "developer": "lmstudio-community",
    "downloads": 132778,
    "createdAt": "2025-05-29T13:27:13.000Z",
    "num_quants": 4,
    "quants": [
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q3_K_L",
        "path": "https://huggingface.co/lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q3_K_L.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q4_K_M",
        "path": "https://huggingface.co/lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q4_K_M.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q6_K",
        "path": "https://huggingface.co/lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q6_K.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "DeepSeek-R1-0528-Qwen3-8B-Q8_0",
        "path": "https://huggingface.co/lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q8_0.gguf",
        "file_size": "8.1 GB"
      }
    ],
    "readme": "https://huggingface.co/lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
    "developer": "DheyoAI",
    "downloads": 683,
    "createdAt": "2025-07-16T14:11:04.000Z",
    "tools": true,
    "num_quants": 2,
    "quants": [
      {
        "model_id": "DeepSeek-R1-Distill-Qwen-1.5B-baseline",
        "path": "https://huggingface.co/DheyoAI/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-1.5B-baseline.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "DeepSeek-R1-Distill-Qwen-1.5B-pct5",
        "path": "https://huggingface.co/DheyoAI/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-1.5B-pct5.gguf",
        "file_size": "1.5 GB"
      }
    ],
    "readme": "https://huggingface.co/DheyoAI/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/resolve/main/README.md",
    "description": "This report introduces Dheyo Quantized models for DeepSeek-R1-Distill-Qwen-1.5B, achieving high reasoning accuracy (78.92% on GSM8K, 79.8% on Math500) with significantly reduced sizes (1."
  },
  {
    "model_name": "DeepSeek-R1-Distill-Qwen-32B-Uncensored-GGUF",
    "developer": "mradermacher",
    "downloads": 5414,
    "createdAt": "2025-01-26T02:35:09.000Z",
    "num_quants": 11,
    "quants": [
      {
        "model_id": "DeepSeek-R1-Distill-Qwen-32B-Uncensored.IQ4_XS",
        "path": "https://huggingface.co/mradermacher/DeepSeek-R1-Distill-Qwen-32B-Uncensored-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Uncensored.IQ4_XS.gguf",
        "file_size": "16.6 GB"
      },
      {
        "model_id": "DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q2_K",
        "path": "https://huggingface.co/mradermacher/DeepSeek-R1-Distill-Qwen-32B-Uncensored-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q2_K.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q3_K_L",
        "path": "https://huggingface.co/mradermacher/DeepSeek-R1-Distill-Qwen-32B-Uncensored-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q3_K_L.gguf",
        "file_size": "16.1 GB"
      },
      {
        "model_id": "DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q3_K_M",
        "path": "https://huggingface.co/mradermacher/DeepSeek-R1-Distill-Qwen-32B-Uncensored-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q3_K_M.gguf",
        "file_size": "14.8 GB"
      },
      {
        "model_id": "DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q3_K_S",
        "path": "https://huggingface.co/mradermacher/DeepSeek-R1-Distill-Qwen-32B-Uncensored-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q3_K_S.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q4_K_M",
        "path": "https://huggingface.co/mradermacher/DeepSeek-R1-Distill-Qwen-32B-Uncensored-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q4_K_M.gguf",
        "file_size": "18.5 GB"
      },
      {
        "model_id": "DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q4_K_S",
        "path": "https://huggingface.co/mradermacher/DeepSeek-R1-Distill-Qwen-32B-Uncensored-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q4_K_S.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q5_K_M",
        "path": "https://huggingface.co/mradermacher/DeepSeek-R1-Distill-Qwen-32B-Uncensored-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q5_K_M.gguf",
        "file_size": "21.7 GB"
      },
      {
        "model_id": "DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q5_K_S",
        "path": "https://huggingface.co/mradermacher/DeepSeek-R1-Distill-Qwen-32B-Uncensored-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q5_K_S.gguf",
        "file_size": "21.1 GB"
      },
      {
        "model_id": "DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q6_K",
        "path": "https://huggingface.co/mradermacher/DeepSeek-R1-Distill-Qwen-32B-Uncensored-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q6_K.gguf",
        "file_size": "25.0 GB"
      },
      {
        "model_id": "DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q8_0",
        "path": "https://huggingface.co/mradermacher/DeepSeek-R1-Distill-Qwen-32B-Uncensored-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q8_0.gguf",
        "file_size": "32.4 GB"
      }
    ],
    "readme": "https://huggingface.co/mradermacher/DeepSeek-R1-Distill-Qwen-32B-Uncensored-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "DeepSeek-TNG-R1T2-Chimera-GGUF",
    "developer": "unsloth",
    "downloads": 17824,
    "createdAt": "2025-07-03T09:19:02.000Z",
    "num_quants": 235,
    "quants": [
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00001-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00001-of-00030.gguf",
        "file_size": "40.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00002-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00002-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00003-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00003-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00004-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00004-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00005-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00005-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00006-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00006-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00007-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00007-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00008-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00008-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00009-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00009-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00010-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00010-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00011-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00011-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00012-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00012-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00013-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00013-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00014-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00014-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00015-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00015-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00016-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00016-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00017-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00017-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00018-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00018-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00019-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00019-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00020-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00020-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00021-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00021-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00022-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00022-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00023-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00023-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00024-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00024-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00025-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00025-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00026-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00026-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00027-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00027-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00028-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00028-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00029-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00029-of-00030.gguf",
        "file_size": "44.6 GB"
      },
      {
        "model_id": "BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00030-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/BF16/DeepSeek-TNG-R1T2-Chimera-BF16-00030-of-00030.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "DeepSeek-TNG-R1T2-Chimera-UD-TQ1_0",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/DeepSeek-TNG-R1T2-Chimera-UD-TQ1_0.gguf",
        "file_size": "150.1 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00001-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00001-of-00008.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00002-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00002-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00003-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00003-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00004-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00004-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00005-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00005-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00006-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00006-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00007-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00007-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00008-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_NL/DeepSeek-TNG-R1T2-Chimera-IQ4_NL-00008-of-00008.gguf",
        "file_size": "28.1 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00001-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00001-of-00008.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00002-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00002-of-00008.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00003-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00003-of-00008.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00004-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00004-of-00008.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00005-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00005-of-00008.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00006-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00006-of-00008.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00007-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00007-of-00008.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00008-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ4_XS/DeepSeek-TNG-R1T2-Chimera-IQ4_XS-00008-of-00008.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-TNG-R1T2-Chimera-Q2_K-00001-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q2_K/DeepSeek-TNG-R1T2-Chimera-Q2_K-00001-of-00005.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-TNG-R1T2-Chimera-Q2_K-00002-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q2_K/DeepSeek-TNG-R1T2-Chimera-Q2_K-00002-of-00005.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-TNG-R1T2-Chimera-Q2_K-00003-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q2_K/DeepSeek-TNG-R1T2-Chimera-Q2_K-00003-of-00005.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-TNG-R1T2-Chimera-Q2_K-00004-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q2_K/DeepSeek-TNG-R1T2-Chimera-Q2_K-00004-of-00005.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-TNG-R1T2-Chimera-Q2_K-00005-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q2_K/DeepSeek-TNG-R1T2-Chimera-Q2_K-00005-of-00005.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q2_K_L/DeepSeek-TNG-R1T2-Chimera-Q2_K_L-00001-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q2_K_L/DeepSeek-TNG-R1T2-Chimera-Q2_K_L-00001-of-00005.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q2_K_L/DeepSeek-TNG-R1T2-Chimera-Q2_K_L-00002-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q2_K_L/DeepSeek-TNG-R1T2-Chimera-Q2_K_L-00002-of-00005.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Q2_K_L/DeepSeek-TNG-R1T2-Chimera-Q2_K_L-00003-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q2_K_L/DeepSeek-TNG-R1T2-Chimera-Q2_K_L-00003-of-00005.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q2_K_L/DeepSeek-TNG-R1T2-Chimera-Q2_K_L-00004-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q2_K_L/DeepSeek-TNG-R1T2-Chimera-Q2_K_L-00004-of-00005.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Q2_K_L/DeepSeek-TNG-R1T2-Chimera-Q2_K_L-00005-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q2_K_L/DeepSeek-TNG-R1T2-Chimera-Q2_K_L-00005-of-00005.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-TNG-R1T2-Chimera-Q3_K_M-00001-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q3_K_M/DeepSeek-TNG-R1T2-Chimera-Q3_K_M-00001-of-00007.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-TNG-R1T2-Chimera-Q3_K_M-00002-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q3_K_M/DeepSeek-TNG-R1T2-Chimera-Q3_K_M-00002-of-00007.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-TNG-R1T2-Chimera-Q3_K_M-00003-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q3_K_M/DeepSeek-TNG-R1T2-Chimera-Q3_K_M-00003-of-00007.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-TNG-R1T2-Chimera-Q3_K_M-00004-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q3_K_M/DeepSeek-TNG-R1T2-Chimera-Q3_K_M-00004-of-00007.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-TNG-R1T2-Chimera-Q3_K_M-00005-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q3_K_M/DeepSeek-TNG-R1T2-Chimera-Q3_K_M-00005-of-00007.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-TNG-R1T2-Chimera-Q3_K_M-00006-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q3_K_M/DeepSeek-TNG-R1T2-Chimera-Q3_K_M-00006-of-00007.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-TNG-R1T2-Chimera-Q3_K_M-00007-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q3_K_M/DeepSeek-TNG-R1T2-Chimera-Q3_K_M-00007-of-00007.gguf",
        "file_size": "21.9 GB"
      },
      {
        "model_id": "Q3_K_S/DeepSeek-TNG-R1T2-Chimera-Q3_K_S-00001-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q3_K_S/DeepSeek-TNG-R1T2-Chimera-Q3_K_S-00001-of-00006.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q3_K_S/DeepSeek-TNG-R1T2-Chimera-Q3_K_S-00002-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q3_K_S/DeepSeek-TNG-R1T2-Chimera-Q3_K_S-00002-of-00006.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q3_K_S/DeepSeek-TNG-R1T2-Chimera-Q3_K_S-00003-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q3_K_S/DeepSeek-TNG-R1T2-Chimera-Q3_K_S-00003-of-00006.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q3_K_S/DeepSeek-TNG-R1T2-Chimera-Q3_K_S-00004-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q3_K_S/DeepSeek-TNG-R1T2-Chimera-Q3_K_S-00004-of-00006.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q3_K_S/DeepSeek-TNG-R1T2-Chimera-Q3_K_S-00005-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q3_K_S/DeepSeek-TNG-R1T2-Chimera-Q3_K_S-00005-of-00006.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q3_K_S/DeepSeek-TNG-R1T2-Chimera-Q3_K_S-00006-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q3_K_S/DeepSeek-TNG-R1T2-Chimera-Q3_K_S-00006-of-00006.gguf",
        "file_size": "38.5 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00001-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00001-of-00008.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00002-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00002-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00003-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00003-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00004-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00004-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00005-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00005-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00006-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00006-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00007-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00007-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00008-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_0/DeepSeek-TNG-R1T2-Chimera-Q4_0-00008-of-00008.gguf",
        "file_size": "30.1 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00001-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00001-of-00009.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00002-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00002-of-00009.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00003-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00003-of-00009.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00004-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00004-of-00009.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00005-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00005-of-00009.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00006-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00006-of-00009.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00007-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00007-of-00009.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00008-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00008-of-00009.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00009-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_1/DeepSeek-TNG-R1T2-Chimera-Q4_1-00009-of-00009.gguf",
        "file_size": "33.4 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00001-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00001-of-00009.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00002-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00002-of-00009.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00003-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00003-of-00009.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00004-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00004-of-00009.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00005-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00005-of-00009.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00006-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00006-of-00009.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00007-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00007-of-00009.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00008-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00008-of-00009.gguf",
        "file_size": "43.8 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00009-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_M/DeepSeek-TNG-R1T2-Chimera-Q4_K_M-00009-of-00009.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00001-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00001-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00002-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00002-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00003-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00003-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00004-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00004-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00005-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00005-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00006-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00006-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00007-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00007-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00008-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q4_K_S/DeepSeek-TNG-R1T2-Chimera-Q4_K_S-00008-of-00008.gguf",
        "file_size": "30.1 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00001-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00001-of-00010.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00002-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00002-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00003-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00003-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00004-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00004-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00005-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00005-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00006-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00006-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00007-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00007-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00008-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00008-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00009-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00009-of-00010.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00010-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_M/DeepSeek-TNG-R1T2-Chimera-Q5_K_M-00010-of-00010.gguf",
        "file_size": "36.2 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00001-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00001-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00002-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00002-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00003-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00003-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00004-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00004-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00005-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00005-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00006-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00006-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00007-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00007-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00008-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00008-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00009-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00009-of-00010.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00010-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q5_K_S/DeepSeek-TNG-R1T2-Chimera-Q5_K_S-00010-of-00010.gguf",
        "file_size": "31.9 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00001-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00001-of-00012.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00002-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00002-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00003-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00003-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00004-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00004-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00005-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00005-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00006-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00006-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00007-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00007-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00008-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00008-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00009-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00009-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00010-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00010-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00011-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00011-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00012-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q6_K/DeepSeek-TNG-R1T2-Chimera-Q6_K-00012-of-00012.gguf",
        "file_size": "29.3 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00001-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00001-of-00015.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00002-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00002-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00003-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00003-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00004-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00004-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00005-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00005-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00006-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00006-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00007-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00007-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00008-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00008-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00009-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00009-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00010-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00010-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00011-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00011-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00012-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00012-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00013-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00013-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00014-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00014-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00015-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/Q8_0/DeepSeek-TNG-R1T2-Chimera-Q8_0-00015-of-00015.gguf",
        "file_size": "27.4 GB"
      },
      {
        "model_id": "UD-IQ1_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_M-00001-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ1_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_M-00001-of-00005.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-IQ1_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_M-00002-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ1_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_M-00002-of-00005.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-IQ1_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_M-00003-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ1_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_M-00003-of-00005.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-IQ1_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_M-00004-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ1_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_M-00004-of-00005.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "UD-IQ1_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_M-00005-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ1_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_M-00005-of-00005.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "UD-IQ1_S/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_S-00001-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ1_S/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_S-00001-of-00004.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-IQ1_S/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_S-00002-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ1_S/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_S-00002-of-00004.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-IQ1_S/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_S-00003-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ1_S/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_S-00003-of-00004.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "UD-IQ1_S/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_S-00004-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ1_S/DeepSeek-TNG-R1T2-Chimera-UD-IQ1_S-00004-of-00004.gguf",
        "file_size": "35.9 GB"
      },
      {
        "model_id": "UD-IQ2_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_M-00001-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ2_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_M-00001-of-00005.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "UD-IQ2_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_M-00002-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ2_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_M-00002-of-00005.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-IQ2_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_M-00003-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ2_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_M-00003-of-00005.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "UD-IQ2_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_M-00004-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ2_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_M-00004-of-00005.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "UD-IQ2_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_M-00005-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ2_M/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_M-00005-of-00005.gguf",
        "file_size": "28.9 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_XXS-00001-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_XXS-00001-of-00005.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_XXS-00002-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_XXS-00002-of-00005.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_XXS-00003-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_XXS-00003-of-00005.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_XXS-00004-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_XXS-00004-of-00005.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_XXS-00005-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ2_XXS-00005-of-00005.gguf",
        "file_size": "16.3 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ3_XXS-00001-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ3_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ3_XXS-00001-of-00006.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ3_XXS-00002-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ3_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ3_XXS-00002-of-00006.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ3_XXS-00003-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ3_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ3_XXS-00003-of-00006.gguf",
        "file_size": "45.5 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ3_XXS-00004-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ3_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ3_XXS-00004-of-00006.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ3_XXS-00005-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ3_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ3_XXS-00005-of-00006.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ3_XXS-00006-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-IQ3_XXS/DeepSeek-TNG-R1T2-Chimera-UD-IQ3_XXS-00006-of-00006.gguf",
        "file_size": "24.7 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q2_K_XL-00001-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q2_K_XL-00001-of-00006.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q2_K_XL-00002-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q2_K_XL-00002-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q2_K_XL-00003-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q2_K_XL-00003-of-00006.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q2_K_XL-00004-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q2_K_XL-00004-of-00006.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q2_K_XL-00005-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q2_K_XL-00005-of-00006.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q2_K_XL-00006-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q2_K_XL-00006-of-00006.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q3_K_XL-00001-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q3_K_XL-00001-of-00007.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q3_K_XL-00002-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q3_K_XL-00002-of-00007.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q3_K_XL-00003-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q3_K_XL-00003-of-00007.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q3_K_XL-00004-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q3_K_XL-00004-of-00007.gguf",
        "file_size": "45.5 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q3_K_XL-00005-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q3_K_XL-00005-of-00007.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q3_K_XL-00006-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q3_K_XL-00006-of-00007.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q3_K_XL-00007-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q3_K_XL-00007-of-00007.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00001-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00001-of-00008.gguf",
        "file_size": "45.5 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00002-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00002-of-00008.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00003-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00003-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00004-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00004-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00005-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00005-of-00008.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00006-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00006-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00007-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00007-of-00008.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00008-of-00008",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q4_K_XL-00008-of-00008.gguf",
        "file_size": "38.0 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00001-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00001-of-00010.gguf",
        "file_size": "43.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00002-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00002-of-00010.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00003-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00003-of-00010.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00004-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00004-of-00010.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00005-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00005-of-00010.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00006-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00006-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00007-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00007-of-00010.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00008-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00008-of-00010.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00009-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00009-of-00010.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00010-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q5_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q5_K_XL-00010-of-00010.gguf",
        "file_size": "42.8 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00001-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00001-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00002-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00002-of-00012.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00003-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00003-of-00012.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00004-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00004-of-00012.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00005-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00005-of-00012.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00006-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00006-of-00012.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00007-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00007-of-00012.gguf",
        "file_size": "43.8 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00008-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00008-of-00012.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00009-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00009-of-00012.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00010-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00010-of-00012.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00011-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00011-of-00012.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00012-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q6_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q6_K_XL-00012-of-00012.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00001-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00001-of-00016.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00002-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00002-of-00016.gguf",
        "file_size": "43.6 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00003-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00003-of-00016.gguf",
        "file_size": "44.6 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00004-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00004-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00005-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00005-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00006-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00006-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00007-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00007-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00008-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00008-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00009-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00009-of-00016.gguf",
        "file_size": "44.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00010-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00010-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00011-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00011-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00012-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00012-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00013-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00013-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00014-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00014-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00015-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00015-of-00016.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00016-of-00016",
        "path": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-TNG-R1T2-Chimera-UD-Q8_K_XL-00016-of-00016.gguf",
        "file_size": "46.3 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "DeepSeek-TNG-R1T2-Chimera-GGUF",
    "developer": "ubergarm",
    "downloads": 1442,
    "createdAt": "2025-07-08T17:26:13.000Z",
    "num_quants": 23,
    "quants": [
      {
        "model_id": "IQ1_S/DeepSeek-TNG-R1T2-Chimera-IQ1_S-00001-of-00003",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ1_S/DeepSeek-TNG-R1T2-Chimera-IQ1_S-00001-of-00003.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "IQ1_S/DeepSeek-TNG-R1T2-Chimera-IQ1_S-00002-of-00003",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ1_S/DeepSeek-TNG-R1T2-Chimera-IQ1_S-00002-of-00003.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "IQ1_S/DeepSeek-TNG-R1T2-Chimera-IQ1_S-00003-of-00003",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ1_S/DeepSeek-TNG-R1T2-Chimera-IQ1_S-00003-of-00003.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "IQ2_KS/DeepSeek-TNG-R1T2-Chimera-IQ2_KS-00001-of-00005",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ2_KS/DeepSeek-TNG-R1T2-Chimera-IQ2_KS-00001-of-00005.gguf",
        "file_size": "41.3 GB"
      },
      {
        "model_id": "IQ2_KS/DeepSeek-TNG-R1T2-Chimera-IQ2_KS-00002-of-00005",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ2_KS/DeepSeek-TNG-R1T2-Chimera-IQ2_KS-00002-of-00005.gguf",
        "file_size": "41.6 GB"
      },
      {
        "model_id": "IQ2_KS/DeepSeek-TNG-R1T2-Chimera-IQ2_KS-00003-of-00005",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ2_KS/DeepSeek-TNG-R1T2-Chimera-IQ2_KS-00003-of-00005.gguf",
        "file_size": "41.6 GB"
      },
      {
        "model_id": "IQ2_KS/DeepSeek-TNG-R1T2-Chimera-IQ2_KS-00004-of-00005",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ2_KS/DeepSeek-TNG-R1T2-Chimera-IQ2_KS-00004-of-00005.gguf",
        "file_size": "41.6 GB"
      },
      {
        "model_id": "IQ2_KS/DeepSeek-TNG-R1T2-Chimera-IQ2_KS-00005-of-00005",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ2_KS/DeepSeek-TNG-R1T2-Chimera-IQ2_KS-00005-of-00005.gguf",
        "file_size": "37.3 GB"
      },
      {
        "model_id": "IQ2_KT/DeepSeek-TNG-R1T2-Chimera-IQ2_KT-00001-of-00004",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ2_KT/DeepSeek-TNG-R1T2-Chimera-IQ2_KT-00001-of-00004.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "IQ2_KT/DeepSeek-TNG-R1T2-Chimera-IQ2_KT-00002-of-00004",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ2_KT/DeepSeek-TNG-R1T2-Chimera-IQ2_KT-00002-of-00004.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "IQ2_KT/DeepSeek-TNG-R1T2-Chimera-IQ2_KT-00003-of-00004",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ2_KT/DeepSeek-TNG-R1T2-Chimera-IQ2_KT-00003-of-00004.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "IQ2_KT/DeepSeek-TNG-R1T2-Chimera-IQ2_KT-00004-of-00004",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ2_KT/DeepSeek-TNG-R1T2-Chimera-IQ2_KT-00004-of-00004.gguf",
        "file_size": "41.4 GB"
      },
      {
        "model_id": "IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-IQ2_XXS-00001-of-00004",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-IQ2_XXS-00001-of-00004.gguf",
        "file_size": "43.8 GB"
      },
      {
        "model_id": "IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-IQ2_XXS-00002-of-00004",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-IQ2_XXS-00002-of-00004.gguf",
        "file_size": "43.4 GB"
      },
      {
        "model_id": "IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-IQ2_XXS-00003-of-00004",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-IQ2_XXS-00003-of-00004.gguf",
        "file_size": "43.4 GB"
      },
      {
        "model_id": "IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-IQ2_XXS-00004-of-00004",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ2_XXS/DeepSeek-TNG-R1T2-Chimera-IQ2_XXS-00004-of-00004.gguf",
        "file_size": "39.1 GB"
      },
      {
        "model_id": "IQ3_KS/DeepSeek-TNG-R1T2-Chimera-IQ3_KS-00001-of-00007",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ3_KS/DeepSeek-TNG-R1T2-Chimera-IQ3_KS-00001-of-00007.gguf",
        "file_size": "40.3 GB"
      },
      {
        "model_id": "IQ3_KS/DeepSeek-TNG-R1T2-Chimera-IQ3_KS-00002-of-00007",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ3_KS/DeepSeek-TNG-R1T2-Chimera-IQ3_KS-00002-of-00007.gguf",
        "file_size": "40.4 GB"
      },
      {
        "model_id": "IQ3_KS/DeepSeek-TNG-R1T2-Chimera-IQ3_KS-00003-of-00007",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ3_KS/DeepSeek-TNG-R1T2-Chimera-IQ3_KS-00003-of-00007.gguf",
        "file_size": "39.9 GB"
      },
      {
        "model_id": "IQ3_KS/DeepSeek-TNG-R1T2-Chimera-IQ3_KS-00004-of-00007",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ3_KS/DeepSeek-TNG-R1T2-Chimera-IQ3_KS-00004-of-00007.gguf",
        "file_size": "40.1 GB"
      },
      {
        "model_id": "IQ3_KS/DeepSeek-TNG-R1T2-Chimera-IQ3_KS-00005-of-00007",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ3_KS/DeepSeek-TNG-R1T2-Chimera-IQ3_KS-00005-of-00007.gguf",
        "file_size": "40.4 GB"
      },
      {
        "model_id": "IQ3_KS/DeepSeek-TNG-R1T2-Chimera-IQ3_KS-00006-of-00007",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ3_KS/DeepSeek-TNG-R1T2-Chimera-IQ3_KS-00006-of-00007.gguf",
        "file_size": "39.9 GB"
      },
      {
        "model_id": "IQ3_KS/DeepSeek-TNG-R1T2-Chimera-IQ3_KS-00007-of-00007",
        "path": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/IQ3_KS/DeepSeek-TNG-R1T2-Chimera-IQ3_KS-00007-of-00007.gguf",
        "file_size": "40.6 GB"
      }
    ],
    "readme": "https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "DeepSeek-V3-0324-GGUF",
    "developer": "unsloth",
    "downloads": 18812,
    "createdAt": "2025-03-25T04:57:18.000Z",
    "num_quants": 123,
    "quants": [
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00001-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00001-of-00030.gguf",
        "file_size": "40.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00002-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00002-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00003-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00003-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00004-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00004-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00005-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00005-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00006-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00006-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00007-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00007-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00008-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00008-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00009-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00009-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00010-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00010-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00011-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00011-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00012-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00012-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00013-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00013-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00014-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00014-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00015-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00015-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00016-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00016-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00017-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00017-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00018-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00018-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00019-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00019-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00020-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00020-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00021-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00021-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00022-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00022-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00023-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00023-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00024-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00024-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00025-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00025-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00026-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00026-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00027-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00027-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00028-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00028-of-00030.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00029-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00029-of-00030.gguf",
        "file_size": "44.6 GB"
      },
      {
        "model_id": "BF16/DeepSeek-V3-0324-BF16-00030-of-00030",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/BF16/DeepSeek-V3-0324-BF16-00030-of-00030.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-V3-0324-Q2_K-00001-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q2_K/DeepSeek-V3-0324-Q2_K-00001-of-00005.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-V3-0324-Q2_K-00002-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q2_K/DeepSeek-V3-0324-Q2_K-00002-of-00005.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-V3-0324-Q2_K-00003-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q2_K/DeepSeek-V3-0324-Q2_K-00003-of-00005.gguf",
        "file_size": "45.5 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-V3-0324-Q2_K-00004-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q2_K/DeepSeek-V3-0324-Q2_K-00004-of-00005.gguf",
        "file_size": "45.5 GB"
      },
      {
        "model_id": "Q2_K/DeepSeek-V3-0324-Q2_K-00005-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q2_K/DeepSeek-V3-0324-Q2_K-00005-of-00005.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-V3-0324-Q3_K_M-00001-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q3_K_M/DeepSeek-V3-0324-Q3_K_M-00001-of-00007.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-V3-0324-Q3_K_M-00002-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q3_K_M/DeepSeek-V3-0324-Q3_K_M-00002-of-00007.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-V3-0324-Q3_K_M-00003-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q3_K_M/DeepSeek-V3-0324-Q3_K_M-00003-of-00007.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-V3-0324-Q3_K_M-00004-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q3_K_M/DeepSeek-V3-0324-Q3_K_M-00004-of-00007.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-V3-0324-Q3_K_M-00005-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q3_K_M/DeepSeek-V3-0324-Q3_K_M-00005-of-00007.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-V3-0324-Q3_K_M-00006-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q3_K_M/DeepSeek-V3-0324-Q3_K_M-00006-of-00007.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q3_K_M/DeepSeek-V3-0324-Q3_K_M-00007-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q3_K_M/DeepSeek-V3-0324-Q3_K_M-00007-of-00007.gguf",
        "file_size": "21.9 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00001-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00001-of-00009.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00002-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00002-of-00009.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00003-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00003-of-00009.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00004-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00004-of-00009.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00005-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00005-of-00009.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00006-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00006-of-00009.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00007-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00007-of-00009.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00008-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00008-of-00009.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00009-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00009-of-00009.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00001-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00001-of-00010.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00002-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00002-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00003-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00003-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00004-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00004-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00005-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00005-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00006-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00006-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00007-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00007-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00008-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00008-of-00010.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00009-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00009-of-00010.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00010-of-00010",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q5_K_M/DeepSeek-V3-0324-Q5_K_M-00010-of-00010.gguf",
        "file_size": "33.8 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-V3-0324-Q6_K-00001-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q6_K/DeepSeek-V3-0324-Q6_K-00001-of-00012.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-V3-0324-Q6_K-00002-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q6_K/DeepSeek-V3-0324-Q6_K-00002-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-V3-0324-Q6_K-00003-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q6_K/DeepSeek-V3-0324-Q6_K-00003-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-V3-0324-Q6_K-00004-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q6_K/DeepSeek-V3-0324-Q6_K-00004-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-V3-0324-Q6_K-00005-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q6_K/DeepSeek-V3-0324-Q6_K-00005-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-V3-0324-Q6_K-00006-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q6_K/DeepSeek-V3-0324-Q6_K-00006-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-V3-0324-Q6_K-00007-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q6_K/DeepSeek-V3-0324-Q6_K-00007-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-V3-0324-Q6_K-00008-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q6_K/DeepSeek-V3-0324-Q6_K-00008-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-V3-0324-Q6_K-00009-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q6_K/DeepSeek-V3-0324-Q6_K-00009-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-V3-0324-Q6_K-00010-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q6_K/DeepSeek-V3-0324-Q6_K-00010-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-V3-0324-Q6_K-00011-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q6_K/DeepSeek-V3-0324-Q6_K-00011-of-00012.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "Q6_K/DeepSeek-V3-0324-Q6_K-00012-of-00012",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q6_K/DeepSeek-V3-0324-Q6_K-00012-of-00012.gguf",
        "file_size": "29.3 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00001-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00001-of-00015.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00002-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00002-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00003-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00003-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00004-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00004-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00005-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00005-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00006-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00006-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00007-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00007-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00008-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00008-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00009-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00009-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00010-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00010-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00011-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00011-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00012-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00012-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00013-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00013-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00014-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00014-of-00015.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q8_0/DeepSeek-V3-0324-Q8_0-00015-of-00015",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q8_0/DeepSeek-V3-0324-Q8_0-00015-of-00015.gguf",
        "file_size": "27.4 GB"
      },
      {
        "model_id": "UD-IQ1_M/DeepSeek-V3-0324-UD-IQ1_M-00001-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-IQ1_M/DeepSeek-V3-0324-UD-IQ1_M-00001-of-00004.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-IQ1_M/DeepSeek-V3-0324-UD-IQ1_M-00002-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-IQ1_M/DeepSeek-V3-0324-UD-IQ1_M-00002-of-00004.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-IQ1_M/DeepSeek-V3-0324-UD-IQ1_M-00003-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-IQ1_M/DeepSeek-V3-0324-UD-IQ1_M-00003-of-00004.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-IQ1_M/DeepSeek-V3-0324-UD-IQ1_M-00004-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-IQ1_M/DeepSeek-V3-0324-UD-IQ1_M-00004-of-00004.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-IQ1_S/DeepSeek-V3-0324-UD-IQ1_S-00001-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-IQ1_S/DeepSeek-V3-0324-UD-IQ1_S-00001-of-00004.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "UD-IQ1_S/DeepSeek-V3-0324-UD-IQ1_S-00002-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-IQ1_S/DeepSeek-V3-0324-UD-IQ1_S-00002-of-00004.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "UD-IQ1_S/DeepSeek-V3-0324-UD-IQ1_S-00003-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-IQ1_S/DeepSeek-V3-0324-UD-IQ1_S-00003-of-00004.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "UD-IQ1_S/DeepSeek-V3-0324-UD-IQ1_S-00004-of-00004",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-IQ1_S/DeepSeek-V3-0324-UD-IQ1_S-00004-of-00004.gguf",
        "file_size": "37.8 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-V3-0324-UD-IQ2_XXS-00001-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-V3-0324-UD-IQ2_XXS-00001-of-00005.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-V3-0324-UD-IQ2_XXS-00002-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-V3-0324-UD-IQ2_XXS-00002-of-00005.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-V3-0324-UD-IQ2_XXS-00003-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-V3-0324-UD-IQ2_XXS-00003-of-00005.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-V3-0324-UD-IQ2_XXS-00004-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-V3-0324-UD-IQ2_XXS-00004-of-00005.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/DeepSeek-V3-0324-UD-IQ2_XXS-00005-of-00005",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-IQ2_XXS/DeepSeek-V3-0324-UD-IQ2_XXS-00005-of-00005.gguf",
        "file_size": "20.6 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-V3-0324-UD-Q2_K_XL-00001-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-V3-0324-UD-Q2_K_XL-00001-of-00006.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-V3-0324-UD-Q2_K_XL-00002-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-V3-0324-UD-Q2_K_XL-00002-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-V3-0324-UD-Q2_K_XL-00003-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-V3-0324-UD-Q2_K_XL-00003-of-00006.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-V3-0324-UD-Q2_K_XL-00004-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-V3-0324-UD-Q2_K_XL-00004-of-00006.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-V3-0324-UD-Q2_K_XL-00005-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-V3-0324-UD-Q2_K_XL-00005-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/DeepSeek-V3-0324-UD-Q2_K_XL-00006-of-00006",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q2_K_XL/DeepSeek-V3-0324-UD-Q2_K_XL-00006-of-00006.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-V3-0324-UD-Q3_K_XL-00001-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-V3-0324-UD-Q3_K_XL-00001-of-00007.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-V3-0324-UD-Q3_K_XL-00002-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-V3-0324-UD-Q3_K_XL-00002-of-00007.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-V3-0324-UD-Q3_K_XL-00003-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-V3-0324-UD-Q3_K_XL-00003-of-00007.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-V3-0324-UD-Q3_K_XL-00004-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-V3-0324-UD-Q3_K_XL-00004-of-00007.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-V3-0324-UD-Q3_K_XL-00005-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-V3-0324-UD-Q3_K_XL-00005-of-00007.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-V3-0324-UD-Q3_K_XL-00006-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-V3-0324-UD-Q3_K_XL-00006-of-00007.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/DeepSeek-V3-0324-UD-Q3_K_XL-00007-of-00007",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q3_K_XL/DeepSeek-V3-0324-UD-Q3_K_XL-00007-of-00007.gguf",
        "file_size": "23.5 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00001-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00001-of-00009.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00002-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00002-of-00009.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00003-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00003-of-00009.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00004-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00004-of-00009.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00005-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00005-of-00009.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00006-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00006-of-00009.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00007-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00007-of-00009.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00008-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00008-of-00009.gguf",
        "file_size": "43.8 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00009-of-00009",
        "path": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/UD-Q4_K_XL/DeepSeek-V3-0324-UD-Q4_K_XL-00009-of-00009.gguf",
        "file_size": "13.8 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "DeepSWE-Preview-GGUF",
    "developer": "lmstudio-community",
    "downloads": 1025,
    "createdAt": "2025-07-03T13:18:41.000Z",
    "num_quants": 4,
    "quants": [
      {
        "model_id": "DeepSWE-Preview-Q3_K_L",
        "path": "https://huggingface.co/lmstudio-community/DeepSWE-Preview-GGUF/resolve/main/DeepSWE-Preview-Q3_K_L.gguf",
        "file_size": "16.1 GB"
      },
      {
        "model_id": "DeepSWE-Preview-Q4_K_M",
        "path": "https://huggingface.co/lmstudio-community/DeepSWE-Preview-GGUF/resolve/main/DeepSWE-Preview-Q4_K_M.gguf",
        "file_size": "18.4 GB"
      },
      {
        "model_id": "DeepSWE-Preview-Q6_K",
        "path": "https://huggingface.co/lmstudio-community/DeepSWE-Preview-GGUF/resolve/main/DeepSWE-Preview-Q6_K.gguf",
        "file_size": "25.0 GB"
      },
      {
        "model_id": "DeepSWE-Preview-Q8_0",
        "path": "https://huggingface.co/lmstudio-community/DeepSWE-Preview-GGUF/resolve/main/DeepSWE-Preview-Q8_0.gguf",
        "file_size": "32.4 GB"
      }
    ],
    "readme": "https://huggingface.co/lmstudio-community/DeepSWE-Preview-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Devstral-Small-2505-GGUF",
    "developer": "unsloth",
    "downloads": 32437,
    "createdAt": "2025-05-21T14:20:05.000Z",
    "num_quants": 28,
    "quants": [
      {
        "model_id": "Devstral-Small-2505-BF16",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-BF16.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "Devstral-Small-2505-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-IQ4_NL.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "Devstral-Small-2505-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-IQ4_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "Devstral-Small-2505-Q2_K",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "Devstral-Small-2505-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-Q2_K_L.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "Devstral-Small-2505-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "Devstral-Small-2505-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "Devstral-Small-2505-Q4_1",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-Q4_1.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "Devstral-Small-2505-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "Devstral-Small-2505-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Devstral-Small-2505-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "Devstral-Small-2505-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "Devstral-Small-2505-Q6_K",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "Devstral-Small-2505-Q8_0",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-Q8_0.gguf",
        "file_size": "23.3 GB"
      },
      {
        "model_id": "Devstral-Small-2505-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-UD-IQ1_M.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "Devstral-Small-2505-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-UD-IQ1_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Devstral-Small-2505-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-UD-IQ2_M.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "Devstral-Small-2505-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-UD-IQ2_XXS.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Devstral-Small-2505-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-UD-IQ3_XXS.gguf",
        "file_size": "8.8 GB"
      },
      {
        "model_id": "Devstral-Small-2505-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-UD-Q2_K_XL.gguf",
        "file_size": "8.7 GB"
      },
      {
        "model_id": "Devstral-Small-2505-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-UD-Q3_K_XL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "Devstral-Small-2505-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-UD-Q4_K_XL.gguf",
        "file_size": "13.5 GB"
      },
      {
        "model_id": "Devstral-Small-2505-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-UD-Q5_K_XL.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "Devstral-Small-2505-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-UD-Q6_K_XL.gguf",
        "file_size": "19.4 GB"
      },
      {
        "model_id": "Devstral-Small-2505-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/Devstral-Small-2505-UD-Q8_K_XL.gguf",
        "file_size": "27.0 GB"
      },
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "837.4 MB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "837.4 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Devstral-Small-2505-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Devstral-Small-2505_gguf",
    "developer": "mistralai",
    "downloads": 17100,
    "createdAt": "2025-05-19T16:34:03.000Z",
    "tools": false,
    "num_quants": 5,
    "quants": [
      {
        "model_id": "devstral",
        "path": "https://huggingface.co/mistralai/Devstral-Small-2505_gguf/resolve/main/devstral.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "devstralQ4_0",
        "path": "https://huggingface.co/mistralai/Devstral-Small-2505_gguf/resolve/main/devstralQ4_0.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "devstralQ4_K_M",
        "path": "https://huggingface.co/mistralai/Devstral-Small-2505_gguf/resolve/main/devstralQ4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "devstralQ5_K_M",
        "path": "https://huggingface.co/mistralai/Devstral-Small-2505_gguf/resolve/main/devstralQ5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "devstralQ8_0",
        "path": "https://huggingface.co/mistralai/Devstral-Small-2505_gguf/resolve/main/devstralQ8_0.gguf",
        "file_size": "23.3 GB"
      }
    ],
    "readme": "https://huggingface.co/mistralai/Devstral-Small-2505_gguf/resolve/main/README.md",
    "description": "Devstral-Small-2505 is an agentic, lightweight, open-source LLM with a 128k context window and Apache 2.0 license, optimized for software engineering tasks and local deployment using GGUF quantized checkpoints."
  },
  {
    "model_name": "Devstral-Small-2507-GGUF",
    "developer": "unsloth",
    "downloads": 53013,
    "createdAt": "2025-07-10T13:20:40.000Z",
    "tools": true,
    "num_quants": 28,
    "quants": [
      {
        "model_id": "Devstral-Small-2507-BF16",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-BF16.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "Devstral-Small-2507-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-IQ4_NL.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "Devstral-Small-2507-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-IQ4_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q2_K",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q2_K_L.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q4_0",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q4_0.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q4_1",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q4_1.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q6_K",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q8_0",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q8_0.gguf",
        "file_size": "23.3 GB"
      },
      {
        "model_id": "Devstral-Small-2507-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-UD-IQ1_M.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "Devstral-Small-2507-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-UD-IQ1_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Devstral-Small-2507-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-UD-IQ2_M.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "Devstral-Small-2507-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-UD-IQ2_XXS.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Devstral-Small-2507-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-UD-IQ3_XXS.gguf",
        "file_size": "8.8 GB"
      },
      {
        "model_id": "Devstral-Small-2507-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-UD-Q2_K_XL.gguf",
        "file_size": "8.7 GB"
      },
      {
        "model_id": "Devstral-Small-2507-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-UD-Q3_K_XL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "Devstral-Small-2507-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-UD-Q4_K_XL.gguf",
        "file_size": "13.5 GB"
      },
      {
        "model_id": "Devstral-Small-2507-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-UD-Q5_K_XL.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "Devstral-Small-2507-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-UD-Q6_K_XL.gguf",
        "file_size": "19.4 GB"
      },
      {
        "model_id": "Devstral-Small-2507-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-UD-Q8_K_XL.gguf",
        "file_size": "27.0 GB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "837.4 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/resolve/main/README.md",
    "description": "This model is an agentic LLM for software engineering tasks, built by Mistral AI and All Hands AI, offering 24B parameters, 128k context window, and Apache 2.0 license, with support for tool calling and optional vision, and optimized for local deployment"
  },
  {
    "model_name": "Devstral-Small-2507-GGUF",
    "developer": "lmstudio-community",
    "downloads": 14709,
    "createdAt": "2025-07-09T19:15:42.000Z",
    "num_quants": 3,
    "quants": [
      {
        "model_id": "Devstral-Small-2507-Q4_K_M",
        "path": "https://huggingface.co/lmstudio-community/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q6_K",
        "path": "https://huggingface.co/lmstudio-community/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q8_0",
        "path": "https://huggingface.co/lmstudio-community/Devstral-Small-2507-GGUF/resolve/main/Devstral-Small-2507-Q8_0.gguf",
        "file_size": "23.3 GB"
      }
    ],
    "readme": "https://huggingface.co/lmstudio-community/Devstral-Small-2507-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Devstral-Small-2507_gguf",
    "developer": "mistralai",
    "downloads": 10282,
    "createdAt": "2025-07-07T12:22:38.000Z",
    "tools": false,
    "num_quants": 4,
    "quants": [
      {
        "model_id": "Devstral-Small-2507-BF16",
        "path": "https://huggingface.co/mistralai/Devstral-Small-2507_gguf/resolve/main/Devstral-Small-2507-BF16.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q4_K_M",
        "path": "https://huggingface.co/mistralai/Devstral-Small-2507_gguf/resolve/main/Devstral-Small-2507-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q5_K_M",
        "path": "https://huggingface.co/mistralai/Devstral-Small-2507_gguf/resolve/main/Devstral-Small-2507-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "Devstral-Small-2507-Q8_0",
        "path": "https://huggingface.co/mistralai/Devstral-Small-2507_gguf/resolve/main/Devstral-Small-2507-Q8_0.gguf",
        "file_size": "23.3 GB"
      }
    ],
    "readme": "https://huggingface.co/mistralai/Devstral-Small-2507_gguf/resolve/main/README.md",
    "description": "The Devstral Small 1.1 model is a lightweight, agentic LLM for software engineering tasks with a 128k context window, available in GGUF quantized formats and Apache 2.0 licensed for both commercial and non-commercial use."
  },
  {
    "model_name": "DiffuCoder-7B-cpGRPO-GGUF",
    "developer": "Mungert",
    "downloads": 1304,
    "createdAt": "2025-07-16T19:37:57.000Z",
    "tools": true,
    "num_quants": 41,
    "quants": [
      {
        "model_id": "DiffuCoder-7B-cpGRPO-bf16",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-bf16.gguf",
        "file_size": "14.2 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-bf16_q4_k",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-bf16_q4_k.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-bf16_q6_k",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-bf16_q6_k.gguf",
        "file_size": "9.6 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-bf16_q8_0",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-bf16_q8_0.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-f16",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-f16.gguf",
        "file_size": "14.2 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-f16_q4_k",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-f16_q4_k.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-f16_q6_k",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-f16_q6_k.gguf",
        "file_size": "9.6 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-f16_q8_0",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-f16_q8_0.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-iq2_m",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-iq2_m.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-iq2_s",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-iq2_s.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-iq2_xs",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-iq2_xs.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-iq2_xxs",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-iq2_xxs.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-iq3_m",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-iq3_m.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-iq3_s",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-iq3_s.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-iq3_xs",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-iq3_xs.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-iq3_xxs",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-iq3_xxs.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-iq4_nl",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-iq4_nl.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-iq4_xs",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-iq4_xs.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q2_k_l",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q2_k_l.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q2_k_m",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q2_k_m.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q2_k_s",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q2_k_s.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q3_k_l",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q3_k_l.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q3_k_m",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q3_k_m.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q3_k_s",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q3_k_s.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q4_0",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q4_0.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q4_0_l",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q4_0_l.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q4_1",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q4_1.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q4_1_l",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q4_1_l.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q4_k_l",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q4_k_l.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q4_k_m",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q4_k_m.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q4_k_s",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q4_k_s.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q5_0",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q5_0.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q5_0_l",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q5_0_l.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q5_1",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q5_1.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q5_1_l",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q5_1_l.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q5_k_l",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q5_k_l.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q5_k_m",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q5_k_m.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q5_k_s",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q5_k_s.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q6_k_l",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q6_k_l.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q6_k_m",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q6_k_m.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "DiffuCoder-7B-cpGRPO-q8_0",
        "path": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/DiffuCoder-7B-cpGRPO-q8_0.gguf",
        "file_size": "7.5 GB"
      }
    ],
    "readme": "https://huggingface.co/Mungert/DiffuCoder-7B-cpGRPO-GGUF/resolve/main/README.md",
    "description": "This is a GGUF quantized version of the DiffuCoder-7B-Instruct model, enhanced with cpGRPO for improved code generation performance and optimized for quantum-ready security checks and network monitoring tasks."
  },
  {
    "model_name": "dolphin-2.7-mixtral-8x7b-GGUF",
    "developer": "TheBloke",
    "downloads": 13855,
    "createdAt": "2024-01-01T12:11:59.000Z",
    "tools": false,
    "num_quants": 8,
    "quants": [
      {
        "model_id": "dolphin-2.7-mixtral-8x7b.Q2_K",
        "path": "https://huggingface.co/TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/resolve/main/dolphin-2.7-mixtral-8x7b.Q2_K.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "dolphin-2.7-mixtral-8x7b.Q3_K_M",
        "path": "https://huggingface.co/TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/resolve/main/dolphin-2.7-mixtral-8x7b.Q3_K_M.gguf",
        "file_size": "19.0 GB"
      },
      {
        "model_id": "dolphin-2.7-mixtral-8x7b.Q4_0",
        "path": "https://huggingface.co/TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/resolve/main/dolphin-2.7-mixtral-8x7b.Q4_0.gguf",
        "file_size": "24.6 GB"
      },
      {
        "model_id": "dolphin-2.7-mixtral-8x7b.Q4_K_M",
        "path": "https://huggingface.co/TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/resolve/main/dolphin-2.7-mixtral-8x7b.Q4_K_M.gguf",
        "file_size": "24.6 GB"
      },
      {
        "model_id": "dolphin-2.7-mixtral-8x7b.Q5_0",
        "path": "https://huggingface.co/TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/resolve/main/dolphin-2.7-mixtral-8x7b.Q5_0.gguf",
        "file_size": "30.0 GB"
      },
      {
        "model_id": "dolphin-2.7-mixtral-8x7b.Q5_K_M",
        "path": "https://huggingface.co/TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/resolve/main/dolphin-2.7-mixtral-8x7b.Q5_K_M.gguf",
        "file_size": "30.0 GB"
      },
      {
        "model_id": "dolphin-2.7-mixtral-8x7b.Q6_K",
        "path": "https://huggingface.co/TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/resolve/main/dolphin-2.7-mixtral-8x7b.Q6_K.gguf",
        "file_size": "35.7 GB"
      },
      {
        "model_id": "dolphin-2.7-mixtral-8x7b.Q8_0",
        "path": "https://huggingface.co/TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/resolve/main/dolphin-2.7-mixtral-8x7b.Q8_0.gguf",
        "file_size": "46.2 GB"
      }
    ],
    "readme": "https://huggingface.co/TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/resolve/main/README.md",
    "description": "This repository provides GGUF format quantized versions of the Dolphin 2.7 Mixtral 8X7B model for efficient inference on CPU and GPU, with detailed instructions on downloading, running, and using the model in various frameworks like llama.cpp, text-generation-webui, and Python libraries"
  },
  {
    "model_name": "dolphin-2.9.3-mistral-7B-32k-GGUF",
    "developer": "mradermacher",
    "downloads": 793,
    "createdAt": "2024-06-25T03:14:26.000Z",
    "num_quants": 15,
    "quants": [
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.IQ3_M",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.IQ3_M.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.IQ3_S",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.IQ3_S.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.IQ3_XS",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.IQ3_XS.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.IQ4_XS",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.IQ4_XS.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.Q2_K",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.Q2_K.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.Q3_K_L",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.Q3_K_L.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.Q3_K_M",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.Q3_K_M.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.Q3_K_S",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.Q3_K_S.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.Q4_K_M",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.Q4_K_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.Q4_K_S",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.Q4_K_S.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.Q5_K_M",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.Q5_K_M.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.Q5_K_S",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.Q5_K_S.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.Q6_K",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.Q6_K.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.Q8_0",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.Q8_0.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-7B-32k.f16",
        "path": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k.f16.gguf",
        "file_size": "13.5 GB"
      }
    ],
    "readme": "https://huggingface.co/mradermacher/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "dolphin-2.9.3-mistral-nemo-12b-gguf",
    "developer": "cognitivecomputations",
    "downloads": 4211,
    "createdAt": "2024-07-24T16:00:27.000Z",
    "num_quants": 15,
    "quants": [
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.F16",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.F16.gguf",
        "file_size": "22.8 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q2_K",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q2_K.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q3_K_L",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q3_K_L.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q3_K_M",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q3_K_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q3_K_S",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q3_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q4_0",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q4_0.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q4_1",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q4_1.gguf",
        "file_size": "7.3 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q4_K_M",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q4_K_M.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q4_K_S",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q4_K_S.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q5_0",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q5_0.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q5_1",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q5_1.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q5_K_M",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q5_K_M.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q5_K_S",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q5_K_S.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q6_K",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q6_K.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q8_0",
        "path": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q8_0.gguf",
        "file_size": "12.1 GB"
      }
    ],
    "readme": "https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "dolphin-2.9.3-mistral-nemo-12b-gguf",
    "developer": "dphn",
    "downloads": 4211,
    "createdAt": "2024-07-24T16:00:27.000Z",
    "num_quants": 15,
    "quants": [
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.F16",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.F16.gguf",
        "file_size": "22.8 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q2_K",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q2_K.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q3_K_L",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q3_K_L.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q3_K_M",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q3_K_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q3_K_S",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q3_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q4_0",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q4_0.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q4_1",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q4_1.gguf",
        "file_size": "7.3 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q4_K_M",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q4_K_M.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q4_K_S",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q4_K_S.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q5_0",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q5_0.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q5_1",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q5_1.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q5_K_M",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q5_K_M.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q5_K_S",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q5_K_S.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q6_K",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q6_K.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "dolphin-2.9.3-mistral-nemo-12b.Q8_0",
        "path": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/dolphin-2.9.3-mistral-nemo-12b.Q8_0.gguf",
        "file_size": "12.1 GB"
      }
    ],
    "readme": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b-gguf/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Dolphin3.0-Llama3.1-8B-GGUF",
    "developer": "dphn",
    "downloads": 34099,
    "createdAt": "2025-01-02T22:11:05.000Z",
    "num_quants": 18,
    "quants": [
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-F16",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-F16.gguf",
        "file_size": "15.0 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q2_K",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q3_K",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q3_K.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q3_K_L",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q3_K_M",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q3_K_S",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q4_0",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q4_0.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q4_1",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q4_1.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q4_K",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q4_K.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q4_K_M",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q4_K_S",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q5_0",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q5_0.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q5_1",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q5_1.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q5_K",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q5_K.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q5_K_M",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q5_K_S",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q6_K",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Dolphin3.0-Llama3.1-8B-Q8_0",
        "path": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/Dolphin3.0-Llama3.1-8B-Q8_0.gguf",
        "file_size": "8.0 GB"
      }
    ],
    "readme": "https://huggingface.co/dphn/Dolphin3.0-Llama3.1-8B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "dots.llm1.inst-GGUF",
    "developer": "unsloth",
    "downloads": 5371,
    "createdAt": "2025-06-16T12:59:47.000Z",
    "num_quants": 65,
    "quants": [
      {
        "model_id": "BF16/dots.llm1.inst-BF16-00001-of-00006",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/BF16/dots.llm1.inst-BF16-00001-of-00006.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "BF16/dots.llm1.inst-BF16-00002-of-00006",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/BF16/dots.llm1.inst-BF16-00002-of-00006.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "BF16/dots.llm1.inst-BF16-00003-of-00006",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/BF16/dots.llm1.inst-BF16-00003-of-00006.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "BF16/dots.llm1.inst-BF16-00004-of-00006",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/BF16/dots.llm1.inst-BF16-00004-of-00006.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "BF16/dots.llm1.inst-BF16-00005-of-00006",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/BF16/dots.llm1.inst-BF16-00005-of-00006.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "BF16/dots.llm1.inst-BF16-00006-of-00006",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/BF16/dots.llm1.inst-BF16-00006-of-00006.gguf",
        "file_size": "36.1 GB"
      },
      {
        "model_id": "IQ4_NL/dots.llm1.inst-IQ4_NL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/IQ4_NL/dots.llm1.inst-IQ4_NL-00001-of-00002.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "IQ4_NL/dots.llm1.inst-IQ4_NL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/IQ4_NL/dots.llm1.inst-IQ4_NL-00002-of-00002.gguf",
        "file_size": "28.7 GB"
      },
      {
        "model_id": "IQ4_XS/dots.llm1.inst-IQ4_XS-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/IQ4_XS/dots.llm1.inst-IQ4_XS-00001-of-00002.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "IQ4_XS/dots.llm1.inst-IQ4_XS-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/IQ4_XS/dots.llm1.inst-IQ4_XS-00002-of-00002.gguf",
        "file_size": "25.7 GB"
      },
      {
        "model_id": "Q2_K/dots.llm1.inst-Q2_K-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q2_K/dots.llm1.inst-Q2_K-00001-of-00002.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q2_K/dots.llm1.inst-Q2_K-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q2_K/dots.llm1.inst-Q2_K-00002-of-00002.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "Q2_K_L/dots.llm1.inst-Q2_K_L-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q2_K_L/dots.llm1.inst-Q2_K_L-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q2_K_L/dots.llm1.inst-Q2_K_L-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q2_K_L/dots.llm1.inst-Q2_K_L-00002-of-00002.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "Q3_K_M/dots.llm1.inst-Q3_K_M-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q3_K_M/dots.llm1.inst-Q3_K_M-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q3_K_M/dots.llm1.inst-Q3_K_M-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q3_K_M/dots.llm1.inst-Q3_K_M-00002-of-00002.gguf",
        "file_size": "22.2 GB"
      },
      {
        "model_id": "Q3_K_S/dots.llm1.inst-Q3_K_S-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q3_K_S/dots.llm1.inst-Q3_K_S-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q3_K_S/dots.llm1.inst-Q3_K_S-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q3_K_S/dots.llm1.inst-Q3_K_S-00002-of-00002.gguf",
        "file_size": "16.6 GB"
      },
      {
        "model_id": "Q4_0/dots.llm1.inst-Q4_0-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q4_0/dots.llm1.inst-Q4_0-00001-of-00002.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "Q4_0/dots.llm1.inst-Q4_0-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q4_0/dots.llm1.inst-Q4_0-00002-of-00002.gguf",
        "file_size": "28.7 GB"
      },
      {
        "model_id": "Q4_1/dots.llm1.inst-Q4_1-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q4_1/dots.llm1.inst-Q4_1-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/dots.llm1.inst-Q4_1-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q4_1/dots.llm1.inst-Q4_1-00002-of-00002.gguf",
        "file_size": "36.9 GB"
      },
      {
        "model_id": "Q4_K_M/dots.llm1.inst-Q4_K_M-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q4_K_M/dots.llm1.inst-Q4_K_M-00001-of-00002.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_K_M/dots.llm1.inst-Q4_K_M-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q4_K_M/dots.llm1.inst-Q4_K_M-00002-of-00002.gguf",
        "file_size": "41.7 GB"
      },
      {
        "model_id": "Q4_K_S/dots.llm1.inst-Q4_K_S-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q4_K_S/dots.llm1.inst-Q4_K_S-00001-of-00002.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_K_S/dots.llm1.inst-Q4_K_S-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q4_K_S/dots.llm1.inst-Q4_K_S-00002-of-00002.gguf",
        "file_size": "34.2 GB"
      },
      {
        "model_id": "Q5_K_M/dots.llm1.inst-Q5_K_M-00001-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q5_K_M/dots.llm1.inst-Q5_K_M-00001-of-00003.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q5_K_M/dots.llm1.inst-Q5_K_M-00002-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q5_K_M/dots.llm1.inst-Q5_K_M-00002-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q5_K_M/dots.llm1.inst-Q5_K_M-00003-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q5_K_M/dots.llm1.inst-Q5_K_M-00003-of-00003.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "Q5_K_S/dots.llm1.inst-Q5_K_S-00001-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q5_K_S/dots.llm1.inst-Q5_K_S-00001-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q5_K_S/dots.llm1.inst-Q5_K_S-00002-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q5_K_S/dots.llm1.inst-Q5_K_S-00002-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q5_K_S/dots.llm1.inst-Q5_K_S-00003-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q5_K_S/dots.llm1.inst-Q5_K_S-00003-of-00003.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Q6_K/dots.llm1.inst-Q6_K-00001-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q6_K/dots.llm1.inst-Q6_K-00001-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q6_K/dots.llm1.inst-Q6_K-00002-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q6_K/dots.llm1.inst-Q6_K-00002-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q6_K/dots.llm1.inst-Q6_K-00003-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q6_K/dots.llm1.inst-Q6_K-00003-of-00003.gguf",
        "file_size": "26.3 GB"
      },
      {
        "model_id": "Q8_0/dots.llm1.inst-Q8_0-00001-of-00004",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q8_0/dots.llm1.inst-Q8_0-00001-of-00004.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q8_0/dots.llm1.inst-Q8_0-00002-of-00004",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q8_0/dots.llm1.inst-Q8_0-00002-of-00004.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q8_0/dots.llm1.inst-Q8_0-00003-of-00004",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q8_0/dots.llm1.inst-Q8_0-00003-of-00004.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q8_0/dots.llm1.inst-Q8_0-00004-of-00004",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/Q8_0/dots.llm1.inst-Q8_0-00004-of-00004.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "UD-IQ1_M/dots.llm1.inst-UD-IQ1_M-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-IQ1_M/dots.llm1.inst-UD-IQ1_M-00001-of-00002.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-IQ1_M/dots.llm1.inst-UD-IQ1_M-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-IQ1_M/dots.llm1.inst-UD-IQ1_M-00002-of-00002.gguf",
        "file_size": "782.4 MB"
      },
      {
        "model_id": "UD-IQ2_M/dots.llm1.inst-UD-IQ2_M-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-IQ2_M/dots.llm1.inst-UD-IQ2_M-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-IQ2_M/dots.llm1.inst-UD-IQ2_M-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-IQ2_M/dots.llm1.inst-UD-IQ2_M-00002-of-00002.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/dots.llm1.inst-UD-IQ2_XXS-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-IQ2_XXS/dots.llm1.inst-UD-IQ2_XXS-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/dots.llm1.inst-UD-IQ2_XXS-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-IQ2_XXS/dots.llm1.inst-UD-IQ2_XXS-00002-of-00002.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/dots.llm1.inst-UD-IQ3_XXS-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-IQ3_XXS/dots.llm1.inst-UD-IQ3_XXS-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/dots.llm1.inst-UD-IQ3_XXS-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-IQ3_XXS/dots.llm1.inst-UD-IQ3_XXS-00002-of-00002.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/dots.llm1.inst-UD-Q2_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q2_K_XL/dots.llm1.inst-UD-Q2_K_XL-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/dots.llm1.inst-UD-Q2_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q2_K_XL/dots.llm1.inst-UD-Q2_K_XL-00002-of-00002.gguf",
        "file_size": "9.6 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/dots.llm1.inst-UD-Q3_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q3_K_XL/dots.llm1.inst-UD-Q3_K_XL-00001-of-00002.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/dots.llm1.inst-UD-Q3_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q3_K_XL/dots.llm1.inst-UD-Q3_K_XL-00002-of-00002.gguf",
        "file_size": "18.2 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/dots.llm1.inst-UD-Q4_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q4_K_XL/dots.llm1.inst-UD-Q4_K_XL-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/dots.llm1.inst-UD-Q4_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q4_K_XL/dots.llm1.inst-UD-Q4_K_XL-00002-of-00002.gguf",
        "file_size": "34.5 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/dots.llm1.inst-UD-Q5_K_XL-00001-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q5_K_XL/dots.llm1.inst-UD-Q5_K_XL-00001-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/dots.llm1.inst-UD-Q5_K_XL-00002-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q5_K_XL/dots.llm1.inst-UD-Q5_K_XL-00002-of-00003.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/dots.llm1.inst-UD-Q5_K_XL-00003-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q5_K_XL/dots.llm1.inst-UD-Q5_K_XL-00003-of-00003.gguf",
        "file_size": "8.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/dots.llm1.inst-UD-Q6_K_XL-00001-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q6_K_XL/dots.llm1.inst-UD-Q6_K_XL-00001-of-00003.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/dots.llm1.inst-UD-Q6_K_XL-00002-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q6_K_XL/dots.llm1.inst-UD-Q6_K_XL-00002-of-00003.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/dots.llm1.inst-UD-Q6_K_XL-00003-of-00003",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q6_K_XL/dots.llm1.inst-UD-Q6_K_XL-00003-of-00003.gguf",
        "file_size": "29.6 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/dots.llm1.inst-UD-Q8_K_XL-00001-of-00004",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q8_K_XL/dots.llm1.inst-UD-Q8_K_XL-00001-of-00004.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/dots.llm1.inst-UD-Q8_K_XL-00002-of-00004",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q8_K_XL/dots.llm1.inst-UD-Q8_K_XL-00002-of-00004.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/dots.llm1.inst-UD-Q8_K_XL-00003-of-00004",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q8_K_XL/dots.llm1.inst-UD-Q8_K_XL-00003-of-00004.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/dots.llm1.inst-UD-Q8_K_XL-00004-of-00004",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/UD-Q8_K_XL/dots.llm1.inst-UD-Q8_K_XL-00004-of-00004.gguf",
        "file_size": "12.7 GB"
      },
      {
        "model_id": "dots.llm1.inst-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/dots.llm1.inst-UD-IQ1_S.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "dots.llm1.inst-UD-TQ1_0",
        "path": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/dots.llm1.inst-UD-TQ1_0.gguf",
        "file_size": "44.7 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/dots.llm1.inst-GGUF/resolve/main/README.md",
    "description": "The `dots.llm1` model is a large-scale MoE model with 14B activated parameters out of 142B total, trained on high-quality data without synthetic data, offering efficient and accurate performance for English and Chinese.",
    "tools": false
  },
  {
    "model_name": "Dream-org_Dream-v0-Instruct-7B-GGUF",
    "developer": "bartowski",
    "downloads": 1431,
    "createdAt": "2025-07-16T19:48:13.000Z",
    "tools": true,
    "num_quants": 24,
    "quants": [
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-IQ2_M",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-IQ2_M.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-IQ3_M",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-IQ3_M.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-IQ3_XS.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-IQ3_XXS.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-IQ4_NL",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-IQ4_NL.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-IQ4_XS.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q2_K",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q2_K.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q2_K_L",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q2_K_L.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q3_K_L.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q3_K_M.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q3_K_S.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q3_K_XL.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q4_0",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q4_0.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q4_1",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q4_1.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q4_K_L.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q4_K_M.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q4_K_S.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q5_K_L.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q5_K_M.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q5_K_S.gguf",
        "file_size": "5.0 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q6_K",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q6_K.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q6_K_L.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-Q8_0",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-Q8_0.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Dream-org_Dream-v0-Instruct-7B-bf16",
        "path": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/Dream-org_Dream-v0-Instruct-7B-bf16.gguf",
        "file_size": "14.2 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Dream-org_Dream-v0-Instruct-7B-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Dream-v0-Instruct-7B model using llama.cpp's imatrix method, offering various quantization types for different performance and quality trade-offs."
  },
  {
    "model_name": "ERNIE-4.5-0.3B-PT-GGUF",
    "developer": "unsloth",
    "downloads": 8867,
    "createdAt": "2025-06-30T05:25:35.000Z",
    "num_quants": 19,
    "quants": [
      {
        "model_id": "ERNIE-4.5-0.3B-PT-F16",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-F16.gguf",
        "file_size": "690.4 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-Q2_K",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-Q2_K.gguf",
        "file_size": "175.2 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-Q2_K_L",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-Q2_K_L.gguf",
        "file_size": "175.2 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-Q3_K_M",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-Q3_K_M.gguf",
        "file_size": "202.7 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-Q3_K_S",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-Q3_K_S.gguf",
        "file_size": "189.7 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-Q4_0",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-Q4_0.gguf",
        "file_size": "222.0 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-Q4_1",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-Q4_1.gguf",
        "file_size": "237.1 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-Q4_K_M",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-Q4_K_M.gguf",
        "file_size": "229.5 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-Q4_K_S",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-Q4_K_S.gguf",
        "file_size": "222.8 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-Q5_K_M",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-Q5_K_M.gguf",
        "file_size": "256.2 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-Q5_K_S",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-Q5_K_S.gguf",
        "file_size": "252.3 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-Q6_K",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-Q6_K.gguf",
        "file_size": "284.6 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-Q8_0",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-Q8_0.gguf",
        "file_size": "367.9 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-UD-Q2_K_XL.gguf",
        "file_size": "175.2 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-UD-Q3_K_XL.gguf",
        "file_size": "202.7 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-UD-Q4_K_XL.gguf",
        "file_size": "229.5 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-UD-Q5_K_XL.gguf",
        "file_size": "256.2 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-UD-Q6_K_XL.gguf",
        "file_size": "309.1 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-UD-Q8_K_XL.gguf",
        "file_size": "462.6 MB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/README.md",
    "description": "ERNIE-4.5-0.3B is a text dense, Apache-2.0 licensed large language model optimized for text generation and fine-tuning with ERNIEKit and FastDeploy, and supported by the transformers library.",
    "tools": false
  },
  {
    "model_name": "ERNIE-4.5-0.3B-PT-GGUF",
    "developer": "Mungert",
    "downloads": 386,
    "createdAt": "2025-07-16T02:52:32.000Z",
    "tools": false,
    "num_quants": 34,
    "quants": [
      {
        "model_id": "ERNIE-4.5-0.3B-PT-bf16",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-bf16.gguf",
        "file_size": "690.4 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-bf16_q4_k",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-bf16_q4_k.gguf",
        "file_size": "476.9 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-bf16_q6_k",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-bf16_q6_k.gguf",
        "file_size": "515.2 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-bf16_q8_0",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-bf16_q8_0.gguf",
        "file_size": "551.2 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-f16",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-f16.gguf",
        "file_size": "690.4 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-f16_q4_k",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-f16_q4_k.gguf",
        "file_size": "476.9 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-f16_q6_k",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-f16_q6_k.gguf",
        "file_size": "515.2 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-f16_q8_0",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-f16_q8_0.gguf",
        "file_size": "551.2 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-iq3_m",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-iq3_m.gguf",
        "file_size": "183.4 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-iq3_s",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-iq3_s.gguf",
        "file_size": "183.4 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-iq3_xs",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-iq3_xs.gguf",
        "file_size": "172.0 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-iq3_xxs",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-iq3_xxs.gguf",
        "file_size": "168.1 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-iq4_nl",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-iq4_nl.gguf",
        "file_size": "222.5 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-iq4_xs",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-iq4_xs.gguf",
        "file_size": "215.1 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q3_k_l",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q3_k_l.gguf",
        "file_size": "225.8 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q3_k_m",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q3_k_m.gguf",
        "file_size": "201.4 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q3_k_s",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q3_k_s.gguf",
        "file_size": "187.9 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q4_0",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q4_0.gguf",
        "file_size": "195.9 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q4_0_l",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q4_0_l.gguf",
        "file_size": "246.4 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q4_1",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q4_1.gguf",
        "file_size": "217.4 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q4_1_l",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q4_1_l.gguf",
        "file_size": "261.6 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q4_k_l",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q4_k_l.gguf",
        "file_size": "253.2 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q4_k_m",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q4_k_m.gguf",
        "file_size": "228.8 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q4_k_s",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q4_k_s.gguf",
        "file_size": "224.6 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q5_0",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q5_0.gguf",
        "file_size": "238.9 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q5_0_l",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q5_0_l.gguf",
        "file_size": "276.8 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q5_1",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q5_1.gguf",
        "file_size": "260.4 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q5_1_l",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q5_1_l.gguf",
        "file_size": "292.0 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q5_k_l",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q5_k_l.gguf",
        "file_size": "281.7 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q5_k_m",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q5_k_m.gguf",
        "file_size": "257.3 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q5_k_s",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q5_k_s.gguf",
        "file_size": "255.1 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q6_k_l",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q6_k_l.gguf",
        "file_size": "309.1 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q6_k_m",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q6_k_m.gguf",
        "file_size": "284.6 MB"
      },
      {
        "model_id": "ERNIE-4.5-0.3B-PT-q8_0",
        "path": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/ERNIE-4.5-0.3B-PT-q8_0.gguf",
        "file_size": "367.9 MB"
      }
    ],
    "readme": "https://huggingface.co/Mungert/ERNIE-4.5-0.3B-PT-GGUF/resolve/main/README.md",
    "description": "ERNIE-4.5-0.3B is a text dense, Apache-2.0 licensed, 0.36B parameter, 18-layer, 16/2-head model for text generation, fine-tuned for general language understanding and generation tasks."
  },
  {
    "model_name": "ERNIE-4.5-21B-A3B-PT-GGUF",
    "developer": "lmstudio-community",
    "downloads": 1268,
    "createdAt": "2025-06-30T03:51:30.000Z",
    "tools": false,
    "num_quants": 4,
    "quants": [
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q3_K_L",
        "path": "https://huggingface.co/lmstudio-community/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q3_K_L.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q4_K_M",
        "path": "https://huggingface.co/lmstudio-community/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q4_K_M.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q6_K",
        "path": "https://huggingface.co/lmstudio-community/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q6_K.gguf",
        "file_size": "16.8 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q8_0",
        "path": "https://huggingface.co/lmstudio-community/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q8_0.gguf",
        "file_size": "21.6 GB"
      }
    ],
    "readme": "https://huggingface.co/lmstudio-community/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Baidu ERNIE-4.5-21B-A3B-PT model by bartowski for text generation."
  },
  {
    "model_name": "ERNIE-4.5-21B-A3B-PT-GGUF",
    "developer": "unsloth",
    "downloads": 3038,
    "createdAt": "2025-07-18T01:00:17.000Z",
    "tools": false,
    "num_quants": 27,
    "quants": [
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-BF16",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-BF16.gguf",
        "file_size": "40.7 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-IQ4_NL",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-IQ4_NL.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-IQ4_XS",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-IQ4_XS.gguf",
        "file_size": "10.9 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q2_K",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q2_K.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q2_K_L",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q2_K_L.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q3_K_M",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q3_K_M.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q3_K_S",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q3_K_S.gguf",
        "file_size": "8.8 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q4_0",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q4_0.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q4_1",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q4_1.gguf",
        "file_size": "12.8 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q4_K_M",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q4_K_M.gguf",
        "file_size": "12.3 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q4_K_S",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q4_K_S.gguf",
        "file_size": "11.6 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q5_K_M",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q5_K_M.gguf",
        "file_size": "14.4 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q5_K_S",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q5_K_S.gguf",
        "file_size": "14.0 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q6_K",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q6_K.gguf",
        "file_size": "16.7 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-Q8_0",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-Q8_0.gguf",
        "file_size": "21.6 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-UD-IQ1_M.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-UD-IQ1_S.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-UD-IQ2_M.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-UD-IQ2_XXS.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-UD-IQ3_XXS.gguf",
        "file_size": "8.9 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-UD-Q2_K_XL.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-UD-Q3_K_XL.gguf",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-UD-Q4_K_XL.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-UD-Q5_K_XL.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-UD-Q6_K_XL.gguf",
        "file_size": "17.9 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-UD-Q8_K_XL.gguf",
        "file_size": "24.8 GB"
      },
      {
        "model_id": "ERNIE-4.5-21B-A3B-PT-UD-TQ1_0",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/ERNIE-4.5-21B-A3B-PT-UD-TQ1_0.gguf",
        "file_size": "6.1 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-PT-GGUF/resolve/main/README.md",
    "description": "ERNIE-4.5-21B-A3B-PT is a large-scale text generation model with 21B parameters and 3B activated parameters per token, trained using advanced multimodal MoE techniques and optimized for high-performance inference on various hardware platforms."
  },
  {
    "model_name": "ERNIE-4.5-300B-A47B-PT-GGUF",
    "developer": "unsloth",
    "downloads": 2237,
    "createdAt": "2025-07-18T01:15:04.000Z",
    "tools": false,
    "num_quants": 114,
    "quants": [
      {
        "model_id": "BF16/ERNIE-4.5-300B-A47B-PT-BF16-00001-of-00013",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/BF16/ERNIE-4.5-300B-A47B-PT-BF16-00001-of-00013.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "BF16/ERNIE-4.5-300B-A47B-PT-BF16-00002-of-00013",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/BF16/ERNIE-4.5-300B-A47B-PT-BF16-00002-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "BF16/ERNIE-4.5-300B-A47B-PT-BF16-00003-of-00013",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/BF16/ERNIE-4.5-300B-A47B-PT-BF16-00003-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "BF16/ERNIE-4.5-300B-A47B-PT-BF16-00004-of-00013",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/BF16/ERNIE-4.5-300B-A47B-PT-BF16-00004-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "BF16/ERNIE-4.5-300B-A47B-PT-BF16-00005-of-00013",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/BF16/ERNIE-4.5-300B-A47B-PT-BF16-00005-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "BF16/ERNIE-4.5-300B-A47B-PT-BF16-00006-of-00013",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/BF16/ERNIE-4.5-300B-A47B-PT-BF16-00006-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "BF16/ERNIE-4.5-300B-A47B-PT-BF16-00007-of-00013",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/BF16/ERNIE-4.5-300B-A47B-PT-BF16-00007-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "BF16/ERNIE-4.5-300B-A47B-PT-BF16-00008-of-00013",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/BF16/ERNIE-4.5-300B-A47B-PT-BF16-00008-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "BF16/ERNIE-4.5-300B-A47B-PT-BF16-00009-of-00013",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/BF16/ERNIE-4.5-300B-A47B-PT-BF16-00009-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "BF16/ERNIE-4.5-300B-A47B-PT-BF16-00010-of-00013",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/BF16/ERNIE-4.5-300B-A47B-PT-BF16-00010-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "BF16/ERNIE-4.5-300B-A47B-PT-BF16-00011-of-00013",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/BF16/ERNIE-4.5-300B-A47B-PT-BF16-00011-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "BF16/ERNIE-4.5-300B-A47B-PT-BF16-00012-of-00013",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/BF16/ERNIE-4.5-300B-A47B-PT-BF16-00012-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "BF16/ERNIE-4.5-300B-A47B-PT-BF16-00013-of-00013",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/BF16/ERNIE-4.5-300B-A47B-PT-BF16-00013-of-00013.gguf",
        "file_size": "37.7 GB"
      },
      {
        "model_id": "ERNIE-4.5-300B-A47B-PT-UD-TQ1_0",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/ERNIE-4.5-300B-A47B-PT-UD-TQ1_0.gguf",
        "file_size": "71.5 GB"
      },
      {
        "model_id": "IQ4_NL/ERNIE-4.5-300B-A47B-PT-IQ4_NL-00001-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/IQ4_NL/ERNIE-4.5-300B-A47B-PT-IQ4_NL-00001-of-00004.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "IQ4_NL/ERNIE-4.5-300B-A47B-PT-IQ4_NL-00002-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/IQ4_NL/ERNIE-4.5-300B-A47B-PT-IQ4_NL-00002-of-00004.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "IQ4_NL/ERNIE-4.5-300B-A47B-PT-IQ4_NL-00003-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/IQ4_NL/ERNIE-4.5-300B-A47B-PT-IQ4_NL-00003-of-00004.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "IQ4_NL/ERNIE-4.5-300B-A47B-PT-IQ4_NL-00004-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/IQ4_NL/ERNIE-4.5-300B-A47B-PT-IQ4_NL-00004-of-00004.gguf",
        "file_size": "18.2 GB"
      },
      {
        "model_id": "IQ4_XS/ERNIE-4.5-300B-A47B-PT-IQ4_XS-00001-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/IQ4_XS/ERNIE-4.5-300B-A47B-PT-IQ4_XS-00001-of-00004.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "IQ4_XS/ERNIE-4.5-300B-A47B-PT-IQ4_XS-00002-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/IQ4_XS/ERNIE-4.5-300B-A47B-PT-IQ4_XS-00002-of-00004.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "IQ4_XS/ERNIE-4.5-300B-A47B-PT-IQ4_XS-00003-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/IQ4_XS/ERNIE-4.5-300B-A47B-PT-IQ4_XS-00003-of-00004.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "IQ4_XS/ERNIE-4.5-300B-A47B-PT-IQ4_XS-00004-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/IQ4_XS/ERNIE-4.5-300B-A47B-PT-IQ4_XS-00004-of-00004.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "Q2_K/ERNIE-4.5-300B-A47B-PT-Q2_K-00001-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q2_K/ERNIE-4.5-300B-A47B-PT-Q2_K-00001-of-00003.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q2_K/ERNIE-4.5-300B-A47B-PT-Q2_K-00002-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q2_K/ERNIE-4.5-300B-A47B-PT-Q2_K-00002-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q2_K/ERNIE-4.5-300B-A47B-PT-Q2_K-00003-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q2_K/ERNIE-4.5-300B-A47B-PT-Q2_K-00003-of-00003.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "Q2_K_L/ERNIE-4.5-300B-A47B-PT-Q2_K_L-00001-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q2_K_L/ERNIE-4.5-300B-A47B-PT-Q2_K_L-00001-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q2_K_L/ERNIE-4.5-300B-A47B-PT-Q2_K_L-00002-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q2_K_L/ERNIE-4.5-300B-A47B-PT-Q2_K_L-00002-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q2_K_L/ERNIE-4.5-300B-A47B-PT-Q2_K_L-00003-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q2_K_L/ERNIE-4.5-300B-A47B-PT-Q2_K_L-00003-of-00003.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "Q3_K_M/ERNIE-4.5-300B-A47B-PT-Q3_K_M-00001-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q3_K_M/ERNIE-4.5-300B-A47B-PT-Q3_K_M-00001-of-00003.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q3_K_M/ERNIE-4.5-300B-A47B-PT-Q3_K_M-00002-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q3_K_M/ERNIE-4.5-300B-A47B-PT-Q3_K_M-00002-of-00003.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q3_K_M/ERNIE-4.5-300B-A47B-PT-Q3_K_M-00003-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q3_K_M/ERNIE-4.5-300B-A47B-PT-Q3_K_M-00003-of-00003.gguf",
        "file_size": "40.9 GB"
      },
      {
        "model_id": "Q3_K_S/ERNIE-4.5-300B-A47B-PT-Q3_K_S-00001-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q3_K_S/ERNIE-4.5-300B-A47B-PT-Q3_K_S-00001-of-00003.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q3_K_S/ERNIE-4.5-300B-A47B-PT-Q3_K_S-00002-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q3_K_S/ERNIE-4.5-300B-A47B-PT-Q3_K_S-00002-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q3_K_S/ERNIE-4.5-300B-A47B-PT-Q3_K_S-00003-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q3_K_S/ERNIE-4.5-300B-A47B-PT-Q3_K_S-00003-of-00003.gguf",
        "file_size": "27.8 GB"
      },
      {
        "model_id": "Q4_0/ERNIE-4.5-300B-A47B-PT-Q4_0-00001-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_0/ERNIE-4.5-300B-A47B-PT-Q4_0-00001-of-00004.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_0/ERNIE-4.5-300B-A47B-PT-Q4_0-00002-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_0/ERNIE-4.5-300B-A47B-PT-Q4_0-00002-of-00004.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q4_0/ERNIE-4.5-300B-A47B-PT-Q4_0-00003-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_0/ERNIE-4.5-300B-A47B-PT-Q4_0-00003-of-00004.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q4_0/ERNIE-4.5-300B-A47B-PT-Q4_0-00004-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_0/ERNIE-4.5-300B-A47B-PT-Q4_0-00004-of-00004.gguf",
        "file_size": "18.2 GB"
      },
      {
        "model_id": "Q4_1/ERNIE-4.5-300B-A47B-PT-Q4_1-00001-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_1/ERNIE-4.5-300B-A47B-PT-Q4_1-00001-of-00004.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q4_1/ERNIE-4.5-300B-A47B-PT-Q4_1-00002-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_1/ERNIE-4.5-300B-A47B-PT-Q4_1-00002-of-00004.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "Q4_1/ERNIE-4.5-300B-A47B-PT-Q4_1-00003-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_1/ERNIE-4.5-300B-A47B-PT-Q4_1-00003-of-00004.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q4_1/ERNIE-4.5-300B-A47B-PT-Q4_1-00004-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_1/ERNIE-4.5-300B-A47B-PT-Q4_1-00004-of-00004.gguf",
        "file_size": "35.9 GB"
      },
      {
        "model_id": "Q4_K_M/ERNIE-4.5-300B-A47B-PT-Q4_K_M-00001-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_K_M/ERNIE-4.5-300B-A47B-PT-Q4_K_M-00001-of-00004.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q4_K_M/ERNIE-4.5-300B-A47B-PT-Q4_K_M-00002-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_K_M/ERNIE-4.5-300B-A47B-PT-Q4_K_M-00002-of-00004.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Q4_K_M/ERNIE-4.5-300B-A47B-PT-Q4_K_M-00003-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_K_M/ERNIE-4.5-300B-A47B-PT-Q4_K_M-00003-of-00004.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q4_K_M/ERNIE-4.5-300B-A47B-PT-Q4_K_M-00004-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_K_M/ERNIE-4.5-300B-A47B-PT-Q4_K_M-00004-of-00004.gguf",
        "file_size": "30.4 GB"
      },
      {
        "model_id": "Q4_K_S/ERNIE-4.5-300B-A47B-PT-Q4_K_S-00001-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_K_S/ERNIE-4.5-300B-A47B-PT-Q4_K_S-00001-of-00004.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Q4_K_S/ERNIE-4.5-300B-A47B-PT-Q4_K_S-00002-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_K_S/ERNIE-4.5-300B-A47B-PT-Q4_K_S-00002-of-00004.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q4_K_S/ERNIE-4.5-300B-A47B-PT-Q4_K_S-00003-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_K_S/ERNIE-4.5-300B-A47B-PT-Q4_K_S-00003-of-00004.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q4_K_S/ERNIE-4.5-300B-A47B-PT-Q4_K_S-00004-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q4_K_S/ERNIE-4.5-300B-A47B-PT-Q4_K_S-00004-of-00004.gguf",
        "file_size": "19.2 GB"
      },
      {
        "model_id": "Q5_K_M/ERNIE-4.5-300B-A47B-PT-Q5_K_M-00001-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q5_K_M/ERNIE-4.5-300B-A47B-PT-Q5_K_M-00001-of-00005.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q5_K_M/ERNIE-4.5-300B-A47B-PT-Q5_K_M-00002-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q5_K_M/ERNIE-4.5-300B-A47B-PT-Q5_K_M-00002-of-00005.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "Q5_K_M/ERNIE-4.5-300B-A47B-PT-Q5_K_M-00003-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q5_K_M/ERNIE-4.5-300B-A47B-PT-Q5_K_M-00003-of-00005.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "Q5_K_M/ERNIE-4.5-300B-A47B-PT-Q5_K_M-00004-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q5_K_M/ERNIE-4.5-300B-A47B-PT-Q5_K_M-00004-of-00005.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q5_K_M/ERNIE-4.5-300B-A47B-PT-Q5_K_M-00005-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q5_K_M/ERNIE-4.5-300B-A47B-PT-Q5_K_M-00005-of-00005.gguf",
        "file_size": "14.2 GB"
      },
      {
        "model_id": "Q5_K_S/ERNIE-4.5-300B-A47B-PT-Q5_K_S-00001-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q5_K_S/ERNIE-4.5-300B-A47B-PT-Q5_K_S-00001-of-00005.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q5_K_S/ERNIE-4.5-300B-A47B-PT-Q5_K_S-00002-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q5_K_S/ERNIE-4.5-300B-A47B-PT-Q5_K_S-00002-of-00005.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q5_K_S/ERNIE-4.5-300B-A47B-PT-Q5_K_S-00003-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q5_K_S/ERNIE-4.5-300B-A47B-PT-Q5_K_S-00003-of-00005.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Q5_K_S/ERNIE-4.5-300B-A47B-PT-Q5_K_S-00004-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q5_K_S/ERNIE-4.5-300B-A47B-PT-Q5_K_S-00004-of-00005.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Q5_K_S/ERNIE-4.5-300B-A47B-PT-Q5_K_S-00005-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q5_K_S/ERNIE-4.5-300B-A47B-PT-Q5_K_S-00005-of-00005.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "Q6_K/ERNIE-4.5-300B-A47B-PT-Q6_K-00001-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q6_K/ERNIE-4.5-300B-A47B-PT-Q6_K-00001-of-00005.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q6_K/ERNIE-4.5-300B-A47B-PT-Q6_K-00002-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q6_K/ERNIE-4.5-300B-A47B-PT-Q6_K-00002-of-00005.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q6_K/ERNIE-4.5-300B-A47B-PT-Q6_K-00003-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q6_K/ERNIE-4.5-300B-A47B-PT-Q6_K-00003-of-00005.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Q6_K/ERNIE-4.5-300B-A47B-PT-Q6_K-00004-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q6_K/ERNIE-4.5-300B-A47B-PT-Q6_K-00004-of-00005.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Q6_K/ERNIE-4.5-300B-A47B-PT-Q6_K-00005-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q6_K/ERNIE-4.5-300B-A47B-PT-Q6_K-00005-of-00005.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Q8_0/ERNIE-4.5-300B-A47B-PT-Q8_0-00001-of-00007",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q8_0/ERNIE-4.5-300B-A47B-PT-Q8_0-00001-of-00007.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Q8_0/ERNIE-4.5-300B-A47B-PT-Q8_0-00002-of-00007",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q8_0/ERNIE-4.5-300B-A47B-PT-Q8_0-00002-of-00007.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/ERNIE-4.5-300B-A47B-PT-Q8_0-00003-of-00007",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q8_0/ERNIE-4.5-300B-A47B-PT-Q8_0-00003-of-00007.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/ERNIE-4.5-300B-A47B-PT-Q8_0-00004-of-00007",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q8_0/ERNIE-4.5-300B-A47B-PT-Q8_0-00004-of-00007.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/ERNIE-4.5-300B-A47B-PT-Q8_0-00005-of-00007",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q8_0/ERNIE-4.5-300B-A47B-PT-Q8_0-00005-of-00007.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/ERNIE-4.5-300B-A47B-PT-Q8_0-00006-of-00007",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q8_0/ERNIE-4.5-300B-A47B-PT-Q8_0-00006-of-00007.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/ERNIE-4.5-300B-A47B-PT-Q8_0-00007-of-00007",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/Q8_0/ERNIE-4.5-300B-A47B-PT-Q8_0-00007-of-00007.gguf",
        "file_size": "21.9 GB"
      },
      {
        "model_id": "UD-IQ1_M/ERNIE-4.5-300B-A47B-PT-UD-IQ1_M-00001-of-00002",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-IQ1_M/ERNIE-4.5-300B-A47B-PT-UD-IQ1_M-00001-of-00002.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-IQ1_M/ERNIE-4.5-300B-A47B-PT-UD-IQ1_M-00002-of-00002",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-IQ1_M/ERNIE-4.5-300B-A47B-PT-UD-IQ1_M-00002-of-00002.gguf",
        "file_size": "40.6 GB"
      },
      {
        "model_id": "UD-IQ1_S/ERNIE-4.5-300B-A47B-PT-UD-IQ1_S-00001-of-00002",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-IQ1_S/ERNIE-4.5-300B-A47B-PT-UD-IQ1_S-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-IQ1_S/ERNIE-4.5-300B-A47B-PT-UD-IQ1_S-00002-of-00002",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-IQ1_S/ERNIE-4.5-300B-A47B-PT-UD-IQ1_S-00002-of-00002.gguf",
        "file_size": "34.1 GB"
      },
      {
        "model_id": "UD-IQ2_M/ERNIE-4.5-300B-A47B-PT-UD-IQ2_M-00001-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-IQ2_M/ERNIE-4.5-300B-A47B-PT-UD-IQ2_M-00001-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-IQ2_M/ERNIE-4.5-300B-A47B-PT-UD-IQ2_M-00002-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-IQ2_M/ERNIE-4.5-300B-A47B-PT-UD-IQ2_M-00002-of-00003.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-IQ2_M/ERNIE-4.5-300B-A47B-PT-UD-IQ2_M-00003-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-IQ2_M/ERNIE-4.5-300B-A47B-PT-UD-IQ2_M-00003-of-00003.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/ERNIE-4.5-300B-A47B-PT-UD-IQ2_XXS-00001-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-IQ2_XXS/ERNIE-4.5-300B-A47B-PT-UD-IQ2_XXS-00001-of-00003.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/ERNIE-4.5-300B-A47B-PT-UD-IQ2_XXS-00002-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-IQ2_XXS/ERNIE-4.5-300B-A47B-PT-UD-IQ2_XXS-00002-of-00003.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/ERNIE-4.5-300B-A47B-PT-UD-IQ2_XXS-00003-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-IQ2_XXS/ERNIE-4.5-300B-A47B-PT-UD-IQ2_XXS-00003-of-00003.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/ERNIE-4.5-300B-A47B-PT-UD-IQ3_XXS-00001-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-IQ3_XXS/ERNIE-4.5-300B-A47B-PT-UD-IQ3_XXS-00001-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/ERNIE-4.5-300B-A47B-PT-UD-IQ3_XXS-00002-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-IQ3_XXS/ERNIE-4.5-300B-A47B-PT-UD-IQ3_XXS-00002-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/ERNIE-4.5-300B-A47B-PT-UD-IQ3_XXS-00003-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-IQ3_XXS/ERNIE-4.5-300B-A47B-PT-UD-IQ3_XXS-00003-of-00003.gguf",
        "file_size": "23.8 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q2_K_XL-00001-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q2_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q2_K_XL-00001-of-00003.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q2_K_XL-00002-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q2_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q2_K_XL-00002-of-00003.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q2_K_XL-00003-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q2_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q2_K_XL-00003-of-00003.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q3_K_XL-00001-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q3_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q3_K_XL-00001-of-00003.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q3_K_XL-00002-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q3_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q3_K_XL-00002-of-00003.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q3_K_XL-00003-of-00003",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q3_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q3_K_XL-00003-of-00003.gguf",
        "file_size": "33.1 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q4_K_XL-00001-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q4_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q4_K_XL-00001-of-00004.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q4_K_XL-00002-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q4_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q4_K_XL-00002-of-00004.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q4_K_XL-00003-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q4_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q4_K_XL-00003-of-00004.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q4_K_XL-00004-of-00004",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q4_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q4_K_XL-00004-of-00004.gguf",
        "file_size": "22.9 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q5_K_XL-00001-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q5_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q5_K_XL-00001-of-00005.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q5_K_XL-00002-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q5_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q5_K_XL-00002-of-00005.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q5_K_XL-00003-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q5_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q5_K_XL-00003-of-00005.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q5_K_XL-00004-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q5_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q5_K_XL-00004-of-00005.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q5_K_XL-00005-of-00005",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q5_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q5_K_XL-00005-of-00005.gguf",
        "file_size": "17.0 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q6_K_XL-00001-of-00006",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q6_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q6_K_XL-00001-of-00006.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q6_K_XL-00002-of-00006",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q6_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q6_K_XL-00002-of-00006.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q6_K_XL-00003-of-00006",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q6_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q6_K_XL-00003-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q6_K_XL-00004-of-00006",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q6_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q6_K_XL-00004-of-00006.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q6_K_XL-00005-of-00006",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q6_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q6_K_XL-00005-of-00006.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q6_K_XL-00006-of-00006",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q6_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q6_K_XL-00006-of-00006.gguf",
        "file_size": "10.3 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00001-of-00008",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00001-of-00008.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00002-of-00008",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00002-of-00008.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00003-of-00008",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00003-of-00008.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00004-of-00008",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00004-of-00008.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00005-of-00008",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00005-of-00008.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00006-of-00008",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00006-of-00008.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00007-of-00008",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00007-of-00008.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00008-of-00008",
        "path": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/UD-Q8_K_XL/ERNIE-4.5-300B-A47B-PT-UD-Q8_K_XL-00008-of-00008.gguf",
        "file_size": "5.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/ERNIE-4.5-300B-A47B-PT-GGUF/resolve/main/README.md",
    "description": "ERNIE-4.5-300B-A47B is a large text MoE model with 300B parameters, trained for advanced language understanding and generation, and available via the transformers library for text generation tasks."
  },
  {
    "model_name": "EXAONE-4.0-1.2B-GGUF",
    "developer": "LGAI-EXAONE",
    "downloads": 4873,
    "createdAt": "2025-07-11T07:03:24.000Z",
    "tools": true,
    "num_quants": 6,
    "quants": [
      {
        "model_id": "EXAONE-4.0-1.2B-BF16",
        "path": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-BF16.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-IQ4_XS",
        "path": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-IQ4_XS.gguf",
        "file_size": "718.9 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-Q4_K_M",
        "path": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-Q4_K_M.gguf",
        "file_size": "774.8 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-Q5_K_M",
        "path": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-Q5_K_M.gguf",
        "file_size": "886.6 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-Q6_K",
        "path": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-Q6_K.gguf",
        "file_size": "1005.3 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-Q8_0",
        "path": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-Q8_0.gguf",
        "file_size": "1.3 GB"
      }
    ],
    "readme": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-1.2B-GGUF/resolve/main/README.md",
    "description": "The EXAONE-4.0-1.2B-GGUF model is a multilingual, hybrid reasoning model that combines non-reasoning and reasoning modes, offering high performance with support for Spanish, Korean, and English, and is available in GGUF format with various quantization options"
  },
  {
    "model_name": "EXAONE-4.0-1.2B-GGUF",
    "developer": "Mungert",
    "downloads": 417,
    "createdAt": "2025-07-20T23:22:57.000Z",
    "tools": true,
    "num_quants": 34,
    "quants": [
      {
        "model_id": "EXAONE-4.0-1.2B-bf16",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-bf16.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-bf16_q4_k",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-bf16_q4_k.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-bf16_q6_k",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-bf16_q6_k.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-bf16_q8_0",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-bf16_q8_0.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-f16",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-f16.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-f16_q4_k",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-f16_q4_k.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-f16_q6_k",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-f16_q6_k.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-f16_q8_0",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-f16_q8_0.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-iq3_m",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-iq3_m.gguf",
        "file_size": "626.1 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-iq3_s",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-iq3_s.gguf",
        "file_size": "612.6 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-iq3_xs",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-iq3_xs.gguf",
        "file_size": "564.9 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-iq3_xxs",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-iq3_xxs.gguf",
        "file_size": "550.2 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-iq4_nl",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-iq4_nl.gguf",
        "file_size": "746.1 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-iq4_xs",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-iq4_xs.gguf",
        "file_size": "715.1 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q3_k_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q3_k_l.gguf",
        "file_size": "708.3 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q3_k_m",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q3_k_m.gguf",
        "file_size": "659.9 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q3_k_s",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q3_k_s.gguf",
        "file_size": "629.1 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q4_0",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q4_0.gguf",
        "file_size": "690.8 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q4_0_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q4_0_l.gguf",
        "file_size": "790.8 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q4_1",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q4_1.gguf",
        "file_size": "767.0 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q4_1_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q4_1_l.gguf",
        "file_size": "854.5 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q4_k_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q4_k_l.gguf",
        "file_size": "826.2 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q4_k_m",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q4_k_m.gguf",
        "file_size": "777.8 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q4_k_s",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q4_k_s.gguf",
        "file_size": "752.2 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q5_0",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q5_0.gguf",
        "file_size": "843.3 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q5_0_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q5_0_l.gguf",
        "file_size": "918.3 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q5_1",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q5_1.gguf",
        "file_size": "919.5 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q5_1_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q5_1_l.gguf",
        "file_size": "982.0 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q5_k_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q5_k_l.gguf",
        "file_size": "938.2 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q5_k_m",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q5_k_m.gguf",
        "file_size": "889.7 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q5_k_s",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q5_k_s.gguf",
        "file_size": "880.2 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q6_k_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q6_k_l.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q6_k_m",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q6_k_m.gguf",
        "file_size": "1005.3 MB"
      },
      {
        "model_id": "EXAONE-4.0-1.2B-q8_0",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/EXAONE-4.0-1.2B-q8_0.gguf",
        "file_size": "1.3 GB"
      }
    ],
    "readme": "https://huggingface.co/Mungert/EXAONE-4.0-1.2B-GGUF/resolve/main/README.md",
    "description": "The EXAONE-4.0-1.2B GGUF model is a multilingual, hybrid attention-based large language model offering both non-reasoning and reasoning modes with enhanced performance and agentic tool use capabilities, licensed under the EXAONE AI Model License Agreement 1.2"
  },
  {
    "model_name": "EXAONE-4.0-32B-GGUF",
    "developer": "LGAI-EXAONE",
    "downloads": 16781,
    "createdAt": "2025-07-11T07:02:22.000Z",
    "tools": true,
    "num_quants": 7,
    "quants": [
      {
        "model_id": "EXAONE-4.0-32B-BF16-00001-of-00002",
        "path": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-BF16-00001-of-00002.gguf",
        "file_size": "30.7 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-BF16-00002-of-00002",
        "path": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-BF16-00002-of-00002.gguf",
        "file_size": "28.9 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-IQ4_XS",
        "path": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-IQ4_XS.gguf",
        "file_size": "16.2 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-Q4_K_M",
        "path": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-Q4_K_M.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-Q5_K_M",
        "path": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-Q5_K_M.gguf",
        "file_size": "21.1 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-Q6_K",
        "path": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-Q6_K.gguf",
        "file_size": "24.5 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-Q8_0",
        "path": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-Q8_0.gguf",
        "file_size": "31.7 GB"
      }
    ],
    "readme": "https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B-GGUF/resolve/main/README.md",
    "description": "The EXAONE-4.0-32B-GGUF model is a large language model offering both non-reasoning and reasoning modes, with support for multiple languages including English, Korean, and Spanish, and it is licensed under the EXAONE AI Model License Agreement 1."
  },
  {
    "model_name": "EXAONE-4.0-32B-GGUF",
    "developer": "Mungert",
    "downloads": 642,
    "createdAt": "2025-07-20T02:45:15.000Z",
    "tools": true,
    "num_quants": 45,
    "quants": [
      {
        "model_id": "EXAONE-4.0-32B-bf16_q4_k",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-bf16_q4_k.gguf",
        "file_size": "32.9 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-bf16_q6_k",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-bf16_q6_k.gguf",
        "file_size": "37.7 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-bf16_q8_0",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-bf16_q8_0.gguf",
        "file_size": "42.2 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-f16_q4_k",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-f16_q4_k.gguf",
        "file_size": "32.9 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-f16_q6_k",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-f16_q6_k.gguf",
        "file_size": "37.7 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-f16_q8_0",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-f16_q8_0.gguf",
        "file_size": "42.2 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-iq1_m",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-iq1_m.gguf",
        "file_size": "8.7 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-iq1_s",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-iq1_s.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-iq2_m",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-iq2_m.gguf",
        "file_size": "10.9 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-iq2_s",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-iq2_s.gguf",
        "file_size": "10.3 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-iq2_xs",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-iq2_xs.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-iq2_xxs",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-iq2_xxs.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-iq3_m",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-iq3_m.gguf",
        "file_size": "14.2 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-iq3_s",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-iq3_s.gguf",
        "file_size": "14.0 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-iq3_xs",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-iq3_xs.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-iq3_xxs",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-iq3_xxs.gguf",
        "file_size": "12.3 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-iq4_nl",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-iq4_nl.gguf",
        "file_size": "16.9 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-iq4_xs",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-iq4_xs.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q2_k_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q2_k_l.gguf",
        "file_size": "11.6 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q2_k_m",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q2_k_m.gguf",
        "file_size": "11.3 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q2_k_s",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q2_k_s.gguf",
        "file_size": "11.2 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q3_k_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q3_k_l.gguf",
        "file_size": "14.9 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q3_k_m",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q3_k_m.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q3_k_s",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q3_k_s.gguf",
        "file_size": "14.4 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q4_0",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q4_0.gguf",
        "file_size": "16.8 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q4_0_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q4_0_l.gguf",
        "file_size": "17.3 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q4_1",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q4_1.gguf",
        "file_size": "18.6 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q4_1_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q4_1_l.gguf",
        "file_size": "19.1 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q4_k_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q4_k_l.gguf",
        "file_size": "18.4 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q4_k_m",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q4_k_m.gguf",
        "file_size": "18.2 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q4_k_s",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q4_k_s.gguf",
        "file_size": "17.3 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q5_0",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q5_0.gguf",
        "file_size": "20.5 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q5_0_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q5_0_l.gguf",
        "file_size": "20.9 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q5_1",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q5_1.gguf",
        "file_size": "22.4 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q5_1_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q5_1_l.gguf",
        "file_size": "22.7 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q5_k_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q5_k_l.gguf",
        "file_size": "21.5 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q5_k_m",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q5_k_m.gguf",
        "file_size": "21.2 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q5_k_s",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q5_k_s.gguf",
        "file_size": "20.9 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q6_k_l",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q6_k_l.gguf",
        "file_size": "24.7 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q6_k_m",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q6_k_m.gguf",
        "file_size": "24.5 GB"
      },
      {
        "model_id": "EXAONE-4.0-32B-q8_0",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/EXAONE-4.0-32B-q8_0.gguf",
        "file_size": "31.7 GB"
      },
      {
        "model_id": "bf16/EXAONE-4.0-32B-bf16-00001-of-00002",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/bf16/EXAONE-4.0-32B-bf16-00001-of-00002.gguf",
        "file_size": "42.8 GB"
      },
      {
        "model_id": "bf16/EXAONE-4.0-32B-bf16-00002-of-00002",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/bf16/EXAONE-4.0-32B-bf16-00002-of-00002.gguf",
        "file_size": "16.9 GB"
      },
      {
        "model_id": "f16/EXAONE-4.0-32B-f16-00001-of-00002",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/f16/EXAONE-4.0-32B-f16-00001-of-00002.gguf",
        "file_size": "42.8 GB"
      },
      {
        "model_id": "f16/EXAONE-4.0-32B-f16-00002-of-00002",
        "path": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/f16/EXAONE-4.0-32B-f16-00002-of-00002.gguf",
        "file_size": "16.9 GB"
      }
    ],
    "readme": "https://huggingface.co/Mungert/EXAONE-4.0-32B-GGUF/resolve/main/README.md",
    "description": "The EXAONE-4.0-32B GGUF model is a large language model with non-reasoning and reasoning modes, supporting multiple languages including Spanish, Korean, and English, and offering improved performance through hybrid attention and QK-Reorder-Norm, with detailed benchmark results and"
  },
  {
    "model_name": "Falcon-H1-1.5B-Instruct-GGUF",
    "developer": "tiiuae",
    "downloads": 2115,
    "createdAt": "2025-05-13T14:03:46.000Z",
    "num_quants": 35,
    "quants": [
      {
        "model_id": "Falcon-H1-1.5B-Instruct-BF16",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-BF16.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-F16",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-F16.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-F32",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-F32.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-IQ1_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-IQ1_M.gguf",
        "file_size": "412.1 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-IQ1_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-IQ1_S.gguf",
        "file_size": "385.4 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-IQ2_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-IQ2_M.gguf",
        "file_size": "551.8 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-IQ2_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-IQ2_S.gguf",
        "file_size": "516.2 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-IQ2_XS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-IQ2_XS.gguf",
        "file_size": "493.7 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-IQ2_XXS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-IQ2_XXS.gguf",
        "file_size": "456.6 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-IQ3_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-IQ3_M.gguf",
        "file_size": "703.3 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-IQ3_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-IQ3_S.gguf",
        "file_size": "693.4 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-IQ3_XS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-IQ3_XS.gguf",
        "file_size": "675.4 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-IQ3_XXS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-IQ3_XXS.gguf",
        "file_size": "617.9 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-IQ4_NL.gguf",
        "file_size": "873.1 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-IQ4_XS.gguf",
        "file_size": "831.2 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q2_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q2_K.gguf",
        "file_size": "583.9 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q2_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q2_K_S.gguf",
        "file_size": "563.4 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q3_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q3_K.gguf",
        "file_size": "729.7 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q3_K_L",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q3_K_L.gguf",
        "file_size": "762.9 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q3_K_M.gguf",
        "file_size": "729.7 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q3_K_S.gguf",
        "file_size": "691.8 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q4_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q4_0.gguf",
        "file_size": "871.6 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q4_1",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q4_1.gguf",
        "file_size": "956.3 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q4_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q4_K.gguf",
        "file_size": "901.0 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q4_K_M.gguf",
        "file_size": "901.0 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q4_K_S.gguf",
        "file_size": "875.3 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q5_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q5_0.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q5_1",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q5_1.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q5_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q5_K.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q5_K_M.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q5_K_S.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q6_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q6_K.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-Q8_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-Q8_0.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-TQ1_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-TQ1_0.gguf",
        "file_size": "440.5 MB"
      },
      {
        "model_id": "Falcon-H1-1.5B-Instruct-TQ2_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/Falcon-H1-1.5B-Instruct-TQ2_0.gguf",
        "file_size": "498.0 MB"
      }
    ],
    "readme": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Falcon-H1-34B-Instruct-GGUF",
    "developer": "tiiuae",
    "downloads": 10556,
    "createdAt": "2025-05-13T17:13:53.000Z",
    "num_quants": 39,
    "quants": [
      {
        "model_id": "BF16/Falcon-H1-34B-Instruct-BF16-00001-of-00002",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/BF16/Falcon-H1-34B-Instruct-BF16-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "BF16/Falcon-H1-34B-Instruct-BF16-00002-of-00002",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/BF16/Falcon-H1-34B-Instruct-BF16-00002-of-00002.gguf",
        "file_size": "16.2 GB"
      },
      {
        "model_id": "F16/Falcon-H1-34B-Instruct-F16-00001-of-00002",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/F16/Falcon-H1-34B-Instruct-F16-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "F16/Falcon-H1-34B-Instruct-F16-00002-of-00002",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/F16/Falcon-H1-34B-Instruct-F16-00002-of-00002.gguf",
        "file_size": "16.2 GB"
      },
      {
        "model_id": "F32/Falcon-H1-34B-Instruct-F32-00001-of-00003",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/F32/Falcon-H1-34B-Instruct-F32-00001-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "F32/Falcon-H1-34B-Instruct-F32-00002-of-00003",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/F32/Falcon-H1-34B-Instruct-F32-00002-of-00003.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "F32/Falcon-H1-34B-Instruct-F32-00003-of-00003",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/F32/Falcon-H1-34B-Instruct-F32-00003-of-00003.gguf",
        "file_size": "32.2 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-IQ1_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-IQ1_M.gguf",
        "file_size": "7.8 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-IQ1_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-IQ1_S.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-IQ2_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-IQ2_M.gguf",
        "file_size": "10.9 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-IQ2_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-IQ2_S.gguf",
        "file_size": "10.1 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-IQ2_XS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-IQ2_XS.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-IQ2_XXS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-IQ2_XXS.gguf",
        "file_size": "8.8 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-IQ3_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-IQ3_M.gguf",
        "file_size": "14.2 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-IQ3_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-IQ3_S.gguf",
        "file_size": "14.0 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-IQ3_XS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-IQ3_XS.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-IQ3_XXS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-IQ3_XXS.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-IQ4_NL.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-IQ4_XS.gguf",
        "file_size": "17.1 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q2_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q2_K.gguf",
        "file_size": "11.8 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q2_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q2_K_S.gguf",
        "file_size": "11.2 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q3_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q3_K.gguf",
        "file_size": "15.1 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q3_K_L",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q3_K_L.gguf",
        "file_size": "16.1 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q3_K_M.gguf",
        "file_size": "15.1 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q3_K_S.gguf",
        "file_size": "14.0 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q4_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q4_0.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q4_1",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q4_1.gguf",
        "file_size": "19.8 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q4_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q4_K.gguf",
        "file_size": "18.9 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q4_K_M.gguf",
        "file_size": "18.9 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q4_K_S.gguf",
        "file_size": "18.1 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q5_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q5_0.gguf",
        "file_size": "21.7 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q5_1",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q5_1.gguf",
        "file_size": "23.6 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q5_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q5_K.gguf",
        "file_size": "22.2 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q5_K_M.gguf",
        "file_size": "22.2 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q5_K_S.gguf",
        "file_size": "21.7 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q6_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q6_K.gguf",
        "file_size": "25.7 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-Q8_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-Q8_0.gguf",
        "file_size": "33.3 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-TQ1_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-TQ1_0.gguf",
        "file_size": "7.8 GB"
      },
      {
        "model_id": "Falcon-H1-34B-Instruct-TQ2_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/Falcon-H1-34B-Instruct-TQ2_0.gguf",
        "file_size": "9.2 GB"
      }
    ],
    "readme": "https://huggingface.co/tiiuae/Falcon-H1-34B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Falcon-H1-3B-Instruct-GGUF",
    "developer": "tiiuae",
    "downloads": 2037,
    "createdAt": "2025-05-13T14:36:15.000Z",
    "num_quants": 34,
    "quants": [
      {
        "model_id": "Falcon-H1-3B-Instruct-BF16",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-BF16.gguf",
        "file_size": "5.9 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-F16",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-F16.gguf",
        "file_size": "5.9 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-F32",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-F32.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-IQ1_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-IQ1_M.gguf",
        "file_size": "773.2 MB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-IQ2_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-IQ2_M.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-IQ2_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-IQ2_S.gguf",
        "file_size": "988.6 MB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-IQ2_XS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-IQ2_XS.gguf",
        "file_size": "952.2 MB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-IQ2_XXS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-IQ2_XXS.gguf",
        "file_size": "870.9 MB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-IQ3_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-IQ3_M.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-IQ3_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-IQ3_S.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-IQ3_XS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-IQ3_XS.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-IQ3_XXS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-IQ3_XXS.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-IQ4_NL.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-IQ4_XS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q2_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q2_K.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q2_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q2_K_S.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q3_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q3_K.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q3_K_L",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q3_K_L.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q3_K_M.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q3_K_S.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q4_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q4_0.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q4_1",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q4_1.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q4_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q4_K.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q4_K_M.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q4_K_S.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q5_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q5_0.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q5_1",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q5_1.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q5_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q5_K.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q5_K_M.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q5_K_S.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q6_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q6_K.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-Q8_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-Q8_0.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-TQ1_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-TQ1_0.gguf",
        "file_size": "793.6 MB"
      },
      {
        "model_id": "Falcon-H1-3B-Instruct-TQ2_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/Falcon-H1-3B-Instruct-TQ2_0.gguf",
        "file_size": "919.3 MB"
      }
    ],
    "readme": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Falcon-H1-7B-Instruct-GGUF",
    "developer": "tiiuae",
    "downloads": 4487,
    "createdAt": "2025-05-13T15:59:29.000Z",
    "num_quants": 34,
    "quants": [
      {
        "model_id": "Falcon-H1-7B-Instruct-BF16",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-BF16.gguf",
        "file_size": "14.1 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-F16",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-F16.gguf",
        "file_size": "14.1 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-F32",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-F32.gguf",
        "file_size": "28.3 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-IQ1_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-IQ1_M.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-IQ2_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-IQ2_M.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-IQ2_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-IQ2_S.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-IQ2_XS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-IQ2_XS.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-IQ2_XXS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-IQ2_XXS.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-IQ3_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-IQ3_M.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-IQ3_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-IQ3_S.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-IQ3_XS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-IQ3_XS.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-IQ3_XXS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-IQ3_XXS.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-IQ4_NL.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-IQ4_XS.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q2_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q2_K.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q2_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q2_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q3_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q3_K.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q3_K_L",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q3_K_L.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q3_K_M.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q3_K_S.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q4_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q4_0.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q4_1",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q4_1.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q4_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q4_K.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q4_K_M.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q4_K_S.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q5_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q5_0.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q5_1",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q5_1.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q5_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q5_K.gguf",
        "file_size": "5.0 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q5_K_M.gguf",
        "file_size": "5.0 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q5_K_S.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q6_K",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q6_K.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q8_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q8_0.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-TQ1_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-TQ1_0.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-TQ2_0",
        "path": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-TQ2_0.gguf",
        "file_size": "2.2 GB"
      }
    ],
    "readme": "https://huggingface.co/tiiuae/Falcon-H1-7B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Falcon-H1-7B-Instruct-GGUF",
    "developer": "unsloth",
    "downloads": 1284,
    "createdAt": "2025-07-10T07:56:03.000Z",
    "num_quants": 26,
    "quants": [
      {
        "model_id": "Falcon-H1-7B-Instruct-BF16",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-BF16.gguf",
        "file_size": "14.1 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-IQ4_NL.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-IQ4_XS.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q2_K",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q2_K.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q2_K_L.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q3_K_M.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q3_K_S.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q4_0",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q4_0.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q4_1",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q4_1.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q4_K_M.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q4_K_S.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q5_K_M.gguf",
        "file_size": "5.0 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q5_K_S.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q6_K",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q6_K.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-Q8_0",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-Q8_0.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-UD-IQ1_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-UD-IQ1_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-UD-IQ2_M.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-UD-IQ2_XXS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-UD-IQ3_XXS.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-UD-Q2_K_XL.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-UD-Q3_K_XL.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-UD-Q4_K_XL.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-UD-Q5_K_XL.gguf",
        "file_size": "5.0 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-UD-Q6_K_XL.gguf",
        "file_size": "6.2 GB"
      },
      {
        "model_id": "Falcon-H1-7B-Instruct-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/Falcon-H1-7B-Instruct-UD-Q8_K_XL.gguf",
        "file_size": "8.8 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Falcon-H1-7B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Fin-R1-GGUF",
    "developer": "Mungert",
    "downloads": 1795,
    "createdAt": "2025-03-21T23:17:12.000Z",
    "num_quants": 40,
    "quants": [
      {
        "model_id": "Fin-R1-bf16-q4_k",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-bf16-q4_k.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Fin-R1-bf16-q6_k",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-bf16-q6_k.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "Fin-R1-bf16-q8_0",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-bf16-q8_0.gguf",
        "file_size": "8.5 GB"
      },
      {
        "model_id": "Fin-R1-bf16",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-bf16.gguf",
        "file_size": "14.2 GB"
      },
      {
        "model_id": "Fin-R1-f16-q4_k",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-f16-q4_k.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Fin-R1-f16-q6_k",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-f16-q6_k.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "Fin-R1-f16-q8_0",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-f16-q8_0.gguf",
        "file_size": "8.5 GB"
      },
      {
        "model_id": "Fin-R1-f16",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-f16.gguf",
        "file_size": "14.2 GB"
      },
      {
        "model_id": "Fin-R1-iq2_m",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-iq2_m.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Fin-R1-iq2_s",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-iq2_s.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Fin-R1-iq2_xs",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-iq2_xs.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Fin-R1-iq2_xxs",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-iq2_xxs.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Fin-R1-iq3_m",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-iq3_m.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Fin-R1-iq3_s",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-iq3_s.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Fin-R1-iq3_xs",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-iq3_xs.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Fin-R1-iq3_xxs",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-iq3_xxs.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Fin-R1-iq4_nl",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-iq4_nl.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Fin-R1-iq4_xs",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-iq4_xs.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Fin-R1-q2_k_l",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q2_k_l.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Fin-R1-q2_k_s",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q2_k_s.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Fin-R1-q3_k_l",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q3_k_l.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Fin-R1-q3_k_m",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q3_k_m.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Fin-R1-q3_k_s",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q3_k_s.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Fin-R1-q4_0",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q4_0.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Fin-R1-q4_0_l",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q4_0_l.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Fin-R1-q4_1",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q4_1.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Fin-R1-q4_1_l",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q4_1_l.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Fin-R1-q4_k_l",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q4_k_l.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Fin-R1-q4_k_m",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q4_k_m.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Fin-R1-q4_k_s",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q4_k_s.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "Fin-R1-q5_0",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q5_0.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Fin-R1-q5_0_l",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q5_0_l.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Fin-R1-q5_1",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q5_1.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Fin-R1-q5_1_l",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q5_1_l.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "Fin-R1-q5_k_l",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q5_k_l.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "Fin-R1-q5_k_m",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q5_k_m.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "Fin-R1-q5_k_s",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q5_k_s.gguf",
        "file_size": "5.0 GB"
      },
      {
        "model_id": "Fin-R1-q6_k_l",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q6_k_l.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Fin-R1-q6_k_m",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q6_k_m.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "Fin-R1-q8_0",
        "path": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/Fin-R1-q8_0.gguf",
        "file_size": "7.5 GB"
      }
    ],
    "readme": "https://huggingface.co/Mungert/Fin-R1-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "gemma-2-2b-it-GGUF",
    "developer": "bartowski",
    "downloads": 119886,
    "createdAt": "2024-07-31T16:45:13.000Z",
    "num_quants": 11,
    "quants": [
      {
        "model_id": "gemma-2-2b-it-IQ3_M",
        "path": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-IQ3_M.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "gemma-2-2b-it-IQ4_XS",
        "path": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-IQ4_XS.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "gemma-2-2b-it-Q3_K_L",
        "path": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q3_K_L.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "gemma-2-2b-it-Q4_K_M",
        "path": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q4_K_M.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "gemma-2-2b-it-Q4_K_S",
        "path": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q4_K_S.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "gemma-2-2b-it-Q5_K_M",
        "path": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q5_K_M.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "gemma-2-2b-it-Q5_K_S",
        "path": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q5_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "gemma-2-2b-it-Q6_K",
        "path": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q6_K.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "gemma-2-2b-it-Q6_K_L",
        "path": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q6_K_L.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "gemma-2-2b-it-Q8_0",
        "path": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q8_0.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "gemma-2-2b-it-f32",
        "path": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-f32.gguf",
        "file_size": "9.7 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Gemma-2-2b-it model by bartowski, optimized for various inference speeds and resource constraints using llama.cpp imatrix quantization.",
    "tools": false
  },
  {
    "model_name": "gemma-2b",
    "developer": "google",
    "downloads": 213563,
    "createdAt": "2024-02-08T08:11:26.000Z",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "gemma-2b",
        "path": "https://huggingface.co/google/gemma-2b/resolve/main/gemma-2b.gguf",
        "file_size": "9.3 GB"
      }
    ],
    "readme": "https://huggingface.co/google/gemma-2b/resolve/main/README.md",
    "description": "The Gemma 2B model is a lightweight, open-source text-to-text large language model from Google, trained on diverse data including web text, code, and mathematics, with support for fine-tuning, multi-GPU training, and various precision optimizations, and evaluated on multiple benchmarks for performance and"
  },
  {
    "model_name": "gemma-2b-it",
    "developer": "google",
    "downloads": 137676,
    "createdAt": "2024-02-08T13:23:59.000Z",
    "num_quants": 1,
    "quants": [
      {
        "model_id": "gemma-2b-it",
        "path": "https://huggingface.co/google/gemma-2b-it/resolve/main/gemma-2b-it.gguf",
        "file_size": "9.3 GB"
      }
    ],
    "readme": "https://huggingface.co/google/gemma-2b-it/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "gemma-3-12b-it-GGUF",
    "developer": "unsloth",
    "downloads": 54013,
    "createdAt": "2025-03-12T10:34:12.000Z",
    "tools": false,
    "num_quants": 29,
    "quants": [
      {
        "model_id": "gemma-3-12b-it-BF16",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-BF16.gguf",
        "file_size": "21.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-IQ4_NL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-IQ4_NL.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-IQ4_XS",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-IQ4_XS.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q2_K",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q2_K.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q2_K_L",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q2_K_L.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q3_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q3_K_M.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q3_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q3_K_S.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q4_0",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q4_0.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q4_1",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q4_1.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q4_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q4_K_M.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q4_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q4_K_S.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q5_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q5_K_M.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q5_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q5_K_S.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q6_K",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q6_K.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "gemma-3-12b-it-Q8_0",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-Q8_0.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-IQ1_M.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-IQ1_S.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-IQ2_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-IQ2_XXS.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-IQ3_XXS.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-Q2_K_XL.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-Q3_K_XL.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-Q4_K_XL.gguf",
        "file_size": "6.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-Q5_K_XL.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-Q6_K_XL.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "gemma-3-12b-it-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/gemma-3-12b-it-UD-Q8_K_XL.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "814.6 MB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "814.6 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/resolve/main/README.md",
    "description": "This is a fine-tuned version of the Google Gemma 3 12B model, optimized for performance and memory efficiency with support for GGUF, 4-bit, and 16-bit formats, and available on Hugging Face."
  },
  {
    "model_name": "gemma-3-12b-it-qat-GGUF",
    "developer": "unsloth",
    "downloads": 10669,
    "createdAt": "2025-04-21T03:55:27.000Z",
    "num_quants": 29,
    "quants": [
      {
        "model_id": "gemma-3-12b-it-qat-BF16",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-BF16.gguf",
        "file_size": "21.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-IQ4_NL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-IQ4_NL.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-IQ4_XS",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-IQ4_XS.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-Q2_K",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-Q2_K.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-Q2_K_L",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-Q2_K_L.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-Q3_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-Q3_K_M.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-Q3_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-Q3_K_S.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-Q4_0",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-Q4_0.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-Q4_1",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-Q4_1.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-Q4_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-Q4_K_M.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-Q4_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-Q4_K_S.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-Q5_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-Q5_K_M.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-Q5_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-Q5_K_S.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-Q6_K",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-Q6_K.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-Q8_0",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-Q8_0.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-UD-IQ1_M.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-UD-IQ1_S.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-UD-IQ2_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-UD-IQ2_XXS.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-UD-IQ3_XXS.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-UD-Q2_K_XL.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-UD-Q3_K_XL.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-UD-Q4_K_XL.gguf",
        "file_size": "6.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-UD-Q5_K_XL.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-UD-Q6_K_XL.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "gemma-3-12b-it-qat-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/gemma-3-12b-it-qat-UD-Q8_K_XL.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "814.6 MB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "814.6 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/gemma-3-12b-it-qat-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "gemma-3-12b-it-qat-q4_0-gguf",
    "developer": "google",
    "downloads": 88892,
    "createdAt": "2025-03-12T12:32:41.000Z",
    "num_quants": 2,
    "quants": [
      {
        "model_id": "gemma-3-12b-it-q4_0",
        "path": "https://huggingface.co/google/gemma-3-12b-it-qat-q4_0-gguf/resolve/main/gemma-3-12b-it-q4_0.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "mmproj-model-f16-12B",
        "path": "https://huggingface.co/google/gemma-3-12b-it-qat-q4_0-gguf/resolve/main/mmproj-model-f16-12B.gguf",
        "file_size": "814.6 MB"
      }
    ],
    "readme": "https://huggingface.co/google/gemma-3-12b-it-qat-q4_0-gguf/resolve/main/README.md",
    "description": "The Gemma 3 model is a lightweight, open-source, instruction-tuned, multimodal model with 128K context window and multilingual support, trained on diverse data including text, code, math, and images, and evaluated on various benchmarks for reasoning, STEM, code, and",
    "tools": false
  },
  {
    "model_name": "gemma-3-1b-it-GGUF",
    "developer": "unsloth",
    "downloads": 27320,
    "createdAt": "2025-03-12T10:57:04.000Z",
    "num_quants": 26,
    "quants": [
      {
        "model_id": "gemma-3-1b-it-BF16",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-BF16.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "gemma-3-1b-it-IQ4_NL",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-IQ4_NL.gguf",
        "file_size": "688.4 MB"
      },
      {
        "model_id": "gemma-3-1b-it-IQ4_XS",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-IQ4_XS.gguf",
        "file_size": "681.3 MB"
      },
      {
        "model_id": "gemma-3-1b-it-Q2_K",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q2_K.gguf",
        "file_size": "657.9 MB"
      },
      {
        "model_id": "gemma-3-1b-it-Q2_K_L",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q2_K_L.gguf",
        "file_size": "657.9 MB"
      },
      {
        "model_id": "gemma-3-1b-it-Q3_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q3_K_M.gguf",
        "file_size": "688.9 MB"
      },
      {
        "model_id": "gemma-3-1b-it-Q3_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q3_K_S.gguf",
        "file_size": "656.9 MB"
      },
      {
        "model_id": "gemma-3-1b-it-Q4_0",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q4_0.gguf",
        "file_size": "688.5 MB"
      },
      {
        "model_id": "gemma-3-1b-it-Q4_1",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q4_1.gguf",
        "file_size": "728.6 MB"
      },
      {
        "model_id": "gemma-3-1b-it-Q4_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q4_K_M.gguf",
        "file_size": "768.7 MB"
      },
      {
        "model_id": "gemma-3-1b-it-Q4_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q4_K_S.gguf",
        "file_size": "744.8 MB"
      },
      {
        "model_id": "gemma-3-1b-it-Q5_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q5_K_M.gguf",
        "file_size": "811.9 MB"
      },
      {
        "model_id": "gemma-3-1b-it-Q5_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q5_K_S.gguf",
        "file_size": "797.7 MB"
      },
      {
        "model_id": "gemma-3-1b-it-Q6_K",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q6_K.gguf",
        "file_size": "964.9 MB"
      },
      {
        "model_id": "gemma-3-1b-it-Q8_0",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q8_0.gguf",
        "file_size": "1019.8 MB"
      },
      {
        "model_id": "gemma-3-1b-it-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-UD-IQ1_M.gguf",
        "file_size": "533.9 MB"
      },
      {
        "model_id": "gemma-3-1b-it-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-UD-IQ1_S.gguf",
        "file_size": "531.2 MB"
      },
      {
        "model_id": "gemma-3-1b-it-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-UD-IQ2_M.gguf",
        "file_size": "551.2 MB"
      },
      {
        "model_id": "gemma-3-1b-it-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-UD-IQ2_XXS.gguf",
        "file_size": "538.3 MB"
      },
      {
        "model_id": "gemma-3-1b-it-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-UD-IQ3_XXS.gguf",
        "file_size": "564.2 MB"
      },
      {
        "model_id": "gemma-3-1b-it-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-UD-Q2_K_XL.gguf",
        "file_size": "661.7 MB"
      },
      {
        "model_id": "gemma-3-1b-it-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-UD-Q3_K_XL.gguf",
        "file_size": "693.2 MB"
      },
      {
        "model_id": "gemma-3-1b-it-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-UD-Q4_K_XL.gguf",
        "file_size": "769.6 MB"
      },
      {
        "model_id": "gemma-3-1b-it-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-UD-Q5_K_XL.gguf",
        "file_size": "833.8 MB"
      },
      {
        "model_id": "gemma-3-1b-it-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-UD-Q6_K_XL.gguf",
        "file_size": "983.3 MB"
      },
      {
        "model_id": "gemma-3-1b-it-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-UD-Q8_K_XL.gguf",
        "file_size": "1.4 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/gemma-3-1b-it-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "gemma-3-1b-it-qat-q4_0-gguf",
    "developer": "google",
    "downloads": 2593,
    "createdAt": "2025-03-10T22:42:41.000Z",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "gemma-3-1b-it-q4_0",
        "path": "https://huggingface.co/google/gemma-3-1b-it-qat-q4_0-gguf/resolve/main/gemma-3-1b-it-q4_0.gguf",
        "file_size": "957.1 MB"
      }
    ],
    "readme": "https://huggingface.co/google/gemma-3-1b-it-qat-q4_0-gguf/resolve/main/README.md",
    "description": "The Gemma 3 model is a lightweight, open-source, instruction-tuned multilingual vision-language model with a 128K context window, trained on diverse data including text, code, math, and images, and available in GGUF format with QAT quantization for efficient deployment."
  },
  {
    "model_name": "gemma-3-27b-it-abliterated-GGUF",
    "developer": "mlabonne",
    "downloads": 17519,
    "createdAt": "2025-03-17T20:35:16.000Z",
    "num_quants": 7,
    "quants": [
      {
        "model_id": "gemma-3-27b-it-abliterated.q2_k",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/gemma-3-27b-it-abliterated.q2_k.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated.q3_k_m",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/gemma-3-27b-it-abliterated.q3_k_m.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated.q4_k_m",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/gemma-3-27b-it-abliterated.q4_k_m.gguf",
        "file_size": "15.4 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated.q5_k_m",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/gemma-3-27b-it-abliterated.q5_k_m.gguf",
        "file_size": "17.9 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated.q6_k",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/gemma-3-27b-it-abliterated.q6_k.gguf",
        "file_size": "20.6 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated.q8_0",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/gemma-3-27b-it-abliterated.q8_0.gguf",
        "file_size": "26.7 GB"
      },
      {
        "model_id": "mmproj-mlabonne_gemma-3-27b-it-abliterated-f16",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/mmproj-mlabonne_gemma-3-27b-it-abliterated-f16.gguf",
        "file_size": "818.0 MB"
      }
    ],
    "readme": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-GGUF/resolve/main/README.md",
    "description": "This is an uncensored Gemma 3 27B IT model created using a layerwise abliteration technique to achieve high acceptance rates while preserving model capabilities.",
    "tools": false
  },
  {
    "model_name": "gemma-3-27b-it-abliterated-v2-GGUF",
    "developer": "mlabonne",
    "downloads": 6613,
    "createdAt": "2025-05-28T22:03:00.000Z",
    "num_quants": 6,
    "quants": [
      {
        "model_id": "gemma-3-27b-it-abliterated-v2.q2_k",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-v2-GGUF/resolve/main/gemma-3-27b-it-abliterated-v2.q2_k.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated-v2.q3_k_m",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-v2-GGUF/resolve/main/gemma-3-27b-it-abliterated-v2.q3_k_m.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated-v2.q4_k_m",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-v2-GGUF/resolve/main/gemma-3-27b-it-abliterated-v2.q4_k_m.gguf",
        "file_size": "15.4 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated-v2.q5_k_m",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-v2-GGUF/resolve/main/gemma-3-27b-it-abliterated-v2.q5_k_m.gguf",
        "file_size": "17.9 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated-v2.q6_k",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-v2-GGUF/resolve/main/gemma-3-27b-it-abliterated-v2.q6_k.gguf",
        "file_size": "20.6 GB"
      },
      {
        "model_id": "gemma-3-27b-it-abliterated-v2.q8_0",
        "path": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-v2-GGUF/resolve/main/gemma-3-27b-it-abliterated-v2.q8_0.gguf",
        "file_size": "26.7 GB"
      }
    ],
    "readme": "https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated-v2-GGUF/resolve/main/README.md",
    "description": "This is an uncensored version of the Google Gemma-3-27B IT model, created using an advanced abliteration technique to enhance refusal accuracy while maintaining coherent outputs.",
    "tools": false
  },
  {
    "model_name": "gemma-3-27b-it-qat-q4_0-gguf",
    "developer": "google",
    "downloads": 7189,
    "createdAt": "2025-03-20T22:44:27.000Z",
    "tools": false,
    "num_quants": 2,
    "quants": [
      {
        "model_id": "gemma-3-27b-it-q4_0",
        "path": "https://huggingface.co/google/gemma-3-27b-it-qat-q4_0-gguf/resolve/main/gemma-3-27b-it-q4_0.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "mmproj-model-f16-27B",
        "path": "https://huggingface.co/google/gemma-3-27b-it-qat-q4_0-gguf/resolve/main/mmproj-model-f16-27B.gguf",
        "file_size": "818.0 MB"
      }
    ],
    "readme": "https://huggingface.co/google/gemma-3-27b-it-qat-q4_0-gguf/resolve/main/README.md",
    "description": "The Gemma 3 model is a lightweight, open-source, multimodal AI model from Google, capable of handling text and image inputs to generate text outputs, trained on diverse data including text, code, math, and images, with performance metrics across various benchmarks and languages, and available in multiple sizes"
  },
  {
    "model_name": "gemma-3-4b-it-GGUF",
    "developer": "unsloth",
    "downloads": 32176,
    "createdAt": "2025-03-12T09:04:23.000Z",
    "num_quants": 29,
    "quants": [
      {
        "model_id": "gemma-3-4b-it-BF16",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-BF16.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "gemma-3-4b-it-IQ4_NL",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-IQ4_NL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "gemma-3-4b-it-IQ4_XS",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-IQ4_XS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q2_K",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q2_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q2_K_L",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q2_K_L.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q3_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q3_K_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q3_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q4_0",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q4_1",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q4_1.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q4_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q4_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q5_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q5_K_M.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q5_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q6_K",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q6_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q8_0",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q8_0.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-IQ1_M.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-IQ1_S.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-IQ2_M.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-IQ2_XXS.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-IQ3_XXS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-Q2_K_XL.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-Q3_K_XL.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-Q4_K_XL.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-Q5_K_XL.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-Q6_K_XL.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "gemma-3-4b-it-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-Q8_K_XL.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "811.8 MB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "811.8 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "gemma-3-4b-it-GGUF",
    "developer": "ggml-org",
    "downloads": 21434,
    "createdAt": "2025-03-12T06:17:39.000Z",
    "num_quants": 4,
    "quants": [
      {
        "model_id": "gemma-3-4b-it-Q4_K_M",
        "path": "https://huggingface.co/ggml-org/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "gemma-3-4b-it-Q8_0",
        "path": "https://huggingface.co/ggml-org/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q8_0.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "gemma-3-4b-it-f16",
        "path": "https://huggingface.co/ggml-org/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-f16.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "mmproj-model-f16",
        "path": "https://huggingface.co/ggml-org/gemma-3-4b-it-GGUF/resolve/main/mmproj-model-f16.gguf",
        "file_size": "811.8 MB"
      }
    ],
    "readme": "https://huggingface.co/ggml-org/gemma-3-4b-it-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "gemma-3-4b-it-qat-q4_0-gguf",
    "developer": "google",
    "downloads": 7299,
    "createdAt": "2025-03-12T20:43:28.000Z",
    "num_quants": 2,
    "quants": [
      {
        "model_id": "gemma-3-4b-it-q4_0",
        "path": "https://huggingface.co/google/gemma-3-4b-it-qat-q4_0-gguf/resolve/main/gemma-3-4b-it-q4_0.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "mmproj-model-f16-4B",
        "path": "https://huggingface.co/google/gemma-3-4b-it-qat-q4_0-gguf/resolve/main/mmproj-model-f16-4B.gguf",
        "file_size": "811.8 MB"
      }
    ],
    "readme": "https://huggingface.co/google/gemma-3-4b-it-qat-q4_0-gguf/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "gemma-3n-E2B-it-GGUF",
    "developer": "unsloth",
    "downloads": 118617,
    "createdAt": "2025-06-26T12:24:52.000Z",
    "tools": false,
    "num_quants": 24,
    "quants": [
      {
        "model_id": "gemma-3n-E2B-it-F16",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-F16.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-IQ4_NL",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-IQ4_NL.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-IQ4_XS",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-IQ4_XS.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-Q2_K",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-Q2_K.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-Q2_K_L",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-Q2_K_L.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-Q3_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-Q3_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-Q3_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-Q3_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-Q4_0",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-Q4_0.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-Q4_1",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-Q4_1.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-Q4_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-Q4_K_M.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-Q4_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-Q4_K_S.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-Q5_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-Q5_K_M.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-Q5_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-Q5_K_S.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-Q6_K",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-Q6_K.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-Q8_0",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-Q8_0.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-UD-IQ2_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-UD-IQ2_XXS.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-UD-IQ3_XXS.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-UD-Q2_K_XL.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-UD-Q3_K_XL.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-UD-Q4_K_XL.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-UD-Q5_K_XL.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-UD-Q6_K_XL.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-UD-Q8_K_XL.gguf",
        "file_size": "7.0 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF/resolve/main/README.md",
    "description": "The Gemma 3n model is a lightweight, efficient, and open-source multilingual image-text-to-text model from Google, optimized for low-resource devices with support for text, image, video, and audio inputs, and capable of generating text outputs with instruction-tuned variants available for fine-tuning"
  },
  {
    "model_name": "gemma-3n-E2B-it-GGUF",
    "developer": "ggml-org",
    "downloads": 3702,
    "createdAt": "2025-06-26T10:09:32.000Z",
    "num_quants": 2,
    "quants": [
      {
        "model_id": "gemma-3n-E2B-it-Q8_0",
        "path": "https://huggingface.co/ggml-org/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-Q8_0.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-f16",
        "path": "https://huggingface.co/ggml-org/gemma-3n-E2B-it-GGUF/resolve/main/gemma-3n-E2B-it-f16.gguf",
        "file_size": "8.3 GB"
      }
    ],
    "readme": "https://huggingface.co/ggml-org/gemma-3n-E2B-it-GGUF/resolve/main/README.md",
    "description": "This GGUF version of the Gemma 3n model is available on Hugging Face and does not include multimodal support.",
    "tools": false
  },
  {
    "model_name": "gemma-3n-E2B-it-text-GGUF",
    "developer": "lmstudio-community",
    "downloads": 4496,
    "createdAt": "2025-06-26T15:16:13.000Z",
    "num_quants": 3,
    "quants": [
      {
        "model_id": "gemma-3n-E2B-it-Q4_K_M",
        "path": "https://huggingface.co/lmstudio-community/gemma-3n-E2B-it-text-GGUF/resolve/main/gemma-3n-E2B-it-Q4_K_M.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-Q6_K",
        "path": "https://huggingface.co/lmstudio-community/gemma-3n-E2B-it-text-GGUF/resolve/main/gemma-3n-E2B-it-Q6_K.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "gemma-3n-E2B-it-Q8_0",
        "path": "https://huggingface.co/lmstudio-community/gemma-3n-E2B-it-text-GGUF/resolve/main/gemma-3n-E2B-it-Q8_0.gguf",
        "file_size": "4.5 GB"
      }
    ],
    "readme": "https://huggingface.co/lmstudio-community/gemma-3n-E2B-it-text-GGUF/resolve/main/README.md",
    "description": "This GGUF quantized version of the Gemma-3n-E2B-it model by Google is provided by the LM Studio team using llama.cpp for efficient deployment.",
    "tools": false
  },
  {
    "model_name": "gemma-3n-E4B-it-GGUF",
    "developer": "unsloth",
    "downloads": 220462,
    "createdAt": "2025-06-26T12:24:35.000Z",
    "tools": false,
    "num_quants": 24,
    "quants": [
      {
        "model_id": "gemma-3n-E4B-it-F16",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-F16.gguf",
        "file_size": "12.8 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-IQ4_NL",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-IQ4_NL.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-IQ4_XS",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-IQ4_XS.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-Q2_K",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-Q2_K_L",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-Q2_K_L.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-Q3_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-Q3_K_M.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-Q3_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-Q3_K_S.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-Q4_0",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-Q4_0.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-Q4_1",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-Q4_1.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-Q4_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-Q4_K_M.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-Q4_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-Q4_K_S.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-Q5_K_M",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-Q5_K_M.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-Q5_K_S",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-Q5_K_S.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-Q6_K",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-Q6_K.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-Q8_0",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-Q8_0.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-UD-IQ2_M.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-UD-IQ2_XXS.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-UD-IQ3_XXS.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-UD-Q2_K_XL.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-UD-Q3_K_XL.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-UD-Q4_K_XL.gguf",
        "file_size": "5.0 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-UD-Q5_K_XL.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-UD-Q6_K_XL.gguf",
        "file_size": "6.2 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-UD-Q8_K_XL.gguf",
        "file_size": "9.9 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF/resolve/main/README.md",
    "description": "The Gemma 3n model is a lightweight, efficient, and open-source multilingual image-text-to-text model from Google, optimized for low-resource devices with support for text, image, video, and audio inputs, and capable of generating text outputs with high performance and accuracy, available on Hugging"
  },
  {
    "model_name": "gemma-3n-E4B-it-GGUF",
    "developer": "ggml-org",
    "downloads": 4787,
    "createdAt": "2025-06-26T09:59:16.000Z",
    "num_quants": 2,
    "quants": [
      {
        "model_id": "gemma-3n-E4B-it-Q8_0",
        "path": "https://huggingface.co/ggml-org/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-Q8_0.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-f16",
        "path": "https://huggingface.co/ggml-org/gemma-3n-E4B-it-GGUF/resolve/main/gemma-3n-E4B-it-f16.gguf",
        "file_size": "12.8 GB"
      }
    ],
    "readme": "https://huggingface.co/ggml-org/gemma-3n-E4B-it-GGUF/resolve/main/README.md",
    "description": "This GGUF version of the Gemma 3n model is available on Hugging Face and does not include multimodal support, developed by Google DeepMind.",
    "tools": false
  },
  {
    "model_name": "gemma-3n-E4B-it-text-GGUF",
    "developer": "lmstudio-community",
    "downloads": 47100,
    "createdAt": "2025-06-26T15:10:43.000Z",
    "num_quants": 3,
    "quants": [
      {
        "model_id": "gemma-3n-E4B-it-Q4_K_M",
        "path": "https://huggingface.co/lmstudio-community/gemma-3n-E4B-it-text-GGUF/resolve/main/gemma-3n-E4B-it-Q4_K_M.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-Q6_K",
        "path": "https://huggingface.co/lmstudio-community/gemma-3n-E4B-it-text-GGUF/resolve/main/gemma-3n-E4B-it-Q6_K.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "gemma-3n-E4B-it-Q8_0",
        "path": "https://huggingface.co/lmstudio-community/gemma-3n-E4B-it-text-GGUF/resolve/main/gemma-3n-E4B-it-Q8_0.gguf",
        "file_size": "6.8 GB"
      }
    ],
    "readme": "https://huggingface.co/lmstudio-community/gemma-3n-E4B-it-text-GGUF/resolve/main/README.md",
    "description": "This GGUF quantized version of the Gemma-3n-E4B-it model by Google is provided by the LM Studio team using llama.cpp for efficient deployment.",
    "tools": false
  },
  {
    "model_name": "gemma-7b",
    "developer": "google",
    "downloads": 70906,
    "createdAt": "2024-02-08T22:36:43.000Z",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "gemma-7b",
        "path": "https://huggingface.co/google/gemma-7b/resolve/main/gemma-7b.gguf",
        "file_size": "31.8 GB"
      }
    ],
    "readme": "https://huggingface.co/google/gemma-7b/resolve/main/README.md",
    "description": "The Gemma 7B model is a lightweight, open-source text-to-text large language model from Google, trained on diverse data including web text, code, and mathematics, with strong performance on benchmark tasks and ethical safety considerations."
  },
  {
    "model_name": "gemma-7b-it",
    "developer": "google",
    "downloads": 73310,
    "createdAt": "2024-02-13T01:07:30.000Z",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "gemma-7b-it",
        "path": "https://huggingface.co/google/gemma-7b-it/resolve/main/gemma-7b-it.gguf",
        "file_size": "31.8 GB"
      }
    ],
    "readme": "https://huggingface.co/google/gemma-7b-it/resolve/main/README.md",
    "description": "The Gemma 7B instruct model is a lightweight, open-source text-to-text large language model from Google, trained on diverse data including web text, code, and math, and suitable for various text generation tasks with support for fine-tuning, GPU acceleration, and ethical safety measures."
  },
  {
    "model_name": "Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF",
    "developer": "DavidAU",
    "downloads": 16988,
    "createdAt": "2024-10-25T00:19:23.000Z",
    "tools": false,
    "num_quants": 22,
    "quants": [
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-IQ4_XS",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-IQ4_XS.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q2_k",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q2_k.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q3_k_l",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q3_k_l.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q3_k_m",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q3_k_m.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q3_k_s",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q3_k_s.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q4_0_4_4",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q4_0_4_4.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q4_0_4_8",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q4_0_4_8.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q4_0_8_8",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q4_0_8_8.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q4_k_m",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q4_k_m.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q4_k_s",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q4_k_s.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q5_k_s",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q5_k_s.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q6_k",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q6_k.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-Q8_0.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-max-IQ4_XS",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-max-IQ4_XS.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-max-cpu-IQ4_XS",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-max-cpu-IQ4_XS.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-D_AU-q5_k_m",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-D_AU-q5_k_m.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-max-D_AU-Q2_k",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-max-D_AU-Q2_k.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-max-D_AU-Q6_k",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-max-D_AU-Q6_k.gguf",
        "file_size": "8.7 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-max-D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-max-D_AU-Q8_0.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-max-cpu-D_AU-Q2_k",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-max-cpu-D_AU-Q2_k.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-max-cpu-D_AU-Q6_k",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-max-cpu-D_AU-Q6_k.gguf",
        "file_size": "8.7 GB"
      },
      {
        "model_id": "Gemma-The-Writer-N-Restless-Quill-10B-max-cpu-D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/Gemma-The-Writer-N-Restless-Quill-10B-max-cpu-D_AU-Q8_0.gguf",
        "file_size": "10.7 GB"
      }
    ],
    "readme": "https://huggingface.co/DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored-GGUF/resolve/main/README.md",
    "description": "This is a highly advanced, uncensored Gemma2 model designed for creative writing, particularly fiction and storytelling, combining four top storytelling models with additional modifications for vivid, detailed, and emotionally engaging prose across various genres, including science fiction, horror, and romance, with options for different quantization levels and"
  },
  {
    "model_name": "GLM-4-32B-0414-GGUF",
    "developer": "unsloth",
    "downloads": 17350,
    "createdAt": "2025-04-25T09:54:10.000Z",
    "num_quants": 27,
    "quants": [
      {
        "model_id": "BF16/GLM-4-32B-0414-BF16-00001-of-00002",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/BF16/GLM-4-32B-0414-BF16-00001-of-00002.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "BF16/GLM-4-32B-0414-BF16-00002-of-00002",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/BF16/GLM-4-32B-0414-BF16-00002-of-00002.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-IQ4_NL",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-IQ4_NL.gguf",
        "file_size": "17.3 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-IQ4_XS",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-IQ4_XS.gguf",
        "file_size": "16.4 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-Q2_K",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-Q2_K.gguf",
        "file_size": "11.4 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-Q2_K_L",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-Q2_K_L.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-Q3_K_M",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-Q3_K_M.gguf",
        "file_size": "14.8 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-Q3_K_S",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-Q3_K_S.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-Q4_0",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-Q4_0.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-Q4_1",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-Q4_1.gguf",
        "file_size": "19.1 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-Q4_K_M",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-Q4_K_M.gguf",
        "file_size": "18.3 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-Q4_K_S",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-Q4_K_S.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-Q5_K_M",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-Q5_K_M.gguf",
        "file_size": "21.5 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-Q5_K_S",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-Q5_K_S.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-Q6_K",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-Q6_K.gguf",
        "file_size": "24.9 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-Q8_0",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-Q8_0.gguf",
        "file_size": "32.2 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-UD-IQ1_M.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-UD-IQ1_S.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-UD-IQ2_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-UD-IQ2_XXS.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-UD-IQ3_XXS.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-UD-Q2_K_XL.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-UD-Q3_K_XL.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-UD-Q4_K_XL.gguf",
        "file_size": "18.6 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-UD-Q5_K_XL.gguf",
        "file_size": "21.5 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-UD-Q6_K_XL.gguf",
        "file_size": "26.8 GB"
      },
      {
        "model_id": "GLM-4-32B-0414-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/GLM-4-32B-0414-UD-Q8_K_XL.gguf",
        "file_size": "36.8 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "GLM-4-9B-0414-GGUF",
    "developer": "unsloth",
    "downloads": 7877,
    "createdAt": "2025-04-30T18:36:06.000Z",
    "num_quants": 26,
    "quants": [
      {
        "model_id": "GLM-4-9B-0414-BF16",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-BF16.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-IQ4_NL",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-IQ4_NL.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-IQ4_XS",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-IQ4_XS.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-Q2_K",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-Q2_K.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-Q2_K_L",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-Q2_K_L.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-Q3_K_M",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-Q3_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-Q3_K_S",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-Q3_K_S.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-Q4_0",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-Q4_0.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-Q4_1",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-Q4_1.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-Q4_K_M",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-Q4_K_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-Q4_K_S",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-Q4_K_S.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-Q5_K_M",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-Q5_K_M.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-Q5_K_S",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-Q5_K_S.gguf",
        "file_size": "6.2 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-Q6_K",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-Q6_K.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-Q8_0",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-Q8_0.gguf",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-UD-IQ1_M.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-UD-IQ1_S.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-UD-IQ2_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-UD-IQ2_XXS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-UD-IQ3_XXS.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-UD-Q2_K_XL.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-UD-Q3_K_XL.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-UD-Q4_K_XL.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-UD-Q5_K_XL.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-UD-Q6_K_XL.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "GLM-4-9B-0414-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/GLM-4-9B-0414-UD-Q8_K_XL.gguf",
        "file_size": "11.2 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/GLM-4-9B-0414-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "google_gemma-3n-E2B-it-GGUF",
    "developer": "bartowski",
    "downloads": 4226,
    "createdAt": "2025-06-26T19:50:06.000Z",
    "num_quants": 21,
    "quants": [
      {
        "model_id": "google_gemma-3n-E2B-it-IQ3_M",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-IQ3_M.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-IQ3_XS",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-IQ3_XS.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-IQ4_NL",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-IQ4_NL.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-IQ4_XS",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-IQ4_XS.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q2_K",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q2_K.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q2_K_L",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q2_K_L.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q3_K_L",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q3_K_L.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q3_K_M",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q3_K_M.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q3_K_S",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q3_K_S.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q3_K_XL.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q4_0",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q4_0.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q4_1",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q4_1.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q4_K_L",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q4_K_L.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q4_K_M",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q4_K_M.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q4_K_S",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q4_K_S.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q5_K_L",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q5_K_L.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q5_K_M",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q5_K_M.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q5_K_S",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q5_K_S.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q6_K",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q6_K.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q6_K_L",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q6_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "google_gemma-3n-E2B-it-Q8_0",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/google_gemma-3n-E2B-it-Q8_0.gguf",
        "file_size": "4.5 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Google Gemma-3n-E2B-it model using llama.cpp, offering various quantization types for different performance and quality trade-offs.",
    "tools": false
  },
  {
    "model_name": "google_gemma-3n-E4B-it-GGUF",
    "developer": "bartowski",
    "downloads": 12158,
    "createdAt": "2025-06-26T19:50:49.000Z",
    "num_quants": 21,
    "quants": [
      {
        "model_id": "google_gemma-3n-E4B-it-IQ3_M",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-IQ3_M.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-IQ3_XS",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-IQ3_XS.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-IQ4_NL",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-IQ4_NL.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-IQ4_XS",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-IQ4_XS.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q2_K",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q2_K.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q2_K_L",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q2_K_L.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q3_K_L",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q3_K_L.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q3_K_M",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q3_K_M.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q3_K_S",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q3_K_S.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q3_K_XL.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q4_0",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q4_0.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q4_1",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q4_1.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q4_K_L",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q4_K_L.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q4_K_M",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q4_K_M.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q4_K_S",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q4_K_S.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q5_K_L",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q5_K_L.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q5_K_M",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q5_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q5_K_S",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q5_K_S.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q6_K",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q6_K.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q6_K_L",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q6_K_L.gguf",
        "file_size": "6.0 GB"
      },
      {
        "model_id": "google_gemma-3n-E4B-it-Q8_0",
        "path": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/google_gemma-3n-E4B-it-Q8_0.gguf",
        "file_size": "6.8 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/google_gemma-3n-E4B-it-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Gemma model using llama.cpp's imatrix method, offering various quantization types for different performance and memory trade-offs.",
    "tools": false
  },
  {
    "model_name": "google_medgemma-27b-it-GGUF",
    "developer": "bartowski",
    "downloads": 1341,
    "createdAt": "2025-07-12T15:54:17.000Z",
    "num_quants": 29,
    "quants": [
      {
        "model_id": "google_medgemma-27b-it-IQ2_M",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-IQ2_M.gguf",
        "file_size": "8.8 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-IQ2_S",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-IQ2_S.gguf",
        "file_size": "8.2 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-IQ2_XS",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-IQ2_XS.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-IQ3_M",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-IQ3_M.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-IQ3_XS",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-IQ3_XS.gguf",
        "file_size": "10.8 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-IQ3_XXS.gguf",
        "file_size": "10.0 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-IQ4_NL",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-IQ4_NL.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-IQ4_XS",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-IQ4_XS.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q2_K",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q2_K.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q2_K_L",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q2_K_L.gguf",
        "file_size": "10.1 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q3_K_L",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q3_K_L.gguf",
        "file_size": "13.5 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q3_K_M",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q3_K_M.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q3_K_S",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q3_K_S.gguf",
        "file_size": "11.3 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q3_K_XL.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q4_0",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q4_0.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q4_1",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q4_1.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q4_K_L",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q4_K_L.gguf",
        "file_size": "15.7 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q4_K_M",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q4_K_M.gguf",
        "file_size": "15.4 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q4_K_S",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q4_K_S.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q5_K_L",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q5_K_L.gguf",
        "file_size": "18.3 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q5_K_M",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q5_K_M.gguf",
        "file_size": "17.9 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q5_K_S",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q5_K_S.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q6_K",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q6_K.gguf",
        "file_size": "20.6 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q6_K_L",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q6_K_L.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-Q8_0",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-Q8_0.gguf",
        "file_size": "26.7 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-bf16/google_medgemma-27b-it-bf16-00001-of-00002",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-bf16/google_medgemma-27b-it-bf16-00001-of-00002.gguf",
        "file_size": "37.2 GB"
      },
      {
        "model_id": "google_medgemma-27b-it-bf16/google_medgemma-27b-it-bf16-00002-of-00002",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/google_medgemma-27b-it-bf16/google_medgemma-27b-it-bf16-00002-of-00002.gguf",
        "file_size": "13.1 GB"
      },
      {
        "model_id": "mmproj-google_medgemma-27b-it-bf16",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/mmproj-google_medgemma-27b-it-bf16.gguf",
        "file_size": "818.0 MB"
      },
      {
        "model_id": "mmproj-google_medgemma-27b-it-f16",
        "path": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/mmproj-google_medgemma-27b-it-f16.gguf",
        "file_size": "818.0 MB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/google_medgemma-27b-it-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "google_medgemma-4b-it-GGUF",
    "developer": "bartowski",
    "downloads": 1283,
    "createdAt": "2025-07-12T15:54:02.000Z",
    "num_quants": 25,
    "quants": [
      {
        "model_id": "google_medgemma-4b-it-IQ3_M",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-IQ3_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-IQ3_XS",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-IQ3_XS.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-IQ3_XXS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-IQ4_NL",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-IQ4_NL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-IQ4_XS",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-IQ4_XS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q2_K",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q2_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q2_K_L",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q2_K_L.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q3_K_L",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q3_K_L.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q3_K_M",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q3_K_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q3_K_S",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q3_K_XL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q4_0",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q4_1",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q4_1.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q4_K_L",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q4_K_L.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q4_K_M",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q4_K_S",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q5_K_L",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q5_K_L.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q5_K_M",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q5_K_M.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q5_K_S",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q6_K",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q6_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q6_K_L",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q6_K_L.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-Q8_0",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-Q8_0.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "google_medgemma-4b-it-bf16",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/google_medgemma-4b-it-bf16.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "mmproj-google_medgemma-4b-it-bf16",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/mmproj-google_medgemma-4b-it-bf16.gguf",
        "file_size": "811.8 MB"
      },
      {
        "model_id": "mmproj-google_medgemma-4b-it-f16",
        "path": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/mmproj-google_medgemma-4b-it-f16.gguf",
        "file_size": "811.8 MB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/google_medgemma-4b-it-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "granite-4.0-tiny-preview-GGUF",
    "developer": "Mungert",
    "downloads": 0,
    "createdAt": "2025-07-22T07:07:31.000Z",
    "tools": false,
    "num_quants": 41,
    "quants": [
      {
        "model_id": "granite-4.0-tiny-preview-bf16",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-bf16.gguf",
        "file_size": "12.4 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-bf16_q4_k",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-bf16_q4_k.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-bf16_q6_k",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-bf16_q6_k.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-bf16_q8_0",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-bf16_q8_0.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-f16",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-f16.gguf",
        "file_size": "12.4 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-f16_q4_k",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-f16_q4_k.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-f16_q6_k",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-f16_q6_k.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-f16_q8_0",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-f16_q8_0.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-iq2_m",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-iq2_m.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-iq2_s",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-iq2_s.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-iq2_xs",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-iq2_xs.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-iq3_m",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-iq3_m.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-iq3_s",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-iq3_s.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-iq3_xs",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-iq3_xs.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-iq3_xxs",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-iq3_xxs.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-iq4_nl",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-iq4_nl.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-iq4_xs",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-iq4_xs.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q2_k_l",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q2_k_l.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q2_k_m",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q2_k_m.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q3_k_l",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q3_k_l.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q3_k_m",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q3_k_m.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q3_k_s",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q3_k_s.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q4_0",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q4_0.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q4_0_l",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q4_0_l.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q4_1",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q4_1.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q4_1_l",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q4_1_l.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q4_k_l",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q4_k_l.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q4_k_m",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q4_k_m.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q4_k_s",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q4_k_s.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q5_0",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q5_0.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q5_0_l",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q5_0_l.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q5_1",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q5_1.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q5_1_l",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q5_1_l.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q5_k_l",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q5_k_l.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q5_k_m",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q5_k_m.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q5_k_s",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q5_k_s.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q6_k_l",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q6_k_l.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q6_k_m",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q6_k_m.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-q8_0",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-q8_0.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-tq1_0",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-tq1_0.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "granite-4.0-tiny-preview-tq2_0",
        "path": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/granite-4.0-tiny-preview-tq2_0.gguf",
        "file_size": "1.7 GB"
      }
    ],
    "readme": "https://huggingface.co/Mungert/granite-4.0-tiny-preview-GGUF/resolve/main/README.md",
    "description": "The Granite-4.0-Tiny-Preview model is a 7B parameter hybrid MoE instruct model fine-tuned for instruction-following tasks with support for multiple languages and enhanced reasoning capabilities."
  },
  {
    "model_name": "HuggingFaceTB.SmolLM2-1.7B-Instruct-GGUF",
    "developer": "DevQuasar",
    "downloads": 103,
    "createdAt": "2024-11-01T01:28:38.000Z",
    "tools": false,
    "num_quants": 6,
    "quants": [
      {
        "model_id": "HuggingFaceTB.SmolLM2-1.7B-Instruct.Q2_K",
        "path": "https://huggingface.co/DevQuasar/HuggingFaceTB.SmolLM2-1.7B-Instruct-GGUF/resolve/main/HuggingFaceTB.SmolLM2-1.7B-Instruct.Q2_K.gguf",
        "file_size": "643.3 MB"
      },
      {
        "model_id": "HuggingFaceTB.SmolLM2-1.7B-Instruct.Q3_K_M",
        "path": "https://huggingface.co/DevQuasar/HuggingFaceTB.SmolLM2-1.7B-Instruct-GGUF/resolve/main/HuggingFaceTB.SmolLM2-1.7B-Instruct.Q3_K_M.gguf",
        "file_size": "820.3 MB"
      },
      {
        "model_id": "HuggingFaceTB.SmolLM2-1.7B-Instruct.Q4_K_M",
        "path": "https://huggingface.co/DevQuasar/HuggingFaceTB.SmolLM2-1.7B-Instruct-GGUF/resolve/main/HuggingFaceTB.SmolLM2-1.7B-Instruct.Q4_K_M.gguf",
        "file_size": "1006.7 MB"
      },
      {
        "model_id": "HuggingFaceTB.SmolLM2-1.7B-Instruct.Q5_K_M",
        "path": "https://huggingface.co/DevQuasar/HuggingFaceTB.SmolLM2-1.7B-Instruct-GGUF/resolve/main/HuggingFaceTB.SmolLM2-1.7B-Instruct.Q5_K_M.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "HuggingFaceTB.SmolLM2-1.7B-Instruct.Q6_K",
        "path": "https://huggingface.co/DevQuasar/HuggingFaceTB.SmolLM2-1.7B-Instruct-GGUF/resolve/main/HuggingFaceTB.SmolLM2-1.7B-Instruct.Q6_K.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "HuggingFaceTB.SmolLM2-1.7B-Instruct.Q8_0",
        "path": "https://huggingface.co/DevQuasar/HuggingFaceTB.SmolLM2-1.7B-Instruct-GGUF/resolve/main/HuggingFaceTB.SmolLM2-1.7B-Instruct.Q8_0.gguf",
        "file_size": "1.7 GB"
      }
    ],
    "readme": "https://huggingface.co/DevQuasar/HuggingFaceTB.SmolLM2-1.7B-Instruct-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the SmolLM2-1.7B-Instruct model, optimized for efficient text generation on Hugging Face."
  },
  {
    "model_name": "HuggingFaceTB_SmolLM3-3B-GGUF",
    "developer": "bartowski",
    "downloads": 5125,
    "createdAt": "2025-07-08T16:09:26.000Z",
    "num_quants": 24,
    "quants": [
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-IQ2_M",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-IQ2_M.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-IQ3_M",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-IQ3_M.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-IQ3_XS",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-IQ3_XS.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-IQ3_XXS.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-IQ4_NL",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-IQ4_NL.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-IQ4_XS",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-IQ4_XS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q2_K",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q2_K.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q2_K_L",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q2_K_L.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q3_K_L",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q3_K_L.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q3_K_M",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q3_K_M.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q3_K_S",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q3_K_S.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q3_K_XL.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q4_0",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q4_0.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q4_1",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q4_1.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q4_K_L",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q4_K_L.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q4_K_M",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q4_K_M.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q4_K_S",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q4_K_S.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q5_K_L",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q5_K_L.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q5_K_M",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q5_K_M.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q5_K_S",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q5_K_S.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q6_K",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q6_K.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q6_K_L",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q6_K_L.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-Q8_0",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-Q8_0.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "HuggingFaceTB_SmolLM3-3B-bf16",
        "path": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/HuggingFaceTB_SmolLM3-3B-bf16.gguf",
        "file_size": "5.7 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/HuggingFaceTB_SmolLM3-3B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Huihui-gemma-3n-E4B-it-abliterated-GGUF",
    "developer": "mradermacher",
    "downloads": 4273,
    "createdAt": "2025-07-11T00:48:21.000Z",
    "tools": false,
    "num_quants": 12,
    "quants": [
      {
        "model_id": "Huihui-gemma-3n-E4B-it-abliterated.IQ4_XS",
        "path": "https://huggingface.co/mradermacher/Huihui-gemma-3n-E4B-it-abliterated-GGUF/resolve/main/Huihui-gemma-3n-E4B-it-abliterated.IQ4_XS.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "Huihui-gemma-3n-E4B-it-abliterated.Q2_K",
        "path": "https://huggingface.co/mradermacher/Huihui-gemma-3n-E4B-it-abliterated-GGUF/resolve/main/Huihui-gemma-3n-E4B-it-abliterated.Q2_K.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Huihui-gemma-3n-E4B-it-abliterated.Q3_K_L",
        "path": "https://huggingface.co/mradermacher/Huihui-gemma-3n-E4B-it-abliterated-GGUF/resolve/main/Huihui-gemma-3n-E4B-it-abliterated.Q3_K_L.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Huihui-gemma-3n-E4B-it-abliterated.Q3_K_M",
        "path": "https://huggingface.co/mradermacher/Huihui-gemma-3n-E4B-it-abliterated-GGUF/resolve/main/Huihui-gemma-3n-E4B-it-abliterated.Q3_K_M.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "Huihui-gemma-3n-E4B-it-abliterated.Q3_K_S",
        "path": "https://huggingface.co/mradermacher/Huihui-gemma-3n-E4B-it-abliterated-GGUF/resolve/main/Huihui-gemma-3n-E4B-it-abliterated.Q3_K_S.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Huihui-gemma-3n-E4B-it-abliterated.Q4_K_M",
        "path": "https://huggingface.co/mradermacher/Huihui-gemma-3n-E4B-it-abliterated-GGUF/resolve/main/Huihui-gemma-3n-E4B-it-abliterated.Q4_K_M.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Huihui-gemma-3n-E4B-it-abliterated.Q4_K_S",
        "path": "https://huggingface.co/mradermacher/Huihui-gemma-3n-E4B-it-abliterated-GGUF/resolve/main/Huihui-gemma-3n-E4B-it-abliterated.Q4_K_S.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "Huihui-gemma-3n-E4B-it-abliterated.Q5_K_M",
        "path": "https://huggingface.co/mradermacher/Huihui-gemma-3n-E4B-it-abliterated-GGUF/resolve/main/Huihui-gemma-3n-E4B-it-abliterated.Q5_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Huihui-gemma-3n-E4B-it-abliterated.Q5_K_S",
        "path": "https://huggingface.co/mradermacher/Huihui-gemma-3n-E4B-it-abliterated-GGUF/resolve/main/Huihui-gemma-3n-E4B-it-abliterated.Q5_K_S.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Huihui-gemma-3n-E4B-it-abliterated.Q6_K",
        "path": "https://huggingface.co/mradermacher/Huihui-gemma-3n-E4B-it-abliterated-GGUF/resolve/main/Huihui-gemma-3n-E4B-it-abliterated.Q6_K.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Huihui-gemma-3n-E4B-it-abliterated.Q8_0",
        "path": "https://huggingface.co/mradermacher/Huihui-gemma-3n-E4B-it-abliterated-GGUF/resolve/main/Huihui-gemma-3n-E4B-it-abliterated.Q8_0.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "Huihui-gemma-3n-E4B-it-abliterated.f16",
        "path": "https://huggingface.co/mradermacher/Huihui-gemma-3n-E4B-it-abliterated-GGUF/resolve/main/Huihui-gemma-3n-E4B-it-abliterated.f16.gguf",
        "file_size": "12.8 GB"
      }
    ],
    "readme": "https://huggingface.co/mradermacher/Huihui-gemma-3n-E4B-it-abliterated-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Huihui-gemma-3n-E4B-it-abliterated model, available in various GGUF quantization formats for different performance and quality trade-offs."
  },
  {
    "model_name": "Huihui-Qwen3-235B-A22B-abliterated-GGUF",
    "developer": "huihui-ai",
    "downloads": 572,
    "createdAt": "2025-06-18T06:26:41.000Z",
    "tools": false,
    "num_quants": 12,
    "quants": [
      {
        "model_id": "Q3_K_M-GGUF/Q3_K_M-GGUF-00001-of-00012",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-GGUF/resolve/main/Q3_K_M-GGUF/Q3_K_M-GGUF-00001-of-00012.gguf",
        "file_size": "8.9 GB"
      },
      {
        "model_id": "Q3_K_M-GGUF/Q3_K_M-GGUF-00002-of-00012",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-GGUF/resolve/main/Q3_K_M-GGUF/Q3_K_M-GGUF-00002-of-00012.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "Q3_K_M-GGUF/Q3_K_M-GGUF-00003-of-00012",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-GGUF/resolve/main/Q3_K_M-GGUF/Q3_K_M-GGUF-00003-of-00012.gguf",
        "file_size": "9.1 GB"
      },
      {
        "model_id": "Q3_K_M-GGUF/Q3_K_M-GGUF-00004-of-00012",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-GGUF/resolve/main/Q3_K_M-GGUF/Q3_K_M-GGUF-00004-of-00012.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "Q3_K_M-GGUF/Q3_K_M-GGUF-00005-of-00012",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-GGUF/resolve/main/Q3_K_M-GGUF/Q3_K_M-GGUF-00005-of-00012.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "Q3_K_M-GGUF/Q3_K_M-GGUF-00006-of-00012",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-GGUF/resolve/main/Q3_K_M-GGUF/Q3_K_M-GGUF-00006-of-00012.gguf",
        "file_size": "9.1 GB"
      },
      {
        "model_id": "Q3_K_M-GGUF/Q3_K_M-GGUF-00007-of-00012",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-GGUF/resolve/main/Q3_K_M-GGUF/Q3_K_M-GGUF-00007-of-00012.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "Q3_K_M-GGUF/Q3_K_M-GGUF-00008-of-00012",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-GGUF/resolve/main/Q3_K_M-GGUF/Q3_K_M-GGUF-00008-of-00012.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "Q3_K_M-GGUF/Q3_K_M-GGUF-00009-of-00012",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-GGUF/resolve/main/Q3_K_M-GGUF/Q3_K_M-GGUF-00009-of-00012.gguf",
        "file_size": "9.1 GB"
      },
      {
        "model_id": "Q3_K_M-GGUF/Q3_K_M-GGUF-00010-of-00012",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-GGUF/resolve/main/Q3_K_M-GGUF/Q3_K_M-GGUF-00010-of-00012.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "Q3_K_M-GGUF/Q3_K_M-GGUF-00011-of-00012",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-GGUF/resolve/main/Q3_K_M-GGUF/Q3_K_M-GGUF-00011-of-00012.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "Q3_K_M-GGUF/Q3_K_M-GGUF-00012-of-00012",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-GGUF/resolve/main/Q3_K_M-GGUF/Q3_K_M-GGUF-00012-of-00012.gguf",
        "file_size": "4.0 GB"
      }
    ],
    "readme": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-GGUF/resolve/main/README.md",
    "description": "This is an uncensored, abliterated version of Qwen3-235B-A22B for text generation, with reduced safety filtering and usage warnings."
  },
  {
    "model_name": "Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF",
    "developer": "huihui-ai",
    "downloads": 1,
    "createdAt": "2025-07-01T23:25:30.000Z",
    "tools": false,
    "num_quants": 15,
    "quants": [
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00001-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00001-of-00015.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00002-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00002-of-00015.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00003-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00003-of-00015.gguf",
        "file_size": "9.1 GB"
      },
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00004-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00004-of-00015.gguf",
        "file_size": "9.1 GB"
      },
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00005-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00005-of-00015.gguf",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00006-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00006-of-00015.gguf",
        "file_size": "9.1 GB"
      },
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00007-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00007-of-00015.gguf",
        "file_size": "9.1 GB"
      },
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00008-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00008-of-00015.gguf",
        "file_size": "9.1 GB"
      },
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00009-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00009-of-00015.gguf",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00010-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00010-of-00015.gguf",
        "file_size": "9.1 GB"
      },
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00011-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00011-of-00015.gguf",
        "file_size": "9.1 GB"
      },
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00012-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00012-of-00015.gguf",
        "file_size": "9.1 GB"
      },
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00013-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00013-of-00015.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00014-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00014-of-00015.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "Q4_K_M-GGUF/Q4_K_M-GGUF-00015-of-00015",
        "path": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/Q4_K_M-GGUF/Q4_K_M-GGUF-00015-of-00015.gguf",
        "file_size": "4.9 GB"
      }
    ],
    "readme": "https://huggingface.co/huihui-ai/Huihui-Qwen3-235B-A22B-abliterated-Q4_K_M-GGUF/resolve/main/README.md",
    "description": "This is an uncensored, abliterated version of Qwen3-235B-A22B with reduced safety filtering, suitable for research and experimental use only."
  },
  {
    "model_name": "Hunyuan-A13B-Instruct-GGUF",
    "developer": "bullerwins",
    "downloads": 20097,
    "createdAt": "2025-06-29T19:45:13.000Z",
    "num_quants": 15,
    "quants": [
      {
        "model_id": "Hunyuan-A13B-Instruct-Q2_K",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q2_K.gguf",
        "file_size": "27.4 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q3_K_L",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q3_K_L.gguf",
        "file_size": "38.8 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q3_K_M.gguf",
        "file_size": "35.9 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q3_K_S.gguf",
        "file_size": "32.4 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q4_K_M.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q4_K_S.gguf",
        "file_size": "42.7 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q5_K_M-00001-of-00002",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q5_K_M-00001-of-00002.gguf",
        "file_size": "41.5 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q5_K_M-00002-of-00002",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q5_K_M-00002-of-00002.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q5_K_S-00001-of-00002",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q5_K_S-00001-of-00002.gguf",
        "file_size": "41.5 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q5_K_S-00002-of-00002",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q5_K_S-00002-of-00002.gguf",
        "file_size": "10.1 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q6_K-00001-of-00002",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q6_K-00001-of-00002.gguf",
        "file_size": "41.7 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q6_K-00002-of-00002",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q6_K-00002-of-00002.gguf",
        "file_size": "19.7 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q8_0-00001-of-00002",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q8_0-00001-of-00002.gguf",
        "file_size": "41.7 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q8_0-00002-of-00002",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q8_0-00002-of-00002.gguf",
        "file_size": "37.9 GB"
      },
      {
        "model_id": "Hunyuan-A13B-InstructQ3_K_L",
        "path": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-InstructQ3_K_L.gguf",
        "file_size": "38.8 GB"
      }
    ],
    "readme": "https://huggingface.co/bullerwins/Hunyuan-A13B-Instruct-GGUF/resolve/main/README.md",
    "description": "The Hugging Face repository for Hunyuan-A13B provides an open-source large language model with 80 billion parameters, 13 billion active parameters, and supports efficient inference through various frameworks like TensorRT-LLM, vLLM, and SGLang, with a focus",
    "tools": true
  },
  {
    "model_name": "Hunyuan-A13B-Instruct-GGUF",
    "developer": "ubergarm",
    "downloads": 1649,
    "createdAt": "2025-07-02T00:39:08.000Z",
    "num_quants": 1,
    "quants": [
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ3_KS",
        "path": "https://huggingface.co/ubergarm/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ3_KS.gguf",
        "file_size": "34.1 GB"
      }
    ],
    "readme": "https://huggingface.co/ubergarm/Hunyuan-A13B-Instruct-GGUF/resolve/main/README.md",
    "description": "This is an imatrix quantized version of Hunyuan-A13B-Instruct using ik_llama.cpp, optimized for high perplexity and performance with specific layer quantization settings and hardware requirements.",
    "tools": true
  },
  {
    "model_name": "Hunyuan-A13B-Instruct-GGUF",
    "developer": "unsloth",
    "downloads": 19821,
    "createdAt": "2025-07-08T13:46:24.000Z",
    "num_quants": 36,
    "quants": [
      {
        "model_id": "BF16/Hunyuan-A13B-Instruct-BF16-00001-of-00004",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/BF16/Hunyuan-A13B-Instruct-BF16-00001-of-00004.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "BF16/Hunyuan-A13B-Instruct-BF16-00002-of-00004",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/BF16/Hunyuan-A13B-Instruct-BF16-00002-of-00004.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Hunyuan-A13B-Instruct-BF16-00003-of-00004",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/BF16/Hunyuan-A13B-Instruct-BF16-00003-of-00004.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "BF16/Hunyuan-A13B-Instruct-BF16-00004-of-00004",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/BF16/Hunyuan-A13B-Instruct-BF16-00004-of-00004.gguf",
        "file_size": "10.8 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ4_NL.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ4_XS.gguf",
        "file_size": "40.0 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q2_K",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q2_K.gguf",
        "file_size": "27.4 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q2_K_L.gguf",
        "file_size": "27.4 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q3_K_M.gguf",
        "file_size": "35.9 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q3_K_S.gguf",
        "file_size": "32.4 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q4_0",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q4_0.gguf",
        "file_size": "42.5 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q4_K_M.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q4_K_S.gguf",
        "file_size": "42.7 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-UD-IQ1_M.gguf",
        "file_size": "23.8 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-UD-IQ1_S.gguf",
        "file_size": "22.9 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-UD-IQ2_M.gguf",
        "file_size": "26.9 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-UD-IQ2_XXS.gguf",
        "file_size": "25.7 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-UD-IQ3_XXS.gguf",
        "file_size": "31.9 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-UD-Q2_K_XL.gguf",
        "file_size": "28.9 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-UD-Q3_K_XL.gguf",
        "file_size": "33.8 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-UD-Q4_K_XL.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-UD-TQ1_0",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-UD-TQ1_0.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Q4_1/Hunyuan-A13B-Instruct-Q4_1-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Q4_1/Hunyuan-A13B-Instruct-Q4_1-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/Hunyuan-A13B-Instruct-Q4_1-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Q4_1/Hunyuan-A13B-Instruct-Q4_1-00002-of-00002.gguf",
        "file_size": "487.5 MB"
      },
      {
        "model_id": "Q5_K_M/Hunyuan-A13B-Instruct-Q5_K_M-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Q5_K_M/Hunyuan-A13B-Instruct-Q5_K_M-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q5_K_M/Hunyuan-A13B-Instruct-Q5_K_M-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Q5_K_M/Hunyuan-A13B-Instruct-Q5_K_M-00002-of-00002.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "Q5_K_S/Hunyuan-A13B-Instruct-Q5_K_S-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Q5_K_S/Hunyuan-A13B-Instruct-Q5_K_S-00001-of-00002.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q5_K_S/Hunyuan-A13B-Instruct-Q5_K_S-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Q5_K_S/Hunyuan-A13B-Instruct-Q5_K_S-00002-of-00002.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Q8_0/Hunyuan-A13B-Instruct-Q8_0-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Q8_0/Hunyuan-A13B-Instruct-Q8_0-00001-of-00002.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/Hunyuan-A13B-Instruct-Q8_0-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/Q8_0/Hunyuan-A13B-Instruct-Q8_0-00002-of-00002.gguf",
        "file_size": "33.7 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Hunyuan-A13B-Instruct-UD-Q5_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Hunyuan-A13B-Instruct-UD-Q5_K_XL-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Hunyuan-A13B-Instruct-UD-Q5_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Hunyuan-A13B-Instruct-UD-Q5_K_XL-00002-of-00002.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Hunyuan-A13B-Instruct-UD-Q6_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Hunyuan-A13B-Instruct-UD-Q6_K_XL-00001-of-00002.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Hunyuan-A13B-Instruct-UD-Q6_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Hunyuan-A13B-Instruct-UD-Q6_K_XL-00002-of-00002.gguf",
        "file_size": "19.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Hunyuan-A13B-Instruct-UD-Q8_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Hunyuan-A13B-Instruct-UD-Q8_K_XL-00001-of-00002.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Hunyuan-A13B-Instruct-UD-Q8_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Hunyuan-A13B-Instruct-UD-Q8_K_XL-00002-of-00002.gguf",
        "file_size": "45.3 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Hunyuan-A13B-Instruct-GGUF",
    "developer": "gabriellarson",
    "downloads": 1143,
    "createdAt": "2025-07-08T11:11:22.000Z",
    "num_quants": 26,
    "quants": [
      {
        "model_id": "Hunyuan-A13B-Instruct-F16",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-F16.gguf",
        "file_size": "149.8 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ1_M",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ1_M.gguf",
        "file_size": "16.9 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ1_S",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ1_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ2_M",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ2_M.gguf",
        "file_size": "24.4 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ2_S",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ2_S.gguf",
        "file_size": "22.2 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ2_XS",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ2_XS.gguf",
        "file_size": "22.0 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ2_XXS",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ2_XXS.gguf",
        "file_size": "19.7 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ3_M",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ3_M.gguf",
        "file_size": "32.9 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ3_S",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ3_S.gguf",
        "file_size": "32.4 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ3_XS",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ3_XS.gguf",
        "file_size": "30.7 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ3_XXS",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ3_XXS.gguf",
        "file_size": "28.9 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ4_NL.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ4_XS.gguf",
        "file_size": "40.0 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q2_K",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q2_K.gguf",
        "file_size": "27.4 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q2_K_S",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q2_K_S.gguf",
        "file_size": "25.6 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q3_K_L",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q3_K_L.gguf",
        "file_size": "38.8 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q3_K_M.gguf",
        "file_size": "35.9 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q3_K_S.gguf",
        "file_size": "32.4 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q4_0",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q4_0.gguf",
        "file_size": "42.5 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q4_K_M.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q4_K_S.gguf",
        "file_size": "42.7 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q5_0",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q5_0.gguf",
        "file_size": "51.8 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q5_K_M.gguf",
        "file_size": "53.2 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q5_K_S.gguf",
        "file_size": "51.6 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q6_K",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q6_K.gguf",
        "file_size": "61.4 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q8_0",
        "path": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q8_0.gguf",
        "file_size": "79.6 GB"
      }
    ],
    "readme": "https://huggingface.co/gabriellarson/Hunyuan-A13B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Hunyuan-A13B-Instruct-GGUF",
    "developer": "tencent",
    "downloads": 1136,
    "createdAt": "2025-07-10T07:25:20.000Z",
    "num_quants": 4,
    "quants": [
      {
        "model_id": "Hunyuan-A13B-Instruct-Q4_0",
        "path": "https://huggingface.co/tencent/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q4_0.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/tencent/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q4_K_M.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q8_0-00001-of-00002",
        "path": "https://huggingface.co/tencent/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q8_0-00001-of-00002.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "Hunyuan-A13B-Instruct-Q8_0-00002-of-00002",
        "path": "https://huggingface.co/tencent/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q8_0-00002-of-00002.gguf",
        "file_size": "35.4 GB"
      }
    ],
    "readme": "https://huggingface.co/tencent/Hunyuan-A13B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Irix-12B-Model_Stock-i1-GGUF",
    "developer": "mradermacher",
    "downloads": 4211,
    "createdAt": "2025-03-28T16:03:25.000Z",
    "num_quants": 24,
    "quants": [
      {
        "model_id": "Irix-12B-Model_Stock.i1-IQ1_M",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-IQ1_M.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-IQ1_S",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-IQ1_S.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-IQ2_M",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-IQ2_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-IQ2_S",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-IQ2_S.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-IQ2_XS",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-IQ2_XS.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-IQ2_XXS",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-IQ2_XXS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-IQ3_M",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-IQ3_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-IQ3_S",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-IQ3_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-IQ3_XS",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-IQ3_XS.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-IQ3_XXS",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-IQ3_XXS.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-IQ4_NL",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-IQ4_NL.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-IQ4_XS",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-IQ4_XS.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-Q2_K",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-Q2_K.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-Q2_K_S",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-Q2_K_S.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-Q3_K_L",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-Q3_K_L.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-Q3_K_M",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-Q3_K_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-Q3_K_S",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-Q3_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-Q4_0",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-Q4_0.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-Q4_1",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-Q4_1.gguf",
        "file_size": "7.3 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-Q4_K_M",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-Q4_K_M.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-Q4_K_S",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-Q4_K_S.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-Q5_K_M",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-Q5_K_M.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-Q5_K_S",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-Q5_K_S.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "Irix-12B-Model_Stock.i1-Q6_K",
        "path": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/Irix-12B-Model_Stock.i1-Q6_K.gguf",
        "file_size": "9.4 GB"
      }
    ],
    "readme": "https://huggingface.co/mradermacher/Irix-12B-Model_Stock-i1-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Jan-nano-128k-GGUF",
    "developer": "unsloth",
    "downloads": 14760,
    "createdAt": "2025-06-25T07:31:40.000Z",
    "num_quants": 26,
    "quants": [
      {
        "model_id": "Jan-nano-128k-BF16",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-BF16.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Jan-nano-128k-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-IQ4_NL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Jan-nano-128k-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-IQ4_XS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Jan-nano-128k-Q2_K",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-Q2_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Jan-nano-128k-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-Q2_K_L.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Jan-nano-128k-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-Q3_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Jan-nano-128k-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Jan-nano-128k-Q4_0",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Jan-nano-128k-Q4_1",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-Q4_1.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Jan-nano-128k-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Jan-nano-128k-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Jan-nano-128k-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Jan-nano-128k-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Jan-nano-128k-Q6_K",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Jan-nano-128k-Q8_0",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-Q8_0.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Jan-nano-128k-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-UD-IQ1_M.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Jan-nano-128k-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-UD-IQ1_S.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Jan-nano-128k-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-UD-IQ2_M.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "Jan-nano-128k-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-UD-IQ2_XXS.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Jan-nano-128k-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-UD-IQ3_XXS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Jan-nano-128k-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-UD-Q2_K_XL.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Jan-nano-128k-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-UD-Q3_K_XL.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Jan-nano-128k-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-UD-Q4_K_XL.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Jan-nano-128k-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-UD-Q5_K_XL.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Jan-nano-128k-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-UD-Q6_K_XL.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Jan-nano-128k-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/Jan-nano-128k-UD-Q8_K_XL.gguf",
        "file_size": "4.7 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Jan-nano-128k-GGUF/resolve/main/README.md",
    "description": "Jan-Nano-128k is a compact language model with a native 128k context window, designed for deep research tasks by enabling efficient processing of long documents and complex multi-turn conversations without performance degradation.",
    "tools": true
  },
  {
    "model_name": "jina-reranker-m0-GGUF",
    "developer": "jinaai",
    "downloads": 806,
    "createdAt": "2025-07-20T21:30:25.000Z",
    "num_quants": 6,
    "quants": [
      {
        "model_id": "jina-reranker-m0-F16",
        "path": "https://huggingface.co/jinaai/jina-reranker-m0-GGUF/resolve/main/jina-reranker-m0-F16.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "jina-reranker-m0-Q3_K_M",
        "path": "https://huggingface.co/jinaai/jina-reranker-m0-GGUF/resolve/main/jina-reranker-m0-Q3_K_M.gguf",
        "file_size": "786.0 MB"
      },
      {
        "model_id": "jina-reranker-m0-Q4_K_M",
        "path": "https://huggingface.co/jinaai/jina-reranker-m0-GGUF/resolve/main/jina-reranker-m0-Q4_K_M.gguf",
        "file_size": "940.4 MB"
      },
      {
        "model_id": "jina-reranker-m0-Q5_K_M",
        "path": "https://huggingface.co/jinaai/jina-reranker-m0-GGUF/resolve/main/jina-reranker-m0-Q5_K_M.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "jina-reranker-m0-Q6_K",
        "path": "https://huggingface.co/jinaai/jina-reranker-m0-GGUF/resolve/main/jina-reranker-m0-Q6_K.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "jina-reranker-m0-Q8_0",
        "path": "https://huggingface.co/jinaai/jina-reranker-m0-GGUF/resolve/main/jina-reranker-m0-Q8_0.gguf",
        "file_size": "1.5 GB"
      }
    ],
    "readme": "https://huggingface.co/jinaai/jina-reranker-m0-GGUF/resolve/main/README.md",
    "description": ""
  },
  {
    "model_name": "KafkaLM-70B-German-V0.1-GGUF",
    "developer": "TheBloke",
    "downloads": 1766,
    "createdAt": "2024-01-31T17:12:07.000Z",
    "tools": false,
    "num_quants": 10,
    "quants": [
      {
        "model_id": "kafkalm-70b-german-v0.1.Q2_K",
        "path": "https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF/resolve/main/kafkalm-70b-german-v0.1.Q2_K.gguf",
        "file_size": "23.7 GB"
      },
      {
        "model_id": "kafkalm-70b-german-v0.1.Q3_K_L",
        "path": "https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF/resolve/main/kafkalm-70b-german-v0.1.Q3_K_L.gguf",
        "file_size": "33.7 GB"
      },
      {
        "model_id": "kafkalm-70b-german-v0.1.Q3_K_M",
        "path": "https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF/resolve/main/kafkalm-70b-german-v0.1.Q3_K_M.gguf",
        "file_size": "31.0 GB"
      },
      {
        "model_id": "kafkalm-70b-german-v0.1.Q3_K_S",
        "path": "https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF/resolve/main/kafkalm-70b-german-v0.1.Q3_K_S.gguf",
        "file_size": "27.9 GB"
      },
      {
        "model_id": "kafkalm-70b-german-v0.1.Q4_0",
        "path": "https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF/resolve/main/kafkalm-70b-german-v0.1.Q4_0.gguf",
        "file_size": "36.2 GB"
      },
      {
        "model_id": "kafkalm-70b-german-v0.1.Q4_K_M",
        "path": "https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF/resolve/main/kafkalm-70b-german-v0.1.Q4_K_M.gguf",
        "file_size": "38.6 GB"
      },
      {
        "model_id": "kafkalm-70b-german-v0.1.Q4_K_S",
        "path": "https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF/resolve/main/kafkalm-70b-german-v0.1.Q4_K_S.gguf",
        "file_size": "36.6 GB"
      },
      {
        "model_id": "kafkalm-70b-german-v0.1.Q5_0",
        "path": "https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF/resolve/main/kafkalm-70b-german-v0.1.Q5_0.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "kafkalm-70b-german-v0.1.Q5_K_M",
        "path": "https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF/resolve/main/kafkalm-70b-german-v0.1.Q5_K_M.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "kafkalm-70b-german-v0.1.Q5_K_S",
        "path": "https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF/resolve/main/kafkalm-70b-german-v0.1.Q5_K_S.gguf",
        "file_size": "44.2 GB"
      }
    ],
    "readme": "https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF/resolve/main/README.md",
    "description": "This is a GGUF format quantized version of Seedbox's KafkaLM 70B German V0.1 model, optimized for efficient inference on CPU and GPU with various quantization levels, including Q2_K, Q3_K, Q4_K, Q5_K, and Q6"
  },
  {
    "model_name": "Kimi-Dev-72B-GGUF",
    "developer": "unsloth",
    "downloads": 38919,
    "createdAt": "2025-06-17T00:37:17.000Z",
    "tools": true,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "BF16/Kimi-Dev-72B-BF16-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/BF16/Kimi-Dev-72B-BF16-00001-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "BF16/Kimi-Dev-72B-BF16-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/BF16/Kimi-Dev-72B-BF16-00002-of-00003.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "BF16/Kimi-Dev-72B-BF16-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/BF16/Kimi-Dev-72B-BF16-00003-of-00003.gguf",
        "file_size": "42.7 GB"
      },
      {
        "model_id": "Kimi-Dev-72B-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Kimi-Dev-72B-IQ4_NL.gguf",
        "file_size": "38.5 GB"
      },
      {
        "model_id": "Kimi-Dev-72B-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Kimi-Dev-72B-IQ4_XS.gguf",
        "file_size": "37.0 GB"
      },
      {
        "model_id": "Kimi-Dev-72B-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Kimi-Dev-72B-Q3_K_M.gguf",
        "file_size": "35.1 GB"
      },
      {
        "model_id": "Kimi-Dev-72B-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Kimi-Dev-72B-Q3_K_S.gguf",
        "file_size": "32.1 GB"
      },
      {
        "model_id": "Kimi-Dev-72B-Q4_0",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Kimi-Dev-72B-Q4_0.gguf",
        "file_size": "38.5 GB"
      },
      {
        "model_id": "Kimi-Dev-72B-Q4_1",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Kimi-Dev-72B-Q4_1.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "Kimi-Dev-72B-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Kimi-Dev-72B-UD-IQ1_M.gguf",
        "file_size": "22.3 GB"
      },
      {
        "model_id": "Kimi-Dev-72B-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Kimi-Dev-72B-UD-IQ1_S.gguf",
        "file_size": "21.5 GB"
      },
      {
        "model_id": "Kimi-Dev-72B-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Kimi-Dev-72B-UD-IQ2_M.gguf",
        "file_size": "27.6 GB"
      },
      {
        "model_id": "Kimi-Dev-72B-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Kimi-Dev-72B-UD-IQ2_XXS.gguf",
        "file_size": "23.9 GB"
      },
      {
        "model_id": "Kimi-Dev-72B-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Kimi-Dev-72B-UD-IQ3_XXS.gguf",
        "file_size": "29.7 GB"
      },
      {
        "model_id": "Kimi-Dev-72B-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Kimi-Dev-72B-UD-Q2_K_XL.gguf",
        "file_size": "28.3 GB"
      },
      {
        "model_id": "Kimi-Dev-72B-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Kimi-Dev-72B-UD-Q3_K_XL.gguf",
        "file_size": "35.7 GB"
      },
      {
        "model_id": "Q6_K/Kimi-Dev-72B-Q6_K-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Q6_K/Kimi-Dev-72B-Q6_K-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q6_K/Kimi-Dev-72B-Q6_K-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Q6_K/Kimi-Dev-72B-Q6_K-00002-of-00002.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "Q8_0/Kimi-Dev-72B-Q8_0-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Q8_0/Kimi-Dev-72B-Q8_0-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q8_0/Kimi-Dev-72B-Q8_0-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/Q8_0/Kimi-Dev-72B-Q8_0-00002-of-00002.gguf",
        "file_size": "25.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-Dev-72B-UD-Q5_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/UD-Q5_K_XL/Kimi-Dev-72B-UD-Q5_K_XL-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-Dev-72B-UD-Q5_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/UD-Q5_K_XL/Kimi-Dev-72B-UD-Q5_K_XL-00002-of-00002.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-Dev-72B-UD-Q6_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/UD-Q6_K_XL/Kimi-Dev-72B-UD-Q6_K_XL-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-Dev-72B-UD-Q6_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/UD-Q6_K_XL/Kimi-Dev-72B-UD-Q6_K_XL-00002-of-00002.gguf",
        "file_size": "16.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-Dev-72B-UD-Q8_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/UD-Q8_K_XL/Kimi-Dev-72B-UD-Q8_K_XL-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-Dev-72B-UD-Q8_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/UD-Q8_K_XL/Kimi-Dev-72B-UD-Q8_K_XL-00002-of-00002.gguf",
        "file_size": "31.7 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Kimi-Dev-72B-GGUF/resolve/main/README.md",
    "description": "Kimi-Dev-72B is an open-source coding LLM for issue resolution that achieves 60.4% performance on SWE-bench Verified, outperforming other leading open-source models."
  },
  {
    "model_name": "Kimi-K2-Instruct-DQ4_K",
    "developer": "anikifoss",
    "downloads": 498,
    "createdAt": "2025-07-14T18:24:32.000Z",
    "num_quants": 14,
    "quants": [
      {
        "model_id": "Kimi-K2-Instruct-DQ4_K-00001-of-00014",
        "path": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/Kimi-K2-Instruct-DQ4_K-00001-of-00014.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DQ4_K-00002-of-00014",
        "path": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/Kimi-K2-Instruct-DQ4_K-00002-of-00014.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DQ4_K-00003-of-00014",
        "path": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/Kimi-K2-Instruct-DQ4_K-00003-of-00014.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DQ4_K-00004-of-00014",
        "path": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/Kimi-K2-Instruct-DQ4_K-00004-of-00014.gguf",
        "file_size": "44.6 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DQ4_K-00005-of-00014",
        "path": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/Kimi-K2-Instruct-DQ4_K-00005-of-00014.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DQ4_K-00006-of-00014",
        "path": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/Kimi-K2-Instruct-DQ4_K-00006-of-00014.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DQ4_K-00007-of-00014",
        "path": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/Kimi-K2-Instruct-DQ4_K-00007-of-00014.gguf",
        "file_size": "44.6 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DQ4_K-00008-of-00014",
        "path": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/Kimi-K2-Instruct-DQ4_K-00008-of-00014.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DQ4_K-00009-of-00014",
        "path": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/Kimi-K2-Instruct-DQ4_K-00009-of-00014.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DQ4_K-00010-of-00014",
        "path": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/Kimi-K2-Instruct-DQ4_K-00010-of-00014.gguf",
        "file_size": "44.6 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DQ4_K-00011-of-00014",
        "path": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/Kimi-K2-Instruct-DQ4_K-00011-of-00014.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DQ4_K-00012-of-00014",
        "path": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/Kimi-K2-Instruct-DQ4_K-00012-of-00014.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DQ4_K-00013-of-00014",
        "path": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/Kimi-K2-Instruct-DQ4_K-00013-of-00014.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DQ4_K-00014-of-00014",
        "path": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/Kimi-K2-Instruct-DQ4_K-00014-of-00014.gguf",
        "file_size": "41.5 GB"
      }
    ],
    "readme": "https://huggingface.co/anikifoss/Kimi-K2-Instruct-DQ4_K/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Kimi-K2-Instruct-DRAFT-0.6B-v2.0-GGUF",
    "developer": "jukofyork",
    "downloads": 311,
    "createdAt": "2025-07-18T11:08:53.000Z",
    "tools": true,
    "num_quants": 3,
    "quants": [
      {
        "model_id": "Kimi-K2-Instruct-DRAFT-0.6B-128k-Q4_0",
        "path": "https://huggingface.co/jukofyork/Kimi-K2-Instruct-DRAFT-0.6B-v2.0-GGUF/resolve/main/Kimi-K2-Instruct-DRAFT-0.6B-128k-Q4_0.gguf",
        "file_size": "426.3 MB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DRAFT-0.6B-32k-Q4_0",
        "path": "https://huggingface.co/jukofyork/Kimi-K2-Instruct-DRAFT-0.6B-v2.0-GGUF/resolve/main/Kimi-K2-Instruct-DRAFT-0.6B-32k-Q4_0.gguf",
        "file_size": "426.3 MB"
      },
      {
        "model_id": "Kimi-K2-Instruct-DRAFT-0.6B-64k-Q4_0",
        "path": "https://huggingface.co/jukofyork/Kimi-K2-Instruct-DRAFT-0.6B-v2.0-GGUF/resolve/main/Kimi-K2-Instruct-DRAFT-0.6B-64k-Q4_0.gguf",
        "file_size": "426.3 MB"
      }
    ],
    "readme": "https://huggingface.co/jukofyork/Kimi-K2-Instruct-DRAFT-0.6B-v2.0-GGUF/resolve/main/README.md",
    "description": "This is a 0.6B parameter draft model for speculative decoding with Kimi-K2-Instruct, quantized in Q4_0 format for context lengths of 32k, 64k, and 128k."
  },
  {
    "model_name": "Kimi-K2-Instruct-GGUF",
    "developer": "gabriellarson",
    "downloads": 2225,
    "createdAt": "2025-07-13T14:51:54.000Z",
    "num_quants": 103,
    "quants": [
      {
        "model_id": "Kimi-K2-Instruct-BF16-00001-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00001-of-00090.gguf",
        "file_size": "24.1 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00002-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00002-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00003-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00003-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00004-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00004-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00005-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00005-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00006-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00006-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00007-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00007-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00008-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00008-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00009-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00009-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00010-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00010-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00011-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00011-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00012-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00012-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00013-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00013-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00014-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00014-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00015-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00015-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00016-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00016-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00017-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00017-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00018-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00018-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00019-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00019-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00020-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00020-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00021-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00021-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00022-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00022-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00023-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00023-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00024-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00024-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00025-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00025-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00026-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00026-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00027-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00027-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00028-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00028-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00029-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00029-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00030-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00030-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00031-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00031-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00032-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00032-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00033-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00033-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00034-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00034-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00035-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00035-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00036-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00036-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00037-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00037-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00038-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00038-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00039-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00039-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00040-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00040-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00041-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00041-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00042-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00042-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00043-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00043-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00044-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00044-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00045-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00045-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00046-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00046-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00047-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00047-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00048-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00048-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00049-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00049-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00050-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00050-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00051-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00051-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00052-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00052-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00053-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00053-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00054-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00054-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00055-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00055-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00056-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00056-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00057-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00057-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00058-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00058-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00059-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00059-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00060-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00060-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00061-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00061-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00062-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00062-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00063-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00063-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00064-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00064-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00065-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00065-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00066-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00066-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00067-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00067-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00068-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00068-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00069-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00069-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00070-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00070-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00071-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00071-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00072-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00072-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00073-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00073-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00074-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00074-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00075-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00075-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00076-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00076-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00077-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00077-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00078-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00078-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00079-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00079-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00080-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00080-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00081-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00081-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00082-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00082-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00083-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00083-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00084-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00084-of-00090.gguf",
        "file_size": "23.5 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00085-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00085-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00086-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00086-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00087-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00087-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00088-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00088-of-00090.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00089-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00089-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-BF16-00090-of-00090",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-BF16-00090-of-00090.gguf",
        "file_size": "21.3 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-Q2_K-00001-of-00013",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-Q2_K-00001-of-00013.gguf",
        "file_size": "26.8 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-Q2_K-00002-of-00013",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-Q2_K-00002-of-00013.gguf",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-Q2_K-00003-of-00013",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-Q2_K-00003-of-00013.gguf",
        "file_size": "27.1 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-Q2_K-00004-of-00013",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-Q2_K-00004-of-00013.gguf",
        "file_size": "27.1 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-Q2_K-00005-of-00013",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-Q2_K-00005-of-00013.gguf",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-Q2_K-00006-of-00013",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-Q2_K-00006-of-00013.gguf",
        "file_size": "27.1 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-Q2_K-00007-of-00013",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-Q2_K-00007-of-00013.gguf",
        "file_size": "27.1 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-Q2_K-00008-of-00013",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-Q2_K-00008-of-00013.gguf",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-Q2_K-00009-of-00013",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-Q2_K-00009-of-00013.gguf",
        "file_size": "27.1 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-Q2_K-00010-of-00013",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-Q2_K-00010-of-00013.gguf",
        "file_size": "27.1 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-Q2_K-00011-of-00013",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-Q2_K-00011-of-00013.gguf",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-Q2_K-00012-of-00013",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-Q2_K-00012-of-00013.gguf",
        "file_size": "27.1 GB"
      },
      {
        "model_id": "Kimi-K2-Instruct-Q2_K-00013-of-00013",
        "path": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-Q2_K-00013-of-00013.gguf",
        "file_size": "24.8 GB"
      }
    ],
    "readme": "https://huggingface.co/gabriellarson/Kimi-K2-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Kimi-K2-Instruct-GGUF",
    "developer": "unsloth",
    "downloads": 117750,
    "createdAt": "2025-07-12T00:58:54.000Z",
    "tools": true,
    "num_quants": 363,
    "quants": [
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00001-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00001-of-00045.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00002-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00002-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00003-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00003-of-00045.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00004-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00004-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00005-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00005-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00006-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00006-of-00045.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00007-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00007-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00008-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00008-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00009-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00009-of-00045.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00010-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00010-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00011-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00011-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00012-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00012-of-00045.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00013-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00013-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00014-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00014-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00015-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00015-of-00045.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00016-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00016-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00017-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00017-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00018-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00018-of-00045.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00019-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00019-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00020-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00020-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00021-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00021-of-00045.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00022-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00022-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00023-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00023-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00024-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00024-of-00045.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00025-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00025-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00026-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00026-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00027-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00027-of-00045.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00028-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00028-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00029-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00029-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00030-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00030-of-00045.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00031-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00031-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00032-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00032-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00033-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00033-of-00045.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00034-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00034-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00035-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00035-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00036-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00036-of-00045.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00037-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00037-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00038-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00038-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00039-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00039-of-00045.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00040-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00040-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00041-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00041-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00042-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00042-of-00045.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00043-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00043-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00044-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00044-of-00045.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "BF16/Kimi-K2-Instruct-BF16-00045-of-00045",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00045-of-00045.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00001-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00001-of-00012.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00002-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00002-of-00012.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00003-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00003-of-00012.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00004-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00004-of-00012.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00005-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00005-of-00012.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00006-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00006-of-00012.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00007-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00007-of-00012.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00008-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00008-of-00012.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00009-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00009-of-00012.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00010-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00010-of-00012.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00011-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00011-of-00012.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00012-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_NL/Kimi-K2-Instruct-IQ4_NL-00012-of-00012.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00001-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00001-of-00012.gguf",
        "file_size": "44.1 GB"
      },
      {
        "model_id": "IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00002-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00002-of-00012.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00003-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00003-of-00012.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00004-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00004-of-00012.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00005-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00005-of-00012.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00006-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00006-of-00012.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00007-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00007-of-00012.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00008-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00008-of-00012.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00009-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00009-of-00012.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00010-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00010-of-00012.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00011-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00011-of-00012.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00012-of-00012",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_XS/Kimi-K2-Instruct-IQ4_XS-00012-of-00012.gguf",
        "file_size": "14.1 GB"
      },
      {
        "model_id": "Q2_K/Kimi-K2-Instruct-Q2_K-00001-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K/Kimi-K2-Instruct-Q2_K-00001-of-00008.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q2_K/Kimi-K2-Instruct-Q2_K-00002-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K/Kimi-K2-Instruct-Q2_K-00002-of-00008.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q2_K/Kimi-K2-Instruct-Q2_K-00003-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K/Kimi-K2-Instruct-Q2_K-00003-of-00008.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q2_K/Kimi-K2-Instruct-Q2_K-00004-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K/Kimi-K2-Instruct-Q2_K-00004-of-00008.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q2_K/Kimi-K2-Instruct-Q2_K-00005-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K/Kimi-K2-Instruct-Q2_K-00005-of-00008.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q2_K/Kimi-K2-Instruct-Q2_K-00006-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K/Kimi-K2-Instruct-Q2_K-00006-of-00008.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q2_K/Kimi-K2-Instruct-Q2_K-00007-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K/Kimi-K2-Instruct-Q2_K-00007-of-00008.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q2_K/Kimi-K2-Instruct-Q2_K-00008-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K/Kimi-K2-Instruct-Q2_K-00008-of-00008.gguf",
        "file_size": "24.8 GB"
      },
      {
        "model_id": "Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00001-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00001-of-00008.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00002-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00002-of-00008.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00003-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00003-of-00008.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00004-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00004-of-00008.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00005-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00005-of-00008.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00006-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00006-of-00008.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00007-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00007-of-00008.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00008-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q2_K_L/Kimi-K2-Instruct-Q2_K_L-00008-of-00008.gguf",
        "file_size": "24.8 GB"
      },
      {
        "model_id": "Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00001-of-00011",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00001-of-00011.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00002-of-00011",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00002-of-00011.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00003-of-00011",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00003-of-00011.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00004-of-00011",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00004-of-00011.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00005-of-00011",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00005-of-00011.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00006-of-00011",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00006-of-00011.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00007-of-00011",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00007-of-00011.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00008-of-00011",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00008-of-00011.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00009-of-00011",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00009-of-00011.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00010-of-00011",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00010-of-00011.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00011-of-00011",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_M/Kimi-K2-Instruct-Q3_K_M-00011-of-00011.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00001-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00001-of-00010.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00002-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00002-of-00010.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00003-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00003-of-00010.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00004-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00004-of-00010.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00005-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00005-of-00010.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00006-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00006-of-00010.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00007-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00007-of-00010.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00008-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00008-of-00010.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00009-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00009-of-00010.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00010-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q3_K_S/Kimi-K2-Instruct-Q3_K_S-00010-of-00010.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Q4_0/Kimi-K2-Instruct-Q4_0-00001-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_0/Kimi-K2-Instruct-Q4_0-00001-of-00013.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q4_0/Kimi-K2-Instruct-Q4_0-00002-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_0/Kimi-K2-Instruct-Q4_0-00002-of-00013.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q4_0/Kimi-K2-Instruct-Q4_0-00003-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_0/Kimi-K2-Instruct-Q4_0-00003-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_0/Kimi-K2-Instruct-Q4_0-00004-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_0/Kimi-K2-Instruct-Q4_0-00004-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_0/Kimi-K2-Instruct-Q4_0-00005-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_0/Kimi-K2-Instruct-Q4_0-00005-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_0/Kimi-K2-Instruct-Q4_0-00006-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_0/Kimi-K2-Instruct-Q4_0-00006-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_0/Kimi-K2-Instruct-Q4_0-00007-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_0/Kimi-K2-Instruct-Q4_0-00007-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_0/Kimi-K2-Instruct-Q4_0-00008-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_0/Kimi-K2-Instruct-Q4_0-00008-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_0/Kimi-K2-Instruct-Q4_0-00009-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_0/Kimi-K2-Instruct-Q4_0-00009-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_0/Kimi-K2-Instruct-Q4_0-00010-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_0/Kimi-K2-Instruct-Q4_0-00010-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_0/Kimi-K2-Instruct-Q4_0-00011-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_0/Kimi-K2-Instruct-Q4_0-00011-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_0/Kimi-K2-Instruct-Q4_0-00012-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_0/Kimi-K2-Instruct-Q4_0-00012-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_0/Kimi-K2-Instruct-Q4_0-00013-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_0/Kimi-K2-Instruct-Q4_0-00013-of-00013.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Q4_1/Kimi-K2-Instruct-Q4_1-00001-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_1/Kimi-K2-Instruct-Q4_1-00001-of-00013.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "Q4_1/Kimi-K2-Instruct-Q4_1-00002-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_1/Kimi-K2-Instruct-Q4_1-00002-of-00013.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/Kimi-K2-Instruct-Q4_1-00003-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_1/Kimi-K2-Instruct-Q4_1-00003-of-00013.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/Kimi-K2-Instruct-Q4_1-00004-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_1/Kimi-K2-Instruct-Q4_1-00004-of-00013.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/Kimi-K2-Instruct-Q4_1-00005-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_1/Kimi-K2-Instruct-Q4_1-00005-of-00013.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/Kimi-K2-Instruct-Q4_1-00006-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_1/Kimi-K2-Instruct-Q4_1-00006-of-00013.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/Kimi-K2-Instruct-Q4_1-00007-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_1/Kimi-K2-Instruct-Q4_1-00007-of-00013.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/Kimi-K2-Instruct-Q4_1-00008-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_1/Kimi-K2-Instruct-Q4_1-00008-of-00013.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/Kimi-K2-Instruct-Q4_1-00009-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_1/Kimi-K2-Instruct-Q4_1-00009-of-00013.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/Kimi-K2-Instruct-Q4_1-00010-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_1/Kimi-K2-Instruct-Q4_1-00010-of-00013.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/Kimi-K2-Instruct-Q4_1-00011-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_1/Kimi-K2-Instruct-Q4_1-00011-of-00013.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/Kimi-K2-Instruct-Q4_1-00012-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_1/Kimi-K2-Instruct-Q4_1-00012-of-00013.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/Kimi-K2-Instruct-Q4_1-00013-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_1/Kimi-K2-Instruct-Q4_1-00013-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00001-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00001-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00002-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00002-of-00013.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00003-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00003-of-00013.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00004-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00004-of-00013.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00005-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00005-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00006-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00006-of-00013.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00007-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00007-of-00013.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00008-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00008-of-00013.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00009-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00009-of-00013.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00010-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00010-of-00013.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00011-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00011-of-00013.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00012-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00012-of-00013.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00013-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_M/Kimi-K2-Instruct-Q4_K_M-00013-of-00013.gguf",
        "file_size": "41.2 GB"
      },
      {
        "model_id": "Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00001-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00001-of-00013.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00002-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00002-of-00013.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00003-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00003-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00004-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00004-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00005-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00005-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00006-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00006-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00007-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00007-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00008-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00008-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00009-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00009-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00010-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00010-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00011-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00011-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00012-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00012-of-00013.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00013-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q4_K_S/Kimi-K2-Instruct-Q4_K_S-00013-of-00013.gguf",
        "file_size": "5.9 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00001-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00001-of-00016.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00002-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00002-of-00016.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00003-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00003-of-00016.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00004-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00004-of-00016.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00005-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00005-of-00016.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00006-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00006-of-00016.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00007-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00007-of-00016.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00008-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00008-of-00016.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00009-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00009-of-00016.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00010-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00010-of-00016.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00011-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00011-of-00016.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00012-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00012-of-00016.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00013-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00013-of-00016.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00014-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00014-of-00016.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00015-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00015-of-00016.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00016-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_M/Kimi-K2-Instruct-Q5_K_M-00016-of-00016.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00001-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00001-of-00015.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00002-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00002-of-00015.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00003-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00003-of-00015.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00004-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00004-of-00015.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00005-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00005-of-00015.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00006-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00006-of-00015.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00007-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00007-of-00015.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00008-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00008-of-00015.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00009-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00009-of-00015.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00010-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00010-of-00015.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00011-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00011-of-00015.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00012-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00012-of-00015.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00013-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00013-of-00015.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00014-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00014-of-00015.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00015-of-00015",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q5_K_S/Kimi-K2-Instruct-Q5_K_S-00015-of-00015.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00001-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00001-of-00018.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00002-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00002-of-00018.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00003-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00003-of-00018.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00004-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00004-of-00018.gguf",
        "file_size": "43.4 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00005-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00005-of-00018.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00006-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00006-of-00018.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00007-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00007-of-00018.gguf",
        "file_size": "43.4 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00008-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00008-of-00018.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00009-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00009-of-00018.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00010-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00010-of-00018.gguf",
        "file_size": "43.4 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00011-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00011-of-00018.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00012-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00012-of-00018.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00013-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00013-of-00018.gguf",
        "file_size": "43.4 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00014-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00014-of-00018.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00015-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00015-of-00018.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00016-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00016-of-00018.gguf",
        "file_size": "43.4 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00017-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00017-of-00018.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "Q6_K/Kimi-K2-Instruct-Q6_K-00018-of-00018",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q6_K/Kimi-K2-Instruct-Q6_K-00018-of-00018.gguf",
        "file_size": "43.4 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00001-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00001-of-00023.gguf",
        "file_size": "41.0 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00002-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00002-of-00023.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00003-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00003-of-00023.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00004-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00004-of-00023.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00005-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00005-of-00023.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00006-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00006-of-00023.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00007-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00007-of-00023.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00008-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00008-of-00023.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00009-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00009-of-00023.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00010-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00010-of-00023.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00011-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00011-of-00023.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00012-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00012-of-00023.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00013-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00013-of-00023.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00014-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00014-of-00023.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00015-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00015-of-00023.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00016-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00016-of-00023.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00017-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00017-of-00023.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00018-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00018-of-00023.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00019-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00019-of-00023.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00020-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00020-of-00023.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00021-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00021-of-00023.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00022-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00022-of-00023.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q8_0/Kimi-K2-Instruct-Q8_0-00023-of-00023",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/Q8_0/Kimi-K2-Instruct-Q8_0-00023-of-00023.gguf",
        "file_size": "28.2 GB"
      },
      {
        "model_id": "UD-IQ1_M/Kimi-K2-Instruct-UD-IQ1_M-00001-of-00007",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ1_M/Kimi-K2-Instruct-UD-IQ1_M-00001-of-00007.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-IQ1_M/Kimi-K2-Instruct-UD-IQ1_M-00002-of-00007",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ1_M/Kimi-K2-Instruct-UD-IQ1_M-00002-of-00007.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-IQ1_M/Kimi-K2-Instruct-UD-IQ1_M-00003-of-00007",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ1_M/Kimi-K2-Instruct-UD-IQ1_M-00003-of-00007.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "UD-IQ1_M/Kimi-K2-Instruct-UD-IQ1_M-00004-of-00007",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ1_M/Kimi-K2-Instruct-UD-IQ1_M-00004-of-00007.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-IQ1_M/Kimi-K2-Instruct-UD-IQ1_M-00005-of-00007",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ1_M/Kimi-K2-Instruct-UD-IQ1_M-00005-of-00007.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-IQ1_M/Kimi-K2-Instruct-UD-IQ1_M-00006-of-00007",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ1_M/Kimi-K2-Instruct-UD-IQ1_M-00006-of-00007.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "UD-IQ1_M/Kimi-K2-Instruct-UD-IQ1_M-00007-of-00007",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ1_M/Kimi-K2-Instruct-UD-IQ1_M-00007-of-00007.gguf",
        "file_size": "11.1 GB"
      },
      {
        "model_id": "UD-IQ1_S/Kimi-K2-Instruct-UD-IQ1_S-00001-of-00006",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ1_S/Kimi-K2-Instruct-UD-IQ1_S-00001-of-00006.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-IQ1_S/Kimi-K2-Instruct-UD-IQ1_S-00002-of-00006",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ1_S/Kimi-K2-Instruct-UD-IQ1_S-00002-of-00006.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-IQ1_S/Kimi-K2-Instruct-UD-IQ1_S-00003-of-00006",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ1_S/Kimi-K2-Instruct-UD-IQ1_S-00003-of-00006.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "UD-IQ1_S/Kimi-K2-Instruct-UD-IQ1_S-00004-of-00006",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ1_S/Kimi-K2-Instruct-UD-IQ1_S-00004-of-00006.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-IQ1_S/Kimi-K2-Instruct-UD-IQ1_S-00005-of-00006",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ1_S/Kimi-K2-Instruct-UD-IQ1_S-00005-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-IQ1_S/Kimi-K2-Instruct-UD-IQ1_S-00006-of-00006",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ1_S/Kimi-K2-Instruct-UD-IQ1_S-00006-of-00006.gguf",
        "file_size": "32.5 GB"
      },
      {
        "model_id": "UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00001-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00001-of-00008.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00002-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00002-of-00008.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00003-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00003-of-00008.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00004-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00004-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00005-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00005-of-00008.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00006-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00006-of-00008.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00007-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00007-of-00008.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00008-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_M/Kimi-K2-Instruct-UD-IQ2_M-00008-of-00008.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/Kimi-K2-Instruct-UD-IQ2_XXS-00001-of-00007",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_XXS/Kimi-K2-Instruct-UD-IQ2_XXS-00001-of-00007.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/Kimi-K2-Instruct-UD-IQ2_XXS-00002-of-00007",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_XXS/Kimi-K2-Instruct-UD-IQ2_XXS-00002-of-00007.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/Kimi-K2-Instruct-UD-IQ2_XXS-00003-of-00007",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_XXS/Kimi-K2-Instruct-UD-IQ2_XXS-00003-of-00007.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/Kimi-K2-Instruct-UD-IQ2_XXS-00004-of-00007",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_XXS/Kimi-K2-Instruct-UD-IQ2_XXS-00004-of-00007.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/Kimi-K2-Instruct-UD-IQ2_XXS-00005-of-00007",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_XXS/Kimi-K2-Instruct-UD-IQ2_XXS-00005-of-00007.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/Kimi-K2-Instruct-UD-IQ2_XXS-00006-of-00007",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_XXS/Kimi-K2-Instruct-UD-IQ2_XXS-00006-of-00007.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-IQ2_XXS/Kimi-K2-Instruct-UD-IQ2_XXS-00007-of-00007",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ2_XXS/Kimi-K2-Instruct-UD-IQ2_XXS-00007-of-00007.gguf",
        "file_size": "33.4 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00001-of-00009",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00001-of-00009.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00002-of-00009",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00002-of-00009.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00003-of-00009",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00003-of-00009.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00004-of-00009",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00004-of-00009.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00005-of-00009",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00005-of-00009.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00006-of-00009",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00006-of-00009.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00007-of-00009",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00007-of-00009.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00008-of-00009",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00008-of-00009.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00009-of-00009",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-IQ3_XXS/Kimi-K2-Instruct-UD-IQ3_XXS-00009-of-00009.gguf",
        "file_size": "26.2 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00001-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00001-of-00008.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00002-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00002-of-00008.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00003-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00003-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00004-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00004-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00005-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00005-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00006-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00006-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00007-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00007-of-00008.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00008-of-00008",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00008-of-00008.gguf",
        "file_size": "32.1 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00001-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00001-of-00010.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00002-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00002-of-00010.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00003-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00003-of-00010.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00004-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00004-of-00010.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00005-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00005-of-00010.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00006-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00006-of-00010.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00007-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00007-of-00010.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00008-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00008-of-00010.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00009-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00009-of-00010.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00010-of-00010",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00010-of-00010.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00001-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00001-of-00013.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00002-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00002-of-00013.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00003-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00003-of-00013.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00004-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00004-of-00013.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00005-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00005-of-00013.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00006-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00006-of-00013.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00007-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00007-of-00013.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00008-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00008-of-00013.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00009-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00009-of-00013.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00010-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00010-of-00013.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00011-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00011-of-00013.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00012-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00012-of-00013.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00013-of-00013",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Kimi-K2-Instruct-UD-Q4_K_XL-00013-of-00013.gguf",
        "file_size": "5.9 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00001-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00001-of-00016.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00002-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00002-of-00016.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00003-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00003-of-00016.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00004-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00004-of-00016.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00005-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00005-of-00016.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00006-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00006-of-00016.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00007-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00007-of-00016.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00008-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00008-of-00016.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00009-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00009-of-00016.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00010-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00010-of-00016.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00011-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00011-of-00016.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00012-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00012-of-00016.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00013-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00013-of-00016.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00014-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00014-of-00016.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00015-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00015-of-00016.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00016-of-00016",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Kimi-K2-Instruct-UD-Q5_K_XL-00016-of-00016.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00001-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00001-of-00019.gguf",
        "file_size": "44.1 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00002-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00002-of-00019.gguf",
        "file_size": "43.0 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00003-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00003-of-00019.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00004-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00004-of-00019.gguf",
        "file_size": "43.0 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00005-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00005-of-00019.gguf",
        "file_size": "44.9 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00006-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00006-of-00019.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00007-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00007-of-00019.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00008-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00008-of-00019.gguf",
        "file_size": "43.6 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00009-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00009-of-00019.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00010-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00010-of-00019.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00011-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00011-of-00019.gguf",
        "file_size": "43.6 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00012-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00012-of-00019.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00013-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00013-of-00019.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00014-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00014-of-00019.gguf",
        "file_size": "43.6 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00015-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00015-of-00019.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00016-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00016-of-00019.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00017-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00017-of-00019.gguf",
        "file_size": "43.6 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00018-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00018-of-00019.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00019-of-00019",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Kimi-K2-Instruct-UD-Q6_K_XL-00019-of-00019.gguf",
        "file_size": "28.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00001-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00001-of-00025.gguf",
        "file_size": "43.3 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00002-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00002-of-00025.gguf",
        "file_size": "42.3 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00003-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00003-of-00025.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00004-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00004-of-00025.gguf",
        "file_size": "42.2 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00005-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00005-of-00025.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00006-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00006-of-00025.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00007-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00007-of-00025.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00008-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00008-of-00025.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00009-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00009-of-00025.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00010-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00010-of-00025.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00011-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00011-of-00025.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00012-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00012-of-00025.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00013-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00013-of-00025.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00014-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00014-of-00025.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00015-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00015-of-00025.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00016-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00016-of-00025.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00017-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00017-of-00025.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00018-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00018-of-00025.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00019-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00019-of-00025.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00020-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00020-of-00025.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00021-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00021-of-00025.gguf",
        "file_size": "45.0 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00022-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00022-of-00025.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00023-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00023-of-00025.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00024-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00024-of-00025.gguf",
        "file_size": "38.0 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00025-of-00025",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Kimi-K2-Instruct-UD-Q8_K_XL-00025-of-00025.gguf",
        "file_size": "42.2 GB"
      },
      {
        "model_id": "UD-TQ1_0/Kimi-K2-Instruct-UD-TQ1_0-00001-of-00005",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-TQ1_0/Kimi-K2-Instruct-UD-TQ1_0-00001-of-00005.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-TQ1_0/Kimi-K2-Instruct-UD-TQ1_0-00002-of-00005",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-TQ1_0/Kimi-K2-Instruct-UD-TQ1_0-00002-of-00005.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-TQ1_0/Kimi-K2-Instruct-UD-TQ1_0-00003-of-00005",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-TQ1_0/Kimi-K2-Instruct-UD-TQ1_0-00003-of-00005.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-TQ1_0/Kimi-K2-Instruct-UD-TQ1_0-00004-of-00005",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-TQ1_0/Kimi-K2-Instruct-UD-TQ1_0-00004-of-00005.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-TQ1_0/Kimi-K2-Instruct-UD-TQ1_0-00005-of-00005",
        "path": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/UD-TQ1_0/Kimi-K2-Instruct-UD-TQ1_0-00005-of-00005.gguf",
        "file_size": "43.0 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/README.md",
    "description": "This is a state-of-the-art 32B activated parameter MoE language model (1T total parameters) trained on 15.5T tokens with the Muon optimizer, offering superior performance in coding, reasoning, and tool use tasks, and available via Hugging Face with a Modified"
  },
  {
    "model_name": "Kimi-K2-Instruct-GGUF",
    "developer": "ubergarm",
    "downloads": 2629,
    "createdAt": "2025-07-14T16:04:11.000Z",
    "tools": false,
    "num_quants": 58,
    "quants": [
      {
        "model_id": "IQ1_KT/Kimi-K2-Instruct-IQ1_KT-00001-of-00006",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ1_KT/Kimi-K2-Instruct-IQ1_KT-00001-of-00006.gguf",
        "file_size": "39.8 GB"
      },
      {
        "model_id": "IQ1_KT/Kimi-K2-Instruct-IQ1_KT-00002-of-00006",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ1_KT/Kimi-K2-Instruct-IQ1_KT-00002-of-00006.gguf",
        "file_size": "38.7 GB"
      },
      {
        "model_id": "IQ1_KT/Kimi-K2-Instruct-IQ1_KT-00003-of-00006",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ1_KT/Kimi-K2-Instruct-IQ1_KT-00003-of-00006.gguf",
        "file_size": "38.7 GB"
      },
      {
        "model_id": "IQ1_KT/Kimi-K2-Instruct-IQ1_KT-00004-of-00006",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ1_KT/Kimi-K2-Instruct-IQ1_KT-00004-of-00006.gguf",
        "file_size": "38.7 GB"
      },
      {
        "model_id": "IQ1_KT/Kimi-K2-Instruct-IQ1_KT-00005-of-00006",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ1_KT/Kimi-K2-Instruct-IQ1_KT-00005-of-00006.gguf",
        "file_size": "38.7 GB"
      },
      {
        "model_id": "IQ1_KT/Kimi-K2-Instruct-IQ1_KT-00006-of-00006",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ1_KT/Kimi-K2-Instruct-IQ1_KT-00006-of-00006.gguf",
        "file_size": "39.6 GB"
      },
      {
        "model_id": "IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00001-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00001-of-00008.gguf",
        "file_size": "43.7 GB"
      },
      {
        "model_id": "IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00002-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00002-of-00008.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00003-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00003-of-00008.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00004-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00004-of-00008.gguf",
        "file_size": "44.6 GB"
      },
      {
        "model_id": "IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00005-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00005-of-00008.gguf",
        "file_size": "44.2 GB"
      },
      {
        "model_id": "IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00006-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00006-of-00008.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00007-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00007-of-00008.gguf",
        "file_size": "44.6 GB"
      },
      {
        "model_id": "IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00008-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KL/Kimi-K2-Instruct-IQ2_KL-00008-of-00008.gguf",
        "file_size": "39.3 GB"
      },
      {
        "model_id": "IQ2_KS/Kimi-K2-Instruct-IQ2_KS-00001-of-00007",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KS/Kimi-K2-Instruct-IQ2_KS-00001-of-00007.gguf",
        "file_size": "41.3 GB"
      },
      {
        "model_id": "IQ2_KS/Kimi-K2-Instruct-IQ2_KS-00002-of-00007",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KS/Kimi-K2-Instruct-IQ2_KS-00002-of-00007.gguf",
        "file_size": "41.5 GB"
      },
      {
        "model_id": "IQ2_KS/Kimi-K2-Instruct-IQ2_KS-00003-of-00007",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KS/Kimi-K2-Instruct-IQ2_KS-00003-of-00007.gguf",
        "file_size": "41.6 GB"
      },
      {
        "model_id": "IQ2_KS/Kimi-K2-Instruct-IQ2_KS-00004-of-00007",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KS/Kimi-K2-Instruct-IQ2_KS-00004-of-00007.gguf",
        "file_size": "41.8 GB"
      },
      {
        "model_id": "IQ2_KS/Kimi-K2-Instruct-IQ2_KS-00005-of-00007",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KS/Kimi-K2-Instruct-IQ2_KS-00005-of-00007.gguf",
        "file_size": "41.5 GB"
      },
      {
        "model_id": "IQ2_KS/Kimi-K2-Instruct-IQ2_KS-00006-of-00007",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KS/Kimi-K2-Instruct-IQ2_KS-00006-of-00007.gguf",
        "file_size": "41.6 GB"
      },
      {
        "model_id": "IQ2_KS/Kimi-K2-Instruct-IQ2_KS-00007-of-00007",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ2_KS/Kimi-K2-Instruct-IQ2_KS-00007-of-00007.gguf",
        "file_size": "40.9 GB"
      },
      {
        "model_id": "IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00001-of-00010",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00001-of-00010.gguf",
        "file_size": "44.0 GB"
      },
      {
        "model_id": "IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00002-of-00010",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00002-of-00010.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00003-of-00010",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00003-of-00010.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00004-of-00010",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00004-of-00010.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00005-of-00010",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00005-of-00010.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00006-of-00010",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00006-of-00010.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00007-of-00010",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00007-of-00010.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00008-of-00010",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00008-of-00010.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00009-of-00010",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00009-of-00010.gguf",
        "file_size": "42.9 GB"
      },
      {
        "model_id": "IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00010-of-00010",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ3_KS/Kimi-K2-Instruct-IQ3_KS-00010-of-00010.gguf",
        "file_size": "43.8 GB"
      },
      {
        "model_id": "IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00001-of-00013",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00001-of-00013.gguf",
        "file_size": "41.7 GB"
      },
      {
        "model_id": "IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00002-of-00013",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00002-of-00013.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00003-of-00013",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00003-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00004-of-00013",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00004-of-00013.gguf",
        "file_size": "43.2 GB"
      },
      {
        "model_id": "IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00005-of-00013",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00005-of-00013.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00006-of-00013",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00006-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00007-of-00013",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00007-of-00013.gguf",
        "file_size": "43.2 GB"
      },
      {
        "model_id": "IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00008-of-00013",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00008-of-00013.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00009-of-00013",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00009-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00010-of-00013",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00010-of-00013.gguf",
        "file_size": "43.2 GB"
      },
      {
        "model_id": "IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00011-of-00013",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00011-of-00013.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00012-of-00013",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00012-of-00013.gguf",
        "file_size": "43.1 GB"
      },
      {
        "model_id": "IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00013-of-00013",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ4_KS/Kimi-K2-Instruct-IQ4_KS-00013-of-00013.gguf",
        "file_size": "40.7 GB"
      },
      {
        "model_id": "mainline/imatrix-mainline-pr9400-plus-kimi-k2-942c55cd5-Kimi-K2-Instruct-Q8_0",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/mainline/imatrix-mainline-pr9400-plus-kimi-k2-942c55cd5-Kimi-K2-Instruct-Q8_0.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "smol-IQ1_KT/Kimi-K2-Instruct-smol-IQ1_KT-00001-of-00005",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/smol-IQ1_KT/Kimi-K2-Instruct-smol-IQ1_KT-00001-of-00005.gguf",
        "file_size": "44.5 GB"
      },
      {
        "model_id": "smol-IQ1_KT/Kimi-K2-Instruct-smol-IQ1_KT-00002-of-00005",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/smol-IQ1_KT/Kimi-K2-Instruct-smol-IQ1_KT-00002-of-00005.gguf",
        "file_size": "44.6 GB"
      },
      {
        "model_id": "smol-IQ1_KT/Kimi-K2-Instruct-smol-IQ1_KT-00003-of-00005",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/smol-IQ1_KT/Kimi-K2-Instruct-smol-IQ1_KT-00003-of-00005.gguf",
        "file_size": "44.6 GB"
      },
      {
        "model_id": "smol-IQ1_KT/Kimi-K2-Instruct-smol-IQ1_KT-00004-of-00005",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/smol-IQ1_KT/Kimi-K2-Instruct-smol-IQ1_KT-00004-of-00005.gguf",
        "file_size": "44.7 GB"
      },
      {
        "model_id": "smol-IQ1_KT/Kimi-K2-Instruct-smol-IQ1_KT-00005-of-00005",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/smol-IQ1_KT/Kimi-K2-Instruct-smol-IQ1_KT-00005-of-00005.gguf",
        "file_size": "40.9 GB"
      },
      {
        "model_id": "smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00001-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00001-of-00008.gguf",
        "file_size": "41.1 GB"
      },
      {
        "model_id": "smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00002-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00002-of-00008.gguf",
        "file_size": "41.9 GB"
      },
      {
        "model_id": "smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00003-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00003-of-00008.gguf",
        "file_size": "41.8 GB"
      },
      {
        "model_id": "smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00004-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00004-of-00008.gguf",
        "file_size": "40.2 GB"
      },
      {
        "model_id": "smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00005-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00005-of-00008.gguf",
        "file_size": "41.8 GB"
      },
      {
        "model_id": "smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00006-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00006-of-00008.gguf",
        "file_size": "40.2 GB"
      },
      {
        "model_id": "smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00007-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00007-of-00008.gguf",
        "file_size": "41.8 GB"
      },
      {
        "model_id": "smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00008-of-00008",
        "path": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/smol-IQ2_KL/Kimi-K2-Instruct-smol-IQ2_KL-00008-of-00008.gguf",
        "file_size": "41.1 GB"
      }
    ],
    "readme": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/README.md",
    "description": "This repository provides imatrix quantized versions of the Kimi-K2-Instruct model using ik_llama.cpp, optimized for lower perplexity with specific quantization recipes and requires the ik_llama.cpp fork for proper execution."
  },
  {
    "model_name": "Kunoichi-DPO-v2-7B-GGUF",
    "developer": "brittlewis12",
    "downloads": 1380,
    "createdAt": "2024-01-16T16:33:41.000Z",
    "num_quants": 28,
    "quants": [
      {
        "model_id": "kunoichi-dpo-v2-7b.IQ1_M",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.IQ1_M.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.IQ1_S",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.IQ1_S.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.IQ2_M",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.IQ2_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.IQ2_S",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.IQ2_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.IQ2_XS",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.IQ2_XS.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.IQ2_XXS",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.IQ2_XXS.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.IQ3_M",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.IQ3_M.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.IQ3_S",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.IQ3_S.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.IQ3_XS",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.IQ3_XS.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.IQ3_XXS",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.IQ3_XXS.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.IQ4_NL",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.IQ4_NL.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.IQ4_XS",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.IQ4_XS.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q2_K",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q2_K.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q2_K_S",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q2_K_S.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q3_K_L",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q3_K_L.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q3_K_M",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q3_K_M.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q3_K_S",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q3_K_S.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q4_0",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q4_0.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q4_1",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q4_1.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q4_K_M",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q4_K_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q4_K_S",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q4_K_S.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q5_0",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q5_0.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q5_1",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q5_1.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q5_K_M",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q5_K_M.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q5_K_S",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q5_K_S.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q6_K",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q6_K.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.Q8_0",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q8_0.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "kunoichi-dpo-v2-7b.fp16",
        "path": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.fp16.gguf",
        "file_size": "13.5 GB"
      }
    ],
    "readme": "https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix",
    "developer": "Lewdiculous",
    "downloads": 13634,
    "createdAt": "2024-06-05T18:21:00.000Z",
    "num_quants": 12,
    "quants": [
      {
        "model_id": "L3-8B-Stheno-v3.2-IQ3_M-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-IQ3_M-imat.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-IQ3_S-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-IQ3_S-imat.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-IQ3_XXS-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-IQ3_XXS-imat.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-IQ4_XS-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-IQ4_XS-imat.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-Q4_K_M-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-Q4_K_M-imat.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-Q4_K_S-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-Q4_K_S-imat.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-Q5_K_M-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-Q5_K_M-imat.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-Q5_K_S-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-Q5_K_S-imat.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-Q6_K-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-Q6_K-imat.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.2-Q8_0-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.2-Q8_0-imat.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "[ARM-Friendly]-L3-8B-Stheno-v3.2-Q4_0-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/[ARM-Friendly]-L3-8B-Stheno-v3.2-Q4_0-imat.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "test",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/test.gguf",
        "file_size": "4.6 GB"
      }
    ],
    "readme": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "L3-8B-Stheno-v3.3-32K-GGUF-IQ-Imatrix",
    "developer": "Lewdiculous",
    "downloads": 746,
    "createdAt": "2024-06-23T20:13:10.000Z",
    "tools": false,
    "num_quants": 12,
    "quants": [
      {
        "model_id": "L3-8B-Stheno-v3.3-32K-BF16",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.3-32K-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.3-32K-BF16.gguf",
        "file_size": "15.0 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.3-32K-F16",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.3-32K-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.3-32K-F16.gguf",
        "file_size": "15.0 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.3-32K-IQ3_M-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.3-32K-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.3-32K-IQ3_M-imat.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.3-32K-IQ3_S-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.3-32K-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.3-32K-IQ3_S-imat.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.3-32K-IQ3_XXS-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.3-32K-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.3-32K-IQ3_XXS-imat.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.3-32K-IQ4_XS-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.3-32K-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.3-32K-IQ4_XS-imat.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.3-32K-Q4_K_M-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.3-32K-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.3-32K-Q4_K_M-imat.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.3-32K-Q4_K_S-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.3-32K-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.3-32K-Q4_K_S-imat.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.3-32K-Q5_K_M-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.3-32K-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.3-32K-Q5_K_M-imat.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.3-32K-Q5_K_S-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.3-32K-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.3-32K-Q5_K_S-imat.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.3-32K-Q6_K-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.3-32K-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.3-32K-Q6_K-imat.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "L3-8B-Stheno-v3.3-32K-Q8_0-imat",
        "path": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.3-32K-GGUF-IQ-Imatrix/resolve/main/L3-8B-Stheno-v3.3-32K-Q8_0-imat.gguf",
        "file_size": "8.0 GB"
      }
    ],
    "readme": "https://huggingface.co/Lewdiculous/L3-8B-Stheno-v3.3-32K-GGUF-IQ-Imatrix/resolve/main/README.md",
    "description": "This is a GGUF-IQ-Imatrix quantized version of the Sao10K/L3-8B-Stheno-v3.3-32K model, trained for roleplay and SillyTavern tasks with 32K context support, optimized for performance on"
  },
  {
    "model_name": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF",
    "developer": "DavidAU",
    "downloads": 11277,
    "createdAt": "2024-10-28T10:09:51.000Z",
    "tools": false,
    "num_quants": 14,
    "quants": [
      {
        "model_id": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-IQ4_XS",
        "path": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-IQ4_XS.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q2_k",
        "path": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q2_k.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q3_k_l",
        "path": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q3_k_l.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q3_k_m",
        "path": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q3_k_m.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q3_k_s",
        "path": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q3_k_s.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q4_0_4_4",
        "path": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q4_0_4_4.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q4_0_4_8",
        "path": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q4_0_4_8.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q4_0_8_8",
        "path": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q4_0_8_8.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q4_k_m",
        "path": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q4_k_m.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q4_k_s",
        "path": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q4_k_s.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q5_k_s",
        "path": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q5_k_s.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q6_k",
        "path": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q6_k.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-Q8_0.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-q5_k_m",
        "path": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-D_AU-q5_k_m.gguf",
        "file_size": "5.0 GB"
      }
    ],
    "readme": "https://huggingface.co/DavidAU/L3.2-Rogue-Creative-Instruct-Uncensored-Abliterated-7B-GGUF/resolve/main/README.md",
    "description": "This is a modified Llama 3.2 model designed for creative writing, with enhanced prose generation, uncensored content, and support for various genres including science fiction, horror, and romance, offering vivid, detailed, and emotionally charged outputs through advanced parameters and templates."
  },
  {
    "model_name": "Lexi-Llama-3-8B-Uncensored-GGUF",
    "developer": "bartowski",
    "downloads": 3872,
    "createdAt": "2024-04-24T03:51:21.000Z",
    "num_quants": 22,
    "quants": [
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ1_M",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ1_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ1_S",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ1_S.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ2_M",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ2_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ2_S",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ2_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ2_XS",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ2_XS.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ2_XXS",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ2_XXS.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ3_M",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ3_M.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ3_S",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ3_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ3_XS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ3_XXS.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ4_NL",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ4_NL.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-IQ4_XS.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q2_K",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q6_K",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored-Q8_0",
        "path": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored-Q8_0.gguf",
        "file_size": "8.0 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Lexi-Llama-3-8B-Uncensored-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "LFM2-1.2B-GGUF",
    "developer": "LiquidAI",
    "downloads": 15467,
    "createdAt": "2025-07-12T12:01:44.000Z",
    "tools": false,
    "num_quants": 6,
    "quants": [
      {
        "model_id": "LFM2-1.2B-F16",
        "path": "https://huggingface.co/LiquidAI/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-F16.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "LFM2-1.2B-Q4_0",
        "path": "https://huggingface.co/LiquidAI/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q4_0.gguf",
        "file_size": "663.5 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q4_K_M",
        "path": "https://huggingface.co/LiquidAI/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q4_K_M.gguf",
        "file_size": "697.0 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q5_K_M",
        "path": "https://huggingface.co/LiquidAI/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q5_K_M.gguf",
        "file_size": "804.3 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q6_K",
        "path": "https://huggingface.co/LiquidAI/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q6_K.gguf",
        "file_size": "918.2 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q8_0",
        "path": "https://huggingface.co/LiquidAI/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q8_0.gguf",
        "file_size": "1.2 GB"
      }
    ],
    "readme": "https://huggingface.co/LiquidAI/LFM2-1.2B-GGUF/resolve/main/README.md",
    "description": "LFM2-1.2B-GGUF is a hybrid model by Liquid AI optimized for edge AI and on-device deployment, offering high quality, speed, and memory efficiency."
  },
  {
    "model_name": "LFM2-1.2B-GGUF",
    "developer": "unsloth",
    "downloads": 2445,
    "createdAt": "2025-07-11T20:08:30.000Z",
    "num_quants": 19,
    "quants": [
      {
        "model_id": "LFM2-1.2B-F16",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-F16.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "LFM2-1.2B-Q2_K",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q2_K.gguf",
        "file_size": "461.0 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q2_K_L",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q2_K_L.gguf",
        "file_size": "461.0 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q3_K_M",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q3_K_M.gguf",
        "file_size": "572.5 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q3_K_S",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q3_K_S.gguf",
        "file_size": "532.3 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q4_0",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q4_0.gguf",
        "file_size": "663.5 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q4_1",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q4_1.gguf",
        "file_size": "725.3 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q4_K_M",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q4_K_M.gguf",
        "file_size": "697.0 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q4_K_S",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q4_K_S.gguf",
        "file_size": "668.0 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q5_K_M",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q5_K_M.gguf",
        "file_size": "804.3 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q5_K_S",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q5_K_S.gguf",
        "file_size": "787.0 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q6_K",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q6_K.gguf",
        "file_size": "918.2 MB"
      },
      {
        "model_id": "LFM2-1.2B-Q8_0",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-Q8_0.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "LFM2-1.2B-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-UD-Q2_K_XL.gguf",
        "file_size": "461.0 MB"
      },
      {
        "model_id": "LFM2-1.2B-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-UD-Q3_K_XL.gguf",
        "file_size": "572.5 MB"
      },
      {
        "model_id": "LFM2-1.2B-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-UD-Q4_K_XL.gguf",
        "file_size": "697.0 MB"
      },
      {
        "model_id": "LFM2-1.2B-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-UD-Q5_K_XL.gguf",
        "file_size": "804.3 MB"
      },
      {
        "model_id": "LFM2-1.2B-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-UD-Q6_K_XL.gguf",
        "file_size": "949.2 MB"
      },
      {
        "model_id": "LFM2-1.2B-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/LFM2-1.2B-UD-Q8_K_XL.gguf",
        "file_size": "1.3 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/LFM2-1.2B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "LFM2-350M-GGUF",
    "developer": "LiquidAI",
    "downloads": 2317,
    "createdAt": "2025-07-12T12:02:17.000Z",
    "tools": false,
    "num_quants": 6,
    "quants": [
      {
        "model_id": "LFM2-350M-F16",
        "path": "https://huggingface.co/LiquidAI/LFM2-350M-GGUF/resolve/main/LFM2-350M-F16.gguf",
        "file_size": "678.5 MB"
      },
      {
        "model_id": "LFM2-350M-Q4_0",
        "path": "https://huggingface.co/LiquidAI/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q4_0.gguf",
        "file_size": "209.1 MB"
      },
      {
        "model_id": "LFM2-350M-Q4_K_M",
        "path": "https://huggingface.co/LiquidAI/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q4_K_M.gguf",
        "file_size": "218.7 MB"
      },
      {
        "model_id": "LFM2-350M-Q5_K_M",
        "path": "https://huggingface.co/LiquidAI/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q5_K_M.gguf",
        "file_size": "248.3 MB"
      },
      {
        "model_id": "LFM2-350M-Q6_K",
        "path": "https://huggingface.co/LiquidAI/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q6_K.gguf",
        "file_size": "279.8 MB"
      },
      {
        "model_id": "LFM2-350M-Q8_0",
        "path": "https://huggingface.co/LiquidAI/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q8_0.gguf",
        "file_size": "361.6 MB"
      }
    ],
    "readme": "https://huggingface.co/LiquidAI/LFM2-350M-GGUF/resolve/main/README.md",
    "description": "LFM2-350M-GGUF is a hybrid model by Liquid AI optimized for edge AI and on-device deployment, designed for high quality, speed, and memory efficiency."
  },
  {
    "model_name": "LFM2-350M-GGUF",
    "developer": "unsloth",
    "downloads": 1260,
    "createdAt": "2025-07-11T19:57:27.000Z",
    "num_quants": 19,
    "quants": [
      {
        "model_id": "LFM2-350M-F16",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-F16.gguf",
        "file_size": "678.5 MB"
      },
      {
        "model_id": "LFM2-350M-Q2_K",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q2_K.gguf",
        "file_size": "153.2 MB"
      },
      {
        "model_id": "LFM2-350M-Q2_K_L",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q2_K_L.gguf",
        "file_size": "153.2 MB"
      },
      {
        "model_id": "LFM2-350M-Q3_K_M",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q3_K_M.gguf",
        "file_size": "184.2 MB"
      },
      {
        "model_id": "LFM2-350M-Q3_K_S",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q3_K_S.gguf",
        "file_size": "172.8 MB"
      },
      {
        "model_id": "LFM2-350M-Q4_0",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q4_0.gguf",
        "file_size": "209.1 MB"
      },
      {
        "model_id": "LFM2-350M-Q4_1",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q4_1.gguf",
        "file_size": "226.3 MB"
      },
      {
        "model_id": "LFM2-350M-Q4_K_M",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q4_K_M.gguf",
        "file_size": "218.7 MB"
      },
      {
        "model_id": "LFM2-350M-Q4_K_S",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q4_K_S.gguf",
        "file_size": "210.5 MB"
      },
      {
        "model_id": "LFM2-350M-Q5_K_M",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q5_K_M.gguf",
        "file_size": "248.3 MB"
      },
      {
        "model_id": "LFM2-350M-Q5_K_S",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q5_K_S.gguf",
        "file_size": "243.4 MB"
      },
      {
        "model_id": "LFM2-350M-Q6_K",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q6_K.gguf",
        "file_size": "279.8 MB"
      },
      {
        "model_id": "LFM2-350M-Q8_0",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-Q8_0.gguf",
        "file_size": "361.6 MB"
      },
      {
        "model_id": "LFM2-350M-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-UD-Q2_K_XL.gguf",
        "file_size": "153.2 MB"
      },
      {
        "model_id": "LFM2-350M-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-UD-Q3_K_XL.gguf",
        "file_size": "184.2 MB"
      },
      {
        "model_id": "LFM2-350M-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-UD-Q4_K_XL.gguf",
        "file_size": "218.7 MB"
      },
      {
        "model_id": "LFM2-350M-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-UD-Q5_K_XL.gguf",
        "file_size": "248.3 MB"
      },
      {
        "model_id": "LFM2-350M-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-UD-Q6_K_XL.gguf",
        "file_size": "295.3 MB"
      },
      {
        "model_id": "LFM2-350M-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/LFM2-350M-UD-Q8_K_XL.gguf",
        "file_size": "421.6 MB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/LFM2-350M-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "LFM2-700M-GGUF",
    "developer": "LiquidAI",
    "downloads": 1776,
    "createdAt": "2025-07-12T12:02:37.000Z",
    "tools": false,
    "num_quants": 6,
    "quants": [
      {
        "model_id": "LFM2-700M-F16",
        "path": "https://huggingface.co/LiquidAI/LFM2-700M-GGUF/resolve/main/LFM2-700M-F16.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "LFM2-700M-Q4_0",
        "path": "https://huggingface.co/LiquidAI/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q4_0.gguf",
        "file_size": "425.6 MB"
      },
      {
        "model_id": "LFM2-700M-Q4_K_M",
        "path": "https://huggingface.co/LiquidAI/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q4_K_M.gguf",
        "file_size": "446.9 MB"
      },
      {
        "model_id": "LFM2-700M-Q5_K_M",
        "path": "https://huggingface.co/LiquidAI/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q5_K_M.gguf",
        "file_size": "513.1 MB"
      },
      {
        "model_id": "LFM2-700M-Q6_K",
        "path": "https://huggingface.co/LiquidAI/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q6_K.gguf",
        "file_size": "583.4 MB"
      },
      {
        "model_id": "LFM2-700M-Q8_0",
        "path": "https://huggingface.co/LiquidAI/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q8_0.gguf",
        "file_size": "754.9 MB"
      }
    ],
    "readme": "https://huggingface.co/LiquidAI/LFM2-700M-GGUF/resolve/main/README.md",
    "description": "LFM2-700M-GGUF is a high-quality, memory-efficient hybrid model from Liquid AI optimized for edge AI and on-device deployment, compatible with llama.cpp and GGUF format."
  },
  {
    "model_name": "LFM2-700M-GGUF",
    "developer": "unsloth",
    "downloads": 2720,
    "createdAt": "2025-07-11T20:08:04.000Z",
    "num_quants": 19,
    "quants": [
      {
        "model_id": "LFM2-700M-F16",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-F16.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "LFM2-700M-Q2_K",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q2_K.gguf",
        "file_size": "300.5 MB"
      },
      {
        "model_id": "LFM2-700M-Q2_K_L",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q2_K_L.gguf",
        "file_size": "300.5 MB"
      },
      {
        "model_id": "LFM2-700M-Q3_K_M",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q3_K_M.gguf",
        "file_size": "369.7 MB"
      },
      {
        "model_id": "LFM2-700M-Q3_K_S",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q3_K_S.gguf",
        "file_size": "344.4 MB"
      },
      {
        "model_id": "LFM2-700M-Q4_0",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q4_0.gguf",
        "file_size": "425.6 MB"
      },
      {
        "model_id": "LFM2-700M-Q4_1",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q4_1.gguf",
        "file_size": "463.9 MB"
      },
      {
        "model_id": "LFM2-700M-Q4_K_M",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q4_K_M.gguf",
        "file_size": "446.9 MB"
      },
      {
        "model_id": "LFM2-700M-Q4_K_S",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q4_K_S.gguf",
        "file_size": "428.6 MB"
      },
      {
        "model_id": "LFM2-700M-Q5_K_M",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q5_K_M.gguf",
        "file_size": "513.1 MB"
      },
      {
        "model_id": "LFM2-700M-Q5_K_S",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q5_K_S.gguf",
        "file_size": "502.1 MB"
      },
      {
        "model_id": "LFM2-700M-Q6_K",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q6_K.gguf",
        "file_size": "583.4 MB"
      },
      {
        "model_id": "LFM2-700M-Q8_0",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-Q8_0.gguf",
        "file_size": "754.9 MB"
      },
      {
        "model_id": "LFM2-700M-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-UD-Q2_K_XL.gguf",
        "file_size": "300.5 MB"
      },
      {
        "model_id": "LFM2-700M-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-UD-Q3_K_XL.gguf",
        "file_size": "369.7 MB"
      },
      {
        "model_id": "LFM2-700M-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-UD-Q4_K_XL.gguf",
        "file_size": "446.9 MB"
      },
      {
        "model_id": "LFM2-700M-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-UD-Q5_K_XL.gguf",
        "file_size": "513.1 MB"
      },
      {
        "model_id": "LFM2-700M-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-UD-Q6_K_XL.gguf",
        "file_size": "606.7 MB"
      },
      {
        "model_id": "LFM2-700M-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/LFM2-700M-UD-Q8_K_XL.gguf",
        "file_size": "844.9 MB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/LFM2-700M-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Lily-Cybersecurity-7B-v0.2-GGUF",
    "developer": "QuantFactory",
    "downloads": 263,
    "createdAt": "2024-10-20T14:09:56.000Z",
    "tools": false,
    "num_quants": 14,
    "quants": [
      {
        "model_id": "Lily-Cybersecurity-7B-v0.2.Q2_K",
        "path": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/Lily-Cybersecurity-7B-v0.2.Q2_K.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "Lily-Cybersecurity-7B-v0.2.Q3_K_L",
        "path": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/Lily-Cybersecurity-7B-v0.2.Q3_K_L.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "Lily-Cybersecurity-7B-v0.2.Q3_K_M",
        "path": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/Lily-Cybersecurity-7B-v0.2.Q3_K_M.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Lily-Cybersecurity-7B-v0.2.Q3_K_S",
        "path": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/Lily-Cybersecurity-7B-v0.2.Q3_K_S.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Lily-Cybersecurity-7B-v0.2.Q4_0",
        "path": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/Lily-Cybersecurity-7B-v0.2.Q4_0.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "Lily-Cybersecurity-7B-v0.2.Q4_1",
        "path": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/Lily-Cybersecurity-7B-v0.2.Q4_1.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "Lily-Cybersecurity-7B-v0.2.Q4_K_M",
        "path": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/Lily-Cybersecurity-7B-v0.2.Q4_K_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Lily-Cybersecurity-7B-v0.2.Q4_K_S",
        "path": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/Lily-Cybersecurity-7B-v0.2.Q4_K_S.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Lily-Cybersecurity-7B-v0.2.Q5_0",
        "path": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/Lily-Cybersecurity-7B-v0.2.Q5_0.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Lily-Cybersecurity-7B-v0.2.Q5_1",
        "path": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/Lily-Cybersecurity-7B-v0.2.Q5_1.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "Lily-Cybersecurity-7B-v0.2.Q5_K_M",
        "path": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/Lily-Cybersecurity-7B-v0.2.Q5_K_M.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "Lily-Cybersecurity-7B-v0.2.Q5_K_S",
        "path": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/Lily-Cybersecurity-7B-v0.2.Q5_K_S.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Lily-Cybersecurity-7B-v0.2.Q6_K",
        "path": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/Lily-Cybersecurity-7B-v0.2.Q6_K.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "Lily-Cybersecurity-7B-v0.2.Q8_0",
        "path": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/Lily-Cybersecurity-7B-v0.2.Q8_0.gguf",
        "file_size": "7.2 GB"
      }
    ],
    "readme": "https://huggingface.co/QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF/resolve/main/README.md",
    "description": "QuantFactory/Lily-Cybersecurity-7B-v0.2-GGUF is a quantized cybersecurity-focused Mistral-7B-Instruct-v0.2 model fine-tuned with 22,000 cybersecurity-related data pairs for tasks like threat analysis, security protocols,"
  },
  {
    "model_name": "Llama-2-7B-Chat-GGUF",
    "developer": "TheBloke",
    "downloads": 77594,
    "createdAt": "2023-09-04T16:38:41.000Z",
    "num_quants": 12,
    "quants": [
      {
        "model_id": "llama-2-7b-chat.Q2_K",
        "path": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q2_K.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "llama-2-7b-chat.Q3_K_L",
        "path": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q3_K_L.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "llama-2-7b-chat.Q3_K_M",
        "path": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q3_K_M.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "llama-2-7b-chat.Q3_K_S",
        "path": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q3_K_S.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "llama-2-7b-chat.Q4_0",
        "path": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_0.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "llama-2-7b-chat.Q4_K_M",
        "path": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "llama-2-7b-chat.Q4_K_S",
        "path": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_S.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "llama-2-7b-chat.Q5_0",
        "path": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q5_0.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "llama-2-7b-chat.Q5_K_M",
        "path": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q5_K_M.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "llama-2-7b-chat.Q5_K_S",
        "path": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q5_K_S.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "llama-2-7b-chat.Q6_K",
        "path": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q6_K.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "llama-2-7b-chat.Q8_0",
        "path": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q8_0.gguf",
        "file_size": "6.7 GB"
      }
    ],
    "readme": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Llama-3-8B-Lexi-Uncensored-GGUF",
    "developer": "Orenguteng",
    "downloads": 9496,
    "createdAt": "2024-04-23T21:57:52.000Z",
    "num_quants": 4,
    "quants": [
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored_F16",
        "path": "https://huggingface.co/Orenguteng/Llama-3-8B-Lexi-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored_F16.gguf",
        "file_size": "15.0 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored_Q4_K_M",
        "path": "https://huggingface.co/Orenguteng/Llama-3-8B-Lexi-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored_Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored_Q5_K_M",
        "path": "https://huggingface.co/Orenguteng/Llama-3-8B-Lexi-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored_Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Lexi-Llama-3-8B-Uncensored_Q8_0",
        "path": "https://huggingface.co/Orenguteng/Llama-3-8B-Lexi-Uncensored-GGUF/resolve/main/Lexi-Llama-3-8B-Uncensored_Q8_0.gguf",
        "file_size": "8.0 GB"
      }
    ],
    "readme": "https://huggingface.co/Orenguteng/Llama-3-8B-Lexi-Uncensored-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Llama-3-8B-LexiFun-Uncensored-V1-GGUF",
    "developer": "bartowski",
    "downloads": 504,
    "createdAt": "2024-05-01T16:13:51.000Z",
    "num_quants": 22,
    "quants": [
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-IQ1_M",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-IQ1_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-IQ1_S",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-IQ1_S.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-IQ2_M",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-IQ2_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-IQ2_S",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-IQ2_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-IQ2_XS",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-IQ2_XS.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-IQ2_XXS",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-IQ2_XXS.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-IQ3_M",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-IQ3_M.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-IQ3_S",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-IQ3_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-IQ3_XS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-IQ3_XXS.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-IQ4_NL",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-IQ4_NL.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-IQ4_XS.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-Q2_K",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-Q6_K",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Llama-3-8B-LexiFun-Uncensored-V1-Q8_0",
        "path": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/Llama-3-8B-LexiFun-Uncensored-V1-Q8_0.gguf",
        "file_size": "8.0 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Llama-3-8B-LexiFun-Uncensored-V1-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "llama-3-sqlcoder-8b-GGUF",
    "developer": "QuantFactory",
    "downloads": 619,
    "createdAt": "2024-05-29T04:25:33.000Z",
    "num_quants": 14,
    "quants": [
      {
        "model_id": "llama-3-sqlcoder-8b.Q2_K",
        "path": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "llama-3-sqlcoder-8b.Q3_K_L",
        "path": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "llama-3-sqlcoder-8b.Q3_K_M",
        "path": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "llama-3-sqlcoder-8b.Q3_K_S",
        "path": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "llama-3-sqlcoder-8b.Q4_0",
        "path": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q4_0.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "llama-3-sqlcoder-8b.Q4_1",
        "path": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q4_1.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "llama-3-sqlcoder-8b.Q4_K_M",
        "path": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "llama-3-sqlcoder-8b.Q4_K_S",
        "path": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "llama-3-sqlcoder-8b.Q5_0",
        "path": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q5_0.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "llama-3-sqlcoder-8b.Q5_1",
        "path": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q5_1.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "llama-3-sqlcoder-8b.Q5_K_M",
        "path": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "llama-3-sqlcoder-8b.Q5_K_S",
        "path": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "llama-3-sqlcoder-8b.Q6_K",
        "path": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "llama-3-sqlcoder-8b.Q8_0",
        "path": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q8_0.gguf",
        "file_size": "8.0 GB"
      }
    ],
    "readme": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Llama-3.2-1B-Instruct-GGUF",
    "developer": "unsloth",
    "downloads": 36793,
    "createdAt": "2024-09-25T19:32:39.000Z",
    "num_quants": 27,
    "quants": [
      {
        "model_id": "Llama-3.2-1B-Instruct-BF16",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-BF16.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-F16",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-F16.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-IQ4_NL.gguf",
        "file_size": "737.2 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-IQ4_XS.gguf",
        "file_size": "708.7 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q2_K",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q2_K.gguf",
        "file_size": "554.0 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q2_K_L.gguf",
        "file_size": "554.0 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q3_K_M.gguf",
        "file_size": "658.8 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q3_K_S.gguf",
        "file_size": "612.0 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_0",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_0.gguf",
        "file_size": "737.2 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_1",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_1.gguf",
        "file_size": "793.2 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_M.gguf",
        "file_size": "770.3 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_S.gguf",
        "file_size": "739.7 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q5_K_M.gguf",
        "file_size": "869.3 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q5_K_S.gguf",
        "file_size": "851.2 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q6_K",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q6_K.gguf",
        "file_size": "974.5 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q8_0",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q8_0.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-UD-IQ1_M.gguf",
        "file_size": "418.8 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-UD-IQ1_S.gguf",
        "file_size": "402.1 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-UD-IQ2_M.gguf",
        "file_size": "511.5 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-UD-IQ2_XXS.gguf",
        "file_size": "442.8 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-UD-IQ3_XXS.gguf",
        "file_size": "548.7 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-UD-Q2_K_XL.gguf",
        "file_size": "577.5 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-UD-Q3_K_XL.gguf",
        "file_size": "690.5 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-UD-Q4_K_XL.gguf",
        "file_size": "795.6 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-UD-Q5_K_XL.gguf",
        "file_size": "877.4 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-UD-Q6_K_XL.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-UD-Q8_K_XL.gguf",
        "file_size": "1.7 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Llama-3.2-1B-Instruct-GGUF",
    "developer": "bartowski",
    "downloads": 51637,
    "createdAt": "2024-09-25T18:35:25.000Z",
    "tools": false,
    "num_quants": 18,
    "quants": [
      {
        "model_id": "Llama-3.2-1B-Instruct-IQ3_M",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-IQ3_M.gguf",
        "file_size": "626.8 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-IQ4_XS.gguf",
        "file_size": "708.7 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q3_K_L.gguf",
        "file_size": "698.6 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q3_K_XL.gguf",
        "file_size": "759.3 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_0",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_0.gguf",
        "file_size": "737.2 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_0_4_4",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_0_4_4.gguf",
        "file_size": "735.2 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_0_4_8",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_0_4_8.gguf",
        "file_size": "735.2 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_0_8_8",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_0_8_8.gguf",
        "file_size": "735.2 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_L.gguf",
        "file_size": "830.9 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_M.gguf",
        "file_size": "770.3 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_S.gguf",
        "file_size": "739.7 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q5_K_L.gguf",
        "file_size": "929.9 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q5_K_M.gguf",
        "file_size": "869.3 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q5_K_S.gguf",
        "file_size": "851.2 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q6_K",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q6_K.gguf",
        "file_size": "974.5 MB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q6_K_L.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-Q8_0",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q8_0.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Llama-3.2-1B-Instruct-f16",
        "path": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-f16.gguf",
        "file_size": "2.3 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Llama-3.2-1B-Instruct model by Bartowski, licensed under the Llama 3.2 Community License, offering various quantization types for different performance and memory trade-offs."
  },
  {
    "model_name": "Llama-3.2-3B-Instruct-GGUF",
    "developer": "bartowski",
    "downloads": 333954,
    "createdAt": "2024-09-25T18:35:33.000Z",
    "tools": false,
    "num_quants": 18,
    "quants": [
      {
        "model_id": "Llama-3.2-3B-Instruct-IQ3_M",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-IQ3_M.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-IQ4_XS.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q3_K_L.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q3_K_XL.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q4_0",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_0.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q4_0_4_4",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_0_4_4.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q4_0_4_8",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_0_4_8.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q4_0_8_8",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_0_8_8.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_L.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_L.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_M.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_S.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q6_K",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q6_K.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q6_K_L.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q8_0",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q8_0.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-f16",
        "path": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-f16.gguf",
        "file_size": "6.0 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Llama-3.2-3B-Instruct model by Bartowski, offering various quantization types (e.g., Q4_K_M, Q5_K_S) for different performance and memory trade-offs, with a focus on compatibility with ARM and CPU"
  },
  {
    "model_name": "Llama-3.2-3B-Instruct-GGUF",
    "developer": "unsloth",
    "downloads": 24558,
    "createdAt": "2024-09-25T19:47:33.000Z",
    "num_quants": 27,
    "quants": [
      {
        "model_id": "Llama-3.2-3B-Instruct-BF16",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-BF16.gguf",
        "file_size": "6.0 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-F16",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-F16.gguf",
        "file_size": "6.0 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-IQ4_NL.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-IQ4_XS.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q2_K",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q2_K.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q2_K_L.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q3_K_M.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q3_K_S.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q4_0",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_0.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q4_1",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_1.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_M.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_S.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q6_K",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q6_K.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-Q8_0",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q8_0.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-UD-IQ1_M.gguf",
        "file_size": "915.9 MB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-UD-IQ1_S.gguf",
        "file_size": "870.1 MB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-UD-IQ2_M.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-UD-IQ2_XXS.gguf",
        "file_size": "998.1 MB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-UD-IQ3_XXS.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-UD-Q2_K_XL.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-UD-Q3_K_XL.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-UD-Q4_K_XL.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-UD-Q5_K_XL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-UD-Q6_K_XL.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Llama-3.2-3B-Instruct-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-UD-Q8_K_XL.gguf",
        "file_size": "3.9 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF",
    "developer": "DavidAU",
    "downloads": 5794,
    "createdAt": "2024-12-12T01:30:01.000Z",
    "num_quants": 14,
    "quants": [
      {
        "model_id": "Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-IQ4_XS",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-IQ4_XS.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q2_k",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q2_k.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q3_k_l",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q3_k_l.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q3_k_m",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q3_k_m.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q3_k_s",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q3_k_s.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q4_0_4_4",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q4_0_4_4.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q4_0_4_8",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q4_0_4_8.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q4_0_8_8",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q4_0_8_8.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q4_k_m",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q4_k_m.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q4_k_s",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q4_k_s.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q5_k_s",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q5_k_s.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q6_k",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q6_k.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-Q8_0.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-q5_k_m",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/Llama-3.2-4X3B-MOE-Hell-California-10B-D_AU-q5_k_m.gguf",
        "file_size": "6.6 GB"
      }
    ],
    "readme": "https://huggingface.co/DavidAU/Llama-3.2-4X3B-MOE-Hell-California-Uncensored-10B-GGUF/resolve/main/README.md",
    "description": "This model is a powerful Llama 3.2 MOE with 10B parameters, combining four top Llama 3.2 3B models for exceptional creative writing, vivid prose, and uncensored output across all genres, including horror, science fiction, romance, and roleplay",
    "tools": false
  },
  {
    "model_name": "Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF",
    "developer": "DavidAU",
    "downloads": 89700,
    "createdAt": "2024-12-10T13:12:37.000Z",
    "tools": false,
    "num_quants": 14,
    "quants": [
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-IQ4_XS",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-IQ4_XS.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q2_k",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q2_k.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q3_k_l",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q3_k_l.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q3_k_m",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q3_k_m.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q3_k_s",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q3_k_s.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_0_4_4",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_0_4_4.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_0_4_8",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_0_4_8.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_0_8_8",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_0_8_8.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_k_m",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_k_m.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_k_s",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q4_k_s.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q5_k_s",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q5_k_s.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q6_k",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q6_k.gguf",
        "file_size": "14.1 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-Q8_0.gguf",
        "file_size": "18.2 GB"
      },
      {
        "model_id": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-q5_k_m",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-q5_k_m.gguf",
        "file_size": "12.3 GB"
      }
    ],
    "readme": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF/resolve/main/README.md",
    "description": "This is a Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B model with mixture of experts for creative writing, fiction, and roleplay, capable of generating vivid, uncensored, and genre-"
  },
  {
    "model_name": "Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF",
    "developer": "DavidAU",
    "downloads": 10843,
    "createdAt": "2025-02-12T00:29:33.000Z",
    "num_quants": 11,
    "quants": [
      {
        "model_id": "L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-IQ4_XS",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF/resolve/main/L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-IQ4_XS.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q2_k",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF/resolve/main/L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q2_k.gguf",
        "file_size": "7.4 GB"
      },
      {
        "model_id": "L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q3_k_l",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF/resolve/main/L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q3_k_l.gguf",
        "file_size": "10.2 GB"
      },
      {
        "model_id": "L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q3_k_m",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF/resolve/main/L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q3_k_m.gguf",
        "file_size": "9.6 GB"
      },
      {
        "model_id": "L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q3_k_s",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF/resolve/main/L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q3_k_s.gguf",
        "file_size": "8.7 GB"
      },
      {
        "model_id": "L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q4_k_m",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF/resolve/main/L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q4_k_m.gguf",
        "file_size": "12.0 GB"
      },
      {
        "model_id": "L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q4_k_s",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF/resolve/main/L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q4_k_s.gguf",
        "file_size": "11.3 GB"
      },
      {
        "model_id": "L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q5_k_s",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF/resolve/main/L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q5_k_s.gguf",
        "file_size": "13.5 GB"
      },
      {
        "model_id": "L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q6_k",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF/resolve/main/L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q6_k.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF/resolve/main/L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q8_0.gguf",
        "file_size": "20.7 GB"
      },
      {
        "model_id": "L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-q5_k_m",
        "path": "https://huggingface.co/DavidAU/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF/resolve/main/L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-q5_k_m.gguf",
        "file_size": "13.9 GB"
      }
    ],
    "readme": "https://huggingface.co/DavidAU/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Llama-3.3-70B-Instruct-GGUF",
    "developer": "unsloth",
    "downloads": 23708,
    "createdAt": "2024-12-06T21:10:26.000Z",
    "num_quants": 38,
    "quants": [
      {
        "model_id": "BF16/Llama-3.3-70B-Instruct-BF16-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/BF16/Llama-3.3-70B-Instruct-BF16-00001-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "BF16/Llama-3.3-70B-Instruct-BF16-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/BF16/Llama-3.3-70B-Instruct-BF16-00002-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "BF16/Llama-3.3-70B-Instruct-BF16-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/BF16/Llama-3.3-70B-Instruct-BF16-00003-of-00003.gguf",
        "file_size": "38.6 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-F16/Llama-3.3-70B-Instruct-F16-00001-of-00004",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-F16/Llama-3.3-70B-Instruct-F16-00001-of-00004.gguf",
        "file_size": "37.0 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-F16/Llama-3.3-70B-Instruct-F16-00002-of-00004",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-F16/Llama-3.3-70B-Instruct-F16-00002-of-00004.gguf",
        "file_size": "37.1 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-F16/Llama-3.3-70B-Instruct-F16-00003-of-00004",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-F16/Llama-3.3-70B-Instruct-F16-00003-of-00004.gguf",
        "file_size": "37.2 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-F16/Llama-3.3-70B-Instruct-F16-00004-of-00004",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-F16/Llama-3.3-70B-Instruct-F16-00004-of-00004.gguf",
        "file_size": "20.1 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-IQ4_NL.gguf",
        "file_size": "37.3 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-IQ4_XS.gguf",
        "file_size": "35.3 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-Q2_K",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q2_K.gguf",
        "file_size": "24.6 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q2_K_L.gguf",
        "file_size": "24.8 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q3_K_M.gguf",
        "file_size": "31.9 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q3_K_S.gguf",
        "file_size": "28.8 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-Q4_0",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q4_0.gguf",
        "file_size": "37.4 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-Q4_1",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q4_1.gguf",
        "file_size": "41.3 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q4_K_M.gguf",
        "file_size": "39.6 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q4_K_S.gguf",
        "file_size": "37.6 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q5_K_M.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q5_K_S.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-Q6_K/Llama-3.3-70B-Instruct-Q6_K-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q6_K/Llama-3.3-70B-Instruct-Q6_K-00001-of-00002.gguf",
        "file_size": "27.9 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-Q6_K/Llama-3.3-70B-Instruct-Q6_K-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q6_K/Llama-3.3-70B-Instruct-Q6_K-00002-of-00002.gguf",
        "file_size": "26.0 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-Q8_0/Llama-3.3-70B-Instruct-Q8_0-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q8_0/Llama-3.3-70B-Instruct-Q8_0-00001-of-00002.gguf",
        "file_size": "37.1 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-Q8_0/Llama-3.3-70B-Instruct-Q8_0-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q8_0/Llama-3.3-70B-Instruct-Q8_0-00002-of-00002.gguf",
        "file_size": "32.8 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-UD-IQ1_M.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-UD-IQ1_S.gguf",
        "file_size": "14.8 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-UD-IQ2_M.gguf",
        "file_size": "22.6 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-UD-IQ2_XXS.gguf",
        "file_size": "18.1 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-UD-IQ3_XXS.gguf",
        "file_size": "25.8 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-UD-Q2_K_XL.gguf",
        "file_size": "25.1 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-UD-Q3_K_XL.gguf",
        "file_size": "32.4 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-UD-Q4_K_XL.gguf",
        "file_size": "39.7 GB"
      },
      {
        "model_id": "Llama-3.3-70B-Instruct-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-UD-Q5_K_XL.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q6_K/Llama-3.3-70B-Instruct-Q6_K-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Q6_K/Llama-3.3-70B-Instruct-Q6_K-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q6_K/Llama-3.3-70B-Instruct-Q6_K-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Q6_K/Llama-3.3-70B-Instruct-Q6_K-00002-of-00002.gguf",
        "file_size": "7.4 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Llama-3.3-70B-Instruct-UD-Q6_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Llama-3.3-70B-Instruct-UD-Q6_K_XL-00001-of-00002.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Llama-3.3-70B-Instruct-UD-Q6_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Llama-3.3-70B-Instruct-UD-Q6_K_XL-00002-of-00002.gguf",
        "file_size": "10.4 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Llama-3.3-70B-Instruct-UD-Q8_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Llama-3.3-70B-Instruct-UD-Q8_K_XL-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Llama-3.3-70B-Instruct-UD-Q8_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Llama-3.3-70B-Instruct-UD-Q8_K_XL-00002-of-00002.gguf",
        "file_size": "29.2 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Llama-4-Scout-17B-16E-Instruct-GGUF",
    "developer": "unsloth",
    "downloads": 88950,
    "createdAt": "2025-04-07T22:19:59.000Z",
    "num_quants": 50,
    "quants": [
      {
        "model_id": "BF16/Llama-4-Scout-17B-16E-Instruct-BF16-00001-of-00005",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/BF16/Llama-4-Scout-17B-16E-Instruct-BF16-00001-of-00005.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "BF16/Llama-4-Scout-17B-16E-Instruct-BF16-00002-of-00005",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/BF16/Llama-4-Scout-17B-16E-Instruct-BF16-00002-of-00005.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "BF16/Llama-4-Scout-17B-16E-Instruct-BF16-00003-of-00005",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/BF16/Llama-4-Scout-17B-16E-Instruct-BF16-00003-of-00005.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "BF16/Llama-4-Scout-17B-16E-Instruct-BF16-00004-of-00005",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/BF16/Llama-4-Scout-17B-16E-Instruct-BF16-00004-of-00005.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "BF16/Llama-4-Scout-17B-16E-Instruct-BF16-00005-of-00005",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/BF16/Llama-4-Scout-17B-16E-Instruct-BF16-00005-of-00005.gguf",
        "file_size": "17.0 GB"
      },
      {
        "model_id": "IQ4_NL/Llama-4-Scout-17B-16E-Instruct-IQ4_NL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/IQ4_NL/Llama-4-Scout-17B-16E-Instruct-IQ4_NL-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "IQ4_NL/Llama-4-Scout-17B-16E-Instruct-IQ4_NL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/IQ4_NL/Llama-4-Scout-17B-16E-Instruct-IQ4_NL-00002-of-00002.gguf",
        "file_size": "10.4 GB"
      },
      {
        "model_id": "IQ4_XS/Llama-4-Scout-17B-16E-Instruct-IQ4_XS-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/IQ4_XS/Llama-4-Scout-17B-16E-Instruct-IQ4_XS-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "IQ4_XS/Llama-4-Scout-17B-16E-Instruct-IQ4_XS-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/IQ4_XS/Llama-4-Scout-17B-16E-Instruct-IQ4_XS-00002-of-00002.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "Llama-4-Scout-17B-16E-Instruct-Q2_K",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Llama-4-Scout-17B-16E-Instruct-Q2_K.gguf",
        "file_size": "36.8 GB"
      },
      {
        "model_id": "Llama-4-Scout-17B-16E-Instruct-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Llama-4-Scout-17B-16E-Instruct-Q2_K_L.gguf",
        "file_size": "37.1 GB"
      },
      {
        "model_id": "Llama-4-Scout-17B-16E-Instruct-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Llama-4-Scout-17B-16E-Instruct-Q3_K_S.gguf",
        "file_size": "43.5 GB"
      },
      {
        "model_id": "Llama-4-Scout-17B-16E-Instruct-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Llama-4-Scout-17B-16E-Instruct-UD-IQ1_M.gguf",
        "file_size": "32.6 GB"
      },
      {
        "model_id": "Llama-4-Scout-17B-16E-Instruct-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Llama-4-Scout-17B-16E-Instruct-UD-IQ1_S.gguf",
        "file_size": "30.2 GB"
      },
      {
        "model_id": "Llama-4-Scout-17B-16E-Instruct-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Llama-4-Scout-17B-16E-Instruct-UD-IQ2_M.gguf",
        "file_size": "36.4 GB"
      },
      {
        "model_id": "Llama-4-Scout-17B-16E-Instruct-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Llama-4-Scout-17B-16E-Instruct-UD-IQ2_XXS.gguf",
        "file_size": "34.8 GB"
      },
      {
        "model_id": "Llama-4-Scout-17B-16E-Instruct-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Llama-4-Scout-17B-16E-Instruct-UD-IQ3_XXS.gguf",
        "file_size": "42.6 GB"
      },
      {
        "model_id": "Llama-4-Scout-17B-16E-Instruct-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Llama-4-Scout-17B-16E-Instruct-UD-Q2_K_XL.gguf",
        "file_size": "39.5 GB"
      },
      {
        "model_id": "Llama-4-Scout-17B-16E-Instruct-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Llama-4-Scout-17B-16E-Instruct-UD-Q3_K_XL.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Llama-4-Scout-17B-16E-Instruct-UD-TQ1_0",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Llama-4-Scout-17B-16E-Instruct-UD-TQ1_0.gguf",
        "file_size": "27.3 GB"
      },
      {
        "model_id": "Q3_K_M/Llama-4-Scout-17B-16E-Instruct-Q3_K_M-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q3_K_M/Llama-4-Scout-17B-16E-Instruct-Q3_K_M-00001-of-00002.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q3_K_M/Llama-4-Scout-17B-16E-Instruct-Q3_K_M-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q3_K_M/Llama-4-Scout-17B-16E-Instruct-Q3_K_M-00002-of-00002.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Q4_0/Llama-4-Scout-17B-16E-Instruct-Q4_0-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q4_0/Llama-4-Scout-17B-16E-Instruct-Q4_0-00001-of-00002.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "Q4_0/Llama-4-Scout-17B-16E-Instruct-Q4_0-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q4_0/Llama-4-Scout-17B-16E-Instruct-Q4_0-00002-of-00002.gguf",
        "file_size": "10.4 GB"
      },
      {
        "model_id": "Q4_1/Llama-4-Scout-17B-16E-Instruct-Q4_1-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q4_1/Llama-4-Scout-17B-16E-Instruct-Q4_1-00001-of-00002.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_1/Llama-4-Scout-17B-16E-Instruct-Q4_1-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q4_1/Llama-4-Scout-17B-16E-Instruct-Q4_1-00002-of-00002.gguf",
        "file_size": "16.6 GB"
      },
      {
        "model_id": "Q4_K_M/Llama-4-Scout-17B-16E-Instruct-Q4_K_M-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q4_K_M/Llama-4-Scout-17B-16E-Instruct-Q4_K_M-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_K_M/Llama-4-Scout-17B-16E-Instruct-Q4_K_M-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q4_K_M/Llama-4-Scout-17B-16E-Instruct-Q4_K_M-00002-of-00002.gguf",
        "file_size": "14.4 GB"
      },
      {
        "model_id": "Q4_K_S/Llama-4-Scout-17B-16E-Instruct-Q4_K_S-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q4_K_S/Llama-4-Scout-17B-16E-Instruct-Q4_K_S-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q4_K_S/Llama-4-Scout-17B-16E-Instruct-Q4_K_S-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q4_K_S/Llama-4-Scout-17B-16E-Instruct-Q4_K_S-00002-of-00002.gguf",
        "file_size": "10.8 GB"
      },
      {
        "model_id": "Q5_K_M/Llama-4-Scout-17B-16E-Instruct-Q5_K_M-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q5_K_M/Llama-4-Scout-17B-16E-Instruct-Q5_K_M-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q5_K_M/Llama-4-Scout-17B-16E-Instruct-Q5_K_M-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q5_K_M/Llama-4-Scout-17B-16E-Instruct-Q5_K_M-00002-of-00002.gguf",
        "file_size": "24.8 GB"
      },
      {
        "model_id": "Q5_K_S/Llama-4-Scout-17B-16E-Instruct-Q5_K_S-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q5_K_S/Llama-4-Scout-17B-16E-Instruct-Q5_K_S-00001-of-00002.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "Q5_K_S/Llama-4-Scout-17B-16E-Instruct-Q5_K_S-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q5_K_S/Llama-4-Scout-17B-16E-Instruct-Q5_K_S-00002-of-00002.gguf",
        "file_size": "22.6 GB"
      },
      {
        "model_id": "Q6_K/Llama-4-Scout-17B-16E-Instruct-Q6_K-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q6_K/Llama-4-Scout-17B-16E-Instruct-Q6_K-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q6_K/Llama-4-Scout-17B-16E-Instruct-Q6_K-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q6_K/Llama-4-Scout-17B-16E-Instruct-Q6_K-00002-of-00002.gguf",
        "file_size": "35.9 GB"
      },
      {
        "model_id": "Q8_0/Llama-4-Scout-17B-16E-Instruct-Q8_0-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q8_0/Llama-4-Scout-17B-16E-Instruct-Q8_0-00001-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q8_0/Llama-4-Scout-17B-16E-Instruct-Q8_0-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q8_0/Llama-4-Scout-17B-16E-Instruct-Q8_0-00002-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q8_0/Llama-4-Scout-17B-16E-Instruct-Q8_0-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/Q8_0/Llama-4-Scout-17B-16E-Instruct-Q8_0-00003-of-00003.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q4_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q4_K_XL-00001-of-00002.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q4_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q4_K_XL-00002-of-00002.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q5_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q5_K_XL-00001-of-00002.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q5_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q5_K_XL-00002-of-00002.gguf",
        "file_size": "27.4 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q6_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q6_K_XL-00001-of-00002.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q6_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/UD-Q6_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q6_K_XL-00002-of-00002.gguf",
        "file_size": "41.5 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q8_K_XL-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q8_K_XL-00001-of-00003.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q8_K_XL-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q8_K_XL-00002-of-00003.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q8_K_XL-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/UD-Q8_K_XL/Llama-4-Scout-17B-16E-Instruct-UD-Q8_K_XL-00003-of-00003.gguf",
        "file_size": "27.2 GB"
      },
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "llama-joycaption-beta-one-hf-llava-mmproj-gguf",
    "developer": "concedo",
    "downloads": 6412,
    "createdAt": "2025-05-15T13:36:04.000Z",
    "num_quants": 4,
    "quants": [
      {
        "model_id": "Llama-Joycaption-Beta-One-Hf-Llava-F16",
        "path": "https://huggingface.co/concedo/llama-joycaption-beta-one-hf-llava-mmproj-gguf/resolve/main/Llama-Joycaption-Beta-One-Hf-Llava-F16.gguf",
        "file_size": "15.0 GB"
      },
      {
        "model_id": "Llama-Joycaption-Beta-One-Hf-Llava-Q4_K",
        "path": "https://huggingface.co/concedo/llama-joycaption-beta-one-hf-llava-mmproj-gguf/resolve/main/Llama-Joycaption-Beta-One-Hf-Llava-Q4_K.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Llama-Joycaption-Beta-One-Hf-Llava-Q8_0",
        "path": "https://huggingface.co/concedo/llama-joycaption-beta-one-hf-llava-mmproj-gguf/resolve/main/Llama-Joycaption-Beta-One-Hf-Llava-Q8_0.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "llama-joycaption-beta-one-llava-mmproj-model-f16",
        "path": "https://huggingface.co/concedo/llama-joycaption-beta-one-hf-llava-mmproj-gguf/resolve/main/llama-joycaption-beta-one-llava-mmproj-model-f16.gguf",
        "file_size": "837.1 MB"
      }
    ],
    "readme": "https://huggingface.co/concedo/llama-joycaption-beta-one-hf-llava-mmproj-gguf/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Llama-OuteTTS-1.0-1B-GGUF",
    "developer": "OuteAI",
    "downloads": 8609,
    "createdAt": "2025-04-06T19:18:26.000Z",
    "num_quants": 15,
    "quants": [
      {
        "model_id": "Llama-OuteTTS-1.0-1B-FP16",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-FP16.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q2_K",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q2_K.gguf",
        "file_size": "564.0 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q3_K_L",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q3_K_L.gguf",
        "file_size": "708.6 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q3_K_M",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q3_K_M.gguf",
        "file_size": "668.8 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q3_K_S",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q3_K_S.gguf",
        "file_size": "622.0 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q4_0",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q4_0.gguf",
        "file_size": "745.2 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q4_1",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q4_1.gguf",
        "file_size": "803.2 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q4_K_M",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q4_K_M.gguf",
        "file_size": "780.3 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q4_K_S",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q4_K_S.gguf",
        "file_size": "749.7 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q5_0",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q5_0.gguf",
        "file_size": "861.2 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q5_1",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q5_1.gguf",
        "file_size": "919.2 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q5_K_M",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q5_K_M.gguf",
        "file_size": "879.3 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q5_K_S",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q5_K_S.gguf",
        "file_size": "861.2 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q6_K",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q6_K.gguf",
        "file_size": "984.5 MB"
      },
      {
        "model_id": "Llama-OuteTTS-1.0-1B-Q8_0",
        "path": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/Llama-OuteTTS-1.0-1B-Q8_0.gguf",
        "file_size": "1.2 GB"
      }
    ],
    "readme": "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "LongWriter-llama3.1-8b-GGUF",
    "developer": "bartowski",
    "downloads": 1695,
    "createdAt": "2024-08-13T18:59:54.000Z",
    "num_quants": 20,
    "quants": [
      {
        "model_id": "LongWriter-llama3.1-8b-IQ2_M",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-IQ2_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-IQ3_M",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-IQ3_M.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-IQ3_XS",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-IQ3_XS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-IQ4_XS",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-IQ4_XS.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q2_K",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q2_K_L",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q2_K_L.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q3_K_L",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q3_K_M",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q3_K_S",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q3_K_XL.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q4_K_L",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q4_K_L.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q4_K_M",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q4_K_S",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q5_K_L",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q5_K_L.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q5_K_M",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q5_K_S",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q6_K",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q6_K_L",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q6_K_L.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-Q8_0",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-Q8_0.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "LongWriter-llama3.1-8b-f32",
        "path": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/LongWriter-llama3.1-8b-f32.gguf",
        "file_size": "29.9 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/LongWriter-llama3.1-8b-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Magistral-Small-2506-GGUF",
    "developer": "unsloth",
    "downloads": 65577,
    "createdAt": "2025-06-10T07:31:42.000Z",
    "num_quants": 27,
    "quants": [
      {
        "model_id": "Magistral-Small-2506-BF16",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-BF16.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "Magistral-Small-2506-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-IQ4_NL.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "Magistral-Small-2506-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-IQ4_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "Magistral-Small-2506-Q2_K",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "Magistral-Small-2506-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-Q2_K_L.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "Magistral-Small-2506-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "Magistral-Small-2506-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "Magistral-Small-2506-Q4_0",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-Q4_0.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Magistral-Small-2506-Q4_1",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-Q4_1.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "Magistral-Small-2506-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "Magistral-Small-2506-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Magistral-Small-2506-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "Magistral-Small-2506-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "Magistral-Small-2506-Q6_K",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "Magistral-Small-2506-Q8_0",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-Q8_0.gguf",
        "file_size": "23.3 GB"
      },
      {
        "model_id": "Magistral-Small-2506-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-UD-IQ2_M.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "Magistral-Small-2506-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-UD-IQ2_XXS.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Magistral-Small-2506-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-UD-IQ3_XXS.gguf",
        "file_size": "8.8 GB"
      },
      {
        "model_id": "Magistral-Small-2506-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-UD-Q2_K_XL.gguf",
        "file_size": "8.7 GB"
      },
      {
        "model_id": "Magistral-Small-2506-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-UD-Q3_K_XL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "Magistral-Small-2506-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-UD-Q4_K_XL.gguf",
        "file_size": "13.5 GB"
      },
      {
        "model_id": "Magistral-Small-2506-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-UD-Q5_K_XL.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "Magistral-Small-2506-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-UD-Q6_K_XL.gguf",
        "file_size": "19.4 GB"
      },
      {
        "model_id": "Magistral-Small-2506-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/Magistral-Small-2506-UD-Q8_K_XL.gguf",
        "file_size": "27.0 GB"
      },
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "837.4 MB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "837.4 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Magistral-Small-2506-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Magistral-Small-2506_gguf",
    "developer": "mistralai",
    "downloads": 2920,
    "createdAt": "2025-06-09T09:25:46.000Z",
    "tools": false,
    "num_quants": 2,
    "quants": [
      {
        "model_id": "Magistral-Small-2506",
        "path": "https://huggingface.co/mistralai/Magistral-Small-2506_gguf/resolve/main/Magistral-Small-2506.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "Magistral-Small-2506_Q8_0",
        "path": "https://huggingface.co/mistralai/Magistral-Small-2506_gguf/resolve/main/Magistral-Small-2506_Q8_0.gguf",
        "file_size": "23.3 GB"
      }
    ],
    "readme": "https://huggingface.co/mistralai/Magistral-Small-2506_gguf/resolve/main/README.md",
    "description": "Magistral-Small-2506_gguf is a 24B parameter, Apache 2.0 licensed, GGUF-quantized reasoning model with 40k context window support, optimized for local deployment and on-device use."
  },
  {
    "model_name": "medgemma-27b-it-GGUF",
    "developer": "unsloth",
    "downloads": 5277,
    "createdAt": "2025-07-09T22:13:24.000Z",
    "tools": false,
    "num_quants": 30,
    "quants": [
      {
        "model_id": "BF16/medgemma-27b-it-BF16-00001-of-00002",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/BF16/medgemma-27b-it-BF16-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "BF16/medgemma-27b-it-BF16-00002-of-00002",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/BF16/medgemma-27b-it-BF16-00002-of-00002.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "medgemma-27b-it-IQ4_NL",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-IQ4_NL.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "medgemma-27b-it-IQ4_XS",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-IQ4_XS.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "medgemma-27b-it-Q2_K",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-Q2_K.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "medgemma-27b-it-Q2_K_L",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-Q2_K_L.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "medgemma-27b-it-Q3_K_M",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-Q3_K_M.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "medgemma-27b-it-Q3_K_S",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-Q3_K_S.gguf",
        "file_size": "11.3 GB"
      },
      {
        "model_id": "medgemma-27b-it-Q4_0",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-Q4_0.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "medgemma-27b-it-Q4_1",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-Q4_1.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "medgemma-27b-it-Q4_K_M",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-Q4_K_M.gguf",
        "file_size": "15.4 GB"
      },
      {
        "model_id": "medgemma-27b-it-Q4_K_S",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-Q4_K_S.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "medgemma-27b-it-Q5_K_M",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-Q5_K_M.gguf",
        "file_size": "17.9 GB"
      },
      {
        "model_id": "medgemma-27b-it-Q5_K_S",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-Q5_K_S.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "medgemma-27b-it-Q6_K",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-Q6_K.gguf",
        "file_size": "20.6 GB"
      },
      {
        "model_id": "medgemma-27b-it-Q8_0",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-Q8_0.gguf",
        "file_size": "26.7 GB"
      },
      {
        "model_id": "medgemma-27b-it-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-UD-IQ1_M.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "medgemma-27b-it-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-UD-IQ1_S.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "medgemma-27b-it-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-UD-IQ2_M.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "medgemma-27b-it-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-UD-IQ2_XXS.gguf",
        "file_size": "7.3 GB"
      },
      {
        "model_id": "medgemma-27b-it-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-UD-IQ3_XXS.gguf",
        "file_size": "10.1 GB"
      },
      {
        "model_id": "medgemma-27b-it-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-UD-Q2_K_XL.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "medgemma-27b-it-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-UD-Q3_K_XL.gguf",
        "file_size": "12.8 GB"
      },
      {
        "model_id": "medgemma-27b-it-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-UD-Q4_K_XL.gguf",
        "file_size": "15.7 GB"
      },
      {
        "model_id": "medgemma-27b-it-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-UD-Q5_K_XL.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "medgemma-27b-it-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-UD-Q6_K_XL.gguf",
        "file_size": "22.1 GB"
      },
      {
        "model_id": "medgemma-27b-it-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/medgemma-27b-it-UD-Q8_K_XL.gguf",
        "file_size": "29.6 GB"
      },
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "818.0 MB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "818.0 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF/resolve/main/README.md",
    "description": "MedGemma is a medical multimodal model trained on diverse medical data for text and image comprehension, offering strong performance on clinical benchmarks and supporting tasks like radiology report generation, dermatology, and pathology analysis."
  },
  {
    "model_name": "medgemma-27b-text-it-GGUF",
    "developer": "unsloth",
    "downloads": 40280,
    "createdAt": "2025-05-20T20:17:33.000Z",
    "num_quants": 26,
    "quants": [
      {
        "model_id": "BF16/medgemma-27b-text-it-BF16-00001-of-00002",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/BF16/medgemma-27b-text-it-BF16-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "BF16/medgemma-27b-text-it-BF16-00002-of-00002",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/BF16/medgemma-27b-text-it-BF16-00002-of-00002.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-IQ4_NL",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-IQ4_NL.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-IQ4_XS",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-IQ4_XS.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-Q2_K",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-Q2_K.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-Q2_K_L",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-Q2_K_L.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-Q3_K_M",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-Q3_K_M.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-Q3_K_S",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-Q3_K_S.gguf",
        "file_size": "11.3 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-Q4_1",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-Q4_1.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-Q4_K_M",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-Q4_K_M.gguf",
        "file_size": "15.4 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-Q4_K_S",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-Q4_K_S.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-Q5_K_M",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-Q5_K_M.gguf",
        "file_size": "17.9 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-Q5_K_S",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-Q5_K_S.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-Q6_K",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-Q6_K.gguf",
        "file_size": "20.6 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-Q8_0",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-Q8_0.gguf",
        "file_size": "26.7 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-UD-IQ1_M.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-UD-IQ1_S.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-UD-IQ2_M.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-UD-IQ2_XXS.gguf",
        "file_size": "7.3 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-UD-IQ3_XXS.gguf",
        "file_size": "10.1 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-UD-Q2_K_XL.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-UD-Q3_K_XL.gguf",
        "file_size": "12.8 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-UD-Q4_K_XL.gguf",
        "file_size": "15.7 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-UD-Q5_K_XL.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-UD-Q6_K_XL.gguf",
        "file_size": "22.1 GB"
      },
      {
        "model_id": "medgemma-27b-text-it-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/medgemma-27b-text-it-UD-Q8_K_XL.gguf",
        "file_size": "29.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/medgemma-27b-text-it-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "medgemma-4b-it-GGUF",
    "developer": "unsloth",
    "downloads": 20287,
    "createdAt": "2025-05-20T19:18:08.000Z",
    "num_quants": 29,
    "quants": [
      {
        "model_id": "medgemma-4b-it-BF16",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-BF16.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "medgemma-4b-it-IQ4_NL",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-IQ4_NL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "medgemma-4b-it-IQ4_XS",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-IQ4_XS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "medgemma-4b-it-Q2_K",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q2_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "medgemma-4b-it-Q2_K_L",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q2_K_L.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "medgemma-4b-it-Q3_K_M",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q3_K_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "medgemma-4b-it-Q3_K_S",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "medgemma-4b-it-Q4_0",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "medgemma-4b-it-Q4_1",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q4_1.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "medgemma-4b-it-Q4_K_M",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "medgemma-4b-it-Q4_K_S",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "medgemma-4b-it-Q5_K_M",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q5_K_M.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "medgemma-4b-it-Q5_K_S",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "medgemma-4b-it-Q6_K",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q6_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "medgemma-4b-it-Q8_0",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q8_0.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "medgemma-4b-it-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-UD-IQ1_M.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "medgemma-4b-it-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-UD-IQ1_S.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "medgemma-4b-it-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-UD-IQ2_M.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "medgemma-4b-it-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-UD-IQ2_XXS.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "medgemma-4b-it-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-UD-IQ3_XXS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "medgemma-4b-it-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-UD-Q2_K_XL.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "medgemma-4b-it-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-UD-Q3_K_XL.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "medgemma-4b-it-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-UD-Q4_K_XL.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "medgemma-4b-it-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-UD-Q5_K_XL.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "medgemma-4b-it-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-UD-Q6_K_XL.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "medgemma-4b-it-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-UD-Q8_K_XL.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "811.8 MB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "811.8 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Menlo_Lucy-GGUF",
    "developer": "bartowski",
    "downloads": 3515,
    "createdAt": "2025-07-18T05:28:56.000Z",
    "tools": true,
    "num_quants": 23,
    "quants": [
      {
        "model_id": "Menlo_Lucy-IQ3_M",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-IQ3_M.gguf",
        "file_size": "854.2 MB"
      },
      {
        "model_id": "Menlo_Lucy-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-IQ3_XS.gguf",
        "file_size": "795.6 MB"
      },
      {
        "model_id": "Menlo_Lucy-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-IQ3_XXS.gguf",
        "file_size": "719.4 MB"
      },
      {
        "model_id": "Menlo_Lucy-IQ4_NL",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-IQ4_NL.gguf",
        "file_size": "1005.6 MB"
      },
      {
        "model_id": "Menlo_Lucy-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-IQ4_XS.gguf",
        "file_size": "963.6 MB"
      },
      {
        "model_id": "Menlo_Lucy-Q2_K",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q2_K.gguf",
        "file_size": "741.8 MB"
      },
      {
        "model_id": "Menlo_Lucy-Q2_K_L",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q2_K_L.gguf",
        "file_size": "813.6 MB"
      },
      {
        "model_id": "Menlo_Lucy-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q3_K_L.gguf",
        "file_size": "957.0 MB"
      },
      {
        "model_id": "Menlo_Lucy-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q3_K_M.gguf",
        "file_size": "896.0 MB"
      },
      {
        "model_id": "Menlo_Lucy-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q3_K_S.gguf",
        "file_size": "827.1 MB"
      },
      {
        "model_id": "Menlo_Lucy-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q3_K_XL.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Menlo_Lucy-Q4_0",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q4_0.gguf",
        "file_size": "1007.8 MB"
      },
      {
        "model_id": "Menlo_Lucy-Q4_1",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q4_1.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Menlo_Lucy-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q4_K_L.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Menlo_Lucy-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q4_K_M.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Menlo_Lucy-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q4_K_S.gguf",
        "file_size": "1011.1 MB"
      },
      {
        "model_id": "Menlo_Lucy-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q5_K_L.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Menlo_Lucy-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q5_K_M.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Menlo_Lucy-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q5_K_S.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Menlo_Lucy-Q6_K",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q6_K.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "Menlo_Lucy-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q6_K_L.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "Menlo_Lucy-Q8_0",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-Q8_0.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "Menlo_Lucy-bf16",
        "path": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/Menlo_Lucy-bf16.gguf",
        "file_size": "3.2 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Menlo_Lucy-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Lucy model by Menlo, optimized for various quantization types and suitable for use with llama.cpp or LM Studio."
  },
  {
    "model_name": "Meta-Llama-3-8B-Instruct-GGUF",
    "developer": "MaziyarPanahi",
    "downloads": 219609,
    "createdAt": "2024-04-18T16:43:25.000Z",
    "num_quants": 16,
    "quants": [
      {
        "model_id": "Meta-Llama-3-8B-Instruct.IQ1_M",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.IQ1_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.IQ1_S",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.IQ1_S.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.IQ2_XS",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.IQ2_XS.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.IQ3_XS",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.IQ3_XS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.IQ4_XS",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.IQ4_XS.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q2_K",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q3_K_L",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q3_K_M",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q3_K_S",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q4_K_M",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q4_K_S",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q5_K_M",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q5_K_S",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q6_K",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q8_0",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q8_0.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.fp16",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.fp16.gguf",
        "file_size": "15.0 GB"
      }
    ],
    "readme": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/README.md",
    "description": "This is a quantized and GGUF version of the Meta Llama 3 8B Instruct model, optimized for efficient inference and compatible with llama.cpp, based on the original Meta Llama 3 model.",
    "tools": false
  },
  {
    "model_name": "Meta-Llama-3-8B-Instruct-GGUF",
    "developer": "QuantFactory",
    "downloads": 17182,
    "createdAt": "2024-04-18T17:03:42.000Z",
    "num_quants": 14,
    "quants": [
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q2_K",
        "path": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q3_K_L",
        "path": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q3_K_M",
        "path": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q3_K_S",
        "path": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q4_0",
        "path": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q4_0.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q4_1",
        "path": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q4_1.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q4_K_M",
        "path": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q4_K_S",
        "path": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q5_0",
        "path": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q5_0.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q5_1",
        "path": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q5_1.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q5_K_M",
        "path": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q5_K_S",
        "path": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q6_K",
        "path": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct.Q8_0",
        "path": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q8_0.gguf",
        "file_size": "8.0 GB"
      }
    ],
    "readme": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Meta-Llama-3-8B-Instruct-GGUF",
    "developer": "lmstudio-community",
    "downloads": 5427,
    "createdAt": "2024-04-18T20:23:48.000Z",
    "num_quants": 5,
    "quants": [
      {
        "model_id": "Meta-Llama-3-8B-Instruct-IQ3_M",
        "path": "https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-IQ3_M.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-Q6_K",
        "path": "https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-Q8_0",
        "path": "https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q8_0.gguf",
        "file_size": "8.0 GB"
      }
    ],
    "readme": "https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Meta-Llama-3-8B-Instruct-GGUF",
    "developer": "bartowski",
    "downloads": 9299,
    "createdAt": "2024-04-29T16:03:11.000Z",
    "num_quants": 24,
    "quants": [
      {
        "model_id": "Meta-Llama-3-8B-Instruct-IQ1_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-IQ1_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-IQ1_S",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-IQ1_S.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-IQ2_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-IQ2_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-IQ2_S",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-IQ2_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-IQ2_XS",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-IQ2_XS.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-IQ2_XXS",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-IQ2_XXS.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-IQ3_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-IQ3_M.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-IQ3_S",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-IQ3_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-IQ3_XS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-IQ3_XXS.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-IQ4_NL.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-IQ4_XS.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-Q2_K",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-Q6_K",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-Q8_0",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q8_0.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-fp16",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-fp16.gguf",
        "file_size": "15.0 GB"
      },
      {
        "model_id": "Meta-Llama-3-8B-Instruct-fp32",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-fp32.gguf",
        "file_size": "29.9 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Meta-Llama-3.1-8B-Instruct-GGUF",
    "developer": "bartowski",
    "downloads": 41695,
    "createdAt": "2024-07-23T15:36:34.000Z",
    "tools": false,
    "num_quants": 24,
    "quants": [
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-IQ2_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-IQ2_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-IQ3_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-IQ3_M.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-IQ3_XS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-IQ4_NL.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-IQ4_XS.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q2_K",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q2_K_L",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q2_K_L.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q3_K_XL.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q4_0_4_4",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_0_4_4.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q4_0_4_8",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_0_4_8.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q4_0_8_8",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_0_8_8.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_L.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q5_K_L.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q6_K",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q6_K_L.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-Q8_0",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct-f32",
        "path": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-f32.gguf",
        "file_size": "29.9 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/README.md",
    "description": "This repository provides quantized versions of the Meta-Llama-3.1-8B-Instruct model using llama.cpp, including various quantization types like Q4_K_M, Q5_K_S, IQ3_M, and others, optimized for different hardware platforms and offering trade-offs between speed,"
  },
  {
    "model_name": "Meta-Llama-3.1-8B-Instruct-GGUF",
    "developer": "MaziyarPanahi",
    "downloads": 205174,
    "createdAt": "2024-07-23T16:17:10.000Z",
    "tools": false,
    "num_quants": 10,
    "quants": [
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct.Q2_K",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct.Q3_K_L",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct.Q3_K_M",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct.Q3_K_S",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct.Q4_K_M",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct.Q4_K_S",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct.Q5_K_M",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct.Q5_K_S",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct.Q6_K",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Meta-Llama-3.1-8B-Instruct.Q8_0",
        "path": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q8_0.gguf",
        "file_size": "8.0 GB"
      }
    ],
    "readme": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/README.md",
    "description": "The Meta-Llama-3.1-8B-Instruct-GGUF model is a GGUF-formatted, quantized, multilingual text-generation model based on Meta's Llama 3.1-8B-Instruct, optimized for efficient inference and supporting 8 languages with enhanced safety"
  },
  {
    "model_name": "microsoft_NextCoder-32B-GGUF",
    "developer": "bartowski",
    "downloads": 3274,
    "createdAt": "2025-07-10T17:23:21.000Z",
    "num_quants": 28,
    "quants": [
      {
        "model_id": "microsoft_NextCoder-32B-IQ2_M",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-IQ2_M.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-IQ2_S",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-IQ2_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-IQ2_XS",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-IQ2_XS.gguf",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-IQ2_XXS",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-IQ2_XXS.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-IQ3_M",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-IQ3_M.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-IQ3_XS",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-IQ3_XS.gguf",
        "file_size": "12.8 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-IQ3_XXS.gguf",
        "file_size": "12.0 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-IQ4_NL",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-IQ4_NL.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-IQ4_XS",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-IQ4_XS.gguf",
        "file_size": "16.5 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q2_K",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q2_K.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q2_K_L",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q2_K_L.gguf",
        "file_size": "12.2 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q3_K_L",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q3_K_L.gguf",
        "file_size": "16.1 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q3_K_M",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q3_K_M.gguf",
        "file_size": "14.8 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q3_K_S",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q3_K_S.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q3_K_XL.gguf",
        "file_size": "16.7 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q4_0",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q4_0.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q4_1",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q4_1.gguf",
        "file_size": "19.2 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q4_K_L",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q4_K_L.gguf",
        "file_size": "19.0 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q4_K_M",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q4_K_M.gguf",
        "file_size": "18.5 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q4_K_S",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q4_K_S.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q5_K_L",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q5_K_L.gguf",
        "file_size": "22.1 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q5_K_M",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q5_K_M.gguf",
        "file_size": "21.7 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q5_K_S",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q5_K_S.gguf",
        "file_size": "21.1 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q6_K",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q6_K.gguf",
        "file_size": "25.0 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q6_K_L",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q6_K_L.gguf",
        "file_size": "25.4 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-Q8_0",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-Q8_0.gguf",
        "file_size": "32.4 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-bf16/microsoft_NextCoder-32B-bf16-00001-of-00002",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-bf16/microsoft_NextCoder-32B-bf16-00001-of-00002.gguf",
        "file_size": "37.1 GB"
      },
      {
        "model_id": "microsoft_NextCoder-32B-bf16/microsoft_NextCoder-32B-bf16-00002-of-00002",
        "path": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/microsoft_NextCoder-32B-bf16/microsoft_NextCoder-32B-bf16-00002-of-00002.gguf",
        "file_size": "23.9 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/microsoft_NextCoder-32B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Midm-2.0-Mini-Instruct-gguf",
    "developer": "mykor",
    "downloads": 1565,
    "createdAt": "2025-07-04T12:38:48.000Z",
    "num_quants": 16,
    "quants": [
      {
        "model_id": "Midm-2.0-Mini-Instruct-BF16",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-BF16.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-F32",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-F32.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-IQ4_NL",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-IQ4_NL.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-IQ4_XS",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-IQ4_XS.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-Q2_K",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-Q2_K.gguf",
        "file_size": "930.2 MB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-Q3_K_L",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-Q3_K_L.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-Q3_K_M",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-Q3_K_M.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-Q3_K_S",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-Q3_K_S.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-Q4_0",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-Q4_0.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-Q4_K_M",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-Q4_K_M.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-Q4_K_S",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-Q4_K_S.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-Q5_0",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-Q5_0.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-Q5_K_M",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-Q5_K_M.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-Q5_K_S",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-Q5_K_S.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-Q6_K",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-Q6_K.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Midm-2.0-Mini-Instruct-Q8_0",
        "path": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-Q8_0.gguf",
        "file_size": "2.3 GB"
      }
    ],
    "readme": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Ministral-8B-Instruct-2410-GGUF",
    "developer": "bartowski",
    "downloads": 25289,
    "createdAt": "2024-10-21T16:27:21.000Z",
    "num_quants": 24,
    "quants": [
      {
        "model_id": "Ministral-8B-Instruct-2410-IQ2_M",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-IQ2_M.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-IQ3_M",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-IQ3_M.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-IQ3_XS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-IQ4_XS.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q2_K",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q2_K_L",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q2_K_L.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q3_K_XL.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q4_0",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q4_0.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q4_0_4_4",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q4_0_4_4.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q4_0_4_8",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q4_0_4_8.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q4_0_8_8",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q4_0_8_8.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q4_K_L.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q5_K_L.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q6_K",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q6_K_L.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-Q8_0",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-Q8_0.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "Ministral-8B-Instruct-2410-f16",
        "path": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410-f16.gguf",
        "file_size": "14.9 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF/resolve/main/README.md",
    "description": "This repository provides quantized versions of the Mistral-8B-Instruct-2410 model for various inference platforms, with a focus on research use under the Mistral AI Research License, requiring users to agree to specific terms and conditions for non-commercial purposes.",
    "tools": true
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.1-GGUF",
    "developer": "TheBloke",
    "downloads": 79311,
    "createdAt": "2023-09-27T17:49:54.000Z",
    "tools": false,
    "num_quants": 12,
    "quants": [
      {
        "model_id": "mistral-7b-instruct-v0.1.Q2_K",
        "path": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q2_K.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "mistral-7b-instruct-v0.1.Q3_K_L",
        "path": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q3_K_L.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "mistral-7b-instruct-v0.1.Q3_K_M",
        "path": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q3_K_M.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "mistral-7b-instruct-v0.1.Q3_K_S",
        "path": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q3_K_S.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "mistral-7b-instruct-v0.1.Q4_0",
        "path": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_0.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "mistral-7b-instruct-v0.1.Q4_K_M",
        "path": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "mistral-7b-instruct-v0.1.Q4_K_S",
        "path": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_S.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "mistral-7b-instruct-v0.1.Q5_0",
        "path": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q5_0.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "mistral-7b-instruct-v0.1.Q5_K_M",
        "path": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q5_K_M.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "mistral-7b-instruct-v0.1.Q5_K_S",
        "path": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q5_K_S.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "mistral-7b-instruct-v0.1.Q6_K",
        "path": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q6_K.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "mistral-7b-instruct-v0.1.Q8_0",
        "path": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q8_0.gguf",
        "file_size": "7.2 GB"
      }
    ],
    "readme": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/README.md",
    "description": "This repository provides GGUF format quantized versions of Mistral AI's Mistral 7B Instruct v0.1 model for efficient CPU and GPU inference with various quantization levels and compatibility with multiple frameworks like llama.cpp, text-generation-webui, and ctransformers."
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3-GGUF",
    "developer": "MaziyarPanahi",
    "downloads": 238616,
    "createdAt": "2024-05-22T17:27:45.000Z",
    "num_quants": 16,
    "quants": [
      {
        "model_id": "Mistral-7B-Instruct-v0.3.IQ1_M",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.IQ1_M.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.IQ1_S",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.IQ1_S.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.IQ2_XS",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.IQ2_XS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.IQ3_XS",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.IQ3_XS.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.IQ4_XS",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.IQ4_XS.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.Q2_K",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q2_K.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.Q3_K_L",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q3_K_L.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.Q3_K_M",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q3_K_M.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.Q3_K_S",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q3_K_S.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.Q4_K_M",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.Q4_K_S",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q4_K_S.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.Q5_K_M",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q5_K_M.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.Q5_K_S",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q5_K_S.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.Q6_K",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q6_K.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.Q8_0",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q8_0.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "Mistral-7B-Instruct-v0.3.fp16",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.fp16.gguf",
        "file_size": "13.5 GB"
      }
    ],
    "readme": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/README.md",
    "description": "This model is a GGUF format version of the Mistral-7B-Instruct-v0.3, quantized for efficient inference on various platforms.",
    "tools": false
  },
  {
    "model_name": "Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf",
    "developer": "DavidAU",
    "downloads": 5290,
    "createdAt": "2024-12-26T11:22:27.000Z",
    "tools": false,
    "num_quants": 19,
    "quants": [
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-IQ4_XS",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-IQ4_XS.gguf",
        "file_size": "12.2 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q2_k",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q2_k.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q3_k_l",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q3_k_l.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q3_k_m",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q3_k_m.gguf",
        "file_size": "10.8 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q3_k_s",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q3_k_s.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q4_k_m",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q4_k_m.gguf",
        "file_size": "13.7 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q4_k_s",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q4_k_s.gguf",
        "file_size": "12.8 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q5_k_s",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q5_k_s.gguf",
        "file_size": "15.5 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q6_k",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q6_k.gguf",
        "file_size": "18.5 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-Q8_0.gguf",
        "file_size": "23.9 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-max-IQ4_XS",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-max-IQ4_XS.gguf",
        "file_size": "13.0 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-max-cpu-IQ4_XS",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-max-cpu-IQ4_XS.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-q5_k_m",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-D_AU-q5_k_m.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-max-D_AU-Q2_k",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-max-D_AU-Q2_k.gguf",
        "file_size": "9.1 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-max-D_AU-Q6_k",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-max-D_AU-Q6_k.gguf",
        "file_size": "19.2 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-max-D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-max-D_AU-Q8_0.gguf",
        "file_size": "24.6 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-max-cpu-D_AU-Q2_k",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-max-cpu-D_AU-Q2_k.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-max-cpu-D_AU-Q6_k",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-max-cpu-D_AU-Q6_k.gguf",
        "file_size": "18.7 GB"
      },
      {
        "model_id": "M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-max-cpu-D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/M-MOE-4X7B-Dark-MultiVerse-UC-E32-24B-max-cpu-D_AU-Q8_0.gguf",
        "file_size": "24.1 GB"
      }
    ],
    "readme": "https://huggingface.co/DavidAU/Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-gguf/resolve/main/README.md",
    "description": "This is an uncensored, vividly detailed, and highly creative Mistral-MOE-4X7B-Dark-MultiVerse-Uncensored-Enhanced32-24B-GGUF model that combines four Mistral 7B models into a 24B parameter model"
  },
  {
    "model_name": "Mistral-Nemo-12B-ArliAI-RPMax-v1.1-GGUF",
    "developer": "ArliAI",
    "downloads": 2177,
    "createdAt": "2024-08-31T17:20:54.000Z",
    "tools": true,
    "num_quants": 11,
    "quants": [
      {
        "model_id": "ArliAI-RPMax-12B-v1.1-Q2_K",
        "path": "https://huggingface.co/ArliAI/Mistral-Nemo-12B-ArliAI-RPMax-v1.1-GGUF/resolve/main/ArliAI-RPMax-12B-v1.1-Q2_K.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "ArliAI-RPMax-12B-v1.1-Q3_K_L",
        "path": "https://huggingface.co/ArliAI/Mistral-Nemo-12B-ArliAI-RPMax-v1.1-GGUF/resolve/main/ArliAI-RPMax-12B-v1.1-Q3_K_L.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "ArliAI-RPMax-12B-v1.1-Q3_K_M",
        "path": "https://huggingface.co/ArliAI/Mistral-Nemo-12B-ArliAI-RPMax-v1.1-GGUF/resolve/main/ArliAI-RPMax-12B-v1.1-Q3_K_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "ArliAI-RPMax-12B-v1.1-Q3_K_S",
        "path": "https://huggingface.co/ArliAI/Mistral-Nemo-12B-ArliAI-RPMax-v1.1-GGUF/resolve/main/ArliAI-RPMax-12B-v1.1-Q3_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "ArliAI-RPMax-12B-v1.1-Q4_K_M",
        "path": "https://huggingface.co/ArliAI/Mistral-Nemo-12B-ArliAI-RPMax-v1.1-GGUF/resolve/main/ArliAI-RPMax-12B-v1.1-Q4_K_M.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "ArliAI-RPMax-12B-v1.1-Q4_K_S",
        "path": "https://huggingface.co/ArliAI/Mistral-Nemo-12B-ArliAI-RPMax-v1.1-GGUF/resolve/main/ArliAI-RPMax-12B-v1.1-Q4_K_S.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "ArliAI-RPMax-12B-v1.1-Q5_K_M",
        "path": "https://huggingface.co/ArliAI/Mistral-Nemo-12B-ArliAI-RPMax-v1.1-GGUF/resolve/main/ArliAI-RPMax-12B-v1.1-Q5_K_M.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "ArliAI-RPMax-12B-v1.1-Q5_K_S",
        "path": "https://huggingface.co/ArliAI/Mistral-Nemo-12B-ArliAI-RPMax-v1.1-GGUF/resolve/main/ArliAI-RPMax-12B-v1.1-Q5_K_S.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "ArliAI-RPMax-12B-v1.1-Q6_K",
        "path": "https://huggingface.co/ArliAI/Mistral-Nemo-12B-ArliAI-RPMax-v1.1-GGUF/resolve/main/ArliAI-RPMax-12B-v1.1-Q6_K.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "ArliAI-RPMax-12B-v1.1-fp16",
        "path": "https://huggingface.co/ArliAI/Mistral-Nemo-12B-ArliAI-RPMax-v1.1-GGUF/resolve/main/ArliAI-RPMax-12B-v1.1-fp16.gguf",
        "file_size": "22.8 GB"
      },
      {
        "model_id": "ArliAI-RPMax-12B-v1.1-q8_0",
        "path": "https://huggingface.co/ArliAI/Mistral-Nemo-12B-ArliAI-RPMax-v1.1-GGUF/resolve/main/ArliAI-RPMax-12B-v1.1-q8_0.gguf",
        "file_size": "12.1 GB"
      }
    ],
    "readme": "https://huggingface.co/ArliAI/Mistral-Nemo-12B-ArliAI-RPMax-v1.1-GGUF/resolve/main/README.md",
    "description": "ArliAI-RPMax-12B-v1.1 is a creative and non-repetitive RP model based on Mistral Nemo 12B Instruct 2407, trained on curated datasets to avoid repeated characters or situations."
  },
  {
    "model_name": "Mistral-Nemo-Instruct-2407-GGUF",
    "developer": "bartowski",
    "downloads": 8221,
    "createdAt": "2024-07-18T15:18:30.000Z",
    "num_quants": 25,
    "quants": [
      {
        "model_id": "Mistral-Nemo-Instruct-2407-IQ2_M",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-IQ2_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-IQ3_M",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-IQ3_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-IQ3_XS.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-IQ4_XS.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q2_K",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q2_K.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q2_K_L",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q2_K_L.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q3_K_L.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q3_K_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q3_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q3_K_XL.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q4_0",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q4_0.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q4_0_4_4",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q4_0_4_4.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q4_0_4_8",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q4_0_4_8.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q4_0_8_8",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q4_0_8_8.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q4_K_L.gguf",
        "file_size": "7.4 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q4_K_M.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q4_K_S.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q5_K_L.gguf",
        "file_size": "8.5 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q5_K_M.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q5_K_S.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q6_K",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q6_K.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q6_K_L.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-Q8_0",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q8_0.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-f16",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-f16.gguf",
        "file_size": "22.8 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407-f32",
        "path": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-f32.gguf",
        "file_size": "45.6 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Mistral-Nemo-Instruct-2407-GGUF",
    "developer": "MaziyarPanahi",
    "downloads": 211264,
    "createdAt": "2024-07-18T14:49:08.000Z",
    "tools": false,
    "num_quants": 11,
    "quants": [
      {
        "model_id": "Mistral-Nemo-Instruct-2407.Q2_K",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407.Q2_K.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407.Q3_K_L",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407.Q3_K_L.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407.Q3_K_M",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407.Q3_K_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407.Q3_K_S",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407.Q3_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407.Q4_K_M",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407.Q4_K_M.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407.Q4_K_S",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407.Q4_K_S.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407.Q5_K_M",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407.Q5_K_M.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407.Q5_K_S",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407.Q5_K_S.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407.Q6_K",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407.Q6_K.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407.Q8_0",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407.Q8_0.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "Mistral-Nemo-Instruct-2407.fp16",
        "path": "https://huggingface.co/MaziyarPanahi/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407.fp16.gguf",
        "file_size": "22.8 GB"
      }
    ],
    "readme": "https://huggingface.co/MaziyarPanahi/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/README.md",
    "description": "This GGUF quantized model for Mistral-Nemo-Instruct-2407 is compatible with various frameworks and tools like llama.cpp, llama-cpp-python, LM Studio, and others, offering efficient text generation with different bit quantization levels."
  },
  {
    "model_name": "Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF",
    "developer": "bartowski",
    "downloads": 12567,
    "createdAt": "2024-09-26T14:36:19.000Z",
    "tools": true,
    "num_quants": 25,
    "quants": [
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-IQ2_M",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-IQ2_M.gguf",
        "file_size": "7.1 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-IQ2_S",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-IQ2_S.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-IQ3_M",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-IQ3_M.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-IQ3_XS.gguf",
        "file_size": "8.5 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-IQ4_XS.gguf",
        "file_size": "11.1 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q2_K",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q2_K.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q2_K_L",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q2_K_L.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q3_K_L.gguf",
        "file_size": "10.9 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q3_K_M.gguf",
        "file_size": "10.0 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q3_K_S.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q3_K_XL.gguf",
        "file_size": "11.1 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q4_0",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q4_0.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q4_0_4_4",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q4_0_4_4.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q4_0_4_8",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q4_0_4_8.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q4_0_8_8",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q4_0_8_8.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q4_K_L.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q4_K_M.gguf",
        "file_size": "12.4 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q4_K_S.gguf",
        "file_size": "11.8 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q5_K_L.gguf",
        "file_size": "14.8 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q5_K_M.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q5_K_S.gguf",
        "file_size": "14.3 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q6_K",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q6_K.gguf",
        "file_size": "17.0 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q6_K_L.gguf",
        "file_size": "17.1 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-Q8_0",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-Q8_0.gguf",
        "file_size": "22.0 GB"
      },
      {
        "model_id": "Mistral-Small-22B-ArliAI-RPMax-v1.1-f16",
        "path": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/Mistral-Small-22B-ArliAI-RPMax-v1.1-f16.gguf",
        "file_size": "41.4 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/resolve/main/README.md",
    "description": "This repository provides GGUF quantized versions of the Mistral-Small-22B-ArliAI-RPMax-v1.1 model for efficient text generation on various hardware platforms, including ARM and CPU, with recommendations based on performance and quality trade-offs."
  },
  {
    "model_name": "Mistral-Small-3.2-24B-Instruct-2506-GGUF",
    "developer": "unsloth",
    "downloads": 118187,
    "createdAt": "2025-06-20T22:27:21.000Z",
    "tools": true,
    "num_quants": 29,
    "quants": [
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-BF16",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-BF16.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-IQ4_NL.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-IQ4_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-Q2_K",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-Q2_K_L.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-Q4_0",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-Q4_0.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-Q4_1",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-Q4_1.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-Q6_K",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-Q8_0",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-Q8_0.gguf",
        "file_size": "23.3 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-UD-IQ1_M.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-UD-IQ1_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-UD-IQ2_M.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-UD-IQ2_XXS.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-UD-IQ3_XXS.gguf",
        "file_size": "8.8 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-UD-Q2_K_XL.gguf",
        "file_size": "8.7 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-UD-Q3_K_XL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-UD-Q4_K_XL.gguf",
        "file_size": "13.5 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-UD-Q5_K_XL.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-UD-Q6_K_XL.gguf",
        "file_size": "19.4 GB"
      },
      {
        "model_id": "Mistral-Small-3.2-24B-Instruct-2506-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/Mistral-Small-3.2-24B-Instruct-2506-UD-Q8_K_XL.gguf",
        "file_size": "27.0 GB"
      },
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "837.4 MB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "837.4 MB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/README.md",
    "description": "This is a quantized Mistral-3.2 Small 24B model optimized for instruction following, function calling, and vision reasoning, available via vLLM or Transformers with a system prompt for enhanced performance."
  },
  {
    "model_name": "mistralai_Devstral-Small-2507-GGUF",
    "developer": "bartowski",
    "downloads": 3525,
    "createdAt": "2025-07-10T14:40:40.000Z",
    "num_quants": 27,
    "quants": [
      {
        "model_id": "mistralai_Devstral-Small-2507-IQ2_M",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-IQ2_M.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-IQ2_S",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-IQ2_S.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-IQ2_XS",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-IQ2_XS.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-IQ3_M",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-IQ3_M.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-IQ3_XS",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-IQ3_XS.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-IQ3_XXS.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-IQ4_NL",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-IQ4_NL.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-IQ4_XS",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-IQ4_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q2_K",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q2_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q2_K_L.gguf",
        "file_size": "8.9 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q3_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q3_K_L.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q3_K_M",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q3_K_S",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q3_K_XL.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q4_0",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q4_0.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q4_1",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q4_1.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q4_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q4_K_L.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q4_K_M",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q4_K_S",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q5_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q5_K_L.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q5_K_M",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q5_K_S",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q6_K",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q6_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q6_K_L.gguf",
        "file_size": "18.3 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-Q8_0",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-Q8_0.gguf",
        "file_size": "23.3 GB"
      },
      {
        "model_id": "mistralai_Devstral-Small-2507-bf16",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mistralai_Devstral-Small-2507-bf16.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "mmproj-mistralai_Devstral-Small-2507-f16",
        "path": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/mmproj-mistralai_Devstral-Small-2507-f16.gguf",
        "file_size": "837.4 MB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/mistralai_Devstral-Small-2507-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "mistralai_Magistral-Small-2506-GGUF",
    "developer": "bartowski",
    "downloads": 5525,
    "createdAt": "2025-06-10T16:09:49.000Z",
    "num_quants": 27,
    "quants": [
      {
        "model_id": "mistralai_Magistral-Small-2506-IQ2_M",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-IQ2_M.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-IQ2_S",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-IQ2_S.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-IQ2_XS",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-IQ2_XS.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-IQ2_XXS",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-IQ2_XXS.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-IQ3_M",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-IQ3_M.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-IQ3_XS",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-IQ3_XS.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-IQ3_XXS.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-IQ4_NL",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-IQ4_NL.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-IQ4_XS",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-IQ4_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q2_K",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q2_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q2_K_L.gguf",
        "file_size": "8.9 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q3_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q3_K_L.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q3_K_M",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q3_K_S",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q3_K_XL.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q4_0",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q4_0.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q4_1",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q4_1.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q4_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q4_K_L.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q4_K_M",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q4_K_S",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q5_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q5_K_L.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q5_K_M",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q5_K_S",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q6_K",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q6_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q6_K_L.gguf",
        "file_size": "18.3 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-Q8_0",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-Q8_0.gguf",
        "file_size": "23.3 GB"
      },
      {
        "model_id": "mistralai_Magistral-Small-2506-bf16",
        "path": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/mistralai_Magistral-Small-2506-bf16.gguf",
        "file_size": "43.9 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/mistralai_Magistral-Small-2506-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Magistral-Small-2506 model by bartowski, optimized for various inference speeds and quality levels using llama.cpp.",
    "tools": false
  },
  {
    "model_name": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF",
    "developer": "bartowski",
    "downloads": 27315,
    "createdAt": "2025-06-20T19:03:22.000Z",
    "num_quants": 29,
    "quants": [
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ2_M",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ2_M.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ2_S",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ2_S.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ2_XS",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ2_XS.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ2_XXS",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ2_XXS.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ3_M",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ3_M.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ3_XS",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ3_XS.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ3_XXS.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ4_NL",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ4_NL.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ4_XS",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-IQ4_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q2_K",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q2_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q2_K_L.gguf",
        "file_size": "8.9 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q3_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q3_K_L.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q3_K_M",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q3_K_S",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q3_K_XL.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q4_0",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q4_0.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q4_1",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q4_1.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q4_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q4_K_L.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q4_K_M",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q4_K_S",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q5_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q5_K_L.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q5_K_M",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q5_K_S",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q6_K",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q6_K_L",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q6_K_L.gguf",
        "file_size": "18.3 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q8_0",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q8_0.gguf",
        "file_size": "23.3 GB"
      },
      {
        "model_id": "mistralai_Mistral-Small-3.2-24B-Instruct-2506-bf16",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mistralai_Mistral-Small-3.2-24B-Instruct-2506-bf16.gguf",
        "file_size": "43.9 GB"
      },
      {
        "model_id": "mmproj-mistralai_Mistral-Small-3.2-24B-Instruct-2506-bf16",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mmproj-mistralai_Mistral-Small-3.2-24B-Instruct-2506-bf16.gguf",
        "file_size": "837.4 MB"
      },
      {
        "model_id": "mmproj-mistralai_Mistral-Small-3.2-24B-Instruct-2506-f16",
        "path": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/mmproj-mistralai_Mistral-Small-3.2-24B-Instruct-2506-f16.gguf",
        "file_size": "837.4 MB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Mistral-Small-3.2-24B-Instruct-2506 model using llama.cpp, offering various quantization types for different performance and quality trade-offs.",
    "tools": true
  },
  {
    "model_name": "Mixtral-8x22B-v0.1-GGUF",
    "developer": "bartowski",
    "downloads": 1290,
    "createdAt": "2024-04-11T04:39:53.000Z",
    "num_quants": 65,
    "quants": [
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_M-00001-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_M-00001-of-00005.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_M-00002-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_M-00002-of-00005.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_M-00003-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_M-00003-of-00005.gguf",
        "file_size": "12.7 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_M-00004-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_M-00004-of-00005.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_M-00005-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_M-00005-of-00005.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_S-00001-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_S-00001-of-00005.gguf",
        "file_size": "13.0 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_S-00002-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_S-00002-of-00005.gguf",
        "file_size": "13.5 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_S-00003-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_S-00003-of-00005.gguf",
        "file_size": "12.3 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_S-00004-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_S-00004-of-00005.gguf",
        "file_size": "13.2 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_S-00005-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_S-00005-of-00005.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_XS-00001-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_XS-00001-of-00005.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_XS-00002-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_XS-00002-of-00005.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_XS-00003-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_XS-00003-of-00005.gguf",
        "file_size": "11.4 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_XS-00004-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_XS-00004-of-00005.gguf",
        "file_size": "12.4 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ3_XS-00005-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ3_XS-00005-of-00005.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ4_NL-00001-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ4_NL-00001-of-00005.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ4_NL-00002-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ4_NL-00002-of-00005.gguf",
        "file_size": "17.6 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ4_NL-00003-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ4_NL-00003-of-00005.gguf",
        "file_size": "15.9 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ4_NL-00004-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ4_NL-00004-of-00005.gguf",
        "file_size": "17.2 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ4_NL-00005-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ4_NL-00005-of-00005.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ4_XS-00001-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ4_XS-00001-of-00005.gguf",
        "file_size": "16.8 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ4_XS-00002-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ4_XS-00002-of-00005.gguf",
        "file_size": "16.6 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ4_XS-00003-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ4_XS-00003-of-00005.gguf",
        "file_size": "15.1 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ4_XS-00004-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ4_XS-00004-of-00005.gguf",
        "file_size": "16.2 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-IQ4_XS-00005-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-IQ4_XS-00005-of-00005.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q2_K-00001-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q2_K-00001-of-00005.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q2_K-00002-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q2_K-00002-of-00005.gguf",
        "file_size": "11.4 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q2_K-00003-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q2_K-00003-of-00005.gguf",
        "file_size": "10.4 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q2_K-00004-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q2_K-00004-of-00005.gguf",
        "file_size": "11.2 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q2_K-00005-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q2_K-00005-of-00005.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_L-00001-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_L-00001-of-00005.gguf",
        "file_size": "15.4 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_L-00002-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_L-00002-of-00005.gguf",
        "file_size": "15.9 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_L-00003-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_L-00003-of-00005.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_L-00004-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_L-00004-of-00005.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_L-00005-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_L-00005-of-00005.gguf",
        "file_size": "6.2 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_M-00001-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_M-00001-of-00005.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_M-00002-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_M-00002-of-00005.gguf",
        "file_size": "14.8 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_M-00003-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_M-00003-of-00005.gguf",
        "file_size": "13.5 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_M-00004-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_M-00004-of-00005.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_M-00005-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_M-00005-of-00005.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_S-00001-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_S-00001-of-00005.gguf",
        "file_size": "13.0 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_S-00002-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_S-00002-of-00005.gguf",
        "file_size": "13.5 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_S-00003-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_S-00003-of-00005.gguf",
        "file_size": "12.3 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_S-00004-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_S-00004-of-00005.gguf",
        "file_size": "13.2 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q3_K_S-00005-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q3_K_S-00005-of-00005.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q4_K_M-00001-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q4_K_M-00001-of-00005.gguf",
        "file_size": "18.6 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q4_K_M-00002-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q4_K_M-00002-of-00005.gguf",
        "file_size": "18.3 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q4_K_M-00003-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q4_K_M-00003-of-00005.gguf",
        "file_size": "16.7 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q4_K_M-00004-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q4_K_M-00004-of-00005.gguf",
        "file_size": "18.3 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q4_K_M-00005-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q4_K_M-00005-of-00005.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q4_K_S-00001-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q4_K_S-00001-of-00005.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q4_K_S-00002-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q4_K_S-00002-of-00005.gguf",
        "file_size": "17.6 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q4_K_S-00003-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q4_K_S-00003-of-00005.gguf",
        "file_size": "15.9 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q4_K_S-00004-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q4_K_S-00004-of-00005.gguf",
        "file_size": "17.2 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q4_K_S-00005-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q4_K_S-00005-of-00005.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q5_K_M-00001-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q5_K_M-00001-of-00005.gguf",
        "file_size": "21.4 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q5_K_M-00002-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q5_K_M-00002-of-00005.gguf",
        "file_size": "21.8 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q5_K_M-00003-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q5_K_M-00003-of-00005.gguf",
        "file_size": "19.8 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q5_K_M-00004-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q5_K_M-00004-of-00005.gguf",
        "file_size": "21.5 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q5_K_M-00005-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q5_K_M-00005-of-00005.gguf",
        "file_size": "8.7 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q5_K_S-00001-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q5_K_S-00001-of-00005.gguf",
        "file_size": "20.5 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q5_K_S-00002-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q5_K_S-00002-of-00005.gguf",
        "file_size": "21.4 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q5_K_S-00003-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q5_K_S-00003-of-00005.gguf",
        "file_size": "19.4 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q5_K_S-00004-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q5_K_S-00004-of-00005.gguf",
        "file_size": "20.9 GB"
      },
      {
        "model_id": "Mixtral-8x22B-v0.1-Q5_K_S-00005-of-00005",
        "path": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/Mixtral-8x22B-v0.1-Q5_K_S-00005-of-00005.gguf",
        "file_size": "8.2 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Mixtral-8x22B-v0.1-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Mixtral-8x7B-Instruct-v0.1-GGUF",
    "developer": "TheBloke",
    "downloads": 38272,
    "createdAt": "2023-12-11T18:08:33.000Z",
    "num_quants": 8,
    "quants": [
      {
        "model_id": "mixtral-8x7b-instruct-v0.1.Q2_K",
        "path": "https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q2_K.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "mixtral-8x7b-instruct-v0.1.Q3_K_M",
        "path": "https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q3_K_M.gguf",
        "file_size": "19.0 GB"
      },
      {
        "model_id": "mixtral-8x7b-instruct-v0.1.Q4_0",
        "path": "https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q4_0.gguf",
        "file_size": "24.6 GB"
      },
      {
        "model_id": "mixtral-8x7b-instruct-v0.1.Q4_K_M",
        "path": "https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf",
        "file_size": "24.6 GB"
      },
      {
        "model_id": "mixtral-8x7b-instruct-v0.1.Q5_0",
        "path": "https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q5_0.gguf",
        "file_size": "30.0 GB"
      },
      {
        "model_id": "mixtral-8x7b-instruct-v0.1.Q5_K_M",
        "path": "https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q5_K_M.gguf",
        "file_size": "30.0 GB"
      },
      {
        "model_id": "mixtral-8x7b-instruct-v0.1.Q6_K",
        "path": "https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q6_K.gguf",
        "file_size": "35.7 GB"
      },
      {
        "model_id": "mixtral-8x7b-instruct-v0.1.Q8_0",
        "path": "https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q8_0.gguf",
        "file_size": "46.2 GB"
      }
    ],
    "readme": "https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/README.md",
    "description": "The Mixtral 8X7B Instruct v0.1 model is a quantized version of Mistral AI's large language model, optimized for efficient inference on various platforms including llama.cpp, LM Studio, and llama-cpp-python, with different quantization levels offering trade-offs between size",
    "tools": false
  },
  {
    "model_name": "mlabonne_gemma-3-27b-it-abliterated-GGUF",
    "developer": "bartowski",
    "downloads": 6478,
    "createdAt": "2025-03-17T23:52:54.000Z",
    "num_quants": 29,
    "quants": [
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-IQ2_M",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-IQ2_M.gguf",
        "file_size": "8.8 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-IQ2_S",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-IQ2_S.gguf",
        "file_size": "8.2 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-IQ2_XS",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-IQ2_XS.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-IQ3_M",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-IQ3_M.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-IQ3_XS",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-IQ3_XS.gguf",
        "file_size": "10.8 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-IQ3_XXS.gguf",
        "file_size": "10.0 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-IQ4_NL",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-IQ4_NL.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-IQ4_XS",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-IQ4_XS.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q2_K",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q2_K.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q2_K_L",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q2_K_L.gguf",
        "file_size": "10.1 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q3_K_L",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q3_K_L.gguf",
        "file_size": "13.5 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q3_K_M",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q3_K_M.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q3_K_S",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q3_K_S.gguf",
        "file_size": "11.3 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q3_K_XL.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q4_0",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q4_0.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q4_1",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q4_1.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q4_K_L",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q4_K_L.gguf",
        "file_size": "15.7 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q4_K_M",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q4_K_M.gguf",
        "file_size": "15.4 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q4_K_S",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q4_K_S.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q5_K_L",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q5_K_L.gguf",
        "file_size": "18.3 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q5_K_M",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q5_K_M.gguf",
        "file_size": "17.9 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q5_K_S",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q5_K_S.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q6_K",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q6_K.gguf",
        "file_size": "20.6 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q6_K_L",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q6_K_L.gguf",
        "file_size": "21.0 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-Q8_0",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-Q8_0.gguf",
        "file_size": "26.7 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-bf16/mlabonne_gemma-3-27b-it-abliterated-bf16-00001-of-00002",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-bf16/mlabonne_gemma-3-27b-it-abliterated-bf16-00001-of-00002.gguf",
        "file_size": "37.2 GB"
      },
      {
        "model_id": "mlabonne_gemma-3-27b-it-abliterated-bf16/mlabonne_gemma-3-27b-it-abliterated-bf16-00002-of-00002",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mlabonne_gemma-3-27b-it-abliterated-bf16/mlabonne_gemma-3-27b-it-abliterated-bf16-00002-of-00002.gguf",
        "file_size": "13.1 GB"
      },
      {
        "model_id": "mmproj-mlabonne_gemma-3-27b-it-abliterated-f16",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mmproj-mlabonne_gemma-3-27b-it-abliterated-f16.gguf",
        "file_size": "818.0 MB"
      },
      {
        "model_id": "mmproj-mlabonne_gemma-3-27b-it-abliterated-f32",
        "path": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/mmproj-mlabonne_gemma-3-27b-it-abliterated-f32.gguf",
        "file_size": "1.6 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/mlabonne_gemma-3-27b-it-abliterated-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "MN-12B-Mag-Mell-R1-GGUF",
    "developer": "bartowski",
    "downloads": 2063,
    "createdAt": "2024-12-28T20:38:12.000Z",
    "num_quants": 24,
    "quants": [
      {
        "model_id": "MN-12B-Mag-Mell-R1-IQ2_M",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-IQ2_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-IQ2_S",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-IQ2_S.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-IQ3_M",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-IQ3_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-IQ3_XS",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-IQ3_XS.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-IQ4_NL",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-IQ4_NL.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-IQ4_XS",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-IQ4_XS.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q2_K",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q2_K.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q2_K_L",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q2_K_L.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q3_K_L",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q3_K_L.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q3_K_M",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q3_K_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q3_K_S",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q3_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q3_K_XL.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q4_0",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q4_0.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q4_1",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q4_1.gguf",
        "file_size": "7.3 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q4_K_L",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q4_K_L.gguf",
        "file_size": "7.4 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q4_K_M",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q4_K_M.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q4_K_S",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q4_K_S.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q5_K_L",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q5_K_L.gguf",
        "file_size": "8.5 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q5_K_M",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q5_K_M.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q5_K_S",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q5_K_S.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q6_K",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q6_K.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q6_K_L",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q6_K_L.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-Q8_0",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-Q8_0.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1-f16",
        "path": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1-f16.gguf",
        "file_size": "22.8 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/MN-12B-Mag-Mell-R1-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "MN-12B-Mag-Mell-R1-GGUF",
    "developer": "mradermacher",
    "downloads": 29530,
    "createdAt": "2024-09-16T19:10:02.000Z",
    "num_quants": 14,
    "quants": [
      {
        "model_id": "MN-12B-Mag-Mell-R1.IQ3_M",
        "path": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1.IQ3_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1.IQ3_S",
        "path": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1.IQ3_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1.IQ3_XS",
        "path": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1.IQ3_XS.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1.IQ4_XS",
        "path": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1.IQ4_XS.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1.Q2_K",
        "path": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1.Q2_K.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1.Q3_K_L",
        "path": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1.Q3_K_L.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1.Q3_K_M",
        "path": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1.Q3_K_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1.Q3_K_S",
        "path": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1.Q3_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1.Q4_K_M",
        "path": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1.Q4_K_M.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1.Q4_K_S",
        "path": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1.Q4_K_S.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1.Q5_K_M",
        "path": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1.Q5_K_M.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1.Q5_K_S",
        "path": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1.Q5_K_S.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1.Q6_K",
        "path": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1.Q6_K.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "MN-12B-Mag-Mell-R1.Q8_0",
        "path": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/MN-12B-Mag-Mell-R1.Q8_0.gguf",
        "file_size": "12.1 GB"
      }
    ],
    "readme": "https://huggingface.co/mradermacher/MN-12B-Mag-Mell-R1-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF",
    "developer": "DavidAU",
    "downloads": 578,
    "createdAt": "2024-11-07T06:58:54.000Z",
    "num_quants": 14,
    "quants": [
      {
        "model_id": "MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-IQ4_XS",
        "path": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-IQ4_XS.gguf",
        "file_size": "9.5 GB"
      },
      {
        "model_id": "MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q2_k",
        "path": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q2_k.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q3_k_l",
        "path": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q3_k_l.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q3_k_m",
        "path": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q3_k_m.gguf",
        "file_size": "8.5 GB"
      },
      {
        "model_id": "MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q3_k_s",
        "path": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q3_k_s.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q4_0_4_4",
        "path": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q4_0_4_4.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q4_0_4_8",
        "path": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q4_0_4_8.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q4_0_8_8",
        "path": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q4_0_8_8.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q4_k_m",
        "path": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q4_k_m.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q4_k_s",
        "path": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q4_k_s.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q5_k_s",
        "path": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q5_k_s.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q6_k",
        "path": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q6_k.gguf",
        "file_size": "14.2 GB"
      },
      {
        "model_id": "MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-Q8_0.gguf",
        "file_size": "18.3 GB"
      },
      {
        "model_id": "MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-q5_k_m",
        "path": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/MN-Dark-Horror-The-Cliffhanger-18.5B-D_AU-q5_k_m.gguf",
        "file_size": "12.3 GB"
      }
    ],
    "readme": "https://huggingface.co/DavidAU/MN-Dark-Horror-The-Cliffhanger-18.5B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "MN-Violet-Lotus-12B-GGUF",
    "developer": "mradermacher",
    "downloads": 12717,
    "createdAt": "2024-11-17T05:53:19.000Z",
    "num_quants": 12,
    "quants": [
      {
        "model_id": "MN-Violet-Lotus-12B.IQ4_XS",
        "path": "https://huggingface.co/mradermacher/MN-Violet-Lotus-12B-GGUF/resolve/main/MN-Violet-Lotus-12B.IQ4_XS.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "MN-Violet-Lotus-12B.Q2_K",
        "path": "https://huggingface.co/mradermacher/MN-Violet-Lotus-12B-GGUF/resolve/main/MN-Violet-Lotus-12B.Q2_K.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "MN-Violet-Lotus-12B.Q3_K_L",
        "path": "https://huggingface.co/mradermacher/MN-Violet-Lotus-12B-GGUF/resolve/main/MN-Violet-Lotus-12B.Q3_K_L.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "MN-Violet-Lotus-12B.Q3_K_M",
        "path": "https://huggingface.co/mradermacher/MN-Violet-Lotus-12B-GGUF/resolve/main/MN-Violet-Lotus-12B.Q3_K_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "MN-Violet-Lotus-12B.Q3_K_S",
        "path": "https://huggingface.co/mradermacher/MN-Violet-Lotus-12B-GGUF/resolve/main/MN-Violet-Lotus-12B.Q3_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "MN-Violet-Lotus-12B.Q4_0_4_4",
        "path": "https://huggingface.co/mradermacher/MN-Violet-Lotus-12B-GGUF/resolve/main/MN-Violet-Lotus-12B.Q4_0_4_4.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "MN-Violet-Lotus-12B.Q4_K_M",
        "path": "https://huggingface.co/mradermacher/MN-Violet-Lotus-12B-GGUF/resolve/main/MN-Violet-Lotus-12B.Q4_K_M.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "MN-Violet-Lotus-12B.Q4_K_S",
        "path": "https://huggingface.co/mradermacher/MN-Violet-Lotus-12B-GGUF/resolve/main/MN-Violet-Lotus-12B.Q4_K_S.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "MN-Violet-Lotus-12B.Q5_K_M",
        "path": "https://huggingface.co/mradermacher/MN-Violet-Lotus-12B-GGUF/resolve/main/MN-Violet-Lotus-12B.Q5_K_M.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "MN-Violet-Lotus-12B.Q5_K_S",
        "path": "https://huggingface.co/mradermacher/MN-Violet-Lotus-12B-GGUF/resolve/main/MN-Violet-Lotus-12B.Q5_K_S.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "MN-Violet-Lotus-12B.Q6_K",
        "path": "https://huggingface.co/mradermacher/MN-Violet-Lotus-12B-GGUF/resolve/main/MN-Violet-Lotus-12B.Q6_K.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "MN-Violet-Lotus-12B.Q8_0",
        "path": "https://huggingface.co/mradermacher/MN-Violet-Lotus-12B-GGUF/resolve/main/MN-Violet-Lotus-12B.Q8_0.gguf",
        "file_size": "12.1 GB"
      }
    ],
    "readme": "https://huggingface.co/mradermacher/MN-Violet-Lotus-12B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "MS3.2-24B-Magnum-Diamond-GGUF",
    "developer": "Doctor-Shotgun",
    "downloads": 9829,
    "createdAt": "2025-06-22T18:07:51.000Z",
    "num_quants": 24,
    "quants": [
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-IQ1_M",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-IQ1_M.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-IQ1_S",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-IQ1_S.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-IQ2_M",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-IQ2_M.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-IQ2_S",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-IQ2_S.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-IQ2_XS",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-IQ2_XS.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-IQ2_XXS",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-IQ2_XXS.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-IQ3_M",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-IQ3_M.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-IQ3_S",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-IQ3_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-IQ3_XS",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-IQ3_XS.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-IQ3_XXS",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-IQ3_XXS.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-IQ4_NL",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-IQ4_NL.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-IQ4_XS",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-IQ4_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-Q2_K",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-Q2_K_S",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-Q2_K_S.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-Q3_K_L",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-Q3_K_L.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-Q3_K_M",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-Q3_K_S",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-Q4_K_M",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-Q4_K_S",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-Q5_K_M",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-Q5_K_S",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-Q6_K",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-Q8_0",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-Q8_0.gguf",
        "file_size": "23.3 GB"
      },
      {
        "model_id": "MS3.2-24B-Magnum-Diamond-bf16",
        "path": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/MS3.2-24B-Magnum-Diamond-bf16.gguf",
        "file_size": "43.9 GB"
      }
    ],
    "readme": "https://huggingface.co/Doctor-Shotgun/MS3.2-24B-Magnum-Diamond-GGUF/resolve/main/README.md",
    "description": "This is a GGUF quantized version of the Doctor-Shotgun/MS3.2-24B-Magnum-Diamond model, optimized for creative writing and roleplay with specific SillyTavern presets provided.",
    "tools": false
  },
  {
    "model_name": "MS3.2-PaintedFantasy-Visage-33B-i1-GGUF",
    "developer": "mradermacher",
    "downloads": 1962,
    "createdAt": "2025-07-03T14:52:05.000Z",
    "num_quants": 23,
    "quants": [
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-IQ1_M",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-IQ1_M.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-IQ1_S",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-IQ1_S.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-IQ2_M",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-IQ2_M.gguf",
        "file_size": "10.6 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-IQ2_S",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-IQ2_S.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-IQ2_XS",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-IQ2_XS.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-IQ2_XXS",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-IQ2_XXS.gguf",
        "file_size": "8.5 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-IQ3_M",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-IQ3_M.gguf",
        "file_size": "14.0 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-IQ3_S",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-IQ3_S.gguf",
        "file_size": "13.7 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-IQ3_XS",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-IQ3_XS.gguf",
        "file_size": "13.0 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-IQ3_XXS",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-IQ3_XXS.gguf",
        "file_size": "12.2 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-IQ4_XS",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-IQ4_XS.gguf",
        "file_size": "16.8 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-Q2_K",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-Q2_K.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-Q2_K_S",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-Q2_K_S.gguf",
        "file_size": "10.9 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-Q3_K_L",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-Q3_K_L.gguf",
        "file_size": "16.4 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-Q3_K_M",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-Q3_K_M.gguf",
        "file_size": "15.1 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-Q3_K_S",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-Q3_K_S.gguf",
        "file_size": "13.7 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-Q4_0",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-Q4_0.gguf",
        "file_size": "17.8 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-Q4_1",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-Q4_1.gguf",
        "file_size": "19.7 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-Q4_K_M",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-Q4_K_M.gguf",
        "file_size": "19.0 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-Q4_K_S",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-Q4_K_S.gguf",
        "file_size": "17.9 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-Q5_K_M",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-Q5_K_M.gguf",
        "file_size": "22.2 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-Q5_K_S",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-Q5_K_S.gguf",
        "file_size": "21.6 GB"
      },
      {
        "model_id": "MS3.2-PaintedFantasy-Visage-33B.i1-Q6_K",
        "path": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/MS3.2-PaintedFantasy-Visage-33B.i1-Q6_K.gguf",
        "file_size": "25.7 GB"
      }
    ],
    "readme": "https://huggingface.co/mradermacher/MS3.2-PaintedFantasy-Visage-33B-i1-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "MythoMakiseMerged-13b",
    "developer": "Heralax",
    "downloads": 270,
    "createdAt": "2023-09-30T06:59:22.000Z",
    "tools": false,
    "num_quants": 2,
    "quants": [
      {
        "model_id": "MythoMakiseMerged-13b-q5km",
        "path": "https://huggingface.co/Heralax/MythoMakiseMerged-13b/resolve/main/MythoMakiseMerged-13b-q5km.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "ggml-model-f16",
        "path": "https://huggingface.co/Heralax/MythoMakiseMerged-13b/resolve/main/ggml-model-f16.gguf",
        "file_size": "24.2 GB"
      }
    ],
    "readme": "https://huggingface.co/Heralax/MythoMakiseMerged-13b/resolve/main/README.md",
    "description": "This model is a fine-tuned version of MythoMax-L2-13b, enhanced with 33% of MythoMax's intelligence merged back in, trained on a visual novel script revamped by GPT-4 to excel in banter, conversation, and roleplay, even"
  },
  {
    "model_name": "MythoMax-L2-13B-GGUF",
    "developer": "TheBloke",
    "downloads": 104493,
    "createdAt": "2023-09-05T03:10:48.000Z",
    "tools": false,
    "num_quants": 12,
    "quants": [
      {
        "model_id": "mythomax-l2-13b.Q2_K",
        "path": "https://huggingface.co/TheBloke/MythoMax-L2-13B-GGUF/resolve/main/mythomax-l2-13b.Q2_K.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "mythomax-l2-13b.Q3_K_L",
        "path": "https://huggingface.co/TheBloke/MythoMax-L2-13B-GGUF/resolve/main/mythomax-l2-13b.Q3_K_L.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "mythomax-l2-13b.Q3_K_M",
        "path": "https://huggingface.co/TheBloke/MythoMax-L2-13B-GGUF/resolve/main/mythomax-l2-13b.Q3_K_M.gguf",
        "file_size": "5.9 GB"
      },
      {
        "model_id": "mythomax-l2-13b.Q3_K_S",
        "path": "https://huggingface.co/TheBloke/MythoMax-L2-13B-GGUF/resolve/main/mythomax-l2-13b.Q3_K_S.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "mythomax-l2-13b.Q4_0",
        "path": "https://huggingface.co/TheBloke/MythoMax-L2-13B-GGUF/resolve/main/mythomax-l2-13b.Q4_0.gguf",
        "file_size": "6.9 GB"
      },
      {
        "model_id": "mythomax-l2-13b.Q4_K_M",
        "path": "https://huggingface.co/TheBloke/MythoMax-L2-13B-GGUF/resolve/main/mythomax-l2-13b.Q4_K_M.gguf",
        "file_size": "7.3 GB"
      },
      {
        "model_id": "mythomax-l2-13b.Q4_K_S",
        "path": "https://huggingface.co/TheBloke/MythoMax-L2-13B-GGUF/resolve/main/mythomax-l2-13b.Q4_K_S.gguf",
        "file_size": "6.9 GB"
      },
      {
        "model_id": "mythomax-l2-13b.Q5_0",
        "path": "https://huggingface.co/TheBloke/MythoMax-L2-13B-GGUF/resolve/main/mythomax-l2-13b.Q5_0.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "mythomax-l2-13b.Q5_K_M",
        "path": "https://huggingface.co/TheBloke/MythoMax-L2-13B-GGUF/resolve/main/mythomax-l2-13b.Q5_K_M.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "mythomax-l2-13b.Q5_K_S",
        "path": "https://huggingface.co/TheBloke/MythoMax-L2-13B-GGUF/resolve/main/mythomax-l2-13b.Q5_K_S.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "mythomax-l2-13b.Q6_K",
        "path": "https://huggingface.co/TheBloke/MythoMax-L2-13B-GGUF/resolve/main/mythomax-l2-13b.Q6_K.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "mythomax-l2-13b.Q8_0",
        "path": "https://huggingface.co/TheBloke/MythoMax-L2-13B-GGUF/resolve/main/mythomax-l2-13b.Q8_0.gguf",
        "file_size": "12.9 GB"
      }
    ],
    "readme": "https://huggingface.co/TheBloke/MythoMax-L2-13B-GGUF/resolve/main/README.md",
    "description": "The MythoMax L2 13B model by Gryphe is a GGUF format variant of the Llama 2 model, offering various quantization options for efficient inference on CPU and GPU, with a custom prompt template for roleplay and storywriting tasks."
  },
  {
    "model_name": "Nanonets-OCR-s-GGUF",
    "developer": "unsloth",
    "downloads": 23229,
    "createdAt": "2025-06-16T10:35:11.000Z",
    "num_quants": 3,
    "quants": [
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/Nanonets-OCR-s-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/Nanonets-OCR-s-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/Nanonets-OCR-s-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "2.5 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Nanonets-OCR-s-GGUF/resolve/main/README.md",
    "description": "Nanonets-OCR-s is a state-of-the-art image-to-markdown OCR model that extracts text, equations, tables, and other structured elements from documents, converting them into semantic markdown for efficient processing by LLMs.",
    "tools": false
  },
  {
    "model_name": "Nidum-Llama-3.2-3B-Uncensored-GGUF",
    "developer": "nidum",
    "downloads": 2258,
    "createdAt": "2024-12-05T04:55:35.000Z",
    "num_quants": 15,
    "quants": [
      {
        "model_id": "Nidum-Llama-3.2-3B-Uncensored-F16",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/Nidum-Llama-3.2-3B-Uncensored-F16.gguf",
        "file_size": "6.0 GB"
      },
      {
        "model_id": "model-Q2_K",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-Q2_K.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "model-Q3_K_L",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-Q3_K_L.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "model-Q3_K_M",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-Q3_K_M.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "model-Q3_K_S",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-Q3_K_S.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "model-Q4_0_4_4",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-Q4_0_4_4.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "model-Q4_0_4_8",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-Q4_0_4_8.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "model-Q4_0_8_8",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-Q4_0_8_8.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "model-Q4_K_M",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-Q4_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "model-Q4_K_S",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-Q4_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "model-Q5_K_M",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-Q5_K_M.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "model-Q5_K_S",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-Q5_K_S.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "model-Q6_K",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-Q6_K.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "model-TQ1_0",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-TQ1_0.gguf",
        "file_size": "883.4 MB"
      },
      {
        "model_id": "model-TQ2_0",
        "path": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-TQ2_0.gguf",
        "file_size": "1009.4 MB"
      }
    ],
    "readme": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Nous-Hermes-2-Mistral-7B-DPO-GGUF",
    "developer": "NousResearch",
    "downloads": 27040,
    "createdAt": "2024-02-20T06:25:05.000Z",
    "num_quants": 12,
    "quants": [
      {
        "model_id": "Nous-Hermes-2-Mistral-7B-DPO.Q2_K",
        "path": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q2_K.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "Nous-Hermes-2-Mistral-7B-DPO.Q3_K_L",
        "path": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q3_K_L.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "Nous-Hermes-2-Mistral-7B-DPO.Q3_K_M",
        "path": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q3_K_M.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Nous-Hermes-2-Mistral-7B-DPO.Q3_K_S",
        "path": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q3_K_S.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Nous-Hermes-2-Mistral-7B-DPO.Q4_0",
        "path": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q4_0.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "Nous-Hermes-2-Mistral-7B-DPO.Q4_K_M",
        "path": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q4_K_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Nous-Hermes-2-Mistral-7B-DPO.Q4_K_S",
        "path": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q4_K_S.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Nous-Hermes-2-Mistral-7B-DPO.Q5_0",
        "path": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q5_0.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Nous-Hermes-2-Mistral-7B-DPO.Q5_K_M",
        "path": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q5_K_M.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "Nous-Hermes-2-Mistral-7B-DPO.Q5_K_S",
        "path": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q5_K_S.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Nous-Hermes-2-Mistral-7B-DPO.Q6_K",
        "path": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q6_K.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "Nous-Hermes-2-Mistral-7B-DPO.Q8_0",
        "path": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q8_0.gguf",
        "file_size": "7.2 GB"
      }
    ],
    "readme": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/README.md",
    "description": "Nous-Hermes 2 Mistral 7B DPO is a 7B parameter model fine-tuned with DPO from Teknium/OpenHermes-2.5-Mistral-7B, showing improved performance on AGIEval, BigBench, GPT4",
    "tools": false
  },
  {
    "model_name": "NSFW_DPO_Noromaid-7b-Mistral-7B-Instruct-v0.1-Q6_K-GGUF",
    "developer": "DavidAU",
    "downloads": 426,
    "createdAt": "2024-04-21T10:43:00.000Z",
    "num_quants": 1,
    "quants": [
      {
        "model_id": "nsfw_dpo_noromaid-7b-mistral-7b-instruct-v0.1.Q6_K",
        "path": "https://huggingface.co/DavidAU/NSFW_DPO_Noromaid-7b-Mistral-7B-Instruct-v0.1-Q6_K-GGUF/resolve/main/nsfw_dpo_noromaid-7b-mistral-7b-instruct-v0.1.Q6_K.gguf",
        "file_size": "5.5 GB"
      }
    ],
    "readme": "https://huggingface.co/DavidAU/NSFW_DPO_Noromaid-7b-Mistral-7B-Instruct-v0.1-Q6_K-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "nvidia_OpenReasoning-Nemotron-1.5B-GGUF",
    "developer": "bartowski",
    "downloads": 2884,
    "createdAt": "2025-07-18T20:42:31.000Z",
    "tools": false,
    "num_quants": 23,
    "quants": [
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-IQ3_M",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-IQ3_M.gguf",
        "file_size": "740.7 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-IQ3_XS",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-IQ3_XS.gguf",
        "file_size": "697.8 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-IQ3_XXS.gguf",
        "file_size": "637.8 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-IQ4_NL",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-IQ4_NL.gguf",
        "file_size": "893.0 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-IQ4_XS",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-IQ4_XS.gguf",
        "file_size": "854.2 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q2_K",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q2_K.gguf",
        "file_size": "645.0 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q2_K_L",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q2_K_L.gguf",
        "file_size": "698.9 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q3_K_L",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q3_K_L.gguf",
        "file_size": "839.4 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q3_K_M",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q3_K_M.gguf",
        "file_size": "786.0 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q3_K_S",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q3_K_S.gguf",
        "file_size": "725.7 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q3_K_XL.gguf",
        "file_size": "893.3 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q4_0",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q4_0.gguf",
        "file_size": "894.1 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q4_1",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q4_1.gguf",
        "file_size": "969.7 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q4_K_L",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q4_K_L.gguf",
        "file_size": "994.3 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q4_K_M",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q4_K_M.gguf",
        "file_size": "940.4 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q4_K_S",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q4_K_S.gguf",
        "file_size": "896.8 MB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q5_K_L",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q5_K_L.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q5_K_M",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q5_K_M.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q5_K_S",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q5_K_S.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q6_K",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q6_K.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q6_K_L",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q6_K_L.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-Q8_0",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-Q8_0.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-1.5B-bf16",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-1.5B-bf16.gguf",
        "file_size": "2.9 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-1.5B-GGUF/resolve/main/README.md",
    "description": "This repository provides quantized versions of the OpenReasoning-Nemotron-1.5B model using llama.cpp, with various quantization types offering different trade-offs between performance, quality, and memory usage, recommended for use with LM Studio or other llama.cpp-based projects."
  },
  {
    "model_name": "nvidia_OpenReasoning-Nemotron-7B-GGUF",
    "developer": "bartowski",
    "downloads": 2005,
    "createdAt": "2025-07-18T20:42:50.000Z",
    "tools": false,
    "num_quants": 24,
    "quants": [
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-IQ2_M",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-IQ2_M.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-IQ3_M",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-IQ3_M.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-IQ3_XS",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-IQ3_XS.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-IQ3_XXS.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-IQ4_NL",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-IQ4_NL.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-IQ4_XS",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-IQ4_XS.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q2_K",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q2_K.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q2_K_L",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q2_K_L.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q3_K_L",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q3_K_L.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q3_K_M",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q3_K_M.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q3_K_S",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q3_K_S.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q3_K_XL.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q4_0",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q4_0.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q4_1",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q4_1.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q4_K_L",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q4_K_L.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q4_K_M",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q4_K_M.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q4_K_S",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q4_K_S.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q5_K_L",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q5_K_L.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q5_K_M",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q5_K_M.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q5_K_S",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q5_K_S.gguf",
        "file_size": "5.0 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q6_K",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q6_K.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q6_K_L",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q6_K_L.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-Q8_0",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-Q8_0.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "nvidia_OpenReasoning-Nemotron-7B-bf16",
        "path": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/nvidia_OpenReasoning-Nemotron-7B-bf16.gguf",
        "file_size": "14.2 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/nvidia_OpenReasoning-Nemotron-7B-GGUF/resolve/main/README.md",
    "description": "This repository provides quantized versions of the OpenReasoning-Nemotron-7B model using llama.cpp's imatrix method, with various quantization types offering different trade-offs between performance, quality, and memory usage, recommended for use in text generation tasks."
  },
  {
    "model_name": "oh-dcft-v3.1-claude-3-5-sonnet-20241022-GGUF",
    "developer": "mradermacher",
    "downloads": 18269,
    "createdAt": "2025-01-15T09:26:16.000Z",
    "num_quants": 12,
    "quants": [
      {
        "model_id": "oh-dcft-v3.1-claude-3-5-sonnet-20241022.IQ4_XS",
        "path": "https://huggingface.co/mradermacher/oh-dcft-v3.1-claude-3-5-sonnet-20241022-GGUF/resolve/main/oh-dcft-v3.1-claude-3-5-sonnet-20241022.IQ4_XS.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q2_K",
        "path": "https://huggingface.co/mradermacher/oh-dcft-v3.1-claude-3-5-sonnet-20241022-GGUF/resolve/main/oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q3_K_L",
        "path": "https://huggingface.co/mradermacher/oh-dcft-v3.1-claude-3-5-sonnet-20241022-GGUF/resolve/main/oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q3_K_M",
        "path": "https://huggingface.co/mradermacher/oh-dcft-v3.1-claude-3-5-sonnet-20241022-GGUF/resolve/main/oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q3_K_S",
        "path": "https://huggingface.co/mradermacher/oh-dcft-v3.1-claude-3-5-sonnet-20241022-GGUF/resolve/main/oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q4_K_M",
        "path": "https://huggingface.co/mradermacher/oh-dcft-v3.1-claude-3-5-sonnet-20241022-GGUF/resolve/main/oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q4_K_S",
        "path": "https://huggingface.co/mradermacher/oh-dcft-v3.1-claude-3-5-sonnet-20241022-GGUF/resolve/main/oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q5_K_M",
        "path": "https://huggingface.co/mradermacher/oh-dcft-v3.1-claude-3-5-sonnet-20241022-GGUF/resolve/main/oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q5_K_S",
        "path": "https://huggingface.co/mradermacher/oh-dcft-v3.1-claude-3-5-sonnet-20241022-GGUF/resolve/main/oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q6_K",
        "path": "https://huggingface.co/mradermacher/oh-dcft-v3.1-claude-3-5-sonnet-20241022-GGUF/resolve/main/oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q8_0",
        "path": "https://huggingface.co/mradermacher/oh-dcft-v3.1-claude-3-5-sonnet-20241022-GGUF/resolve/main/oh-dcft-v3.1-claude-3-5-sonnet-20241022.Q8_0.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "oh-dcft-v3.1-claude-3-5-sonnet-20241022.f16",
        "path": "https://huggingface.co/mradermacher/oh-dcft-v3.1-claude-3-5-sonnet-20241022-GGUF/resolve/main/oh-dcft-v3.1-claude-3-5-sonnet-20241022.f16.gguf",
        "file_size": "15.0 GB"
      }
    ],
    "readme": "https://huggingface.co/mradermacher/oh-dcft-v3.1-claude-3-5-sonnet-20241022-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Open-Insurance-LLM-Llama3-8B-GGUF",
    "developer": "bartowski",
    "downloads": 756,
    "createdAt": "2024-11-26T18:52:43.000Z",
    "num_quants": 24,
    "quants": [
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-IQ2_M",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-IQ2_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-IQ3_M",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-IQ3_M.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-IQ3_XS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-IQ4_XS.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q2_K",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q2_K.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q2_K_L",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q2_K_L.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q3_K_L.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q3_K_M.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q3_K_S.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q3_K_XL.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q4_0",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q4_0.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q4_0_4_4",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q4_0_4_4.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q4_0_4_8",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q4_0_4_8.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q4_0_8_8",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q4_0_8_8.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q4_K_L.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q4_K_M.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q4_K_S.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q5_K_L.gguf",
        "file_size": "5.6 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q5_K_M.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q5_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q6_K",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q6_K.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q6_K_L.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-Q8_0",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-Q8_0.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "Open-Insurance-LLM-Llama3-8B-f16",
        "path": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/Open-Insurance-LLM-Llama3-8B-f16.gguf",
        "file_size": "15.0 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Open-Insurance-LLM-Llama3-8B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "OpenReasoning-Nemotron-32B-GGUF",
    "developer": "unsloth",
    "downloads": 274,
    "createdAt": "2025-07-21T18:35:57.000Z",
    "tools": false,
    "num_quants": 27,
    "quants": [
      {
        "model_id": "BF16/OpenReasoning-Nemotron-32B-BF16-00001-of-00002",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/BF16/OpenReasoning-Nemotron-32B-BF16-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "BF16/OpenReasoning-Nemotron-32B-BF16-00002-of-00002",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/BF16/OpenReasoning-Nemotron-32B-BF16-00002-of-00002.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-IQ4_NL",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-IQ4_NL.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-IQ4_XS",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-IQ4_XS.gguf",
        "file_size": "16.5 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-Q2_K",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-Q2_K.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-Q2_K_L",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-Q2_K_L.gguf",
        "file_size": "11.6 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-Q3_K_M",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-Q3_K_M.gguf",
        "file_size": "14.8 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-Q3_K_S",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-Q3_K_S.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-Q4_0",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-Q4_0.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-Q4_1",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-Q4_1.gguf",
        "file_size": "19.2 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-Q4_K_M",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-Q4_K_M.gguf",
        "file_size": "18.5 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-Q4_K_S",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-Q4_K_S.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-Q5_K_M",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-Q5_K_M.gguf",
        "file_size": "21.7 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-Q5_K_S",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-Q5_K_S.gguf",
        "file_size": "21.1 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-Q6_K",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-Q6_K.gguf",
        "file_size": "25.0 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-Q8_0",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-Q8_0.gguf",
        "file_size": "32.4 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-UD-IQ1_M.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-UD-IQ1_S.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-UD-IQ2_M.gguf",
        "file_size": "10.6 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-UD-IQ2_XXS.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-UD-IQ3_XXS.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-UD-Q2_K_XL.gguf",
        "file_size": "11.8 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-UD-Q3_K_XL.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-UD-Q4_K_XL.gguf",
        "file_size": "18.7 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-UD-Q5_K_XL.gguf",
        "file_size": "21.7 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-UD-Q6_K_XL.gguf",
        "file_size": "26.6 GB"
      },
      {
        "model_id": "OpenReasoning-Nemotron-32B-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-UD-Q8_K_XL.gguf",
        "file_size": "36.1 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF/resolve/main/README.md",
    "description": "The OpenReasoning-Nemotron-32B model is a large language model derived from Qwen2.5-32B-Instruct, optimized for reasoning tasks in math, code, and science with superior performance across benchmarks and enhanced by GenSelect inference mode."
  },
  {
    "model_name": "Osmosis-Apply-1.7B",
    "developer": "osmosis-ai",
    "downloads": 443,
    "createdAt": "2025-06-19T07:02:07.000Z",
    "tools": true,
    "num_quants": 12,
    "quants": [
      {
        "model_id": "osmosis-apply-1.7b-bf16",
        "path": "https://huggingface.co/osmosis-ai/Osmosis-Apply-1.7B/resolve/main/osmosis-apply-1.7b-bf16.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "osmosis-mcp-1.7b.IQ4_XS",
        "path": "https://huggingface.co/osmosis-ai/Osmosis-Apply-1.7B/resolve/main/osmosis-mcp-1.7b.IQ4_XS.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "osmosis-mcp-1.7b.Q2_K",
        "path": "https://huggingface.co/osmosis-ai/Osmosis-Apply-1.7B/resolve/main/osmosis-mcp-1.7b.Q2_K.gguf",
        "file_size": "839.1 MB"
      },
      {
        "model_id": "osmosis-mcp-1.7b.Q3_K_L",
        "path": "https://huggingface.co/osmosis-ai/Osmosis-Apply-1.7B/resolve/main/osmosis-mcp-1.7b.Q3_K_L.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "osmosis-mcp-1.7b.Q3_K_M",
        "path": "https://huggingface.co/osmosis-ai/Osmosis-Apply-1.7B/resolve/main/osmosis-mcp-1.7b.Q3_K_M.gguf",
        "file_size": "1023.5 MB"
      },
      {
        "model_id": "osmosis-mcp-1.7b.Q3_K_S",
        "path": "https://huggingface.co/osmosis-ai/Osmosis-Apply-1.7B/resolve/main/osmosis-mcp-1.7b.Q3_K_S.gguf",
        "file_size": "954.6 MB"
      },
      {
        "model_id": "osmosis-mcp-1.7b.Q4_K_M",
        "path": "https://huggingface.co/osmosis-ai/Osmosis-Apply-1.7B/resolve/main/osmosis-mcp-1.7b.Q4_K_M.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "osmosis-mcp-1.7b.Q4_K_S",
        "path": "https://huggingface.co/osmosis-ai/Osmosis-Apply-1.7B/resolve/main/osmosis-mcp-1.7b.Q4_K_S.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "osmosis-mcp-1.7b.Q5_K_M",
        "path": "https://huggingface.co/osmosis-ai/Osmosis-Apply-1.7B/resolve/main/osmosis-mcp-1.7b.Q5_K_M.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "osmosis-mcp-1.7b.Q5_K_S",
        "path": "https://huggingface.co/osmosis-ai/Osmosis-Apply-1.7B/resolve/main/osmosis-mcp-1.7b.Q5_K_S.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "osmosis-mcp-1.7b.Q6_K",
        "path": "https://huggingface.co/osmosis-ai/Osmosis-Apply-1.7B/resolve/main/osmosis-mcp-1.7b.Q6_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "osmosis-mcp-1.7b.Q8_0",
        "path": "https://huggingface.co/osmosis-ai/Osmosis-Apply-1.7B/resolve/main/osmosis-mcp-1.7b.Q8_0.gguf",
        "file_size": "2.0 GB"
      }
    ],
    "readme": "https://huggingface.co/osmosis-ai/Osmosis-Apply-1.7B/resolve/main/README.md",
    "description": "Osmosis-Apply-1.7B is a language model finetuned on Qwen3-1.7B to apply edit snippets to original code for code merges, with a reward function prioritizing exactness in the output."
  },
  {
    "model_name": "osmosis-mcp-4b",
    "developer": "osmosis-ai",
    "downloads": 13296,
    "createdAt": "2025-05-08T18:46:48.000Z",
    "num_quants": 14,
    "quants": [
      {
        "model_id": "osmosis-mcp-4B-BF16",
        "path": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/osmosis-mcp-4B-BF16.gguf",
        "file_size": "8.2 GB"
      },
      {
        "model_id": "osmosis-mcp-4B-F16",
        "path": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/osmosis-mcp-4B-F16.gguf",
        "file_size": "8.2 GB"
      },
      {
        "model_id": "osmosis-mcp-4B-Q4_K_S",
        "path": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/osmosis-mcp-4B-Q4_K_S.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "osmosis-mcp-4b.IQ4_XS",
        "path": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/osmosis-mcp-4b.IQ4_XS.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "osmosis-mcp-4b.Q2_K",
        "path": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/osmosis-mcp-4b.Q2_K.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "osmosis-mcp-4b.Q3_K_L",
        "path": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/osmosis-mcp-4b.Q3_K_L.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "osmosis-mcp-4b.Q3_K_M",
        "path": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/osmosis-mcp-4b.Q3_K_M.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "osmosis-mcp-4b.Q3_K_S",
        "path": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/osmosis-mcp-4b.Q3_K_S.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "osmosis-mcp-4b.Q4_K_M",
        "path": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/osmosis-mcp-4b.Q4_K_M.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "osmosis-mcp-4b.Q4_K_S",
        "path": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/osmosis-mcp-4b.Q4_K_S.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "osmosis-mcp-4b.Q5_K_M",
        "path": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/osmosis-mcp-4b.Q5_K_M.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "osmosis-mcp-4b.Q5_K_S",
        "path": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/osmosis-mcp-4b.Q5_K_S.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "osmosis-mcp-4b.Q6_K",
        "path": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/osmosis-mcp-4b.Q6_K.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "osmosis-mcp-4b.Q8_0",
        "path": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/osmosis-mcp-4b.Q8_0.gguf",
        "file_size": "4.4 GB"
      }
    ],
    "readme": "https://huggingface.co/osmosis-ai/osmosis-mcp-4b/resolve/main/README.md",
    "description": "Osmosis-MCP-4B is a Qwen3-4B model fine-tuned with reinforcement learning to excel at multi-step tool usage in a curriculum-based training approach, offering a practical, open-source solution for MCP-style agents.",
    "tools": true
  },
  {
    "model_name": "phi-2-GGUF",
    "developer": "TheBloke",
    "downloads": 151378,
    "createdAt": "2023-12-18T20:22:56.000Z",
    "tools": false,
    "num_quants": 12,
    "quants": [
      {
        "model_id": "phi-2.Q2_K",
        "path": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q2_K.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "phi-2.Q3_K_L",
        "path": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q3_K_L.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "phi-2.Q3_K_M",
        "path": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q3_K_M.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "phi-2.Q3_K_S",
        "path": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q3_K_S.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "phi-2.Q4_0",
        "path": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_0.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "phi-2.Q4_K_M",
        "path": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_M.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "phi-2.Q4_K_S",
        "path": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_S.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "phi-2.Q5_0",
        "path": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q5_0.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "phi-2.Q5_K_M",
        "path": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q5_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "phi-2.Q5_K_S",
        "path": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q5_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "phi-2.Q6_K",
        "path": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q6_K.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "phi-2.Q8_0",
        "path": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q8_0.gguf",
        "file_size": "2.8 GB"
      }
    ],
    "readme": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/README.md",
    "description": "This repository provides GGUF format models for Microsoft's Phi 2, offering various quantization options for efficient CPU/GPU inference with support from llama.cpp and other frameworks."
  },
  {
    "model_name": "Phi-3-mini-4k-instruct-gguf",
    "developer": "microsoft",
    "downloads": 57565,
    "createdAt": "2024-04-22T17:02:08.000Z",
    "tools": false,
    "num_quants": 2,
    "quants": [
      {
        "model_id": "Phi-3-mini-4k-instruct-fp16",
        "path": "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf",
        "file_size": "7.1 GB"
      },
      {
        "model_id": "Phi-3-mini-4k-instruct-q4",
        "path": "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf",
        "file_size": "2.2 GB"
      }
    ],
    "readme": "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/README.md",
    "description": "This repository provides the GGUF format for the Phi-3-Mini-4K-Instruct model, a 3.8B parameter lightweight model trained on high-quality data for reasoning, code, and long context tasks."
  },
  {
    "model_name": "Phi-4-reasoning-plus-GGUF",
    "developer": "unsloth",
    "downloads": 13557,
    "createdAt": "2025-05-01T02:04:54.000Z",
    "num_quants": 24,
    "quants": [
      {
        "model_id": "Phi-4-reasoning-plus-BF16",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-BF16.gguf",
        "file_size": "27.3 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-IQ4_NL.gguf",
        "file_size": "7.8 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-IQ4_XS.gguf",
        "file_size": "7.4 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-Q2_K",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-Q2_K.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-Q2_K_L.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-Q3_K_M.gguf",
        "file_size": "6.9 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-Q3_K_S.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-Q4_0",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-Q4_0.gguf",
        "file_size": "7.8 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-Q4_1",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-Q4_1.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-Q4_K_M.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-Q5_K_M.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-Q6_K",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-Q6_K.gguf",
        "file_size": "11.2 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-Q8_0",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-Q8_0.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-UD-IQ1_M.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-UD-IQ1_S.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-UD-IQ2_M.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-UD-IQ2_XXS.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-UD-IQ3_XXS.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-UD-Q2_K_XL.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-UD-Q3_K_XL.gguf",
        "file_size": "6.9 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-UD-Q4_K_XL.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-UD-Q5_K_XL.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-UD-Q6_K_XL.gguf",
        "file_size": "12.2 GB"
      },
      {
        "model_id": "Phi-4-reasoning-plus-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/Phi-4-reasoning-plus-UD-Q8_K_XL.gguf",
        "file_size": "16.8 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF",
    "developer": "bartowski",
    "downloads": 11895,
    "createdAt": "2025-05-23T18:09:44.000Z",
    "num_quants": 26,
    "quants": [
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ2_M",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ2_M.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ2_S",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ2_S.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ2_XS",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ2_XS.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ3_M",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ3_M.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ3_XS",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ3_XS.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ3_XXS.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ4_NL",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ4_NL.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ4_XS",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-IQ4_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q2_K",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q2_K_L",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q2_K_L.gguf",
        "file_size": "8.9 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q3_K_L",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q3_K_L.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q3_K_M",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q3_K_S",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q3_K_XL.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q4_0",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q4_0.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q4_1",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q4_1.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q4_K_L",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q4_K_L.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q4_K_M",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q4_K_S",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q5_K_L",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q5_K_L.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q5_K_M",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q5_K_S",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q6_K",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q6_K_L",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q6_K_L.gguf",
        "file_size": "18.3 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q8_0",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-Q8_0.gguf",
        "file_size": "23.3 GB"
      },
      {
        "model_id": "PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-bf16",
        "path": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-bf16.gguf",
        "file_size": "43.9 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/README.md",
    "description": "This repository provides quantized versions of the PocketDoc/Dans-PersonalityEngine-V1.3.0-24b model for efficient text generation on various hardware, including CPUs and GPUs, with options for different quantization levels and formats like Q6_K_L, Q4_K_M,",
    "tools": false
  },
  {
    "model_name": "POLARIS-Project_Polaris-4B-Preview-GGUF",
    "developer": "bartowski",
    "downloads": 5255,
    "createdAt": "2025-06-24T04:38:50.000Z",
    "num_quants": 24,
    "quants": [
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-IQ2_M",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-IQ2_M.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-IQ3_M",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-IQ3_M.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-IQ3_XS",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-IQ3_XS.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-IQ3_XXS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-IQ4_NL",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-IQ4_NL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-IQ4_XS",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-IQ4_XS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q2_K",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q2_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q2_K_L",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q2_K_L.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q3_K_L",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q3_K_L.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q3_K_M",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q3_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q3_K_S",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q3_K_XL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q4_0",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q4_1",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q4_1.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q4_K_L",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q4_K_L.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q4_K_M",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q4_K_S",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q5_K_L",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q5_K_L.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q5_K_M",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q5_K_S",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q6_K",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q6_K_L",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q6_K_L.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-Q8_0",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-Q8_0.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "POLARIS-Project_Polaris-4B-Preview-bf16",
        "path": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/POLARIS-Project_Polaris-4B-Preview-bf16.gguf",
        "file_size": "7.5 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/POLARIS-Project_Polaris-4B-Preview-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Polaris-4B-Preview model using llama.cpp, offering various quantization types for different performance and quality trade-offs.",
    "tools": false
  },
  {
    "model_name": "prompt-generator-GGUF",
    "developer": "mav23",
    "downloads": 206,
    "createdAt": "2024-11-30T14:30:00.000Z",
    "num_quants": 17,
    "quants": [
      {
        "model_id": "prompt-generator.Q2_K",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q2_K.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "prompt-generator.Q3_K",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q3_K.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "prompt-generator.Q3_K_L",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q3_K_L.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "prompt-generator.Q3_K_M",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q3_K_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "prompt-generator.Q3_K_S",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "prompt-generator.Q4_0",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q4_0.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "prompt-generator.Q4_1",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q4_1.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "prompt-generator.Q4_K",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q4_K.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "prompt-generator.Q4_K_M",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q4_K_M.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "prompt-generator.Q4_K_S",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "prompt-generator.Q5_0",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q5_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "prompt-generator.Q5_1",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q5_1.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "prompt-generator.Q5_K",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q5_K.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "prompt-generator.Q5_K_M",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q5_K_M.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "prompt-generator.Q5_K_S",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q5_K_S.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "prompt-generator.Q6_K",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q6_K.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "prompt-generator.Q8_0",
        "path": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/prompt-generator.Q8_0.gguf",
        "file_size": "3.4 GB"
      }
    ],
    "readme": "https://huggingface.co/mav23/prompt-generator-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "QVikhr-3-4B-Instruction-GGUF",
    "developer": "Vikhrmodels",
    "downloads": 2850,
    "createdAt": "2025-06-28T21:03:17.000Z",
    "num_quants": 31,
    "quants": [
      {
        "model_id": "QVikhr-3-4B-Instruction-F16",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-F16.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-IQ1_M",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-IQ1_M.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-IQ1_S",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-IQ1_S.gguf",
        "file_size": "1006.4 MB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-IQ2_M",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-IQ2_M.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-IQ2_S",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-IQ2_S.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-IQ2_XS",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-IQ2_XS.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-IQ2_XXS",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-IQ2_XXS.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-IQ3_M",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-IQ3_M.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-IQ3_S",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-IQ3_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-IQ3_XS",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-IQ3_XS.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-IQ3_XXS",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-IQ3_XXS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-IQ4_NL",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-IQ4_NL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-IQ4_XS",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-IQ4_XS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q2_K",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q2_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q2_K_S",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q2_K_S.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q3_K",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q3_K.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q3_K_L",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q3_K_L.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q3_K_M",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q3_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q3_K_S",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q4_0",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q4_1",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q4_1.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q4_K",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q4_K.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q4_K_M",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q4_K_S",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q5_0",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q5_0.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q5_1",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q5_1.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q5_K",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q5_K.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q5_K_M",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q5_K_S",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q6_K",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "QVikhr-3-4B-Instruction-Q8_0",
        "path": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/QVikhr-3-4B-Instruction-Q8_0.gguf",
        "file_size": "4.0 GB"
      }
    ],
    "readme": "https://huggingface.co/Vikhrmodels/QVikhr-3-4B-Instruction-GGUF/resolve/main/README.md",
    "description": "QVikhr-3-4B-Instruction is an instructive model based on Qwen/Qwen3-4B, trained on the Russian-language dataset GrandMaster2 for high-efficiency text processing in Russian and English.",
    "tools": true
  },
  {
    "model_name": "Qwen2-VL-2B-Instruct-GGUF",
    "developer": "bartowski",
    "downloads": 4036,
    "createdAt": "2024-12-14T19:43:17.000Z",
    "num_quants": 24,
    "quants": [
      {
        "model_id": "Qwen2-VL-2B-Instruct-IQ2_M",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-IQ2_M.gguf",
        "file_size": "573.2 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-IQ3_M",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-IQ3_M.gguf",
        "file_size": "740.7 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-IQ3_XS.gguf",
        "file_size": "697.8 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-IQ4_NL.gguf",
        "file_size": "893.0 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-IQ4_XS.gguf",
        "file_size": "854.2 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q2_K",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q2_K.gguf",
        "file_size": "645.0 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q2_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q2_K_L.gguf",
        "file_size": "698.9 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q3_K_L.gguf",
        "file_size": "839.4 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q3_K_M.gguf",
        "file_size": "786.0 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q3_K_S.gguf",
        "file_size": "725.7 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q3_K_XL.gguf",
        "file_size": "893.3 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q4_0",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q4_0.gguf",
        "file_size": "894.1 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q4_K_L.gguf",
        "file_size": "994.3 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q4_K_M.gguf",
        "file_size": "940.4 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q4_K_S.gguf",
        "file_size": "896.8 MB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q5_K_L.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q5_K_M.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q5_K_S.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q6_K",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q6_K.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q6_K_L.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-Q8_0",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-Q8_0.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Qwen2-VL-2B-Instruct-f16",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/Qwen2-VL-2B-Instruct-f16.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "mmproj-Qwen2-VL-2B-Instruct-f16",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/mmproj-Qwen2-VL-2B-Instruct-f16.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "mmproj-Qwen2-VL-2B-Instruct-f32",
        "path": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/mmproj-Qwen2-VL-2B-Instruct-f32.gguf",
        "file_size": "2.5 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Qwen2-VL-2B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Qwen2.5-14B_Uncensored_Instruct-GGUF",
    "developer": "bartowski",
    "downloads": 4445,
    "createdAt": "2024-09-22T22:26:11.000Z",
    "num_quants": 24,
    "quants": [
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-IQ2_M",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-IQ2_M.gguf",
        "file_size": "5.0 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-IQ3_M",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-IQ3_M.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-IQ3_XS.gguf",
        "file_size": "5.9 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-IQ4_XS.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q2_K",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q2_K.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q2_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q2_K_L.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q3_K_L.gguf",
        "file_size": "7.4 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q3_K_M.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q3_K_S.gguf",
        "file_size": "6.2 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q3_K_XL.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q4_0",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q4_0.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q4_0_4_4",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q4_0_4_4.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q4_0_4_8",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q4_0_4_8.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q4_0_8_8",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q4_0_8_8.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q4_K_L.gguf",
        "file_size": "8.9 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q4_K_M.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q4_K_S.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q5_K_L.gguf",
        "file_size": "10.2 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q5_K_M.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q5_K_S.gguf",
        "file_size": "9.6 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q6_K",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q6_K.gguf",
        "file_size": "11.3 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q6_K_L.gguf",
        "file_size": "11.6 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-Q8_0",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-Q8_0.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "Qwen2.5-14B_Uncensored_Instruct-f16",
        "path": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/Qwen2.5-14B_Uncensored_Instruct-f16.gguf",
        "file_size": "27.5 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF/resolve/main/README.md",
    "description": "This repository provides quantized versions of the Qwen2.5-14B_Uncensored_Instruct model using llama.cpp, with various quantization types and optimizations for different hardware, including ARM and Apple Metal, suitable for different performance and quality trade-offs.",
    "tools": true
  },
  {
    "model_name": "Qwen2.5-Coder-32B-Instruct-GGUF",
    "developer": "bartowski",
    "downloads": 11918,
    "createdAt": "2024-11-06T19:20:14.000Z",
    "num_quants": 28,
    "quants": [
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-IQ2_M",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-IQ2_M.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-IQ2_S",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-IQ2_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-IQ2_XS",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-IQ2_XS.gguf",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-IQ2_XXS",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-IQ2_XXS.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-IQ3_M",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-IQ3_M.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-IQ3_XS.gguf",
        "file_size": "12.8 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-IQ3_XXS.gguf",
        "file_size": "12.0 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-IQ4_NL.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-IQ4_XS.gguf",
        "file_size": "16.5 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q2_K",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q2_K.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q2_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q2_K_L.gguf",
        "file_size": "12.2 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q3_K_L.gguf",
        "file_size": "16.1 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q3_K_M.gguf",
        "file_size": "14.8 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q3_K_S.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q3_K_XL.gguf",
        "file_size": "16.7 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q4_0",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q4_0.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q4_0_4_4",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q4_0_4_4.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q4_0_4_8",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q4_0_4_8.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q4_0_8_8",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q4_0_8_8.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q4_K_L.gguf",
        "file_size": "19.0 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q4_K_M.gguf",
        "file_size": "18.5 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q4_K_S.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q5_K_L.gguf",
        "file_size": "22.1 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q5_K_M.gguf",
        "file_size": "21.7 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q5_K_S.gguf",
        "file_size": "21.1 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q6_K",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q6_K.gguf",
        "file_size": "25.0 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q6_K_L.gguf",
        "file_size": "25.4 GB"
      },
      {
        "model_id": "Qwen2.5-Coder-32B-Instruct-Q8_0",
        "path": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q8_0.gguf",
        "file_size": "32.4 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Qwen2.5-VL-7B-Instruct-GGUF",
    "developer": "unsloth",
    "downloads": 6756,
    "createdAt": "2025-05-11T13:03:32.000Z",
    "num_quants": 29,
    "quants": [
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-BF16",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-BF16.gguf",
        "file_size": "14.2 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-IQ4_NL.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-IQ4_XS.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-Q2_K",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-Q2_K.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-Q2_K_L.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-Q3_K_M.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-Q3_K_S.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-Q4_0",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-Q4_0.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-Q4_1",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-Q4_1.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-Q4_K_M.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-Q4_K_S.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-Q5_K_M.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-Q5_K_S.gguf",
        "file_size": "5.0 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-Q6_K",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-Q6_K.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-Q8_0",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-Q8_0.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-UD-IQ1_M.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-UD-IQ1_S.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-UD-IQ2_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-UD-IQ2_XXS.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-UD-IQ3_XXS.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-UD-Q2_K_XL.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-UD-Q3_K_XL.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-UD-Q4_K_XL.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-UD-Q5_K_XL.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-UD-Q6_K_XL.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "Qwen2.5-VL-7B-Instruct-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/Qwen2.5-VL-7B-Instruct-UD-Q8_K_XL.gguf",
        "file_size": "9.5 GB"
      },
      {
        "model_id": "mmproj-BF16",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/mmproj-BF16.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "mmproj-F16",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/mmproj-F16.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "mmproj-F32",
        "path": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/mmproj-F32.gguf",
        "file_size": "2.5 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/resolve/main/README.md",
    "description": "The Qwen2.5-VL-7B-Instruct model is a versatile vision-language model that supports image-text understanding, video analysis, structured output generation, and agent-like reasoning, with enhanced performance through dynamic resolution and frame rate training, efficient vision encoders, and compatibility with various visual input",
    "tools": false
  },
  {
    "model_name": "Qwen3-0.6B-GGUF",
    "developer": "unsloth",
    "downloads": 29318,
    "createdAt": "2025-04-28T10:24:13.000Z",
    "tools": true,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "Qwen3-0.6B-BF16",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-BF16.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Qwen3-0.6B-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-IQ4_NL.gguf",
        "file_size": "363.9 MB"
      },
      {
        "model_id": "Qwen3-0.6B-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-IQ4_XS.gguf",
        "file_size": "350.8 MB"
      },
      {
        "model_id": "Qwen3-0.6B-Q2_K",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-Q2_K.gguf",
        "file_size": "282.5 MB"
      },
      {
        "model_id": "Qwen3-0.6B-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-Q2_K_L.gguf",
        "file_size": "282.5 MB"
      },
      {
        "model_id": "Qwen3-0.6B-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-Q3_K_M.gguf",
        "file_size": "331.0 MB"
      },
      {
        "model_id": "Qwen3-0.6B-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-Q3_K_S.gguf",
        "file_size": "308.1 MB"
      },
      {
        "model_id": "Qwen3-0.6B-Q4_0",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-Q4_0.gguf",
        "file_size": "364.5 MB"
      },
      {
        "model_id": "Qwen3-0.6B-Q4_1",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-Q4_1.gguf",
        "file_size": "390.1 MB"
      },
      {
        "model_id": "Qwen3-0.6B-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-Q4_K_M.gguf",
        "file_size": "378.3 MB"
      },
      {
        "model_id": "Qwen3-0.6B-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-Q4_K_S.gguf",
        "file_size": "365.5 MB"
      },
      {
        "model_id": "Qwen3-0.6B-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-Q5_K_M.gguf",
        "file_size": "423.8 MB"
      },
      {
        "model_id": "Qwen3-0.6B-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-Q5_K_S.gguf",
        "file_size": "416.4 MB"
      },
      {
        "model_id": "Qwen3-0.6B-Q6_K",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-Q6_K.gguf",
        "file_size": "472.2 MB"
      },
      {
        "model_id": "Qwen3-0.6B-Q8_0",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-Q8_0.gguf",
        "file_size": "609.8 MB"
      },
      {
        "model_id": "Qwen3-0.6B-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-UD-IQ1_M.gguf",
        "file_size": "210.5 MB"
      },
      {
        "model_id": "Qwen3-0.6B-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-UD-IQ1_S.gguf",
        "file_size": "204.7 MB"
      },
      {
        "model_id": "Qwen3-0.6B-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-UD-IQ2_M.gguf",
        "file_size": "256.3 MB"
      },
      {
        "model_id": "Qwen3-0.6B-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-UD-IQ2_XXS.gguf",
        "file_size": "223.2 MB"
      },
      {
        "model_id": "Qwen3-0.6B-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-UD-IQ3_XXS.gguf",
        "file_size": "269.0 MB"
      },
      {
        "model_id": "Qwen3-0.6B-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-UD-Q2_K_XL.gguf",
        "file_size": "287.7 MB"
      },
      {
        "model_id": "Qwen3-0.6B-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-UD-Q3_K_XL.gguf",
        "file_size": "340.1 MB"
      },
      {
        "model_id": "Qwen3-0.6B-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-UD-Q4_K_XL.gguf",
        "file_size": "386.6 MB"
      },
      {
        "model_id": "Qwen3-0.6B-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-UD-Q5_K_XL.gguf",
        "file_size": "425.7 MB"
      },
      {
        "model_id": "Qwen3-0.6B-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-UD-Q6_K_XL.gguf",
        "file_size": "549.8 MB"
      },
      {
        "model_id": "Qwen3-0.6B-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-UD-Q8_K_XL.gguf",
        "file_size": "805.2 MB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/README.md",
    "description": "Qwen3-0.6B is a large language model developed by Alibaba Cloud, offering enhanced reasoning, instruction-following, and multilingual capabilities with support for seamless switching between thinking and non-thinking modes."
  },
  {
    "model_name": "Qwen3-1.7B-GGUF",
    "developer": "unsloth",
    "downloads": 16312,
    "createdAt": "2025-04-28T12:22:37.000Z",
    "num_quants": 26,
    "quants": [
      {
        "model_id": "Qwen3-1.7B-BF16",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-BF16.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "Qwen3-1.7B-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-IQ4_NL.gguf",
        "file_size": "1005.6 MB"
      },
      {
        "model_id": "Qwen3-1.7B-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-IQ4_XS.gguf",
        "file_size": "963.6 MB"
      },
      {
        "model_id": "Qwen3-1.7B-Q2_K",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-Q2_K.gguf",
        "file_size": "741.8 MB"
      },
      {
        "model_id": "Qwen3-1.7B-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-Q2_K_L.gguf",
        "file_size": "741.8 MB"
      },
      {
        "model_id": "Qwen3-1.7B-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-Q3_K_M.gguf",
        "file_size": "896.0 MB"
      },
      {
        "model_id": "Qwen3-1.7B-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-Q3_K_S.gguf",
        "file_size": "827.1 MB"
      },
      {
        "model_id": "Qwen3-1.7B-Q4_0",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-Q4_0.gguf",
        "file_size": "1007.8 MB"
      },
      {
        "model_id": "Qwen3-1.7B-Q4_1",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-Q4_1.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Qwen3-1.7B-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-Q4_K_M.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Qwen3-1.7B-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-Q4_K_S.gguf",
        "file_size": "1011.1 MB"
      },
      {
        "model_id": "Qwen3-1.7B-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-Q5_K_M.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Qwen3-1.7B-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-Q5_K_S.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Qwen3-1.7B-Q6_K",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-Q6_K.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "Qwen3-1.7B-Q8_0",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-Q8_0.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "Qwen3-1.7B-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-UD-IQ1_M.gguf",
        "file_size": "535.9 MB"
      },
      {
        "model_id": "Qwen3-1.7B-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-UD-IQ1_S.gguf",
        "file_size": "512.9 MB"
      },
      {
        "model_id": "Qwen3-1.7B-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-UD-IQ2_M.gguf",
        "file_size": "675.9 MB"
      },
      {
        "model_id": "Qwen3-1.7B-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-UD-IQ2_XXS.gguf",
        "file_size": "577.7 MB"
      },
      {
        "model_id": "Qwen3-1.7B-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-UD-IQ3_XXS.gguf",
        "file_size": "729.7 MB"
      },
      {
        "model_id": "Qwen3-1.7B-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-UD-Q2_K_XL.gguf",
        "file_size": "760.9 MB"
      },
      {
        "model_id": "Qwen3-1.7B-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-UD-Q3_K_XL.gguf",
        "file_size": "924.0 MB"
      },
      {
        "model_id": "Qwen3-1.7B-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-UD-Q4_K_XL.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Qwen3-1.7B-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-UD-Q5_K_XL.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Qwen3-1.7B-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-UD-Q6_K_XL.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Qwen3-1.7B-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/Qwen3-1.7B-UD-Q8_K_XL.gguf",
        "file_size": "2.2 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Qwen3-1.7B-GGUF/resolve/main/README.md",
    "description": "Qwen3-1.7B is a large language model developed by Alibaba Cloud, offering advanced reasoning, instruction-following, and multilingual capabilities with seamless switching between thinking and non-thinking modes for optimal performance.",
    "tools": true
  },
  {
    "model_name": "Qwen3-14B-GGUF",
    "developer": "Qwen",
    "downloads": 17959,
    "createdAt": "2025-05-01T10:25:24.000Z",
    "num_quants": 5,
    "quants": [
      {
        "model_id": "Qwen3-14B-Q4_K_M",
        "path": "https://huggingface.co/Qwen/Qwen3-14B-GGUF/resolve/main/Qwen3-14B-Q4_K_M.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "Qwen3-14B-Q5_0",
        "path": "https://huggingface.co/Qwen/Qwen3-14B-GGUF/resolve/main/Qwen3-14B-Q5_0.gguf",
        "file_size": "9.6 GB"
      },
      {
        "model_id": "Qwen3-14B-Q5_K_M",
        "path": "https://huggingface.co/Qwen/Qwen3-14B-GGUF/resolve/main/Qwen3-14B-Q5_K_M.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "Qwen3-14B-Q6_K",
        "path": "https://huggingface.co/Qwen/Qwen3-14B-GGUF/resolve/main/Qwen3-14B-Q6_K.gguf",
        "file_size": "11.3 GB"
      },
      {
        "model_id": "Qwen3-14B-Q8_0",
        "path": "https://huggingface.co/Qwen/Qwen3-14B-GGUF/resolve/main/Qwen3-14B-Q8_0.gguf",
        "file_size": "14.6 GB"
      }
    ],
    "readme": "https://huggingface.co/Qwen/Qwen3-14B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Qwen3-235B-A22B-GGUF",
    "developer": "unsloth",
    "downloads": 34754,
    "createdAt": "2025-04-28T15:18:03.000Z",
    "num_quants": 72,
    "quants": [
      {
        "model_id": "BF16/Qwen3-235B-A22B-BF16-00001-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/BF16/Qwen3-235B-A22B-BF16-00001-of-00010.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-BF16-00002-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/BF16/Qwen3-235B-A22B-BF16-00002-of-00010.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-BF16-00003-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/BF16/Qwen3-235B-A22B-BF16-00003-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-BF16-00004-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/BF16/Qwen3-235B-A22B-BF16-00004-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-BF16-00005-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/BF16/Qwen3-235B-A22B-BF16-00005-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-BF16-00006-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/BF16/Qwen3-235B-A22B-BF16-00006-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-BF16-00007-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/BF16/Qwen3-235B-A22B-BF16-00007-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-BF16-00008-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/BF16/Qwen3-235B-A22B-BF16-00008-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-BF16-00009-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/BF16/Qwen3-235B-A22B-BF16-00009-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-BF16-00010-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/BF16/Qwen3-235B-A22B-BF16-00010-of-00010.gguf",
        "file_size": "21.2 GB"
      },
      {
        "model_id": "IQ4_XS/Qwen3-235B-A22B-IQ4_XS-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/IQ4_XS/Qwen3-235B-A22B-IQ4_XS-00001-of-00003.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "IQ4_XS/Qwen3-235B-A22B-IQ4_XS-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/IQ4_XS/Qwen3-235B-A22B-IQ4_XS-00002-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "IQ4_XS/Qwen3-235B-A22B-IQ4_XS-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/IQ4_XS/Qwen3-235B-A22B-IQ4_XS-00003-of-00003.gguf",
        "file_size": "23.9 GB"
      },
      {
        "model_id": "Q2_K/Qwen3-235B-A22B-Q2_K-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q2_K/Qwen3-235B-A22B-Q2_K-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q2_K/Qwen3-235B-A22B-Q2_K-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q2_K/Qwen3-235B-A22B-Q2_K-00002-of-00002.gguf",
        "file_size": "33.3 GB"
      },
      {
        "model_id": "Q2_K_L/Qwen3-235B-A22B-Q2_K_L-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q2_K_L/Qwen3-235B-A22B-Q2_K_L-00001-of-00002.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q2_K_L/Qwen3-235B-A22B-Q2_K_L-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q2_K_L/Qwen3-235B-A22B-Q2_K_L-00002-of-00002.gguf",
        "file_size": "33.6 GB"
      },
      {
        "model_id": "Q3_K_M/Qwen3-235B-A22B-Q3_K_M-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q3_K_M/Qwen3-235B-A22B-Q3_K_M-00001-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q3_K_M/Qwen3-235B-A22B-Q3_K_M-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q3_K_M/Qwen3-235B-A22B-Q3_K_M-00002-of-00003.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q3_K_M/Qwen3-235B-A22B-Q3_K_M-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q3_K_M/Qwen3-235B-A22B-Q3_K_M-00003-of-00003.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "Q3_K_S/Qwen3-235B-A22B-Q3_K_S-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q3_K_S/Qwen3-235B-A22B-Q3_K_S-00001-of-00003.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q3_K_S/Qwen3-235B-A22B-Q3_K_S-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q3_K_S/Qwen3-235B-A22B-Q3_K_S-00002-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q3_K_S/Qwen3-235B-A22B-Q3_K_S-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q3_K_S/Qwen3-235B-A22B-Q3_K_S-00003-of-00003.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Q4_1/Qwen3-235B-A22B-Q4_1-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q4_1/Qwen3-235B-A22B-Q4_1-00001-of-00003.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_1/Qwen3-235B-A22B-Q4_1-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q4_1/Qwen3-235B-A22B-Q4_1-00002-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/Qwen3-235B-A22B-Q4_1-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q4_1/Qwen3-235B-A22B-Q4_1-00003-of-00003.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Q4_K_M/Qwen3-235B-A22B-Q4_K_M-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q4_K_M/Qwen3-235B-A22B-Q4_K_M-00001-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q4_K_M/Qwen3-235B-A22B-Q4_K_M-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q4_K_M/Qwen3-235B-A22B-Q4_K_M-00002-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q4_K_M/Qwen3-235B-A22B-Q4_K_M-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q4_K_M/Qwen3-235B-A22B-Q4_K_M-00003-of-00003.gguf",
        "file_size": "39.4 GB"
      },
      {
        "model_id": "Q4_K_S/Qwen3-235B-A22B-Q4_K_S-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q4_K_S/Qwen3-235B-A22B-Q4_K_S-00001-of-00003.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q4_K_S/Qwen3-235B-A22B-Q4_K_S-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q4_K_S/Qwen3-235B-A22B-Q4_K_S-00002-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q4_K_S/Qwen3-235B-A22B-Q4_K_S-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q4_K_S/Qwen3-235B-A22B-Q4_K_S-00003-of-00003.gguf",
        "file_size": "31.7 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-235B-A22B-Q5_K_M-00001-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q5_K_M/Qwen3-235B-A22B-Q5_K_M-00001-of-00004.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-235B-A22B-Q5_K_M-00002-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q5_K_M/Qwen3-235B-A22B-Q5_K_M-00002-of-00004.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-235B-A22B-Q5_K_M-00003-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q5_K_M/Qwen3-235B-A22B-Q5_K_M-00003-of-00004.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-235B-A22B-Q5_K_M-00004-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q5_K_M/Qwen3-235B-A22B-Q5_K_M-00004-of-00004.gguf",
        "file_size": "16.9 GB"
      },
      {
        "model_id": "Q5_K_S/Qwen3-235B-A22B-Q5_K_S-00001-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q5_K_S/Qwen3-235B-A22B-Q5_K_S-00001-of-00004.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q5_K_S/Qwen3-235B-A22B-Q5_K_S-00002-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q5_K_S/Qwen3-235B-A22B-Q5_K_S-00002-of-00004.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q5_K_S/Qwen3-235B-A22B-Q5_K_S-00003-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q5_K_S/Qwen3-235B-A22B-Q5_K_S-00003-of-00004.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q5_K_S/Qwen3-235B-A22B-Q5_K_S-00004-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q5_K_S/Qwen3-235B-A22B-Q5_K_S-00004-of-00004.gguf",
        "file_size": "12.2 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-235B-A22B-Q6_K-00001-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q6_K/Qwen3-235B-A22B-Q6_K-00001-of-00004.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-235B-A22B-Q6_K-00002-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q6_K/Qwen3-235B-A22B-Q6_K-00002-of-00004.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-235B-A22B-Q6_K-00003-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q6_K/Qwen3-235B-A22B-Q6_K-00003-of-00004.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-235B-A22B-Q6_K-00004-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q6_K/Qwen3-235B-A22B-Q6_K-00004-of-00004.gguf",
        "file_size": "41.2 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-235B-A22B-Q8_0-00001-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q8_0/Qwen3-235B-A22B-Q8_0-00001-of-00006.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-235B-A22B-Q8_0-00002-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q8_0/Qwen3-235B-A22B-Q8_0-00002-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-235B-A22B-Q8_0-00003-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q8_0/Qwen3-235B-A22B-Q8_0-00003-of-00006.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-235B-A22B-Q8_0-00004-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q8_0/Qwen3-235B-A22B-Q8_0-00004-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-235B-A22B-Q8_0-00005-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q8_0/Qwen3-235B-A22B-Q8_0-00005-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-235B-A22B-Q8_0-00006-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/Q8_0/Qwen3-235B-A22B-Q8_0-00006-of-00006.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Qwen3-235B-A22B-UD-Q2_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q2_K_XL/Qwen3-235B-A22B-UD-Q2_K_XL-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Qwen3-235B-A22B-UD-Q2_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q2_K_XL/Qwen3-235B-A22B-UD-Q2_K_XL-00002-of-00002.gguf",
        "file_size": "35.6 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Qwen3-235B-A22B-UD-Q3_K_XL-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q3_K_XL/Qwen3-235B-A22B-UD-Q3_K_XL-00001-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Qwen3-235B-A22B-UD-Q3_K_XL-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q3_K_XL/Qwen3-235B-A22B-UD-Q3_K_XL-00002-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Qwen3-235B-A22B-UD-Q3_K_XL-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q3_K_XL/Qwen3-235B-A22B-UD-Q3_K_XL-00003-of-00003.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Qwen3-235B-A22B-UD-Q4_K_XL-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q4_K_XL/Qwen3-235B-A22B-UD-Q4_K_XL-00001-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Qwen3-235B-A22B-UD-Q4_K_XL-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q4_K_XL/Qwen3-235B-A22B-UD-Q4_K_XL-00002-of-00003.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Qwen3-235B-A22B-UD-Q4_K_XL-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q4_K_XL/Qwen3-235B-A22B-UD-Q4_K_XL-00003-of-00003.gguf",
        "file_size": "32.3 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Qwen3-235B-A22B-UD-Q5_K_XL-00001-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q5_K_XL/Qwen3-235B-A22B-UD-Q5_K_XL-00001-of-00004.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Qwen3-235B-A22B-UD-Q5_K_XL-00002-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q5_K_XL/Qwen3-235B-A22B-UD-Q5_K_XL-00002-of-00004.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Qwen3-235B-A22B-UD-Q5_K_XL-00003-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q5_K_XL/Qwen3-235B-A22B-UD-Q5_K_XL-00003-of-00004.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Qwen3-235B-A22B-UD-Q5_K_XL-00004-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q5_K_XL/Qwen3-235B-A22B-UD-Q5_K_XL-00004-of-00004.gguf",
        "file_size": "16.6 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Qwen3-235B-A22B-UD-Q6_K_XL-00001-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q6_K_XL/Qwen3-235B-A22B-UD-Q6_K_XL-00001-of-00004.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Qwen3-235B-A22B-UD-Q6_K_XL-00002-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q6_K_XL/Qwen3-235B-A22B-UD-Q6_K_XL-00002-of-00004.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Qwen3-235B-A22B-UD-Q6_K_XL-00003-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q6_K_XL/Qwen3-235B-A22B-UD-Q6_K_XL-00003-of-00004.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Qwen3-235B-A22B-UD-Q6_K_XL-00004-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q6_K_XL/Qwen3-235B-A22B-UD-Q6_K_XL-00004-of-00004.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Qwen3-235B-A22B-UD-Q8_K_XL-00001-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q8_K_XL/Qwen3-235B-A22B-UD-Q8_K_XL-00001-of-00006.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Qwen3-235B-A22B-UD-Q8_K_XL-00002-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q8_K_XL/Qwen3-235B-A22B-UD-Q8_K_XL-00002-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Qwen3-235B-A22B-UD-Q8_K_XL-00003-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q8_K_XL/Qwen3-235B-A22B-UD-Q8_K_XL-00003-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Qwen3-235B-A22B-UD-Q8_K_XL-00004-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q8_K_XL/Qwen3-235B-A22B-UD-Q8_K_XL-00004-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Qwen3-235B-A22B-UD-Q8_K_XL-00005-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q8_K_XL/Qwen3-235B-A22B-UD-Q8_K_XL-00005-of-00006.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Qwen3-235B-A22B-UD-Q8_K_XL-00006-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/UD-Q8_K_XL/Qwen3-235B-A22B-UD-Q8_K_XL-00006-of-00006.gguf",
        "file_size": "16.2 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/resolve/main/README.md",
    "description": "The Qwen3-235B-A22B model is a large language model with 235B parameters, offering seamless switching between thinking and non-thinking modes, enhanced reasoning capabilities, and support for 100+ languages, with the ability to handle long texts via Ya",
    "tools": true
  },
  {
    "model_name": "Qwen3-235B-A22B-GGUF",
    "developer": "ubergarm",
    "downloads": 533,
    "createdAt": "2025-04-30T00:40:48.000Z",
    "num_quants": 3,
    "quants": [
      {
        "model_id": "Qwen3-235B-A22B-mix-IQ3_K-00001-of-00003",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-GGUF/resolve/main/Qwen3-235B-A22B-mix-IQ3_K-00001-of-00003.gguf",
        "file_size": "36.2 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-mix-IQ3_K-00002-of-00003",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-GGUF/resolve/main/Qwen3-235B-A22B-mix-IQ3_K-00002-of-00003.gguf",
        "file_size": "36.3 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-mix-IQ3_K-00003-of-00003",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-GGUF/resolve/main/Qwen3-235B-A22B-mix-IQ3_K-00003-of-00003.gguf",
        "file_size": "34.3 GB"
      }
    ],
    "readme": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "Qwen3-235B-A22B-Instruct-2507-GGUF",
    "developer": "unsloth",
    "downloads": 2657,
    "createdAt": "2025-07-21T18:07:24.000Z",
    "tools": true,
    "num_quants": 72,
    "quants": [
      {
        "model_id": "BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00001-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00001-of-00010.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00002-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00002-of-00010.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00003-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00003-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00004-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00004-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00005-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00005-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00006-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00006-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00007-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00007-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00008-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00008-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00009-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00009-of-00010.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00010-of-00010",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/BF16/Qwen3-235B-A22B-Instruct-2507-BF16-00010-of-00010.gguf",
        "file_size": "21.2 GB"
      },
      {
        "model_id": "IQ4_XS/Qwen3-235B-A22B-Instruct-2507-IQ4_XS-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/IQ4_XS/Qwen3-235B-A22B-Instruct-2507-IQ4_XS-00001-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "IQ4_XS/Qwen3-235B-A22B-Instruct-2507-IQ4_XS-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/IQ4_XS/Qwen3-235B-A22B-Instruct-2507-IQ4_XS-00002-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "IQ4_XS/Qwen3-235B-A22B-Instruct-2507-IQ4_XS-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/IQ4_XS/Qwen3-235B-A22B-Instruct-2507-IQ4_XS-00003-of-00003.gguf",
        "file_size": "23.9 GB"
      },
      {
        "model_id": "Q2_K/Qwen3-235B-A22B-Instruct-2507-Q2_K-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q2_K/Qwen3-235B-A22B-Instruct-2507-Q2_K-00001-of-00002.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q2_K/Qwen3-235B-A22B-Instruct-2507-Q2_K-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q2_K/Qwen3-235B-A22B-Instruct-2507-Q2_K-00002-of-00002.gguf",
        "file_size": "33.3 GB"
      },
      {
        "model_id": "Q2_K_L/Qwen3-235B-A22B-Instruct-2507-Q2_K_L-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q2_K_L/Qwen3-235B-A22B-Instruct-2507-Q2_K_L-00001-of-00002.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q2_K_L/Qwen3-235B-A22B-Instruct-2507-Q2_K_L-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q2_K_L/Qwen3-235B-A22B-Instruct-2507-Q2_K_L-00002-of-00002.gguf",
        "file_size": "33.6 GB"
      },
      {
        "model_id": "Q3_K_M/Qwen3-235B-A22B-Instruct-2507-Q3_K_M-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q3_K_M/Qwen3-235B-A22B-Instruct-2507-Q3_K_M-00001-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q3_K_M/Qwen3-235B-A22B-Instruct-2507-Q3_K_M-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q3_K_M/Qwen3-235B-A22B-Instruct-2507-Q3_K_M-00002-of-00003.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q3_K_M/Qwen3-235B-A22B-Instruct-2507-Q3_K_M-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q3_K_M/Qwen3-235B-A22B-Instruct-2507-Q3_K_M-00003-of-00003.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "Q3_K_S/Qwen3-235B-A22B-Instruct-2507-Q3_K_S-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q3_K_S/Qwen3-235B-A22B-Instruct-2507-Q3_K_S-00001-of-00003.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q3_K_S/Qwen3-235B-A22B-Instruct-2507-Q3_K_S-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q3_K_S/Qwen3-235B-A22B-Instruct-2507-Q3_K_S-00002-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q3_K_S/Qwen3-235B-A22B-Instruct-2507-Q3_K_S-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q3_K_S/Qwen3-235B-A22B-Instruct-2507-Q3_K_S-00003-of-00003.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Q4_0/Qwen3-235B-A22B-Instruct-2507-Q4_0-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q4_0/Qwen3-235B-A22B-Instruct-2507-Q4_0-00001-of-00003.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q4_0/Qwen3-235B-A22B-Instruct-2507-Q4_0-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q4_0/Qwen3-235B-A22B-Instruct-2507-Q4_0-00002-of-00003.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "Q4_0/Qwen3-235B-A22B-Instruct-2507-Q4_0-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q4_0/Qwen3-235B-A22B-Instruct-2507-Q4_0-00003-of-00003.gguf",
        "file_size": "31.3 GB"
      },
      {
        "model_id": "Q4_1/Qwen3-235B-A22B-Instruct-2507-Q4_1-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q4_1/Qwen3-235B-A22B-Instruct-2507-Q4_1-00001-of-00003.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_1/Qwen3-235B-A22B-Instruct-2507-Q4_1-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q4_1/Qwen3-235B-A22B-Instruct-2507-Q4_1-00002-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_1/Qwen3-235B-A22B-Instruct-2507-Q4_1-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q4_1/Qwen3-235B-A22B-Instruct-2507-Q4_1-00003-of-00003.gguf",
        "file_size": "44.4 GB"
      },
      {
        "model_id": "Q4_K_M/Qwen3-235B-A22B-Instruct-2507-Q4_K_M-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q4_K_M/Qwen3-235B-A22B-Instruct-2507-Q4_K_M-00001-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q4_K_M/Qwen3-235B-A22B-Instruct-2507-Q4_K_M-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q4_K_M/Qwen3-235B-A22B-Instruct-2507-Q4_K_M-00002-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q4_K_M/Qwen3-235B-A22B-Instruct-2507-Q4_K_M-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q4_K_M/Qwen3-235B-A22B-Instruct-2507-Q4_K_M-00003-of-00003.gguf",
        "file_size": "39.4 GB"
      },
      {
        "model_id": "Q4_K_S/Qwen3-235B-A22B-Instruct-2507-Q4_K_S-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q4_K_S/Qwen3-235B-A22B-Instruct-2507-Q4_K_S-00001-of-00003.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q4_K_S/Qwen3-235B-A22B-Instruct-2507-Q4_K_S-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q4_K_S/Qwen3-235B-A22B-Instruct-2507-Q4_K_S-00002-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q4_K_S/Qwen3-235B-A22B-Instruct-2507-Q4_K_S-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q4_K_S/Qwen3-235B-A22B-Instruct-2507-Q4_K_S-00003-of-00003.gguf",
        "file_size": "31.7 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-235B-A22B-Instruct-2507-Q5_K_M-00001-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q5_K_M/Qwen3-235B-A22B-Instruct-2507-Q5_K_M-00001-of-00004.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-235B-A22B-Instruct-2507-Q5_K_M-00002-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q5_K_M/Qwen3-235B-A22B-Instruct-2507-Q5_K_M-00002-of-00004.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-235B-A22B-Instruct-2507-Q5_K_M-00003-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q5_K_M/Qwen3-235B-A22B-Instruct-2507-Q5_K_M-00003-of-00004.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-235B-A22B-Instruct-2507-Q5_K_M-00004-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q5_K_M/Qwen3-235B-A22B-Instruct-2507-Q5_K_M-00004-of-00004.gguf",
        "file_size": "16.9 GB"
      },
      {
        "model_id": "Q5_K_S/Qwen3-235B-A22B-Instruct-2507-Q5_K_S-00001-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q5_K_S/Qwen3-235B-A22B-Instruct-2507-Q5_K_S-00001-of-00004.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q5_K_S/Qwen3-235B-A22B-Instruct-2507-Q5_K_S-00002-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q5_K_S/Qwen3-235B-A22B-Instruct-2507-Q5_K_S-00002-of-00004.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q5_K_S/Qwen3-235B-A22B-Instruct-2507-Q5_K_S-00003-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q5_K_S/Qwen3-235B-A22B-Instruct-2507-Q5_K_S-00003-of-00004.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Q5_K_S/Qwen3-235B-A22B-Instruct-2507-Q5_K_S-00004-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q5_K_S/Qwen3-235B-A22B-Instruct-2507-Q5_K_S-00004-of-00004.gguf",
        "file_size": "12.2 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-235B-A22B-Instruct-2507-Q6_K-00001-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q6_K/Qwen3-235B-A22B-Instruct-2507-Q6_K-00001-of-00004.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-235B-A22B-Instruct-2507-Q6_K-00002-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q6_K/Qwen3-235B-A22B-Instruct-2507-Q6_K-00002-of-00004.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-235B-A22B-Instruct-2507-Q6_K-00003-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q6_K/Qwen3-235B-A22B-Instruct-2507-Q6_K-00003-of-00004.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-235B-A22B-Instruct-2507-Q6_K-00004-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q6_K/Qwen3-235B-A22B-Instruct-2507-Q6_K-00004-of-00004.gguf",
        "file_size": "41.2 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-235B-A22B-Instruct-2507-Q8_0-00001-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q8_0/Qwen3-235B-A22B-Instruct-2507-Q8_0-00001-of-00006.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-235B-A22B-Instruct-2507-Q8_0-00002-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q8_0/Qwen3-235B-A22B-Instruct-2507-Q8_0-00002-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-235B-A22B-Instruct-2507-Q8_0-00003-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q8_0/Qwen3-235B-A22B-Instruct-2507-Q8_0-00003-of-00006.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-235B-A22B-Instruct-2507-Q8_0-00004-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q8_0/Qwen3-235B-A22B-Instruct-2507-Q8_0-00004-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-235B-A22B-Instruct-2507-Q8_0-00005-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q8_0/Qwen3-235B-A22B-Instruct-2507-Q8_0-00005-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-235B-A22B-Instruct-2507-Q8_0-00006-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Q8_0/Qwen3-235B-A22B-Instruct-2507-Q8_0-00006-of-00006.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q2_K_XL-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q2_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q2_K_XL-00001-of-00002.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q2_K_XL-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q2_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q2_K_XL-00002-of-00002.gguf",
        "file_size": "36.1 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q3_K_XL-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q3_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q3_K_XL-00001-of-00003.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q3_K_XL-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q3_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q3_K_XL-00002-of-00003.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q3_K_XL-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q3_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q3_K_XL-00003-of-00003.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q4_K_XL-00001-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q4_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q4_K_XL-00001-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q4_K_XL-00002-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q4_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q4_K_XL-00002-of-00003.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q4_K_XL-00003-of-00003",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q4_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q4_K_XL-00003-of-00003.gguf",
        "file_size": "32.3 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q6_K_XL-00001-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q6_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q6_K_XL-00001-of-00005.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q6_K_XL-00002-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q6_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q6_K_XL-00002-of-00005.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q6_K_XL-00003-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q6_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q6_K_XL-00003-of-00005.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q6_K_XL-00004-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q6_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q6_K_XL-00004-of-00005.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q6_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q6_K_XL-00005-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q6_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q6_K_XL-00005-of-00005.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q8_K_XL-00001-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q8_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q8_K_XL-00001-of-00006.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q8_K_XL-00002-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q8_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q8_K_XL-00002-of-00006.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q8_K_XL-00003-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q8_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q8_K_XL-00003-of-00006.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q8_K_XL-00004-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q8_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q8_K_XL-00004-of-00006.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q8_K_XL-00005-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q8_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q8_K_XL-00005-of-00006.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-Q8_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q8_K_XL-00006-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/UD-Q8_K_XL/Qwen3-235B-A22B-Instruct-2507-UD-Q8_K_XL-00006-of-00006.gguf",
        "file_size": "24.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/README.md",
    "description": "This is a large-scale, instruction-following Qwen3 model with 235B parameters, enhanced capabilities in reasoning, coding, and multilingual tasks, and optimized for performance and memory efficiency."
  },
  {
    "model_name": "Qwen3-235B-A22B-Instruct-2507-GGUF",
    "developer": "lmstudio-community",
    "downloads": 1360,
    "createdAt": "2025-07-21T19:13:36.000Z",
    "tools": true,
    "num_quants": 19,
    "quants": [
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q3_K_L-00001-of-00003",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q3_K_L-00001-of-00003.gguf",
        "file_size": "37.2 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q3_K_L-00002-of-00003",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q3_K_L-00002-of-00003.gguf",
        "file_size": "36.9 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q3_K_L-00003-of-00003",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q3_K_L-00003-of-00003.gguf",
        "file_size": "29.4 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q4_K_M-00001-of-00004",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q4_K_M-00001-of-00004.gguf",
        "file_size": "37.1 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q4_K_M-00002-of-00004",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q4_K_M-00002-of-00004.gguf",
        "file_size": "37.1 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q4_K_M-00003-of-00004",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q4_K_M-00003-of-00004.gguf",
        "file_size": "37.1 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q4_K_M-00004-of-00004",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q4_K_M-00004-of-00004.gguf",
        "file_size": "21.5 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q6_K-00001-of-00005",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q6_K-00001-of-00005.gguf",
        "file_size": "37.2 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q6_K-00002-of-00005",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q6_K-00002-of-00005.gguf",
        "file_size": "36.8 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q6_K-00003-of-00005",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q6_K-00003-of-00005.gguf",
        "file_size": "36.8 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q6_K-00004-of-00005",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q6_K-00004-of-00005.gguf",
        "file_size": "36.8 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q6_K-00005-of-00005",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q6_K-00005-of-00005.gguf",
        "file_size": "32.3 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q8_0-00001-of-00007",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q8_0-00001-of-00007.gguf",
        "file_size": "36.6 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q8_0-00002-of-00007",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q8_0-00002-of-00007.gguf",
        "file_size": "36.9 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q8_0-00003-of-00007",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q8_0-00003-of-00007.gguf",
        "file_size": "36.9 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q8_0-00004-of-00007",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q8_0-00004-of-00007.gguf",
        "file_size": "36.9 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q8_0-00005-of-00007",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q8_0-00005-of-00007.gguf",
        "file_size": "36.9 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q8_0-00006-of-00007",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q8_0-00006-of-00007.gguf",
        "file_size": "36.9 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-Q8_0-00007-of-00007",
        "path": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/Qwen3-235B-A22B-Instruct-2507-Q8_0-00007-of-00007.gguf",
        "file_size": "11.4 GB"
      }
    ],
    "readme": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Qwen3-235B-A22B-Instruct-2507 model by Qwen, optimized for text generation using GGUF quantization from llama.cpp."
  },
  {
    "model_name": "Qwen3-235B-A22B-Instruct-2507-GGUF",
    "developer": "ubergarm",
    "downloads": 148,
    "createdAt": "2025-07-21T21:50:49.000Z",
    "tools": true,
    "num_quants": 12,
    "quants": [
      {
        "model_id": "IQ2_KL/Qwen3-235B-A22B-Instruct-IQ2_KL-00001-of-00002",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/IQ2_KL/Qwen3-235B-A22B-Instruct-IQ2_KL-00001-of-00002.gguf",
        "file_size": "40.9 GB"
      },
      {
        "model_id": "IQ2_KL/Qwen3-235B-A22B-Instruct-IQ2_KL-00002-of-00002",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/IQ2_KL/Qwen3-235B-A22B-Instruct-IQ2_KL-00002-of-00002.gguf",
        "file_size": "41.0 GB"
      },
      {
        "model_id": "IQ3_K/Qwen3-235B-A22B-Instruct-IQ3_K-00001-of-00003",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/IQ3_K/Qwen3-235B-A22B-Instruct-IQ3_K-00001-of-00003.gguf",
        "file_size": "36.1 GB"
      },
      {
        "model_id": "IQ3_K/Qwen3-235B-A22B-Instruct-IQ3_K-00002-of-00003",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/IQ3_K/Qwen3-235B-A22B-Instruct-IQ3_K-00002-of-00003.gguf",
        "file_size": "36.3 GB"
      },
      {
        "model_id": "IQ3_K/Qwen3-235B-A22B-Instruct-IQ3_K-00003-of-00003",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/IQ3_K/Qwen3-235B-A22B-Instruct-IQ3_K-00003-of-00003.gguf",
        "file_size": "34.2 GB"
      },
      {
        "model_id": "IQ5_K/Qwen3-235B-A22B-Instruct-IQ5_K-00001-of-00004",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/IQ5_K/Qwen3-235B-A22B-Instruct-IQ5_K-00001-of-00004.gguf",
        "file_size": "40.5 GB"
      },
      {
        "model_id": "IQ5_K/Qwen3-235B-A22B-Instruct-IQ5_K-00002-of-00004",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/IQ5_K/Qwen3-235B-A22B-Instruct-IQ5_K-00002-of-00004.gguf",
        "file_size": "40.4 GB"
      },
      {
        "model_id": "IQ5_K/Qwen3-235B-A22B-Instruct-IQ5_K-00003-of-00004",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/IQ5_K/Qwen3-235B-A22B-Instruct-IQ5_K-00003-of-00004.gguf",
        "file_size": "40.5 GB"
      },
      {
        "model_id": "IQ5_K/Qwen3-235B-A22B-Instruct-IQ5_K-00004-of-00004",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/IQ5_K/Qwen3-235B-A22B-Instruct-IQ5_K-00004-of-00004.gguf",
        "file_size": "40.3 GB"
      },
      {
        "model_id": "pure-IQ4_KS/Qwen3-235B-A22B-Instruct-pure-IQ4_KS-00001-of-00003",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/pure-IQ4_KS/Qwen3-235B-A22B-Instruct-pure-IQ4_KS-00001-of-00003.gguf",
        "file_size": "39.9 GB"
      },
      {
        "model_id": "pure-IQ4_KS/Qwen3-235B-A22B-Instruct-pure-IQ4_KS-00002-of-00003",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/pure-IQ4_KS/Qwen3-235B-A22B-Instruct-pure-IQ4_KS-00002-of-00003.gguf",
        "file_size": "40.0 GB"
      },
      {
        "model_id": "pure-IQ4_KS/Qwen3-235B-A22B-Instruct-pure-IQ4_KS-00003-of-00003",
        "path": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/pure-IQ4_KS/Qwen3-235B-A22B-Instruct-pure-IQ4_KS-00003-of-00003.gguf",
        "file_size": "37.1 GB"
      }
    ],
    "readme": "https://huggingface.co/ubergarm/Qwen3-235B-A22B-Instruct-2507-GGUF/resolve/main/README.md",
    "description": "This repository provides quantized versions of the Qwen3-235B-A22B-Instruct-2507 model using ik_llama.cpp, optimized for different memory footprints and perplexity performance."
  },
  {
    "model_name": "Qwen3-235B-A22B-Instruct-2507-gguf-q2ks-mixed-AutoRound-inc",
    "developer": "Intel",
    "downloads": 0,
    "createdAt": "2025-07-22T14:02:55.000Z",
    "tools": true,
    "num_quants": 2,
    "quants": [
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-128x10B-Q2_K_S-00001-of-00002",
        "path": "https://huggingface.co/Intel/Qwen3-235B-A22B-Instruct-2507-gguf-q2ks-mixed-AutoRound-inc/resolve/main/Qwen3-235B-A22B-Instruct-2507-128x10B-Q2_K_S-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-128x10B-Q2_K_S-00002-of-00002",
        "path": "https://huggingface.co/Intel/Qwen3-235B-A22B-Instruct-2507-gguf-q2ks-mixed-AutoRound-inc/resolve/main/Qwen3-235B-A22B-Instruct-2507-128x10B-Q2_K_S-00002-of-00002.gguf",
        "file_size": "27.9 GB"
      }
    ],
    "readme": "https://huggingface.co/Intel/Qwen3-235B-A22B-Instruct-2507-gguf-q2ks-mixed-AutoRound-inc/resolve/main/README.md",
    "description": "This model is a mixed gguf:q2ks version of Qwen/Qwen3-235B-A22B-Instruct-2507, with the embedding layer and lm-head quantized to 8 bits and non-expert layers quantized to 4 bits using"
  },
  {
    "model_name": "Qwen3-235B-A22B-Instruct-2507-gguf-q4km-AutoRound-inc",
    "developer": "Intel",
    "downloads": 0,
    "createdAt": "2025-07-22T13:58:13.000Z",
    "tools": true,
    "num_quants": 3,
    "quants": [
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-128x10B-Q4_K_M-00001-of-00003",
        "path": "https://huggingface.co/Intel/Qwen3-235B-A22B-Instruct-2507-gguf-q4km-AutoRound-inc/resolve/main/Qwen3-235B-A22B-Instruct-2507-128x10B-Q4_K_M-00001-of-00003.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-128x10B-Q4_K_M-00002-of-00003",
        "path": "https://huggingface.co/Intel/Qwen3-235B-A22B-Instruct-2507-gguf-q4km-AutoRound-inc/resolve/main/Qwen3-235B-A22B-Instruct-2507-128x10B-Q4_K_M-00002-of-00003.gguf",
        "file_size": "46.6 GB"
      },
      {
        "model_id": "Qwen3-235B-A22B-Instruct-2507-128x10B-Q4_K_M-00003-of-00003",
        "path": "https://huggingface.co/Intel/Qwen3-235B-A22B-Instruct-2507-gguf-q4km-AutoRound-inc/resolve/main/Qwen3-235B-A22B-Instruct-2507-128x10B-Q4_K_M-00003-of-00003.gguf",
        "file_size": "30.8 GB"
      }
    ],
    "readme": "https://huggingface.co/Intel/Qwen3-235B-A22B-Instruct-2507-gguf-q4km-AutoRound-inc/resolve/main/README.md",
    "description": "This is a quantized version of the Qwen3-235B-A22B-Instruct-2507 model using the Intel AutoRound algorithm, optimized for efficient inference on gguf:q4km format."
  },
  {
    "model_name": "Qwen3-30B-A3B-GGUF",
    "developer": "unsloth",
    "downloads": 119559,
    "createdAt": "2025-04-28T13:48:41.000Z",
    "tools": true,
    "num_quants": 27,
    "quants": [
      {
        "model_id": "BF16/Qwen3-30B-A3B-BF16-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/BF16/Qwen3-30B-A3B-BF16-00001-of-00002.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "BF16/Qwen3-30B-A3B-BF16-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/BF16/Qwen3-30B-A3B-BF16-00002-of-00002.gguf",
        "file_size": "10.6 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-IQ4_NL.gguf",
        "file_size": "16.1 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-IQ4_XS.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q2_K",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q2_K.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q2_K_L.gguf",
        "file_size": "10.6 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q3_K_M.gguf",
        "file_size": "13.7 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q3_K_S.gguf",
        "file_size": "12.4 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q4_0",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q4_0.gguf",
        "file_size": "16.2 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q4_1",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q4_1.gguf",
        "file_size": "17.9 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q4_K_M.gguf",
        "file_size": "17.3 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q4_K_S.gguf",
        "file_size": "16.3 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q5_K_M.gguf",
        "file_size": "20.2 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q5_K_S.gguf",
        "file_size": "19.6 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q6_K",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q6_K.gguf",
        "file_size": "23.4 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q8_0",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q8_0.gguf",
        "file_size": "30.3 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-UD-IQ1_M.gguf",
        "file_size": "9.0 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-UD-IQ1_S.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-UD-IQ2_M.gguf",
        "file_size": "10.1 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-UD-IQ2_XXS.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-UD-IQ3_XXS.gguf",
        "file_size": "12.0 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-UD-Q2_K_XL.gguf",
        "file_size": "11.0 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-UD-Q3_K_XL.gguf",
        "file_size": "12.9 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-UD-Q4_K_XL.gguf",
        "file_size": "16.5 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-UD-Q5_K_XL.gguf",
        "file_size": "20.2 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-UD-Q6_K_XL.gguf",
        "file_size": "24.5 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-UD-Q8_K_XL.gguf",
        "file_size": "33.5 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF/resolve/main/README.md",
    "description": "Qwen3-30B-A3B is a large language model developed by Alibaba Cloud, offering advanced reasoning, instruction-following, and multilingual capabilities with seamless switching between thinking and non-thinking modes, and is available for fine-tuning and deployment via Hugging Face and other frameworks."
  },
  {
    "model_name": "Qwen3-30B-A3B-GGUF",
    "developer": "ubergarm",
    "downloads": 322,
    "createdAt": "2025-05-02T00:10:00.000Z",
    "num_quants": 1,
    "quants": [
      {
        "model_id": "Qwen3-30B-A3B-mix-IQ4_K",
        "path": "https://huggingface.co/ubergarm/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-mix-IQ4_K.gguf",
        "file_size": "17.7 GB"
      }
    ],
    "readme": "https://huggingface.co/ubergarm/Qwen3-30B-A3B-GGUF/resolve/main/README.md",
    "description": "This repository provides quantized versions of the Qwen3-30B-A3B model using ik_llama.cpp, optimized for high-quality generation with reduced memory footprint, requiring specific hardware and software support for proper execution.",
    "tools": true
  },
  {
    "model_name": "Qwen3-30B-A3B-GGUF",
    "developer": "Qwen",
    "downloads": 9844,
    "createdAt": "2025-05-05T08:38:52.000Z",
    "tools": true,
    "num_quants": 5,
    "quants": [
      {
        "model_id": "Qwen3-30B-A3B-Q4_K_M",
        "path": "https://huggingface.co/Qwen/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q4_K_M.gguf",
        "file_size": "17.3 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q5_0",
        "path": "https://huggingface.co/Qwen/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q5_0.gguf",
        "file_size": "19.6 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q5_K_M",
        "path": "https://huggingface.co/Qwen/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q5_K_M.gguf",
        "file_size": "20.2 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q6_K",
        "path": "https://huggingface.co/Qwen/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q6_K.gguf",
        "file_size": "23.4 GB"
      },
      {
        "model_id": "Qwen3-30B-A3B-Q8_0",
        "path": "https://huggingface.co/Qwen/Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q8_0.gguf",
        "file_size": "30.3 GB"
      }
    ],
    "readme": "https://huggingface.co/Qwen/Qwen3-30B-A3B-GGUF/resolve/main/README.md",
    "description": "Qwen3-30B-A3B-GGUF is a large language model with 30.5B parameters, supporting seamless switching between thinking and non-thinking modes, enhanced reasoning, multilingual capabilities, and efficient inference via quantization methods like Q8_0."
  },
  {
    "model_name": "Qwen3-32B-GGUF",
    "developer": "unsloth",
    "downloads": 29310,
    "createdAt": "2025-04-28T08:55:52.000Z",
    "tools": true,
    "num_quants": 27,
    "quants": [
      {
        "model_id": "BF16/Qwen3-32B-BF16-00001-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/BF16/Qwen3-32B-BF16-00001-of-00002.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "BF16/Qwen3-32B-BF16-00002-of-00002",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/BF16/Qwen3-32B-BF16-00002-of-00002.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "Qwen3-32B-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-IQ4_NL.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "Qwen3-32B-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-IQ4_XS.gguf",
        "file_size": "16.5 GB"
      },
      {
        "model_id": "Qwen3-32B-Q2_K",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-Q2_K.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "Qwen3-32B-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-Q2_K_L.gguf",
        "file_size": "11.7 GB"
      },
      {
        "model_id": "Qwen3-32B-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-Q3_K_M.gguf",
        "file_size": "14.9 GB"
      },
      {
        "model_id": "Qwen3-32B-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-Q3_K_S.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "Qwen3-32B-Q4_0",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-Q4_0.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "Qwen3-32B-Q4_1",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-Q4_1.gguf",
        "file_size": "19.2 GB"
      },
      {
        "model_id": "Qwen3-32B-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-Q4_K_M.gguf",
        "file_size": "18.4 GB"
      },
      {
        "model_id": "Qwen3-32B-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-Q4_K_S.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "Qwen3-32B-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-Q5_K_M.gguf",
        "file_size": "21.6 GB"
      },
      {
        "model_id": "Qwen3-32B-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-Q5_K_S.gguf",
        "file_size": "21.1 GB"
      },
      {
        "model_id": "Qwen3-32B-Q6_K",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-Q6_K.gguf",
        "file_size": "25.0 GB"
      },
      {
        "model_id": "Qwen3-32B-Q8_0",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-Q8_0.gguf",
        "file_size": "32.4 GB"
      },
      {
        "model_id": "Qwen3-32B-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-UD-IQ1_M.gguf",
        "file_size": "7.7 GB"
      },
      {
        "model_id": "Qwen3-32B-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-UD-IQ1_S.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "Qwen3-32B-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-UD-IQ2_M.gguf",
        "file_size": "10.8 GB"
      },
      {
        "model_id": "Qwen3-32B-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-UD-IQ2_XXS.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "Qwen3-32B-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-UD-IQ3_XXS.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "Qwen3-32B-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-UD-Q2_K_XL.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "Qwen3-32B-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-UD-Q3_K_XL.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "Qwen3-32B-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-UD-Q4_K_XL.gguf",
        "file_size": "18.6 GB"
      },
      {
        "model_id": "Qwen3-32B-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-UD-Q5_K_XL.gguf",
        "file_size": "21.6 GB"
      },
      {
        "model_id": "Qwen3-32B-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-UD-Q6_K_XL.gguf",
        "file_size": "27.0 GB"
      },
      {
        "model_id": "Qwen3-32B-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-UD-Q8_K_XL.gguf",
        "file_size": "36.8 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/README.md",
    "description": "Qwen3-32B is a large language model developed by Alibaba Cloud, offering enhanced reasoning, instruction-following, and multilingual capabilities with support for seamless switching between thinking and non-thinking modes, and is available for fine-tuning and deployment via Hugging Face and other frameworks."
  },
  {
    "model_name": "Qwen3-4B-GGUF",
    "developer": "unsloth",
    "downloads": 29899,
    "createdAt": "2025-04-28T07:55:09.000Z",
    "num_quants": 26,
    "quants": [
      {
        "model_id": "Qwen3-4B-BF16",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-BF16.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Qwen3-4B-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-IQ4_NL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Qwen3-4B-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-IQ4_XS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Qwen3-4B-Q2_K",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q2_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Qwen3-4B-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q2_K_L.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Qwen3-4B-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q3_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Qwen3-4B-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Qwen3-4B-Q4_0",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Qwen3-4B-Q4_1",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q4_1.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Qwen3-4B-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Qwen3-4B-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Qwen3-4B-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Qwen3-4B-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Qwen3-4B-Q6_K",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Qwen3-4B-Q8_0",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q8_0.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-IQ1_M.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-IQ1_S.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-IQ2_M.gguf",
        "file_size": "1.4 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-IQ2_XXS.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-IQ3_XXS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-Q2_K_XL.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-Q3_K_XL.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-Q4_K_XL.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-Q5_K_XL.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-Q6_K_XL.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "Qwen3-4B-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-Q8_K_XL.gguf",
        "file_size": "4.7 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "qwen3-4B-rpg-roleplay",
    "developer": "Chun121",
    "downloads": 2260,
    "createdAt": "2025-04-30T23:55:22.000Z",
    "num_quants": 4,
    "quants": [
      {
        "model_id": "gguf_f16/unsloth.F16",
        "path": "https://huggingface.co/Chun121/qwen3-4B-rpg-roleplay/resolve/main/gguf_f16/unsloth.F16.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "gguf_q4_k_m/unsloth.F16",
        "path": "https://huggingface.co/Chun121/qwen3-4B-rpg-roleplay/resolve/main/gguf_q4_k_m/unsloth.F16.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "gguf_q4_k_m/unsloth.Q4_K_M",
        "path": "https://huggingface.co/Chun121/qwen3-4B-rpg-roleplay/resolve/main/gguf_q4_k_m/unsloth.Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "gguf_q8_0/unsloth.Q8_0",
        "path": "https://huggingface.co/Chun121/qwen3-4B-rpg-roleplay/resolve/main/gguf_q8_0/unsloth.Q8_0.gguf",
        "file_size": "4.0 GB"
      }
    ],
    "readme": "https://huggingface.co/Chun121/qwen3-4B-rpg-roleplay/resolve/main/README.md",
    "description": "This is a LoRA fine-tuned version of Qwen3-4B, optimized for character-based conversations and roleplay scenarios using the Gryphe-Aesir-RPG-Charcards-Opus-Mixed-split dataset.",
    "tools": true
  },
  {
    "model_name": "Qwen3-Coder-480B-A35B-Instruct-GGUF",
    "developer": "unsloth",
    "downloads": 0,
    "createdAt": "2025-07-22T19:45:59.000Z",
    "tools": true,
    "num_quants": 73,
    "quants": [
      {
        "model_id": "Q2_K/Qwen3-Coder-480B-A35B-Instruct-Q2_K-00001-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q2_K/Qwen3-Coder-480B-A35B-Instruct-Q2_K-00001-of-00004.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q2_K/Qwen3-Coder-480B-A35B-Instruct-Q2_K-00002-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q2_K/Qwen3-Coder-480B-A35B-Instruct-Q2_K-00002-of-00004.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "Q2_K/Qwen3-Coder-480B-A35B-Instruct-Q2_K-00003-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q2_K/Qwen3-Coder-480B-A35B-Instruct-Q2_K-00003-of-00004.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "Q2_K/Qwen3-Coder-480B-A35B-Instruct-Q2_K-00004-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q2_K/Qwen3-Coder-480B-A35B-Instruct-Q2_K-00004-of-00004.gguf",
        "file_size": "24.2 GB"
      },
      {
        "model_id": "Q3_K_M/Qwen3-Coder-480B-A35B-Instruct-Q3_K_M-00001-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q3_K_M/Qwen3-Coder-480B-A35B-Instruct-Q3_K_M-00001-of-00005.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q3_K_M/Qwen3-Coder-480B-A35B-Instruct-Q3_K_M-00002-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q3_K_M/Qwen3-Coder-480B-A35B-Instruct-Q3_K_M-00002-of-00005.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Q3_K_M/Qwen3-Coder-480B-A35B-Instruct-Q3_K_M-00003-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q3_K_M/Qwen3-Coder-480B-A35B-Instruct-Q3_K_M-00003-of-00005.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q3_K_M/Qwen3-Coder-480B-A35B-Instruct-Q3_K_M-00004-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q3_K_M/Qwen3-Coder-480B-A35B-Instruct-Q3_K_M-00004-of-00005.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "Q3_K_M/Qwen3-Coder-480B-A35B-Instruct-Q3_K_M-00005-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q3_K_M/Qwen3-Coder-480B-A35B-Instruct-Q3_K_M-00005-of-00005.gguf",
        "file_size": "29.3 GB"
      },
      {
        "model_id": "Q4_K_M/Qwen3-Coder-480B-A35B-Instruct-Q4_K_M-00001-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q4_K_M/Qwen3-Coder-480B-A35B-Instruct-Q4_K_M-00001-of-00006.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "Q4_K_M/Qwen3-Coder-480B-A35B-Instruct-Q4_K_M-00002-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q4_K_M/Qwen3-Coder-480B-A35B-Instruct-Q4_K_M-00002-of-00006.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q4_K_M/Qwen3-Coder-480B-A35B-Instruct-Q4_K_M-00003-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q4_K_M/Qwen3-Coder-480B-A35B-Instruct-Q4_K_M-00003-of-00006.gguf",
        "file_size": "45.5 GB"
      },
      {
        "model_id": "Q4_K_M/Qwen3-Coder-480B-A35B-Instruct-Q4_K_M-00004-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q4_K_M/Qwen3-Coder-480B-A35B-Instruct-Q4_K_M-00004-of-00006.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "Q4_K_M/Qwen3-Coder-480B-A35B-Instruct-Q4_K_M-00005-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q4_K_M/Qwen3-Coder-480B-A35B-Instruct-Q4_K_M-00005-of-00006.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "Q4_K_M/Qwen3-Coder-480B-A35B-Instruct-Q4_K_M-00006-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q4_K_M/Qwen3-Coder-480B-A35B-Instruct-Q4_K_M-00006-of-00006.gguf",
        "file_size": "39.8 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-Coder-480B-A35B-Instruct-Q5_K_M-00001-of-00007",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q5_K_M/Qwen3-Coder-480B-A35B-Instruct-Q5_K_M-00001-of-00007.gguf",
        "file_size": "46.4 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-Coder-480B-A35B-Instruct-Q5_K_M-00002-of-00007",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q5_K_M/Qwen3-Coder-480B-A35B-Instruct-Q5_K_M-00002-of-00007.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-Coder-480B-A35B-Instruct-Q5_K_M-00003-of-00007",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q5_K_M/Qwen3-Coder-480B-A35B-Instruct-Q5_K_M-00003-of-00007.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-Coder-480B-A35B-Instruct-Q5_K_M-00004-of-00007",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q5_K_M/Qwen3-Coder-480B-A35B-Instruct-Q5_K_M-00004-of-00007.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-Coder-480B-A35B-Instruct-Q5_K_M-00005-of-00007",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q5_K_M/Qwen3-Coder-480B-A35B-Instruct-Q5_K_M-00005-of-00007.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-Coder-480B-A35B-Instruct-Q5_K_M-00006-of-00007",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q5_K_M/Qwen3-Coder-480B-A35B-Instruct-Q5_K_M-00006-of-00007.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "Q5_K_M/Qwen3-Coder-480B-A35B-Instruct-Q5_K_M-00007-of-00007",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q5_K_M/Qwen3-Coder-480B-A35B-Instruct-Q5_K_M-00007-of-00007.gguf",
        "file_size": "43.6 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00001-of-00009",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00001-of-00009.gguf",
        "file_size": "44.8 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00002-of-00009",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00002-of-00009.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00003-of-00009",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00003-of-00009.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00004-of-00009",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00004-of-00009.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00005-of-00009",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00005-of-00009.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00006-of-00009",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00006-of-00009.gguf",
        "file_size": "45.1 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00007-of-00009",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00007-of-00009.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00008-of-00009",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00008-of-00009.gguf",
        "file_size": "45.2 GB"
      },
      {
        "model_id": "Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00009-of-00009",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q6_K/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00009-of-00009.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00001-of-00011",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00001-of-00011.gguf",
        "file_size": "44.3 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00002-of-00011",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00002-of-00011.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00003-of-00011",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00003-of-00011.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00004-of-00011",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00004-of-00011.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00005-of-00011",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00005-of-00011.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00006-of-00011",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00006-of-00011.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00007-of-00011",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00007-of-00011.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00008-of-00011",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00008-of-00011.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00009-of-00011",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00009-of-00011.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00010-of-00011",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00010-of-00011.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00011-of-00011",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Q8_0/Qwen3-Coder-480B-A35B-Instruct-Q8_0-00011-of-00011.gguf",
        "file_size": "18.7 GB"
      },
      {
        "model_id": "UD-IQ1_M/Qwen3-Coder-480B-A35B-Instruct-UD-IQ1_M-00001-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-IQ1_M/Qwen3-Coder-480B-A35B-Instruct-UD-IQ1_M-00001-of-00004.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-IQ1_M/Qwen3-Coder-480B-A35B-Instruct-UD-IQ1_M-00002-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-IQ1_M/Qwen3-Coder-480B-A35B-Instruct-UD-IQ1_M-00002-of-00004.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-IQ1_M/Qwen3-Coder-480B-A35B-Instruct-UD-IQ1_M-00003-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-IQ1_M/Qwen3-Coder-480B-A35B-Instruct-UD-IQ1_M-00003-of-00004.gguf",
        "file_size": "46.3 GB"
      },
      {
        "model_id": "UD-IQ1_M/Qwen3-Coder-480B-A35B-Instruct-UD-IQ1_M-00004-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-IQ1_M/Qwen3-Coder-480B-A35B-Instruct-UD-IQ1_M-00004-of-00004.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/Qwen3-Coder-480B-A35B-Instruct-UD-IQ3_XXS-00001-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-IQ3_XXS/Qwen3-Coder-480B-A35B-Instruct-UD-IQ3_XXS-00001-of-00005.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/Qwen3-Coder-480B-A35B-Instruct-UD-IQ3_XXS-00002-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-IQ3_XXS/Qwen3-Coder-480B-A35B-Instruct-UD-IQ3_XXS-00002-of-00005.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/Qwen3-Coder-480B-A35B-Instruct-UD-IQ3_XXS-00003-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-IQ3_XXS/Qwen3-Coder-480B-A35B-Instruct-UD-IQ3_XXS-00003-of-00005.gguf",
        "file_size": "45.5 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/Qwen3-Coder-480B-A35B-Instruct-UD-IQ3_XXS-00004-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-IQ3_XXS/Qwen3-Coder-480B-A35B-Instruct-UD-IQ3_XXS-00004-of-00005.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "UD-IQ3_XXS/Qwen3-Coder-480B-A35B-Instruct-UD-IQ3_XXS-00005-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-IQ3_XXS/Qwen3-Coder-480B-A35B-Instruct-UD-IQ3_XXS-00005-of-00005.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q2_K_XL-00001-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q2_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q2_K_XL-00001-of-00004.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q2_K_XL-00002-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q2_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q2_K_XL-00002-of-00004.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q2_K_XL-00003-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q2_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q2_K_XL-00003-of-00004.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q2_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q2_K_XL-00004-of-00004",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q2_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q2_K_XL-00004-of-00004.gguf",
        "file_size": "29.6 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q3_K_XL-00001-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q3_K_XL-00001-of-00005.gguf",
        "file_size": "45.8 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q3_K_XL-00002-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q3_K_XL-00002-of-00005.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q3_K_XL-00003-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q3_K_XL-00003-of-00005.gguf",
        "file_size": "45.7 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q3_K_XL-00004-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q3_K_XL-00004-of-00005.gguf",
        "file_size": "46.2 GB"
      },
      {
        "model_id": "UD-Q3_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q3_K_XL-00005-of-00005",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q3_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q3_K_XL-00005-of-00005.gguf",
        "file_size": "14.8 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q4_K_XL-00001-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q4_K_XL-00001-of-00006.gguf",
        "file_size": "45.3 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q4_K_XL-00002-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q4_K_XL-00002-of-00006.gguf",
        "file_size": "45.9 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q4_K_XL-00003-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q4_K_XL-00003-of-00006.gguf",
        "file_size": "46.1 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q4_K_XL-00004-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q4_K_XL-00004-of-00006.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q4_K_XL-00005-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q4_K_XL-00005-of-00006.gguf",
        "file_size": "46.5 GB"
      },
      {
        "model_id": "UD-Q4_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q4_K_XL-00006-of-00006",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q4_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q4_K_XL-00006-of-00006.gguf",
        "file_size": "27.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q5_K_XL-00001-of-00007",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q5_K_XL-00001-of-00007.gguf",
        "file_size": "45.5 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q5_K_XL-00002-of-00007",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q5_K_XL-00002-of-00007.gguf",
        "file_size": "45.6 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q5_K_XL-00003-of-00007",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q5_K_XL-00003-of-00007.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q5_K_XL-00004-of-00007",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q5_K_XL-00004-of-00007.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q5_K_XL-00005-of-00007",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q5_K_XL-00005-of-00007.gguf",
        "file_size": "45.4 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q5_K_XL-00006-of-00007",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q5_K_XL-00006-of-00007.gguf",
        "file_size": "46.0 GB"
      },
      {
        "model_id": "UD-Q5_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q5_K_XL-00007-of-00007",
        "path": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/UD-Q5_K_XL/Qwen3-Coder-480B-A35B-Instruct-UD-Q5_K_XL-00007-of-00007.gguf",
        "file_size": "43.2 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/README.md",
    "description": "This is a large-scale, high-performance code model (Qwen3-Coder-480B-A35B-Instruct) with 256K native token context support, optimized for repository-scale understanding and agentic coding tasks, available via Hugging Face for fine-tuning and"
  },
  {
    "model_name": "Qwen3-Coder-480B-A35B-Instruct-GGUF",
    "developer": "ubergarm",
    "downloads": 0,
    "createdAt": "2025-07-23T02:58:23.000Z",
    "tools": true,
    "num_quants": 4,
    "quants": [
      {
        "model_id": "IQ2_KS/Qwen3-480B-A35B-Instruct-IQ2_KS-00001-of-00004",
        "path": "https://huggingface.co/ubergarm/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/IQ2_KS/Qwen3-480B-A35B-Instruct-IQ2_KS-00001-of-00004.gguf",
        "file_size": "36.1 GB"
      },
      {
        "model_id": "IQ2_KS/Qwen3-480B-A35B-Instruct-IQ2_KS-00002-of-00004",
        "path": "https://huggingface.co/ubergarm/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/IQ2_KS/Qwen3-480B-A35B-Instruct-IQ2_KS-00002-of-00004.gguf",
        "file_size": "35.9 GB"
      },
      {
        "model_id": "IQ2_KS/Qwen3-480B-A35B-Instruct-IQ2_KS-00003-of-00004",
        "path": "https://huggingface.co/ubergarm/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/IQ2_KS/Qwen3-480B-A35B-Instruct-IQ2_KS-00003-of-00004.gguf",
        "file_size": "36.2 GB"
      },
      {
        "model_id": "IQ2_KS/Qwen3-480B-A35B-Instruct-IQ2_KS-00004-of-00004",
        "path": "https://huggingface.co/ubergarm/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/IQ2_KS/Qwen3-480B-A35B-Instruct-IQ2_KS-00004-of-00004.gguf",
        "file_size": "35.9 GB"
      }
    ],
    "readme": "https://huggingface.co/ubergarm/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/README.md",
    "description": "This repository provides quantized versions of the Qwen3-Coder-480B-A35B-Instruct model using ik_llama.cpp, optimized for different memory footprints and performance metrics."
  },
  {
    "model_name": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF",
    "developer": "DavidAU",
    "downloads": 1219,
    "createdAt": "2025-07-17T07:28:04.000Z",
    "tools": true,
    "num_quants": 81,
    "quants": [
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-BF16",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-BF16.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-F16",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-F16.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ2_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ2_M-imat.gguf",
        "file_size": "325.3 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ2_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ2_S-imat.gguf",
        "file_size": "310.0 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ2_XS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ2_XS-imat.gguf",
        "file_size": "292.4 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ2_XXS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ2_XXS-imat.gguf",
        "file_size": "274.5 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ3_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ3_M-imat.gguf",
        "file_size": "417.2 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ3_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ3_S-imat.gguf",
        "file_size": "398.5 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ3_XS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ3_XS-imat.gguf",
        "file_size": "383.9 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ3_XXS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ3_XXS-imat.gguf",
        "file_size": "345.3 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ4_NL-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ4_NL-imat.gguf",
        "file_size": "482.1 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ4_XS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-IQ4_XS-imat.gguf",
        "file_size": "462.5 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q2_K-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q2_K-imat.gguf",
        "file_size": "360.1 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q2_K_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q2_K_S-imat.gguf",
        "file_size": "338.0 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q3_K_L-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q3_K_L-imat.gguf",
        "file_size": "463.4 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q3_K_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q3_K_M-imat.gguf",
        "file_size": "432.9 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q3_K_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q3_K_S-imat.gguf",
        "file_size": "398.5 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q4_0-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q4_0-imat.gguf",
        "file_size": "483.1 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q4_1-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q4_1-imat.gguf",
        "file_size": "521.5 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q4_K_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q4_K_M-imat.gguf",
        "file_size": "503.8 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q4_K_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q4_K_S-imat.gguf",
        "file_size": "484.5 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q5_0-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q5_0-imat.gguf",
        "file_size": "561.8 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q5_1-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q5_1-imat.gguf",
        "file_size": "600.3 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q5_K_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q5_K_M-imat.gguf",
        "file_size": "572.1 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q5_K_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q5_K_S-imat.gguf",
        "file_size": "560.9 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q6_K-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q6_K-imat.gguf",
        "file_size": "644.6 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-D_AU-Q8_0.gguf",
        "file_size": "833.1 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-BF16",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-BF16.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-F16",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-F16.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ2_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ2_M-imat.gguf",
        "file_size": "325.3 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ2_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ2_S-imat.gguf",
        "file_size": "310.0 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ2_XS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ2_XS-imat.gguf",
        "file_size": "292.4 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ2_XXS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ2_XXS-imat.gguf",
        "file_size": "274.5 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ3_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ3_M-imat.gguf",
        "file_size": "417.2 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ3_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ3_S-imat.gguf",
        "file_size": "398.5 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ3_XS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ3_XS-imat.gguf",
        "file_size": "383.9 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ3_XXS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ3_XXS-imat.gguf",
        "file_size": "345.3 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ4_NL-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ4_NL-imat.gguf",
        "file_size": "482.1 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ4_XS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-IQ4_XS-imat.gguf",
        "file_size": "462.5 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q2_K-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q2_K-imat.gguf",
        "file_size": "360.1 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q2_K_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q2_K_S-imat.gguf",
        "file_size": "338.0 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q3_K_L-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q3_K_L-imat.gguf",
        "file_size": "463.4 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q3_K_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q3_K_M-imat.gguf",
        "file_size": "432.9 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q3_K_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q3_K_S-imat.gguf",
        "file_size": "398.5 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q4_0-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q4_0-imat.gguf",
        "file_size": "483.1 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q4_1-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q4_1-imat.gguf",
        "file_size": "521.5 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q4_K_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q4_K_M-imat.gguf",
        "file_size": "503.8 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q4_K_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q4_K_S-imat.gguf",
        "file_size": "484.5 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q5_0-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q5_0-imat.gguf",
        "file_size": "561.8 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q5_1-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q5_1-imat.gguf",
        "file_size": "600.3 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q5_K_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q5_K_M-imat.gguf",
        "file_size": "572.1 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q5_K_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q5_K_S-imat.gguf",
        "file_size": "560.9 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q6_K-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q6_K-imat.gguf",
        "file_size": "644.6 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO2-EX-D_AU-Q8_0.gguf",
        "file_size": "797.1 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-BF16",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-BF16.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-F16",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-F16.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ2_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ2_M-imat.gguf",
        "file_size": "302.1 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ2_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ2_S-imat.gguf",
        "file_size": "286.8 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ2_XS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ2_XS-imat.gguf",
        "file_size": "269.2 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ2_XXS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ2_XXS-imat.gguf",
        "file_size": "251.3 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ3_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ3_M-imat.gguf",
        "file_size": "374.3 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ3_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ3_S-imat.gguf",
        "file_size": "355.6 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ3_XS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ3_XS-imat.gguf",
        "file_size": "341.0 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ3_XXS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ3_XXS-imat.gguf",
        "file_size": "322.1 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ4_NL-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ4_NL-imat.gguf",
        "file_size": "439.3 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ4_XS-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-IQ4_XS-imat.gguf",
        "file_size": "419.6 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q2_K-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q2_K-imat.gguf",
        "file_size": "317.2 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q2_K_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q2_K_S-imat.gguf",
        "file_size": "295.1 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q3_K_L-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q3_K_L-imat.gguf",
        "file_size": "420.6 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q3_K_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q3_K_M-imat.gguf",
        "file_size": "390.1 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q3_K_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q3_K_S-imat.gguf",
        "file_size": "355.6 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q4_0-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q4_0-imat.gguf",
        "file_size": "440.2 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q4_1-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q4_1-imat.gguf",
        "file_size": "478.6 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q4_K_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q4_K_M-imat.gguf",
        "file_size": "460.9 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q4_K_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q4_K_S-imat.gguf",
        "file_size": "441.6 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q5_0-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q5_0-imat.gguf",
        "file_size": "518.9 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q5_1-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q5_1-imat.gguf",
        "file_size": "557.4 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q5_K_M-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q5_K_M-imat.gguf",
        "file_size": "529.2 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q5_K_S-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q5_K_S-imat.gguf",
        "file_size": "518.0 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q6_K-imat",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q6_K-imat.gguf",
        "file_size": "601.7 MB"
      },
      {
        "model_id": "Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q8_0",
        "path": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/Qwen3-Zero-Coder-Reasoning-0.8B-NEO3-EX-D_AU-Q8_0.gguf",
        "file_size": "754.3 MB"
      }
    ],
    "readme": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF/resolve/main/README.md",
    "description": "This is a high-performance coder model based on Qwen3, capable of generating code and reasoning blocks efficiently with varying quantization levels, optimized for speed and problem-solving across different hardware configurations."
  },
  {
    "model_name": "Qwen_Qwen3-30B-A3B-GGUF",
    "developer": "bartowski",
    "downloads": 4715,
    "createdAt": "2025-04-28T12:18:44.000Z",
    "num_quants": 28,
    "quants": [
      {
        "model_id": "Qwen_Qwen3-30B-A3B-IQ2_M",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-IQ2_M.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-IQ2_S",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-IQ2_S.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-IQ2_XS",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-IQ2_XS.gguf",
        "file_size": "8.5 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-IQ2_XXS",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-IQ2_XXS.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-IQ3_M",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-IQ3_M.gguf",
        "file_size": "13.1 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-IQ3_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-IQ3_XXS.gguf",
        "file_size": "11.4 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-IQ4_NL",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-IQ4_NL.gguf",
        "file_size": "16.2 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-IQ4_XS.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q2_K",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q2_K.gguf",
        "file_size": "10.2 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q2_K_L",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q2_K_L.gguf",
        "file_size": "10.4 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q3_K_L.gguf",
        "file_size": "13.6 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q3_K_M.gguf",
        "file_size": "13.1 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q3_K_S.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q3_K_XL.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q4_0",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q4_0.gguf",
        "file_size": "16.4 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q4_1",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q4_1.gguf",
        "file_size": "17.9 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q4_K_L.gguf",
        "file_size": "17.6 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q4_K_M.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q4_K_S.gguf",
        "file_size": "16.7 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q5_K_L.gguf",
        "file_size": "20.4 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q5_K_M.gguf",
        "file_size": "20.3 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q5_K_S.gguf",
        "file_size": "19.7 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q6_K",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q6_K.gguf",
        "file_size": "23.4 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q6_K_L.gguf",
        "file_size": "23.5 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-Q8_0",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q8_0.gguf",
        "file_size": "30.3 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-bf16/Qwen_Qwen3-30B-A3B-bf16-00001-of-00002",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-bf16/Qwen_Qwen3-30B-A3B-bf16-00001-of-00002.gguf",
        "file_size": "37.0 GB"
      },
      {
        "model_id": "Qwen_Qwen3-30B-A3B-bf16/Qwen_Qwen3-30B-A3B-bf16-00002-of-00002",
        "path": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-bf16/Qwen_Qwen3-30B-A3B-bf16-00002-of-00002.gguf",
        "file_size": "19.9 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Qwen3-30B-A3B model using llama.cpp, offering various quantization types for different performance and quality trade-offs on different hardware platforms.",
    "tools": true
  },
  {
    "model_name": "reka-flash-3.1-GGUF",
    "developer": "mradermacher",
    "downloads": 1134,
    "createdAt": "2025-07-10T18:09:29.000Z",
    "num_quants": 11,
    "quants": [
      {
        "model_id": "reka-flash-3.1.IQ4_XS",
        "path": "https://huggingface.co/mradermacher/reka-flash-3.1-GGUF/resolve/main/reka-flash-3.1.IQ4_XS.gguf",
        "file_size": "10.8 GB"
      },
      {
        "model_id": "reka-flash-3.1.Q2_K",
        "path": "https://huggingface.co/mradermacher/reka-flash-3.1-GGUF/resolve/main/reka-flash-3.1.Q2_K.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "reka-flash-3.1.Q3_K_L",
        "path": "https://huggingface.co/mradermacher/reka-flash-3.1-GGUF/resolve/main/reka-flash-3.1.Q3_K_L.gguf",
        "file_size": "10.6 GB"
      },
      {
        "model_id": "reka-flash-3.1.Q3_K_M",
        "path": "https://huggingface.co/mradermacher/reka-flash-3.1-GGUF/resolve/main/reka-flash-3.1.Q3_K_M.gguf",
        "file_size": "10.1 GB"
      },
      {
        "model_id": "reka-flash-3.1.Q3_K_S",
        "path": "https://huggingface.co/mradermacher/reka-flash-3.1-GGUF/resolve/main/reka-flash-3.1.Q3_K_S.gguf",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "reka-flash-3.1.Q4_K_M",
        "path": "https://huggingface.co/mradermacher/reka-flash-3.1-GGUF/resolve/main/reka-flash-3.1.Q4_K_M.gguf",
        "file_size": "12.7 GB"
      },
      {
        "model_id": "reka-flash-3.1.Q4_K_S",
        "path": "https://huggingface.co/mradermacher/reka-flash-3.1-GGUF/resolve/main/reka-flash-3.1.Q4_K_S.gguf",
        "file_size": "11.8 GB"
      },
      {
        "model_id": "reka-flash-3.1.Q5_K_M",
        "path": "https://huggingface.co/mradermacher/reka-flash-3.1-GGUF/resolve/main/reka-flash-3.1.Q5_K_M.gguf",
        "file_size": "14.6 GB"
      },
      {
        "model_id": "reka-flash-3.1.Q5_K_S",
        "path": "https://huggingface.co/mradermacher/reka-flash-3.1-GGUF/resolve/main/reka-flash-3.1.Q5_K_S.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "reka-flash-3.1.Q6_K",
        "path": "https://huggingface.co/mradermacher/reka-flash-3.1-GGUF/resolve/main/reka-flash-3.1.Q6_K.gguf",
        "file_size": "17.2 GB"
      },
      {
        "model_id": "reka-flash-3.1.Q8_0",
        "path": "https://huggingface.co/mradermacher/reka-flash-3.1-GGUF/resolve/main/reka-flash-3.1.Q8_0.gguf",
        "file_size": "20.7 GB"
      }
    ],
    "readme": "https://huggingface.co/mradermacher/reka-flash-3.1-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "reka-flash-3.1-rekaquant-q3_k_s",
    "developer": "RekaAI",
    "downloads": 1237,
    "createdAt": "2025-05-30T14:20:48.000Z",
    "num_quants": 1,
    "quants": [
      {
        "model_id": "reka-flash-3.1-rekaquant-q3_k_s",
        "path": "https://huggingface.co/RekaAI/reka-flash-3.1-rekaquant-q3_k_s/resolve/main/reka-flash-3.1-rekaquant-q3_k_s.gguf",
        "file_size": "8.6 GB"
      }
    ],
    "readme": "https://huggingface.co/RekaAI/reka-flash-3.1-rekaquant-q3_k_s/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Research-Reasoner-7B-v0.3",
    "developer": "Raymond-dev-546730",
    "downloads": 190,
    "createdAt": "2025-04-03T05:26:56.000Z",
    "num_quants": 20,
    "quants": [
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-IQ3_XS",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-IQ3_XS.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-IQ4_NL",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-IQ4_NL.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-IQ4_XS",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-IQ4_XS.gguf",
        "file_size": "3.7 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q2_K",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q2_K.gguf",
        "file_size": "2.5 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q3_K",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q3_K.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q3_K_M",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q3_K_M.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q3_K_S",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q3_K_S.gguf",
        "file_size": "3.0 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q4_0",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q4_0.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q4_1",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q4_1.gguf",
        "file_size": "4.2 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q4_K",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q4_K.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q4_K_M",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q4_K_M.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q4_K_S",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q4_K_S.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q5_0",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q5_0.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q5_1",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q5_1.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q5_K",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q5_K.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q5_K_M",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q5_K_M.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q5_K_S",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q5_K_S.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q6_K",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q6_K.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q8_0",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-Q8_0.gguf",
        "file_size": "7.2 GB"
      },
      {
        "model_id": "Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-f16",
        "path": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/Model_Weights/llama.cpp/Research-Reasoner-7B-v0.3-f16.gguf",
        "file_size": "13.5 GB"
      }
    ],
    "readme": "https://huggingface.co/Raymond-dev-546730/Research-Reasoner-7B-v0.3/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "RL-MemoryAgent-14B-GGUF",
    "developer": "mradermacher",
    "downloads": 656,
    "createdAt": "2025-06-22T17:33:53.000Z",
    "num_quants": 11,
    "quants": [
      {
        "model_id": "RL-MemoryAgent-14B.IQ4_XS",
        "path": "https://huggingface.co/mradermacher/RL-MemoryAgent-14B-GGUF/resolve/main/RL-MemoryAgent-14B.IQ4_XS.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "RL-MemoryAgent-14B.Q2_K",
        "path": "https://huggingface.co/mradermacher/RL-MemoryAgent-14B-GGUF/resolve/main/RL-MemoryAgent-14B.Q2_K.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "RL-MemoryAgent-14B.Q3_K_L",
        "path": "https://huggingface.co/mradermacher/RL-MemoryAgent-14B-GGUF/resolve/main/RL-MemoryAgent-14B.Q3_K_L.gguf",
        "file_size": "7.4 GB"
      },
      {
        "model_id": "RL-MemoryAgent-14B.Q3_K_M",
        "path": "https://huggingface.co/mradermacher/RL-MemoryAgent-14B-GGUF/resolve/main/RL-MemoryAgent-14B.Q3_K_M.gguf",
        "file_size": "6.8 GB"
      },
      {
        "model_id": "RL-MemoryAgent-14B.Q3_K_S",
        "path": "https://huggingface.co/mradermacher/RL-MemoryAgent-14B-GGUF/resolve/main/RL-MemoryAgent-14B.Q3_K_S.gguf",
        "file_size": "6.2 GB"
      },
      {
        "model_id": "RL-MemoryAgent-14B.Q4_K_M",
        "path": "https://huggingface.co/mradermacher/RL-MemoryAgent-14B-GGUF/resolve/main/RL-MemoryAgent-14B.Q4_K_M.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "RL-MemoryAgent-14B.Q4_K_S",
        "path": "https://huggingface.co/mradermacher/RL-MemoryAgent-14B-GGUF/resolve/main/RL-MemoryAgent-14B.Q4_K_S.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "RL-MemoryAgent-14B.Q5_K_M",
        "path": "https://huggingface.co/mradermacher/RL-MemoryAgent-14B-GGUF/resolve/main/RL-MemoryAgent-14B.Q5_K_M.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "RL-MemoryAgent-14B.Q5_K_S",
        "path": "https://huggingface.co/mradermacher/RL-MemoryAgent-14B-GGUF/resolve/main/RL-MemoryAgent-14B.Q5_K_S.gguf",
        "file_size": "9.6 GB"
      },
      {
        "model_id": "RL-MemoryAgent-14B.Q6_K",
        "path": "https://huggingface.co/mradermacher/RL-MemoryAgent-14B-GGUF/resolve/main/RL-MemoryAgent-14B.Q6_K.gguf",
        "file_size": "11.3 GB"
      },
      {
        "model_id": "RL-MemoryAgent-14B.Q8_0",
        "path": "https://huggingface.co/mradermacher/RL-MemoryAgent-14B-GGUF/resolve/main/RL-MemoryAgent-14B.Q8_0.gguf",
        "file_size": "14.6 GB"
      }
    ],
    "readme": "https://huggingface.co/mradermacher/RL-MemoryAgent-14B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "RuadaptQwen3-4B-Instruct-GGUF",
    "developer": "RefalMachine",
    "downloads": 2954,
    "createdAt": "2025-06-30T06:13:47.000Z",
    "num_quants": 16,
    "quants": [
      {
        "model_id": "BF16",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/BF16.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "IQ3_S",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/IQ3_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "IQ3_XS",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/IQ3_XS.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "IQ4_NL",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/IQ4_NL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "IQ4_XS",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/IQ4_XS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Q2_K",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/Q2_K.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "Q3_K_M",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/Q3_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Q3_K_S",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/Q3_K_S.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "Q4_0",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Q4_K_M",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Q4_K_S",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Q5_0",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/Q5_0.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Q5_K_M",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Q5_K_S",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Q6_K",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Q8_0",
        "path": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/Q8_0.gguf",
        "file_size": "4.0 GB"
      }
    ],
    "readme": "https://huggingface.co/RefalMachine/RuadaptQwen3-4B-Instruct-GGUF/resolve/main/README.md",
    "description": "RuadaptQwen3-4B-Instruct is a Russian-adapted version of Qwen/Qwen3-4B, featuring a new tokenizer, continued pre-training on Russian data, and LEP (Learned Embedding Propagation) applied to enhance Russian text generation speed by up to",
    "tools": true
  },
  {
    "model_name": "Seed-Coder-8B-Reasoning-GGUF",
    "developer": "unsloth",
    "downloads": 2689,
    "createdAt": "2025-05-18T12:29:03.000Z",
    "num_quants": 25,
    "quants": [
      {
        "model_id": "Seed-Coder-8B-Reasoning-BF16",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-BF16.gguf",
        "file_size": "15.4 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-IQ4_NL",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-IQ4_NL.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-IQ4_XS",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-IQ4_XS.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-Q2_K",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-Q2_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-Q2_K_L",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-Q2_K_L.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-Q3_K_M",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-Q3_K_M.gguf",
        "file_size": "3.9 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-Q3_K_S",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-Q3_K_S.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-Q4_1",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-Q4_1.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-Q4_K_M",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-Q4_K_M.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-Q4_K_S",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-Q4_K_S.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-Q5_K_M",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-Q5_K_M.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-Q5_K_S",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-Q5_K_S.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-Q6_K",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-Q6_K.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-Q8_0",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-Q8_0.gguf",
        "file_size": "8.2 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-UD-IQ1_M",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-UD-IQ1_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-UD-IQ1_S",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-UD-IQ1_S.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-UD-IQ2_M.gguf",
        "file_size": "2.9 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-UD-IQ2_XXS.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-UD-IQ3_XXS.gguf",
        "file_size": "3.2 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-UD-Q2_K_XL.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-UD-Q3_K_XL.gguf",
        "file_size": "4.0 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-UD-Q4_K_XL.gguf",
        "file_size": "4.8 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-UD-Q5_K_XL.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-UD-Q6_K_XL.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "Seed-Coder-8B-Reasoning-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/Seed-Coder-8B-Reasoning-UD-Q8_K_XL.gguf",
        "file_size": "10.3 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/Seed-Coder-8B-Reasoning-GGUF/resolve/main/README.md",
    "description": "The Seed-Coder-8B-Reasoning model is a high-performance, parameter-efficient, and transparent open-source code model trained for enhanced reasoning capabilities using RL.",
    "tools": false
  },
  {
    "model_name": "Skywork-R1V3-38B-GGUF",
    "developer": "Skywork",
    "downloads": 281,
    "createdAt": "2025-07-15T08:34:45.000Z",
    "tools": true,
    "num_quants": 5,
    "quants": [
      {
        "model_id": "Skywork-R1V3-38B-Q4_K_M",
        "path": "https://huggingface.co/Skywork/Skywork-R1V3-38B-GGUF/resolve/main/Skywork-R1V3-38B-Q4_K_M.gguf",
        "file_size": "18.5 GB"
      },
      {
        "model_id": "Skywork-R1V3-38B-Q8_0",
        "path": "https://huggingface.co/Skywork/Skywork-R1V3-38B-GGUF/resolve/main/Skywork-R1V3-38B-Q8_0.gguf",
        "file_size": "32.4 GB"
      },
      {
        "model_id": "mmproj-Skywork-R1V3-38B-bf16",
        "path": "https://huggingface.co/Skywork/Skywork-R1V3-38B-GGUF/resolve/main/mmproj-Skywork-R1V3-38B-bf16.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "mmproj-Skywork-R1V3-38B-f16",
        "path": "https://huggingface.co/Skywork/Skywork-R1V3-38B-GGUF/resolve/main/mmproj-Skywork-R1V3-38B-f16.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "mmproj-Skywork-R1V3-38B-q8_0",
        "path": "https://huggingface.co/Skywork/Skywork-R1V3-38B-GGUF/resolve/main/mmproj-Skywork-R1V3-38B-q8_0.gguf",
        "file_size": "5.6 GB"
      }
    ],
    "readme": "https://huggingface.co/Skywork/Skywork-R1V3-38B-GGUF/resolve/main/README.md",
    "description": "This repository provides a GGUF quantized version of the Skywork-R1V3-38B model for fast and memory-efficient local inference using llama.cpp."
  },
  {
    "model_name": "Skywork_Skywork-R1V3-38B-GGUF",
    "developer": "bartowski",
    "downloads": 9214,
    "createdAt": "2025-07-09T03:57:41.000Z",
    "num_quants": 30,
    "quants": [
      {
        "model_id": "Skywork_Skywork-R1V3-38B-IQ2_M",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-IQ2_M.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-IQ2_S",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-IQ2_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-IQ2_XS",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-IQ2_XS.gguf",
        "file_size": "9.3 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-IQ2_XXS",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-IQ2_XXS.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-IQ3_M",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-IQ3_M.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-IQ3_XS",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-IQ3_XS.gguf",
        "file_size": "12.8 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-IQ3_XXS.gguf",
        "file_size": "12.0 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-IQ4_NL",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-IQ4_NL.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-IQ4_XS",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-IQ4_XS.gguf",
        "file_size": "16.5 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q2_K",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q2_K.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q2_K_L",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q2_K_L.gguf",
        "file_size": "12.2 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q3_K_L",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q3_K_L.gguf",
        "file_size": "16.1 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q3_K_M",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q3_K_M.gguf",
        "file_size": "14.8 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q3_K_S",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q3_K_S.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q3_K_XL.gguf",
        "file_size": "16.7 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q4_0",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q4_0.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q4_1",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q4_1.gguf",
        "file_size": "19.2 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q4_K_L",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q4_K_L.gguf",
        "file_size": "19.0 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q4_K_M",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q4_K_M.gguf",
        "file_size": "18.5 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q4_K_S",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q4_K_S.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q5_K_L",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q5_K_L.gguf",
        "file_size": "22.1 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q5_K_M",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q5_K_M.gguf",
        "file_size": "21.7 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q5_K_S",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q5_K_S.gguf",
        "file_size": "21.1 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q6_K",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q6_K.gguf",
        "file_size": "25.0 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q6_K_L",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q6_K_L.gguf",
        "file_size": "25.4 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-Q8_0",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-Q8_0.gguf",
        "file_size": "32.4 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-bf16/Skywork_Skywork-R1V3-38B-bf16-00001-of-00002",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-bf16/Skywork_Skywork-R1V3-38B-bf16-00001-of-00002.gguf",
        "file_size": "37.1 GB"
      },
      {
        "model_id": "Skywork_Skywork-R1V3-38B-bf16/Skywork_Skywork-R1V3-38B-bf16-00002-of-00002",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/Skywork_Skywork-R1V3-38B-bf16/Skywork_Skywork-R1V3-38B-bf16-00002-of-00002.gguf",
        "file_size": "23.9 GB"
      },
      {
        "model_id": "mmproj-Skywork_Skywork-R1V3-38B-bf16",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/mmproj-Skywork_Skywork-R1V3-38B-bf16.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "mmproj-Skywork_Skywork-R1V3-38B-f16",
        "path": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/mmproj-Skywork_Skywork-R1V3-38B-f16.gguf",
        "file_size": "10.5 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/Skywork_Skywork-R1V3-38B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "SmolLM2-135M-Instruct-GGUF",
    "developer": "bartowski",
    "downloads": 1358,
    "createdAt": "2024-10-31T19:25:41.000Z",
    "num_quants": 23,
    "quants": [
      {
        "model_id": "SmolLM2-135M-Instruct-IQ3_M",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-IQ3_M.gguf",
        "file_size": "86.0 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-IQ3_XS",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-IQ3_XS.gguf",
        "file_size": "84.1 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-IQ4_XS",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-IQ4_XS.gguf",
        "file_size": "86.7 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q2_K",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q2_K.gguf",
        "file_size": "84.1 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q2_K_L",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q2_K_L.gguf",
        "file_size": "84.1 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q3_K_L",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q3_K_L.gguf",
        "file_size": "93.0 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q3_K_M",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q3_K_M.gguf",
        "file_size": "89.2 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q3_K_S",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q3_K_S.gguf",
        "file_size": "84.1 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q3_K_XL.gguf",
        "file_size": "93.0 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q4_0",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q4_0.gguf",
        "file_size": "87.6 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q4_0_4_4",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q4_0_4_4.gguf",
        "file_size": "87.5 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q4_0_4_8",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q4_0_4_8.gguf",
        "file_size": "87.5 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q4_0_8_8",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q4_0_8_8.gguf",
        "file_size": "87.5 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q4_K_L",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q4_K_L.gguf",
        "file_size": "100.6 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q4_K_M",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q4_K_M.gguf",
        "file_size": "100.6 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q4_K_S",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q4_K_S.gguf",
        "file_size": "97.3 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q5_K_L",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q5_K_L.gguf",
        "file_size": "106.9 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q5_K_M",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q5_K_M.gguf",
        "file_size": "106.9 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q5_K_S",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q5_K_S.gguf",
        "file_size": "104.9 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q6_K",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q6_K.gguf",
        "file_size": "132.0 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q6_K_L",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q6_K_L.gguf",
        "file_size": "132.0 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-Q8_0",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q8_0.gguf",
        "file_size": "138.1 MB"
      },
      {
        "model_id": "SmolLM2-135M-Instruct-f16",
        "path": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-f16.gguf",
        "file_size": "258.3 MB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "SmolLM3-3B-128K-GGUF",
    "developer": "unsloth",
    "downloads": 5540,
    "createdAt": "2025-07-08T23:13:59.000Z",
    "num_quants": 24,
    "quants": [
      {
        "model_id": "SmolLM3-3B-128K-BF16",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-BF16.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-IQ4_NL",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-IQ4_NL.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-IQ4_XS",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-IQ4_XS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-Q2_K",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-Q2_K.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-Q2_K_L",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-Q2_K_L.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-Q3_K_M",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-Q3_K_M.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-Q3_K_S",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-Q3_K_S.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-Q4_0",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-Q4_0.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-Q4_1",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-Q4_1.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-Q4_K_M",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-Q4_K_M.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-Q4_K_S",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-Q4_K_S.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-Q5_K_M",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-Q5_K_M.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-Q5_K_S",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-Q5_K_S.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-Q6_K",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-Q6_K.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-Q8_0",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-Q8_0.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-UD-IQ2_M.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-UD-IQ2_XXS.gguf",
        "file_size": "910.9 MB"
      },
      {
        "model_id": "SmolLM3-3B-128K-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-UD-IQ3_XXS.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-UD-Q2_K_XL.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-UD-Q3_K_XL.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-UD-Q4_K_XL.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-UD-Q5_K_XL.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-UD-Q6_K_XL.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "SmolLM3-3B-128K-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/SmolLM3-3B-128K-UD-Q8_K_XL.gguf",
        "file_size": "3.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/SmolLM3-3B-128K-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "SmolLM3-3B-GGUF",
    "developer": "ggml-org",
    "downloads": 12149,
    "createdAt": "2025-07-08T12:36:39.000Z",
    "tools": true,
    "num_quants": 3,
    "quants": [
      {
        "model_id": "SmolLM3-Q4_K_M",
        "path": "https://huggingface.co/ggml-org/SmolLM3-3B-GGUF/resolve/main/SmolLM3-Q4_K_M.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "SmolLM3-Q8_0",
        "path": "https://huggingface.co/ggml-org/SmolLM3-3B-GGUF/resolve/main/SmolLM3-Q8_0.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "SmolLM3-f16",
        "path": "https://huggingface.co/ggml-org/SmolLM3-3B-GGUF/resolve/main/SmolLM3-f16.gguf",
        "file_size": "5.7 GB"
      }
    ],
    "readme": "https://huggingface.co/ggml-org/SmolLM3-3B-GGUF/resolve/main/README.md",
    "description": "SmolLM3-GGUF is a 3B parameter multilingual language model with advanced reasoning and long context capabilities, trained on 11.2T tokens and optimized for hybrid reasoning, available under the Apache 2.0 license."
  },
  {
    "model_name": "SmolLM3-3B-GGUF",
    "developer": "unsloth",
    "downloads": 11552,
    "createdAt": "2025-07-08T22:00:38.000Z",
    "num_quants": 24,
    "quants": [
      {
        "model_id": "SmolLM3-3B-BF16",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-BF16.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "SmolLM3-3B-IQ4_NL",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-IQ4_NL.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "SmolLM3-3B-IQ4_XS",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-IQ4_XS.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "SmolLM3-3B-Q2_K",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-Q2_K.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "SmolLM3-3B-Q2_K_L",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-Q2_K_L.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "SmolLM3-3B-Q3_K_M",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-Q3_K_M.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "SmolLM3-3B-Q3_K_S",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-Q3_K_S.gguf",
        "file_size": "1.3 GB"
      },
      {
        "model_id": "SmolLM3-3B-Q4_0",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-Q4_0.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "SmolLM3-3B-Q4_1",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-Q4_1.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "SmolLM3-3B-Q4_K_M",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-Q4_K_M.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "SmolLM3-3B-Q4_K_S",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-Q4_K_S.gguf",
        "file_size": "1.7 GB"
      },
      {
        "model_id": "SmolLM3-3B-Q5_K_M",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-Q5_K_M.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "SmolLM3-3B-Q5_K_S",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-Q5_K_S.gguf",
        "file_size": "2.0 GB"
      },
      {
        "model_id": "SmolLM3-3B-Q6_K",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-Q6_K.gguf",
        "file_size": "2.4 GB"
      },
      {
        "model_id": "SmolLM3-3B-Q8_0",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-Q8_0.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "SmolLM3-3B-UD-IQ2_M",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-UD-IQ2_M.gguf",
        "file_size": "1.1 GB"
      },
      {
        "model_id": "SmolLM3-3B-UD-IQ2_XXS",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-UD-IQ2_XXS.gguf",
        "file_size": "910.9 MB"
      },
      {
        "model_id": "SmolLM3-3B-UD-IQ3_XXS",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-UD-IQ3_XXS.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "SmolLM3-3B-UD-Q2_K_XL",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-UD-Q2_K_XL.gguf",
        "file_size": "1.2 GB"
      },
      {
        "model_id": "SmolLM3-3B-UD-Q3_K_XL",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-UD-Q3_K_XL.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "SmolLM3-3B-UD-Q4_K_XL",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-UD-Q4_K_XL.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "SmolLM3-3B-UD-Q5_K_XL",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-UD-Q5_K_XL.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "SmolLM3-3B-UD-Q6_K_XL",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-UD-Q6_K_XL.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "SmolLM3-3B-UD-Q8_K_XL",
        "path": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/SmolLM3-3B-UD-Q8_K_XL.gguf",
        "file_size": "3.6 GB"
      }
    ],
    "readme": "https://huggingface.co/unsloth/SmolLM3-3B-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "SmolVLM2-2.2B-Instruct-GGUF",
    "developer": "ggml-org",
    "downloads": 4136,
    "createdAt": "2025-04-21T19:03:24.000Z",
    "num_quants": 5,
    "quants": [
      {
        "model_id": "SmolVLM2-2.2B-Instruct-Q4_K_M",
        "path": "https://huggingface.co/ggml-org/SmolVLM2-2.2B-Instruct-GGUF/resolve/main/SmolVLM2-2.2B-Instruct-Q4_K_M.gguf",
        "file_size": "1.0 GB"
      },
      {
        "model_id": "SmolVLM2-2.2B-Instruct-Q8_0",
        "path": "https://huggingface.co/ggml-org/SmolVLM2-2.2B-Instruct-GGUF/resolve/main/SmolVLM2-2.2B-Instruct-Q8_0.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "SmolVLM2-2.2B-Instruct-f16",
        "path": "https://huggingface.co/ggml-org/SmolVLM2-2.2B-Instruct-GGUF/resolve/main/SmolVLM2-2.2B-Instruct-f16.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "mmproj-SmolVLM2-2.2B-Instruct-Q8_0",
        "path": "https://huggingface.co/ggml-org/SmolVLM2-2.2B-Instruct-GGUF/resolve/main/mmproj-SmolVLM2-2.2B-Instruct-Q8_0.gguf",
        "file_size": "565.1 MB"
      },
      {
        "model_id": "mmproj-SmolVLM2-2.2B-Instruct-f16",
        "path": "https://huggingface.co/ggml-org/SmolVLM2-2.2B-Instruct-GGUF/resolve/main/mmproj-SmolVLM2-2.2B-Instruct-f16.gguf",
        "file_size": "831.9 MB"
      }
    ],
    "readme": "https://huggingface.co/ggml-org/SmolVLM2-2.2B-Instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Snowpiercer-15B-v2-GGUF",
    "developer": "TheDrummer",
    "downloads": 1941,
    "createdAt": "2025-07-10T01:07:59.000Z",
    "num_quants": 6,
    "quants": [
      {
        "model_id": "Snowpiercer-15B-v1g-Q2_K",
        "path": "https://huggingface.co/TheDrummer/Snowpiercer-15B-v2-GGUF/resolve/main/Snowpiercer-15B-v1g-Q2_K.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "Snowpiercer-15B-v1g-Q3_K_M",
        "path": "https://huggingface.co/TheDrummer/Snowpiercer-15B-v2-GGUF/resolve/main/Snowpiercer-15B-v1g-Q3_K_M.gguf",
        "file_size": "6.9 GB"
      },
      {
        "model_id": "Snowpiercer-15B-v1g-Q4_K_M",
        "path": "https://huggingface.co/TheDrummer/Snowpiercer-15B-v2-GGUF/resolve/main/Snowpiercer-15B-v1g-Q4_K_M.gguf",
        "file_size": "8.5 GB"
      },
      {
        "model_id": "Snowpiercer-15B-v1g-Q5_K_M",
        "path": "https://huggingface.co/TheDrummer/Snowpiercer-15B-v2-GGUF/resolve/main/Snowpiercer-15B-v1g-Q5_K_M.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "Snowpiercer-15B-v1g-Q6_K",
        "path": "https://huggingface.co/TheDrummer/Snowpiercer-15B-v2-GGUF/resolve/main/Snowpiercer-15B-v1g-Q6_K.gguf",
        "file_size": "11.4 GB"
      },
      {
        "model_id": "Snowpiercer-15B-v1g-Q8_0",
        "path": "https://huggingface.co/TheDrummer/Snowpiercer-15B-v2-GGUF/resolve/main/Snowpiercer-15B-v1g-Q8_0.gguf",
        "file_size": "14.8 GB"
      }
    ],
    "readme": "https://huggingface.co/TheDrummer/Snowpiercer-15B-v2-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Sorachio-1B-Chat",
    "developer": "IzzulGod",
    "downloads": 277,
    "createdAt": "2025-07-05T05:04:13.000Z",
    "num_quants": 2,
    "quants": [
      {
        "model_id": "sorachio-1b-chat-f16",
        "path": "https://huggingface.co/IzzulGod/Sorachio-1B-Chat/resolve/main/sorachio-1b-chat-f16.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "sorachio-1b-chat-q8_0",
        "path": "https://huggingface.co/IzzulGod/Sorachio-1B-Chat/resolve/main/sorachio-1b-chat-q8_0.gguf",
        "file_size": "1019.8 MB"
      }
    ],
    "readme": "https://huggingface.co/IzzulGod/Sorachio-1B-Chat/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "SpaceThinker-Qwen2.5VL-3B",
    "developer": "remyxai",
    "downloads": 6457,
    "createdAt": "2025-04-17T17:34:23.000Z",
    "num_quants": 2,
    "quants": [
      {
        "model_id": "gguf/spacethinker-qwen2.5VL-3B-F16",
        "path": "https://huggingface.co/remyxai/SpaceThinker-Qwen2.5VL-3B/resolve/main/gguf/spacethinker-qwen2.5VL-3B-F16.gguf",
        "file_size": "5.8 GB"
      },
      {
        "model_id": "gguf/spacethinker-qwen2.5vl-3b-vision",
        "path": "https://huggingface.co/remyxai/SpaceThinker-Qwen2.5VL-3B/resolve/main/gguf/spacethinker-qwen2.5vl-3b-vision.gguf",
        "file_size": "2.5 GB"
      }
    ],
    "readme": "https://huggingface.co/remyxai/SpaceThinker-Qwen2.5VL-3B/resolve/main/README.md",
    "description": "SpaceThinker-Qwen2.5VL-3B is a multimodal vision-language model trained to enhance spatial reasoning through test-time compute, achieving strong performance on various spatial reasoning benchmarks like SpatialScore and QSpatial-Bench with a focus on quantitative spatial tasks such as distance estimation and object relations.",
    "tools": true
  },
  {
    "model_name": "Spiral-Qwen3-4B-F32-GGUF",
    "developer": "prithivMLmods",
    "downloads": 516,
    "createdAt": "2025-07-05T12:11:00.000Z",
    "num_quants": 13,
    "quants": [
      {
        "model_id": "Spiral-Qwen3-4B.BF16",
        "path": "https://huggingface.co/prithivMLmods/Spiral-Qwen3-4B-F32-GGUF/resolve/main/Spiral-Qwen3-4B.BF16.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Spiral-Qwen3-4B.F16",
        "path": "https://huggingface.co/prithivMLmods/Spiral-Qwen3-4B-F32-GGUF/resolve/main/Spiral-Qwen3-4B.F16.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Spiral-Qwen3-4B.F32",
        "path": "https://huggingface.co/prithivMLmods/Spiral-Qwen3-4B-F32-GGUF/resolve/main/Spiral-Qwen3-4B.F32.gguf",
        "file_size": "15.0 GB"
      },
      {
        "model_id": "Spiral-Qwen3-4B.Q2_K",
        "path": "https://huggingface.co/prithivMLmods/Spiral-Qwen3-4B-F32-GGUF/resolve/main/Spiral-Qwen3-4B.Q2_K.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "Spiral-Qwen3-4B.Q3_K_L",
        "path": "https://huggingface.co/prithivMLmods/Spiral-Qwen3-4B-F32-GGUF/resolve/main/Spiral-Qwen3-4B.Q3_K_L.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Spiral-Qwen3-4B.Q3_K_M",
        "path": "https://huggingface.co/prithivMLmods/Spiral-Qwen3-4B-F32-GGUF/resolve/main/Spiral-Qwen3-4B.Q3_K_M.gguf",
        "file_size": "1.9 GB"
      },
      {
        "model_id": "Spiral-Qwen3-4B.Q3_K_S",
        "path": "https://huggingface.co/prithivMLmods/Spiral-Qwen3-4B-F32-GGUF/resolve/main/Spiral-Qwen3-4B.Q3_K_S.gguf",
        "file_size": "1.8 GB"
      },
      {
        "model_id": "Spiral-Qwen3-4B.Q4_K_M",
        "path": "https://huggingface.co/prithivMLmods/Spiral-Qwen3-4B-F32-GGUF/resolve/main/Spiral-Qwen3-4B.Q4_K_M.gguf",
        "file_size": "2.3 GB"
      },
      {
        "model_id": "Spiral-Qwen3-4B.Q4_K_S",
        "path": "https://huggingface.co/prithivMLmods/Spiral-Qwen3-4B-F32-GGUF/resolve/main/Spiral-Qwen3-4B.Q4_K_S.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Spiral-Qwen3-4B.Q5_K_M",
        "path": "https://huggingface.co/prithivMLmods/Spiral-Qwen3-4B-F32-GGUF/resolve/main/Spiral-Qwen3-4B.Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Spiral-Qwen3-4B.Q5_K_S",
        "path": "https://huggingface.co/prithivMLmods/Spiral-Qwen3-4B-F32-GGUF/resolve/main/Spiral-Qwen3-4B.Q5_K_S.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "Spiral-Qwen3-4B.Q6_K",
        "path": "https://huggingface.co/prithivMLmods/Spiral-Qwen3-4B-F32-GGUF/resolve/main/Spiral-Qwen3-4B.Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Spiral-Qwen3-4B.Q8_0",
        "path": "https://huggingface.co/prithivMLmods/Spiral-Qwen3-4B-F32-GGUF/resolve/main/Spiral-Qwen3-4B.Q8_0.gguf",
        "file_size": "4.0 GB"
      }
    ],
    "readme": "https://huggingface.co/prithivMLmods/Spiral-Qwen3-4B-F32-GGUF/resolve/main/README.md",
    "description": "",
    "tools": true
  },
  {
    "model_name": "T-pro-it-2.0-GGUF",
    "developer": "t-tech",
    "downloads": 31102,
    "createdAt": "2025-07-17T21:36:22.000Z",
    "tools": true,
    "num_quants": 14,
    "quants": [
      {
        "model_id": "T-pro-it-2.0-IQ3_XS",
        "path": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/T-pro-it-2.0-IQ3_XS.gguf",
        "file_size": "12.8 GB"
      },
      {
        "model_id": "T-pro-it-2.0-IQ4_NL",
        "path": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/T-pro-it-2.0-IQ4_NL.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "T-pro-it-2.0-IQ4_XS",
        "path": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/T-pro-it-2.0-IQ4_XS.gguf",
        "file_size": "16.6 GB"
      },
      {
        "model_id": "T-pro-it-2.0-Q2_K",
        "path": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/T-pro-it-2.0-Q2_K.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "T-pro-it-2.0-Q3_K_M",
        "path": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/T-pro-it-2.0-Q3_K_M.gguf",
        "file_size": "14.9 GB"
      },
      {
        "model_id": "T-pro-it-2.0-Q3_K_S",
        "path": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/T-pro-it-2.0-Q3_K_S.gguf",
        "file_size": "13.4 GB"
      },
      {
        "model_id": "T-pro-it-2.0-Q4_0",
        "path": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/T-pro-it-2.0-Q4_0.gguf",
        "file_size": "17.4 GB"
      },
      {
        "model_id": "T-pro-it-2.0-Q4_K_M",
        "path": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/T-pro-it-2.0-Q4_K_M.gguf",
        "file_size": "18.4 GB"
      },
      {
        "model_id": "T-pro-it-2.0-Q4_K_S",
        "path": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/T-pro-it-2.0-Q4_K_S.gguf",
        "file_size": "17.5 GB"
      },
      {
        "model_id": "T-pro-it-2.0-Q5_0",
        "path": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/T-pro-it-2.0-Q5_0.gguf",
        "file_size": "21.1 GB"
      },
      {
        "model_id": "T-pro-it-2.0-Q5_K_M",
        "path": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/T-pro-it-2.0-Q5_K_M.gguf",
        "file_size": "21.6 GB"
      },
      {
        "model_id": "T-pro-it-2.0-Q5_K_S",
        "path": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/T-pro-it-2.0-Q5_K_S.gguf",
        "file_size": "21.1 GB"
      },
      {
        "model_id": "T-pro-it-2.0-Q6_K",
        "path": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/T-pro-it-2.0-Q6_K.gguf",
        "file_size": "25.0 GB"
      },
      {
        "model_id": "T-pro-it-2.0-Q8_0",
        "path": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/T-pro-it-2.0-Q8_0.gguf",
        "file_size": "32.4 GB"
      }
    ],
    "readme": "https://huggingface.co/t-tech/T-pro-it-2.0-GGUF/resolve/main/README.md",
    "description": "This repository provides the T-pro-it-2.0 model in GGUF format for use with llama.cpp or Ollama, with various quantization options for different hardware requirements."
  },
  {
    "model_name": "TAIDE-LX-7B-Chat-4bit",
    "developer": "taide",
    "downloads": 18,
    "createdAt": "2024-04-15T03:28:54.000Z",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "taide-7b-a.2-q4_k_m",
        "path": "https://huggingface.co/taide/TAIDE-LX-7B-Chat-4bit/resolve/main/taide-7b-a.2-q4_k_m.gguf",
        "file_size": "3.9 GB"
      }
    ],
    "readme": "https://huggingface.co/taide/TAIDE-LX-7B-Chat-4bit/resolve/main/README.md",
    "description": "TAIDE-LX-7B-Chat 是以 LLaMA2-7B 為基礎，結合台灣繁體中文資料訓練而成的大型語言模型，提供多種任務支援，如寫文章、寫信、摘要、翻譯等，並需用戶同意"
  },
  {
    "model_name": "TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF",
    "developer": "bartowski",
    "downloads": 6544,
    "createdAt": "2025-07-09T16:53:47.000Z",
    "tools": false,
    "num_quants": 30,
    "quants": [
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-IQ2_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-IQ2_M.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-IQ2_S",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-IQ2_S.gguf",
        "file_size": "8.7 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-IQ2_XS",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-IQ2_XS.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-IQ2_XXS",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-IQ2_XXS.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-IQ3_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-IQ3_M.gguf",
        "file_size": "12.2 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-IQ3_XS",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-IQ3_XS.gguf",
        "file_size": "11.3 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-IQ3_XXS.gguf",
        "file_size": "10.5 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-IQ4_NL",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-IQ4_NL.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-IQ4_XS",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-IQ4_XS.gguf",
        "file_size": "14.5 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q2_K",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q2_K.gguf",
        "file_size": "10.2 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q2_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q2_K_L.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q3_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q3_K_L.gguf",
        "file_size": "14.1 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q3_K_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q3_K_M.gguf",
        "file_size": "13.1 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q3_K_S",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q3_K_S.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q3_K_XL.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q4_0",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q4_0.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q4_1",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q4_1.gguf",
        "file_size": "16.8 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q4_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q4_K_L.gguf",
        "file_size": "17.1 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q4_K_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q4_K_M.gguf",
        "file_size": "16.1 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q4_K_S",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q4_K_S.gguf",
        "file_size": "15.3 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q5_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q5_K_L.gguf",
        "file_size": "19.7 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q5_K_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q5_K_M.gguf",
        "file_size": "18.9 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q5_K_S",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q5_K_S.gguf",
        "file_size": "18.4 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q6_K",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q6_K.gguf",
        "file_size": "21.7 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q6_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q6_K_L.gguf",
        "file_size": "22.4 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-Q8_0",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-Q8_0.gguf",
        "file_size": "28.1 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-bf16/TheDrummer_Big-Tiger-Gemma-27B-v3-bf16-00001-of-00002",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-bf16/TheDrummer_Big-Tiger-Gemma-27B-v3-bf16-00001-of-00002.gguf",
        "file_size": "37.1 GB"
      },
      {
        "model_id": "TheDrummer_Big-Tiger-Gemma-27B-v3-bf16/TheDrummer_Big-Tiger-Gemma-27B-v3-bf16-00002-of-00002",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/TheDrummer_Big-Tiger-Gemma-27B-v3-bf16/TheDrummer_Big-Tiger-Gemma-27B-v3-bf16-00002-of-00002.gguf",
        "file_size": "15.8 GB"
      },
      {
        "model_id": "mmproj-TheDrummer_Big-Tiger-Gemma-27B-v3-bf16",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/mmproj-TheDrummer_Big-Tiger-Gemma-27B-v3-bf16.gguf",
        "file_size": "818.0 MB"
      },
      {
        "model_id": "mmproj-TheDrummer_Big-Tiger-Gemma-27B-v3-f16",
        "path": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/mmproj-TheDrummer_Big-Tiger-Gemma-27B-v3-f16.gguf",
        "file_size": "818.0 MB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/TheDrummer_Big-Tiger-Gemma-27B-v3-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Big-Tiger-Gemma-27B-v3 model by TheDrummer using llama.cpp's imatrix method, offering various quantization options for different performance and quality trade-offs."
  },
  {
    "model_name": "TheDrummer_Cydonia-24B-v4-GGUF",
    "developer": "bartowski",
    "downloads": 6095,
    "createdAt": "2025-07-18T17:30:25.000Z",
    "tools": false,
    "num_quants": 26,
    "quants": [
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-IQ2_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-IQ2_M.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-IQ2_S",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-IQ2_S.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-IQ2_XS",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-IQ2_XS.gguf",
        "file_size": "6.7 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-IQ3_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-IQ3_M.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-IQ3_XS",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-IQ3_XS.gguf",
        "file_size": "9.2 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-IQ3_XXS.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-IQ4_NL",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-IQ4_NL.gguf",
        "file_size": "12.5 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-IQ4_XS",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-IQ4_XS.gguf",
        "file_size": "11.9 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q2_K",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q2_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q2_K_L.gguf",
        "file_size": "8.9 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q3_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q3_K_L.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q3_K_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q3_K_S",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q3_K_XL.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q4_0",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q4_0.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q4_1",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q4_1.gguf",
        "file_size": "13.9 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q4_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q4_K_L.gguf",
        "file_size": "13.8 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q4_K_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q4_K_S",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q5_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q5_K_L.gguf",
        "file_size": "16.0 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q5_K_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q5_K_S",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q6_K",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q6_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q6_K_L.gguf",
        "file_size": "18.3 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-Q8_0",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-Q8_0.gguf",
        "file_size": "23.3 GB"
      },
      {
        "model_id": "TheDrummer_Cydonia-24B-v4-bf16",
        "path": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-24B-v4-bf16.gguf",
        "file_size": "43.9 GB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/TheDrummer_Cydonia-24B-v4-GGUF/resolve/main/README.md",
    "description": "This is a quantized version of the Cydonia-24B-v4 model using llama.cpp's imatrix method, offering various quantization types for different performance and memory trade-offs."
  },
  {
    "model_name": "TheDrummer_Tiger-Gemma-12B-v3-GGUF",
    "developer": "bartowski",
    "downloads": 2762,
    "createdAt": "2025-07-09T16:53:33.000Z",
    "num_quants": 27,
    "quants": [
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-IQ2_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-IQ2_M.gguf",
        "file_size": "4.4 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-IQ2_S",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-IQ2_S.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-IQ3_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-IQ3_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-IQ3_XS",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-IQ3_XS.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-IQ3_XXS",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-IQ3_XXS.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-IQ4_NL",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-IQ4_NL.gguf",
        "file_size": "6.9 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-IQ4_XS",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-IQ4_XS.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q2_K",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q2_K.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q2_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q2_K_L.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q3_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q3_K_L.gguf",
        "file_size": "6.4 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q3_K_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q3_K_M.gguf",
        "file_size": "6.0 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q3_K_S",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q3_K_S.gguf",
        "file_size": "5.5 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q3_K_XL",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q3_K_XL.gguf",
        "file_size": "7.3 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q4_0",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q4_0.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q4_1",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q4_1.gguf",
        "file_size": "7.6 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q4_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q4_K_L.gguf",
        "file_size": "8.0 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q4_K_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q4_K_M.gguf",
        "file_size": "7.3 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q4_K_S",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q4_K_S.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q5_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q5_K_L.gguf",
        "file_size": "9.1 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q5_K_M",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q5_K_M.gguf",
        "file_size": "8.5 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q5_K_S",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q5_K_S.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q6_K",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q6_K.gguf",
        "file_size": "9.8 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q6_K_L",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q6_K_L.gguf",
        "file_size": "10.2 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-Q8_0",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-Q8_0.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "TheDrummer_Tiger-Gemma-12B-v3-bf16",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/TheDrummer_Tiger-Gemma-12B-v3-bf16.gguf",
        "file_size": "23.8 GB"
      },
      {
        "model_id": "mmproj-TheDrummer_Tiger-Gemma-12B-v3-bf16",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/mmproj-TheDrummer_Tiger-Gemma-12B-v3-bf16.gguf",
        "file_size": "814.6 MB"
      },
      {
        "model_id": "mmproj-TheDrummer_Tiger-Gemma-12B-v3-f16",
        "path": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/mmproj-TheDrummer_Tiger-Gemma-12B-v3-f16.gguf",
        "file_size": "814.6 MB"
      }
    ],
    "readme": "https://huggingface.co/bartowski/TheDrummer_Tiger-Gemma-12B-v3-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8",
    "developer": "ValueFX9507",
    "downloads": 4286,
    "createdAt": "2025-02-15T13:30:54.000Z",
    "num_quants": 7,
    "quants": [
      {
        "model_id": "Tifa-DeepsexV2-7b-0218-Q8",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/Tifa-DeepsexV2-7b-0218-Q8.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Tifa-DeepsexV2-7b-Cot-0222-Q8",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/Tifa-DeepsexV2-7b-Cot-0222-Q8.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Tifa-DeepsexV2-7b-Cot-0301-Q8",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/Tifa-DeepsexV2-7b-Cot-0301-Q8.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Tifa-DeepsexV2-7b-NoCot-0222-Q8",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/Tifa-DeepsexV2-7b-NoCot-0222-Q8.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Tifa-DeepsexV2-7b-NoCot-0228-Q8",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/Tifa-DeepsexV2-7b-NoCot-0228-Q8.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Tifa-DeepsexV2-7b-NoCot-0325-Q8",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/Tifa-DeepsexV2-7b-NoCot-0325-Q8.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Tifa-DeepsexV2-7b-Q8",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/Tifa-DeepsexV2-7b-Q8.gguf",
        "file_size": "7.5 GB"
      }
    ],
    "readme": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Tifa-DeepsexV3-14b-GGUF-Q6",
    "developer": "ValueFX9507",
    "downloads": 3995,
    "createdAt": "2025-06-26T10:15:21.000Z",
    "num_quants": 1,
    "quants": [
      {
        "model_id": "Tifa-DeepsexV3-14b-Chat-NoCot-0626-Q6",
        "path": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV3-14b-GGUF-Q6/resolve/main/Tifa-DeepsexV3-14b-Chat-NoCot-0626-Q6.gguf",
        "file_size": "11.3 GB"
      }
    ],
    "readme": "https://huggingface.co/ValueFX9507/Tifa-DeepsexV3-14b-GGUF-Q6/resolve/main/README.md",
    "description": "Tifa-DeepSexV3-14b 是基于 Qwen14b 的深度优化模型，支持长文生成、超长关联、控制器调节输出风格和字数，并能避免负面词汇，适用于角色扮演和多种文本生成任务。",
    "tools": true
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0-GGUF",
    "developer": "TheBloke",
    "downloads": 69977,
    "createdAt": "2023-12-31T20:53:43.000Z",
    "tools": false,
    "num_quants": 12,
    "quants": [
      {
        "model_id": "tinyllama-1.1b-chat-v1.0.Q2_K",
        "path": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q2_K.gguf",
        "file_size": "460.7 MB"
      },
      {
        "model_id": "tinyllama-1.1b-chat-v1.0.Q3_K_L",
        "path": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q3_K_L.gguf",
        "file_size": "565.1 MB"
      },
      {
        "model_id": "tinyllama-1.1b-chat-v1.0.Q3_K_M",
        "path": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q3_K_M.gguf",
        "file_size": "525.3 MB"
      },
      {
        "model_id": "tinyllama-1.1b-chat-v1.0.Q3_K_S",
        "path": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q3_K_S.gguf",
        "file_size": "477.1 MB"
      },
      {
        "model_id": "tinyllama-1.1b-chat-v1.0.Q4_0",
        "path": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_0.gguf",
        "file_size": "608.2 MB"
      },
      {
        "model_id": "tinyllama-1.1b-chat-v1.0.Q4_K_M",
        "path": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "file_size": "637.8 MB"
      },
      {
        "model_id": "tinyllama-1.1b-chat-v1.0.Q4_K_S",
        "path": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_S.gguf",
        "file_size": "613.9 MB"
      },
      {
        "model_id": "tinyllama-1.1b-chat-v1.0.Q5_0",
        "path": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q5_0.gguf",
        "file_size": "731.5 MB"
      },
      {
        "model_id": "tinyllama-1.1b-chat-v1.0.Q5_K_M",
        "path": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q5_K_M.gguf",
        "file_size": "746.7 MB"
      },
      {
        "model_id": "tinyllama-1.1b-chat-v1.0.Q5_K_S",
        "path": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q5_K_S.gguf",
        "file_size": "731.5 MB"
      },
      {
        "model_id": "tinyllama-1.1b-chat-v1.0.Q6_K",
        "path": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q6_K.gguf",
        "file_size": "862.5 MB"
      },
      {
        "model_id": "tinyllama-1.1b-chat-v1.0.Q8_0",
        "path": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q8_0.gguf",
        "file_size": "1.1 GB"
      }
    ],
    "readme": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/README.md",
    "description": "This repository provides GGUF format quantized versions of the TinyLlama 1.1B Chat v1.0 model for efficient GPU inference, with various quantization options and compatibility with multiple frameworks like llama.cpp, text-generation-webui, and llama-cpp-python."
  },
  {
    "model_name": "Triplex",
    "developer": "SciPhi",
    "downloads": 1870,
    "createdAt": "2024-07-10T21:58:18.000Z",
    "tools": false,
    "num_quants": 1,
    "quants": [
      {
        "model_id": "quantized_model-Q4_K_M",
        "path": "https://huggingface.co/SciPhi/Triplex/resolve/main/quantized_model-Q4_K_M.gguf",
        "file_size": "2.2 GB"
      }
    ],
    "readme": "https://huggingface.co/SciPhi/Triplex/resolve/main/README.md",
    "description": "Triplex is a state-of-the-art LLM for knowledge graph construction that reduces costs by 98% and enables efficient local graph building from unstructured data."
  },
  {
    "model_name": "UIGEN-X-8B-GGUF",
    "developer": "mradermacher",
    "downloads": 546,
    "createdAt": "2025-07-19T03:26:18.000Z",
    "tools": true,
    "num_quants": 12,
    "quants": [
      {
        "model_id": "UIGEN-X-8B.IQ4_XS",
        "path": "https://huggingface.co/mradermacher/UIGEN-X-8B-GGUF/resolve/main/UIGEN-X-8B.IQ4_XS.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "UIGEN-X-8B.Q2_K",
        "path": "https://huggingface.co/mradermacher/UIGEN-X-8B-GGUF/resolve/main/UIGEN-X-8B.Q2_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "UIGEN-X-8B.Q3_K_L",
        "path": "https://huggingface.co/mradermacher/UIGEN-X-8B-GGUF/resolve/main/UIGEN-X-8B.Q3_K_L.gguf",
        "file_size": "4.1 GB"
      },
      {
        "model_id": "UIGEN-X-8B.Q3_K_M",
        "path": "https://huggingface.co/mradermacher/UIGEN-X-8B-GGUF/resolve/main/UIGEN-X-8B.Q3_K_M.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "UIGEN-X-8B.Q3_K_S",
        "path": "https://huggingface.co/mradermacher/UIGEN-X-8B-GGUF/resolve/main/UIGEN-X-8B.Q3_K_S.gguf",
        "file_size": "3.5 GB"
      },
      {
        "model_id": "UIGEN-X-8B.Q4_K_M",
        "path": "https://huggingface.co/mradermacher/UIGEN-X-8B-GGUF/resolve/main/UIGEN-X-8B.Q4_K_M.gguf",
        "file_size": "4.7 GB"
      },
      {
        "model_id": "UIGEN-X-8B.Q4_K_S",
        "path": "https://huggingface.co/mradermacher/UIGEN-X-8B-GGUF/resolve/main/UIGEN-X-8B.Q4_K_S.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "UIGEN-X-8B.Q5_K_M",
        "path": "https://huggingface.co/mradermacher/UIGEN-X-8B-GGUF/resolve/main/UIGEN-X-8B.Q5_K_M.gguf",
        "file_size": "5.4 GB"
      },
      {
        "model_id": "UIGEN-X-8B.Q5_K_S",
        "path": "https://huggingface.co/mradermacher/UIGEN-X-8B-GGUF/resolve/main/UIGEN-X-8B.Q5_K_S.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "UIGEN-X-8B.Q6_K",
        "path": "https://huggingface.co/mradermacher/UIGEN-X-8B-GGUF/resolve/main/UIGEN-X-8B.Q6_K.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "UIGEN-X-8B.Q8_0",
        "path": "https://huggingface.co/mradermacher/UIGEN-X-8B-GGUF/resolve/main/UIGEN-X-8B.Q8_0.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "UIGEN-X-8B.f16",
        "path": "https://huggingface.co/mradermacher/UIGEN-X-8B-GGUF/resolve/main/UIGEN-X-8B.f16.gguf",
        "file_size": "15.3 GB"
      }
    ],
    "readme": "https://huggingface.co/mradermacher/UIGEN-X-8B-GGUF/resolve/main/README.md",
    "description": "The model is a quantized version of the Tesslate/UIGEN-X-8B base model, optimized for text generation and hybrid thinking with various GGUF quantization types available."
  },
  {
    "model_name": "Violet_Twilight-v0.2-GGUF",
    "developer": "Epiculous",
    "downloads": 93100,
    "createdAt": "2024-09-13T13:19:21.000Z",
    "num_quants": 20,
    "quants": [
      {
        "model_id": "Violet_Twilight-v0.2.IQ1_S",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.IQ1_S.gguf",
        "file_size": "2.8 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.IQ2_XS",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.IQ2_XS.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.IQ2_XXS",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.IQ2_XXS.gguf",
        "file_size": "3.3 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.IQ3_XS",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.IQ3_XS.gguf",
        "file_size": "4.9 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.IQ3_XXS",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.IQ3_XXS.gguf",
        "file_size": "4.6 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.IQ4_NL",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.IQ4_NL.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.IQ4_XS",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.IQ4_XS.gguf",
        "file_size": "6.3 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.Q3_K_L",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.Q3_K_L.gguf",
        "file_size": "6.1 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.Q3_K_M",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.Q3_K_M.gguf",
        "file_size": "5.7 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.Q3_K_S",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.Q3_K_S.gguf",
        "file_size": "5.2 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.Q4_K_M",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.Q4_K_M.gguf",
        "file_size": "7.0 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.Q4_K_S",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.Q4_K_S.gguf",
        "file_size": "6.6 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.Q5_1",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.Q5_1.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.Q5_K_M",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.Q5_K_M.gguf",
        "file_size": "8.1 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.Q5_K_S",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.Q5_K_S.gguf",
        "file_size": "7.9 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.Q6_K",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.Q6_K.gguf",
        "file_size": "9.4 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.Q8_0",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.Q8_0.gguf",
        "file_size": "12.1 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.bf16",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.bf16.gguf",
        "file_size": "22.8 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.f16",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.f16.gguf",
        "file_size": "22.8 GB"
      },
      {
        "model_id": "Violet_Twilight-v0.2.f32",
        "path": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/Violet_Twilight-v0.2.f32.gguf",
        "file_size": "45.6 GB"
      }
    ],
    "readme": "https://huggingface.co/Epiculous/Violet_Twilight-v0.2-GGUF/resolve/main/README.md",
    "description": "The Violet_Twilight-v0.2 model is a SLERP merge of Azure_Dusk-v0.2 and Crimson_Dawn-v0.2, trained on ChatML with support for gguf quantization.",
    "tools": false
  },
  {
    "model_name": "Voxtral-3B-But-4B-Text-Only-GGUF",
    "developer": "SaisExperiments",
    "downloads": 2574,
    "createdAt": "2025-07-16T08:55:59.000Z",
    "tools": true,
    "num_quants": 7,
    "quants": [
      {
        "model_id": "Voxtral-3B-But-4B-Text-Only-F16",
        "path": "https://huggingface.co/SaisExperiments/Voxtral-3B-But-4B-Text-Only-GGUF/resolve/main/Voxtral-3B-But-4B-Text-Only-F16.gguf",
        "file_size": "7.5 GB"
      },
      {
        "model_id": "Voxtral-3B-But-4B-Text-Only-IQ4_NL",
        "path": "https://huggingface.co/SaisExperiments/Voxtral-3B-But-4B-Text-Only-GGUF/resolve/main/Voxtral-3B-But-4B-Text-Only-IQ4_NL.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Voxtral-3B-But-4B-Text-Only-IQ4_XS",
        "path": "https://huggingface.co/SaisExperiments/Voxtral-3B-But-4B-Text-Only-GGUF/resolve/main/Voxtral-3B-But-4B-Text-Only-IQ4_XS.gguf",
        "file_size": "2.1 GB"
      },
      {
        "model_id": "Voxtral-3B-But-4B-Text-Only-Q4_0",
        "path": "https://huggingface.co/SaisExperiments/Voxtral-3B-But-4B-Text-Only-GGUF/resolve/main/Voxtral-3B-But-4B-Text-Only-Q4_0.gguf",
        "file_size": "2.2 GB"
      },
      {
        "model_id": "Voxtral-3B-But-4B-Text-Only-Q5_K_M",
        "path": "https://huggingface.co/SaisExperiments/Voxtral-3B-But-4B-Text-Only-GGUF/resolve/main/Voxtral-3B-But-4B-Text-Only-Q5_K_M.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "Voxtral-3B-But-4B-Text-Only-Q6_K",
        "path": "https://huggingface.co/SaisExperiments/Voxtral-3B-But-4B-Text-Only-GGUF/resolve/main/Voxtral-3B-But-4B-Text-Only-Q6_K.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "Voxtral-3B-But-4B-Text-Only-Q8_0",
        "path": "https://huggingface.co/SaisExperiments/Voxtral-3B-But-4B-Text-Only-GGUF/resolve/main/Voxtral-3B-But-4B-Text-Only-Q8_0.gguf",
        "file_size": "4.0 GB"
      }
    ],
    "readme": "https://huggingface.co/SaisExperiments/Voxtral-3B-But-4B-Text-Only-GGUF/resolve/main/README.md",
    "description": "This model is a quantized version of the Mistral AI Voxtral-Mini-3B-2507 base model, with Whisper layers removed and mixed with MiniStral configurations, resulting in a 4B text-only model."
  },
  {
    "model_name": "WiNGPT-Babel-2-GGUF",
    "developer": "winninghealth",
    "downloads": 363,
    "createdAt": "2025-06-11T06:11:04.000Z",
    "tools": false,
    "num_quants": 3,
    "quants": [
      {
        "model_id": "WiNGPT-Babel-2-IQ4_XS",
        "path": "https://huggingface.co/winninghealth/WiNGPT-Babel-2-GGUF/resolve/main/WiNGPT-Babel-2-IQ4_XS.gguf",
        "file_size": "1.5 GB"
      },
      {
        "model_id": "WiNGPT-Babel-2-Q4_K_M",
        "path": "https://huggingface.co/winninghealth/WiNGPT-Babel-2-GGUF/resolve/main/WiNGPT-Babel-2-Q4_K_M.gguf",
        "file_size": "1.6 GB"
      },
      {
        "model_id": "WiNGPT-Babel-2-Q8_0",
        "path": "https://huggingface.co/winninghealth/WiNGPT-Babel-2-GGUF/resolve/main/WiNGPT-Babel-2-Q8_0.gguf",
        "file_size": "2.6 GB"
      }
    ],
    "readme": "https://huggingface.co/winninghealth/WiNGPT-Babel-2-GGUF/resolve/main/README.md",
    "description": "WiNGPT-Babel-2 is a multilingual translation language model optimized for 55 languages, enhanced Chinese translation, and structured data handling, built on the GemmaX2-28-2B-Pretrain base model."
  },
  {
    "model_name": "WizardLM-7B-uncensored-GGUF",
    "developer": "TheBloke",
    "downloads": 5366,
    "createdAt": "2023-09-19T23:17:28.000Z",
    "num_quants": 12,
    "quants": [
      {
        "model_id": "WizardLM-7B-uncensored.Q2_K",
        "path": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGUF/resolve/main/WizardLM-7B-uncensored.Q2_K.gguf",
        "file_size": "2.6 GB"
      },
      {
        "model_id": "WizardLM-7B-uncensored.Q3_K_L",
        "path": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGUF/resolve/main/WizardLM-7B-uncensored.Q3_K_L.gguf",
        "file_size": "3.4 GB"
      },
      {
        "model_id": "WizardLM-7B-uncensored.Q3_K_M",
        "path": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGUF/resolve/main/WizardLM-7B-uncensored.Q3_K_M.gguf",
        "file_size": "3.1 GB"
      },
      {
        "model_id": "WizardLM-7B-uncensored.Q3_K_S",
        "path": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGUF/resolve/main/WizardLM-7B-uncensored.Q3_K_S.gguf",
        "file_size": "2.7 GB"
      },
      {
        "model_id": "WizardLM-7B-uncensored.Q4_0",
        "path": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGUF/resolve/main/WizardLM-7B-uncensored.Q4_0.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "WizardLM-7B-uncensored.Q4_K_M",
        "path": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGUF/resolve/main/WizardLM-7B-uncensored.Q4_K_M.gguf",
        "file_size": "3.8 GB"
      },
      {
        "model_id": "WizardLM-7B-uncensored.Q4_K_S",
        "path": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGUF/resolve/main/WizardLM-7B-uncensored.Q4_K_S.gguf",
        "file_size": "3.6 GB"
      },
      {
        "model_id": "WizardLM-7B-uncensored.Q5_0",
        "path": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGUF/resolve/main/WizardLM-7B-uncensored.Q5_0.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "WizardLM-7B-uncensored.Q5_K_M",
        "path": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGUF/resolve/main/WizardLM-7B-uncensored.Q5_K_M.gguf",
        "file_size": "4.5 GB"
      },
      {
        "model_id": "WizardLM-7B-uncensored.Q5_K_S",
        "path": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGUF/resolve/main/WizardLM-7B-uncensored.Q5_K_S.gguf",
        "file_size": "4.3 GB"
      },
      {
        "model_id": "WizardLM-7B-uncensored.Q6_K",
        "path": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGUF/resolve/main/WizardLM-7B-uncensored.Q6_K.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "WizardLM-7B-uncensored.Q8_0",
        "path": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGUF/resolve/main/WizardLM-7B-uncensored.Q8_0.gguf",
        "file_size": "6.7 GB"
      }
    ],
    "readme": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "XortronCriminalComputingConfig-GGUF",
    "developer": "mradermacher",
    "downloads": 1618,
    "createdAt": "2025-05-05T05:05:00.000Z",
    "num_quants": 11,
    "quants": [
      {
        "model_id": "XortronCriminalComputingConfig.IQ4_XS",
        "path": "https://huggingface.co/mradermacher/XortronCriminalComputingConfig-GGUF/resolve/main/XortronCriminalComputingConfig.IQ4_XS.gguf",
        "file_size": "12.0 GB"
      },
      {
        "model_id": "XortronCriminalComputingConfig.Q2_K",
        "path": "https://huggingface.co/mradermacher/XortronCriminalComputingConfig-GGUF/resolve/main/XortronCriminalComputingConfig.Q2_K.gguf",
        "file_size": "8.3 GB"
      },
      {
        "model_id": "XortronCriminalComputingConfig.Q3_K_L",
        "path": "https://huggingface.co/mradermacher/XortronCriminalComputingConfig-GGUF/resolve/main/XortronCriminalComputingConfig.Q3_K_L.gguf",
        "file_size": "11.5 GB"
      },
      {
        "model_id": "XortronCriminalComputingConfig.Q3_K_M",
        "path": "https://huggingface.co/mradermacher/XortronCriminalComputingConfig-GGUF/resolve/main/XortronCriminalComputingConfig.Q3_K_M.gguf",
        "file_size": "10.7 GB"
      },
      {
        "model_id": "XortronCriminalComputingConfig.Q3_K_S",
        "path": "https://huggingface.co/mradermacher/XortronCriminalComputingConfig-GGUF/resolve/main/XortronCriminalComputingConfig.Q3_K_S.gguf",
        "file_size": "9.7 GB"
      },
      {
        "model_id": "XortronCriminalComputingConfig.Q4_K_M",
        "path": "https://huggingface.co/mradermacher/XortronCriminalComputingConfig-GGUF/resolve/main/XortronCriminalComputingConfig.Q4_K_M.gguf",
        "file_size": "13.3 GB"
      },
      {
        "model_id": "XortronCriminalComputingConfig.Q4_K_S",
        "path": "https://huggingface.co/mradermacher/XortronCriminalComputingConfig-GGUF/resolve/main/XortronCriminalComputingConfig.Q4_K_S.gguf",
        "file_size": "12.6 GB"
      },
      {
        "model_id": "XortronCriminalComputingConfig.Q5_K_M",
        "path": "https://huggingface.co/mradermacher/XortronCriminalComputingConfig-GGUF/resolve/main/XortronCriminalComputingConfig.Q5_K_M.gguf",
        "file_size": "15.6 GB"
      },
      {
        "model_id": "XortronCriminalComputingConfig.Q5_K_S",
        "path": "https://huggingface.co/mradermacher/XortronCriminalComputingConfig-GGUF/resolve/main/XortronCriminalComputingConfig.Q5_K_S.gguf",
        "file_size": "15.2 GB"
      },
      {
        "model_id": "XortronCriminalComputingConfig.Q6_K",
        "path": "https://huggingface.co/mradermacher/XortronCriminalComputingConfig-GGUF/resolve/main/XortronCriminalComputingConfig.Q6_K.gguf",
        "file_size": "18.0 GB"
      },
      {
        "model_id": "XortronCriminalComputingConfig.Q8_0",
        "path": "https://huggingface.co/mradermacher/XortronCriminalComputingConfig-GGUF/resolve/main/XortronCriminalComputingConfig.Q8_0.gguf",
        "file_size": "23.3 GB"
      }
    ],
    "readme": "https://huggingface.co/mradermacher/XortronCriminalComputingConfig-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  },
  {
    "model_name": "Xwin-LM-13B-v0.2-GGUF",
    "developer": "TheBloke",
    "downloads": 1458,
    "createdAt": "2023-10-15T00:54:23.000Z",
    "num_quants": 12,
    "quants": [
      {
        "model_id": "xwin-lm-13b-v0.2.Q2_K",
        "path": "https://huggingface.co/TheBloke/Xwin-LM-13B-v0.2-GGUF/resolve/main/xwin-lm-13b-v0.2.Q2_K.gguf",
        "file_size": "5.1 GB"
      },
      {
        "model_id": "xwin-lm-13b-v0.2.Q3_K_L",
        "path": "https://huggingface.co/TheBloke/Xwin-LM-13B-v0.2-GGUF/resolve/main/xwin-lm-13b-v0.2.Q3_K_L.gguf",
        "file_size": "6.5 GB"
      },
      {
        "model_id": "xwin-lm-13b-v0.2.Q3_K_M",
        "path": "https://huggingface.co/TheBloke/Xwin-LM-13B-v0.2-GGUF/resolve/main/xwin-lm-13b-v0.2.Q3_K_M.gguf",
        "file_size": "5.9 GB"
      },
      {
        "model_id": "xwin-lm-13b-v0.2.Q3_K_S",
        "path": "https://huggingface.co/TheBloke/Xwin-LM-13B-v0.2-GGUF/resolve/main/xwin-lm-13b-v0.2.Q3_K_S.gguf",
        "file_size": "5.3 GB"
      },
      {
        "model_id": "xwin-lm-13b-v0.2.Q4_0",
        "path": "https://huggingface.co/TheBloke/Xwin-LM-13B-v0.2-GGUF/resolve/main/xwin-lm-13b-v0.2.Q4_0.gguf",
        "file_size": "6.9 GB"
      },
      {
        "model_id": "xwin-lm-13b-v0.2.Q4_K_M",
        "path": "https://huggingface.co/TheBloke/Xwin-LM-13B-v0.2-GGUF/resolve/main/xwin-lm-13b-v0.2.Q4_K_M.gguf",
        "file_size": "7.3 GB"
      },
      {
        "model_id": "xwin-lm-13b-v0.2.Q4_K_S",
        "path": "https://huggingface.co/TheBloke/Xwin-LM-13B-v0.2-GGUF/resolve/main/xwin-lm-13b-v0.2.Q4_K_S.gguf",
        "file_size": "6.9 GB"
      },
      {
        "model_id": "xwin-lm-13b-v0.2.Q5_0",
        "path": "https://huggingface.co/TheBloke/Xwin-LM-13B-v0.2-GGUF/resolve/main/xwin-lm-13b-v0.2.Q5_0.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "xwin-lm-13b-v0.2.Q5_K_M",
        "path": "https://huggingface.co/TheBloke/Xwin-LM-13B-v0.2-GGUF/resolve/main/xwin-lm-13b-v0.2.Q5_K_M.gguf",
        "file_size": "8.6 GB"
      },
      {
        "model_id": "xwin-lm-13b-v0.2.Q5_K_S",
        "path": "https://huggingface.co/TheBloke/Xwin-LM-13B-v0.2-GGUF/resolve/main/xwin-lm-13b-v0.2.Q5_K_S.gguf",
        "file_size": "8.4 GB"
      },
      {
        "model_id": "xwin-lm-13b-v0.2.Q6_K",
        "path": "https://huggingface.co/TheBloke/Xwin-LM-13B-v0.2-GGUF/resolve/main/xwin-lm-13b-v0.2.Q6_K.gguf",
        "file_size": "9.9 GB"
      },
      {
        "model_id": "xwin-lm-13b-v0.2.Q8_0",
        "path": "https://huggingface.co/TheBloke/Xwin-LM-13B-v0.2-GGUF/resolve/main/xwin-lm-13b-v0.2.Q8_0.gguf",
        "file_size": "12.9 GB"
      }
    ],
    "readme": "https://huggingface.co/TheBloke/Xwin-LM-13B-v0.2-GGUF/resolve/main/README.md",
    "description": "This repository provides GGUF format models for Xwin-LM's Xwin LM 13B v0.2, offering various quantization options for efficient inference on CPU and GPU with support from llama.cpp, text-generation-webui, and other frameworks.",
    "tools": false
  },
  {
    "model_name": "YandexGPT-5-Lite-8B-instruct-GGUF",
    "developer": "yandex",
    "downloads": 1516,
    "createdAt": "2025-03-28T16:24:33.000Z",
    "num_quants": 1,
    "quants": [
      {
        "model_id": "YandexGPT-5-Lite-8B-instruct-Q4_K_M",
        "path": "https://huggingface.co/yandex/YandexGPT-5-Lite-8B-instruct-GGUF/resolve/main/YandexGPT-5-Lite-8B-instruct-Q4_K_M.gguf",
        "file_size": "4.6 GB"
      }
    ],
    "readme": "https://huggingface.co/yandex/YandexGPT-5-Lite-8B-instruct-GGUF/resolve/main/README.md",
    "description": "",
    "tools": false
  }
]