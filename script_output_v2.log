Loaded 201 existing entries from model_catalog_v2.json

=== Fetching GGUF models from HuggingFace API ===
Fetching page 1...
Processing GGUF: MiniMaxAI/MiniMax-M2.5
Processing GGUF: Qwen/Qwen3.5-397B-A17B
Processing GGUF: zai-org/GLM-5
Processing GGUF: Nanbeige/Nanbeige4.1-3B
Processing GGUF: moonshotai/Kimi-K2.5
Processing GGUF: unsloth/Qwen3.5-397B-A17B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: inclusionAI/Ring-2.5-1T
Processing GGUF: nineninesix/kani-tts-2-en
Processing GGUF: unsloth/MiniMax-M2.5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Qwen/Qwen3-Coder-Next
Processing GGUF: jdopensource/JoyAI-LLM-Flash
Processing GGUF: openbmb/MiniCPM-SALA
Processing GGUF: unsloth/GLM-5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: DMindAI/DMind-3
Processing GGUF: AIDC-AI/Ovis2.6-30B-A3B
Processing GGUF: zai-org/GLM-OCR
Processing GGUF: unsloth/Qwen3-Coder-Next-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Fortytwo-Network/Strand-Rust-Coder-14B-v1
Processing GGUF: nvidia/NVIDIA-Nemotron-Nano-9B-v2-Japanese
Processing GGUF: inclusionAI/Ling-2.5-1T
Processing GGUF: lm-provers/QED-Nano
Processing GGUF: zai-org/GLM-5-FP8
Processing GGUF: DMindAI/DMind-3-nano
Processing GGUF: DMindAI/DMind-3-mini
Processing GGUF: stepfun-ai/Step-3.5-Flash
Processing GGUF: salakash/Minimalism
Processing GGUF: unsloth/GLM-4.7-Flash-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: zai-org/GLM-4.7-Flash
Processing GGUF: ubergarm/MiniMax-M2.5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: CohereLabs/tiny-aya-global
Processing GGUF: TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF
  -> Added with 13 quants
Processing GGUF: openai/gpt-oss-20b
Processing GGUF: openai/gpt-oss-120b
Processing GGUF: inclusionAI/LLaDA2.1-mini
Processing GGUF: Aratako/MioTTS-2.6B
Processing GGUF: inclusionAI/ZwZ-8B
Processing GGUF: nineninesix/kani-tts-2-pt
Processing GGUF: Qwen/Qwen3.5-397B-A17B-FP8
Processing GGUF: deepseek-ai/DeepSeek-OCR-2
Processing GGUF: DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF
  -> Added with 12 quants
Processing GGUF: meta-llama/Llama-3.1-8B-Instruct
Processing GGUF: Shaligram-Dewangan/Dhi-5B-Base
Processing GGUF: CohereLabs/tiny-aya-base
Processing GGUF: PrimeIntellect/INTELLECT-3.1
Processing GGUF: ruv/ruvltra-claude-code
  -> Added with 1 quants
Processing GGUF: unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: mmnga-o/NVIDIA-Nemotron-Nano-9B-v2-Japanese-gguf
  -> Failed to summarize README: Request timed out.
  -> Added with 13 quants
Processing GGUF: google/medgemma-1.5-4b-it
Processing GGUF: deepseek-ai/DeepSeek-V3.2
Processing GGUF: Qwen/Qwen3-0.6B
Processing GGUF: openbmb/MiniCPM-o-4_5-gguf
  -> Added with 19 quants
Processing GGUF: UCSB-SURFI/VulnLLM-R-7B
Processing GGUF: inference-net/Schematron-3B
Processing GGUF: Qwen/Qwen3-Coder-Next-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: inclusionAI/LLaDA2.1-flash
Processing GGUF: mratsim/MiniMax-M2.5-BF16-INT4-AWQ
Processing GGUF: google/translategemma-4b-it
Processing GGUF: unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF
  -> Added with 27 quants
Processing GGUF: inclusionAI/ZwZ-4B
Processing GGUF: google/gemma-3-27b-it
Processing GGUF: Qwen/Qwen3-8B
Processing GGUF: ytu-ce-cosmos/Turkish-Gemma-9b-T1
Processing GGUF: HauhauCS/GPTOSS-120B-Uncensored-HauhauCS-Aggressive
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: AesSedai/MiniMax-M2.5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: jdopensource/JoyAI-LLM-Flash-Base
Processing GGUF: Qwen/Qwen3-4B-Instruct-2507
Processing GGUF: CohereLabs/tiny-aya-water
Processing GGUF: unsloth/Kimi-K2.5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: ubergarm/Qwen3.5-397B-A17B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: zai-org/GLM-4.7
Processing GGUF: LiquidAI/LFM2.5-1.2B-Instruct
Processing GGUF: Cordux/flux2-klein-4B-uncensored-text-encoder
  -> Added with 1 quants
Processing GGUF: PaddlePaddle/PaddleOCR-VL-1.5
Processing GGUF: deepseek-ai/DeepSeek-R1
Processing GGUF: unsloth/gpt-oss-20b-GGUF
  -> Added with 16 quants
Processing GGUF: google/functiongemma-270m-it
Processing GGUF: Edge-Quant/Nanbeige4.1-3B-Q4_K_M-GGUF
  -> Added with 1 quants
Processing GGUF: megabytes/Nanbeige4.1-3B-heretic
Processing GGUF: ox-ox/MiniMax-M2.5-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 2 quants
Processing GGUF: nvidia/music-flamingo-think-2601-hf
Processing GGUF: puwaer/Qwen3-Next-80B-A3B-Thinking-GRPO-Uncensored
Processing GGUF: google/gemma-3-4b-it
Processing GGUF: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16
Processing GGUF: bharatgenai/Param2-17B-A2.4B-Thinking
Processing GGUF: Qwen/Qwen2.5-Coder-7B-Instruct
Processing GGUF: rednote-hilab/dots.ocr
Processing GGUF: MiniMaxAI/MiniMax-M2.1
Processing GGUF: google/translategemma-27b-it
Processing GGUF: Qwen/Qwen3-Coder-Next-FP8
Processing GGUF: AesSedai/Qwen3.5-397B-A17B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: MiniMaxAI/MiniMax-M2
Processing GGUF: ByteDance/Ouro-2.6B
Processing GGUF: Nanbeige/Nanbeige4-3B-Base
Processing GGUF: lightonai/LightOnOCR-2-1B
Processing GGUF: CohereLabs/tiny-aya-earth
Processing GGUF: distil-labs/distil-home-assistant-functiongemma
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: puwaer/Qwen3-Next-80B-A3B-Thinking-GRPO-Uncensored-gguf
  -> Failed to summarize README: Request timed out.
  -> Added with 4 quants
Processing GGUF: cerebras/MiniMax-M2.5-REAP-172B-A10B
Processing GGUF: google/gemma-3n-E2B-it-litert-lm
Processing GGUF: google/gemma-3n-E4B-it-litert-lm
Processing GGUF: google/gemma-3-270m
Processing GGUF: ByteDance/Ouro-1.4B
Processing GGUF: Alibaba-DAMO-Academy/RynnBrain-2B
Processing GGUF: BennyDaBall/Qwen3-4b-Z-Image-Engineer-V4
  -> Added with 10 quants
Processing GGUF: CohereLabs/tiny-aya-global-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 5 quants
Processing GGUF: meta-llama/Llama-3.1-8B
Processing GGUF: LiquidAI/LFM2-8B-A1B
Processing GGUF: deepseek-ai/DeepSeek-OCR
Processing GGUF: ByteDance/Ouro-2.6B-Thinking
Processing GGUF: neuphonic/neutts-nano
Processing GGUF: bartowski/kldzj_gpt-oss-120b-heretic-v2-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: unsloth/Nemotron-3-Nano-30B-A3B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: nvidia/music-flamingo-2601-hf
Processing GGUF: LiquidAI/LFM2.5-1.2B-Thinking
Processing GGUF: nvidia/Kimi-K2.5-NVFP4
Processing GGUF: AngelSlim/HY-1.8B-2Bit-GGUF
  -> Added with 3 quants
Processing GGUF: bknyaz/Qwen3-Coder-Next-REAM
Processing GGUF: Goekdeniz-Guelmez/JOSIE-4B-Thinking
Processing GGUF: CohereLabs/tiny-aya-fire
Processing GGUF: ubergarm/GLM-5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: stepfun-ai/NextStep-1.1-Pretrain-256px
Processing GGUF: heretic-org/Nanbeige4.1-3B-heretic
Processing GGUF: magibu/magibu-11b-v0.8
Processing GGUF: byteshape/Qwen3-Coder-30B-A3B-Instruct-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 13 quants
Processing GGUF: Trendyol/Trendyol-LLM-Asure-12B
Processing GGUF: Qwen/Qwen2.5-7B-Instruct
Processing GGUF: Qwen/Qwen3-Embedding-8B
Processing GGUF: Qwen/Qwen3-VL-8B-Instruct
Processing GGUF: PleIAs/Baguettotron
Processing GGUF: p-e-w/gemma-3-12b-it-heretic
Processing GGUF: DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf
  -> Added with 17 quants
Processing GGUF: Nanbeige/Nanbeige4-3B-Thinking-2511
Processing GGUF: ArliAI/gpt-oss-120b-Derestricted
Processing GGUF: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-NVFP4
Processing GGUF: Qwen/Qwen3-VL-Embedding-2B
Processing GGUF: google/translategemma-12b-it
Processing GGUF: internlm/Intern-S1-Pro
Processing GGUF: Andycurrent/Gemma-3-4B-VL-it-Gemini-Pro-Heretic-Uncensored-Thinking_GGUF
  -> Added with 8 quants
Processing GGUF: OpenResearcher/OpenResearcher-30B-A3B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 6 quants
Processing GGUF: syvai/plapre-nano
  -> Failed to summarize README: Request timed out.
  -> Added with 5 quants
Processing GGUF: CohereLabs/tiny-aya-water-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 5 quants
Processing GGUF: NoesisLab/Spartacus-1B-Instruct
Processing GGUF: sarvamai/sarvam-1
Processing GGUF: google/gemma-3-12b-it
Processing GGUF: litert-community/Gemma3-1B-IT
Processing GGUF: Qwen/Qwen3-8B-GGUF
  -> Added with 5 quants
Processing GGUF: huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated
  -> Failed to summarize README: Request timed out.
  -> Added with 4 quants
Processing GGUF: moonshotai/Kimi-K2-Thinking
Processing GGUF: deepseek-ai/DeepSeek-V3.2-Speciale
Processing GGUF: XiaomiMiMo/MiMo-V2-Flash
Processing GGUF: Qwen/Qwen3-VL-Embedding-8B
Processing GGUF: ubergarm/Step-3.5-Flash-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: huihui-ai/Huihui-Qwen3-Coder-Next-abliterated
Processing GGUF: mradermacher/Qwen3-Coder-Next-REAM-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 11 quants
Processing GGUF: bartowski/moonshotai_Kimi-K2.5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: mradermacher/Nanbeige4.1-3B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 12 quants
Processing GGUF: Goekdeniz-Guelmez/JOSIE-4B-Instruct
Processing GGUF: snap-stanford/humanlm-opinion
Processing GGUF: MuXodious/HER-32B-absolute-heresy
Processing GGUF: Qwen/Qwen2.5-Coder-7B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: meta-llama/Llama-3.2-3B-Instruct
Processing GGUF: dphn/Dolphin3.0-Llama3.1-8B
Processing GGUF: microsoft/Phi-4-mini-instruct
Processing GGUF: google/gemma-3-1b-it
Processing GGUF: Qwen/Qwen3-32B
Processing GGUF: Qwen/Qwen3-Embedding-0.6B
Processing GGUF: google/gemma-3n-E4B-it
Processing GGUF: dphn/Dolphin-Mistral-24B-Venice-Edition
Processing GGUF: Qwen/Qwen3-30B-A3B-Instruct-2507
Processing GGUF: Qwen/Qwen3-30B-A3B-Thinking-2507
Processing GGUF: unsloth/gpt-oss-120b-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Qwen/Qwen3-VL-30B-A3B-Instruct
Processing GGUF: Fortytwo-Network/Strand-Rust-Coder-14B-v1-GGUF
  -> Added with 5 quants
Processing GGUF: p-e-w/gpt-oss-20b-heretic
Processing GGUF: zai-org/GLM-4.6V-Flash
Processing GGUF: unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF
  -> Added with 26 quants
Processing GGUF: nvidia/Cosmos-Reason2-8B
Processing GGUF: unsloth/MiniMax-M2.1-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill
Processing GGUF: Alibaba-DAMO-Academy/RynnBrain-30B-A3B
Processing GGUF: unsloth/GLM-OCR
Processing GGUF: bartowski/stepfun-ai_Step-3.5-Flash-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: inclusionAI/ZwZ-7B
Processing GGUF: OccultAI/Morpheus-8B-v1
Processing GGUF: heretic-org/Qwen3-4B-Instruct-2507-heretic
Processing GGUF: heretic-org/Qwen3-4B-Thinking-2507-heretic
Processing GGUF: QuantTrio/MiniMax-M2.5-AWQ
Processing GGUF: vincentzed-hf/Qwen3.5-397B-A17B-NVFP4
Processing GGUF: trillionlabs/Tri-21B-Think
Processing GGUF: cerebras/MiniMax-M2.5-REAP-139B-A10B
Processing GGUF: meta-llama/Llama-2-7b-hf
Processing GGUF: TinyLlama/TinyLlama-1.1B-Chat-v1.0
Processing GGUF: google/gemma-7b
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: meta-llama/Llama-3.2-1B-Instruct
Processing GGUF: meta-llama/Llama-3.3-70B-Instruct
Processing GGUF: AlicanKiraz0/Cybersecurity-BaronLLM_Offensive_Security_LLM_Q6_K_GGUF
  -> Added with 1 quants
Processing GGUF: Qwen/Qwen3-4B
Processing GGUF: google/medgemma-4b-it
Processing GGUF: sarvamai/sarvam-m
Processing GGUF: DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf
  -> Added with 18 quants
Processing GGUF: Qwen/Qwen3-Next-80B-A3B-Instruct
Processing GGUF: Qwen/Qwen3-VL-2B-Instruct
Processing GGUF: p-e-w/Qwen3-4B-Instruct-2507-heretic
Processing GGUF: onnx-community/gpt-oss-20b-ONNX
Processing GGUF: LiquidAI/LFM2.5-1.2B-Instruct-GGUF
  -> Added with 7 quants
Processing GGUF: bakrianoo/arabic-legal-documents-ocr-1.0
Processing GGUF: SicariusSicariiStuff/Assistant_Pepe_8B
Processing GGUF: Nanbeige/ToolMind-Web-3B
Processing GGUF: HauhauCS/GPT-OSS-20B-Uncensored-HauhauCS-Aggressive
  -> Added with 1 quants
Processing GGUF: Dogacel/Universal-DeepSeek-OCR-2
Processing GGUF: jinaai/jina-embeddings-v5-text-small-retrieval
  -> Failed to summarize README: Request timed out.
  -> Added with 14 quants
Processing GGUF: bartowski/moonshotai_Kimi-Linear-48B-A3B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: MuXodious/gpt-oss-20b-RichardErkhov-heresy
Processing GGUF: Aratako/MioTTS-GGUF
  -> Added with 24 quants
Processing GGUF: DarkArtsForge/Raven-8B-v1
Processing GGUF: DevQuasar/MiniMaxAI.MiniMax-M2.5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Ex0bit/MiniMax-M2.5-PRISM-PRO
  -> Failed to summarize README: Request timed out.
  -> Added with 7 quants
Processing GGUF: MikeRoz/MiniMax-M2.5-exl3
Processing GGUF: p-e-w/Qwen3-4B-Instruct-2507-heretic-v4
Processing GGUF: ggml-org/Qwen3-Coder-Next-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: unsloth/Qwen3.5-397B-A17B
Processing GGUF: KnutJaegersberg/JoyAI-LLM-Flash-Q6_K-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: mistralai/Mistral-7B-Instruct-v0.2
Processing GGUF: CohereLabs/c4ai-command-r-plus
Processing GGUF: aaditya/Llama3-OpenBioLLM-8B
Processing GGUF: DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF
  -> Added with 14 quants
Processing GGUF: microsoft/phi-4-gguf
  -> Failed to summarize README: Request timed out.
  -> Added with 23 quants
Processing GGUF: Qwen/Qwen2.5-VL-3B-Instruct
Processing GGUF: ByteDance-Seed/UI-TARS-1.5-7B
Processing GGUF: darkc0de/XortronCriminalComputingConfig
Processing GGUF: Qwen/Qwen3-4B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 5 quants
Processing GGUF: ibm-granite/granite-docling-258M
Processing GGUF: Qwen/Qwen3-Embedding-4B
Processing GGUF: google/gemma-3n-E4B
Processing GGUF: google/medgemma-27b-it
Processing GGUF: LiquidAI/LFM2-350M
Processing GGUF: LGAI-EXAONE/EXAONE-4.0-1.2B
Processing GGUF: moondream/moondream3-preview
Processing GGUF: PaddlePaddle/PaddleOCR-VL
Processing GGUF: Nanbeige/Nanbeige4-3B-Thinking-2510
Processing GGUF: Qwen/Qwen3-VL-8B-Instruct-GGUF
  -> Added with 3 quants
Processing GGUF: TheDrummer/Cydonia-24B-v4.3-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 6 quants
Processing GGUF: nvidia/NVIDIA-Nemotron-Parse-v1.1
Processing GGUF: ServiceNow-AI/Apriel-1.6-15b-Thinker
Processing GGUF: sbintuitions/diafill-llm-jp-3.1-13b-instruct4
Processing GGUF: tencent/HY-MT1.5-1.8B
Processing GGUF: LiquidAI/LFM2.5-VL-1.6B
Processing GGUF: tiiuae/Falcon-H1-Tiny-90M-Instruct
Processing GGUF: stepfun-ai/Step-Audio-R1.1
Processing GGUF: LiquidAI/LFM2.5-1.2B-Thinking-GGUF
  -> Added with 7 quants
Processing GGUF: bluolightning/manga-ocr-mobile
Processing GGUF: lmstudio-community/GLM-4.7-Flash-MLX-6bit
Processing GGUF: bartowski/zai-org_GLM-4.7-Flash-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: huihui-ai/Huihui-GLM-4.7-Flash-abliterated
Processing GGUF: squ11z1/gpt-oss-nano
  -> Added with 3 quants
Processing GGUF: BennyDaBall/Qwen3-4b-Z-Image-Turbo-AbliteratedV1
  -> Added with 8 quants
Processing GGUF: stepfun-ai/Step-3.5-Flash-GGUF-Q4_K_S
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: FutureMa/Eva-4B-V2
Processing GGUF: Aratako/MioTTS-1.7B
Processing GGUF: neuphonic/neutts-nano-german
Processing GGUF: neuphonic/neutts-nano-french
Processing GGUF: NoesisLab/NanoHammer-1.5B-Instruct
Processing GGUF: Intel/Qwen3-Coder-Next-int4-AutoRound
Processing GGUF: amazon/gpt-oss-120b-p-eagle
Processing GGUF: DavidAU/gemma-3-12b-it-vl-Deepseek-v3.1-Heretic-Uncensored-Thinking
Processing GGUF: mlx-community/Nanbeige4.1-3B-8bit
Processing GGUF: DavidAU/Qwen3-30B-A3B-YOYO-V2-Claude-4.6-Opus-High-INSTRUCT
Processing GGUF: InternRobotics/RoboInter-VLM_qwenvl25_3b
Processing GGUF: DavidAU/Gemma-3-27b-it-vl-SuperBrain7x-High-Reasoning-ULTRAMIND-Heretic-Uncensored
Processing GGUF: unsloth/MiniMax-M2.5
Processing GGUF: ConicCat/GLM-4.7-Architect-355B-A32B
Processing GGUF: CohereLabs/tiny-aya-fire-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 5 quants
Processing GGUF: ggml-org/GLM-OCR-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 0 quants
Processing GGUF: mratsim/MiniMax-M2.5-FP8-INT4-AWQ
Processing GGUF: byteshape/Devstral-Small-2-24B-Instruct-2512-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 8 quants
Processing GGUF: openai-community/gpt2
Processing GGUF: kha-white/manga-ocr-base
Processing GGUF: meta-llama/Llama-2-7b-chat-hf
Processing GGUF: google/gemma-2b
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: BioMistral/BioMistral-7B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 11 quants
Processing GGUF: xai-org/grok-1
Processing GGUF: Orenguteng/Llama-3-8B-Lexi-Uncensored
Processing GGUF: mlabonne/NeuralDaredevil-8B-abliterated
Processing GGUF: deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct
Processing GGUF: meta-llama/Llama-3.1-70B-Instruct
Processing GGUF: Qwen/Qwen2.5-14B-Instruct
Processing GGUF: meta-llama/Llama-3.2-1B
Processing GGUF: HuggingFaceTB/SmolLM2-360M
Processing GGUF: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
Processing GGUF: Qwen/Qwen2.5-VL-7B-Instruct
Processing GGUF: mlabonne/gemma-3-27b-it-abliterated
Processing GGUF: microsoft/bitnet-b1.58-2B-4T
Processing GGUF: Qwen/Qwen3-14B
Processing GGUF: Qwen/Qwen3-30B-A3B
Processing GGUF: Qwen/Qwen3-0.6B-Base
Processing GGUF: deepseek-ai/DeepSeek-R1-0528-Qwen3-8B
Processing GGUF: unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF
  -> Added with 26 quants
Processing GGUF: sarvamai/sarvam-translate
Processing GGUF: huihui-ai/Huihui-Qwen3-4B-abliterated-v2
Processing GGUF: HuggingFaceTB/SmolLM3-3B
Processing GGUF: moonshotai/Kimi-K2-Instruct
Processing GGUF: Qwen/Qwen3-Coder-30B-A3B-Instruct
Processing GGUF: ggml-org/gpt-oss-20b-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: Qwen/Qwen3-4B-Thinking-2507
Processing GGUF: nvidia/NVIDIA-Nemotron-Nano-9B-v2
Processing GGUF: openbmb/MiniCPM-V-4_5
Processing GGUF: openai/gpt-oss-safeguard-20b
Processing GGUF: nineninesix/kani-tts-370m
Processing GGUF: datalab-to/chandra
Processing GGUF: Cannae-AI/MedicalLlama3.2-vision-11B-IT
Processing GGUF: mradermacher/gemma-3-12b-it-heretic-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 13 quants
Processing GGUF: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-Base-BF16
Processing GGUF: nvidia/Qwen3-Next-80B-A3B-Thinking-NVFP4
Processing GGUF: Intel/MiniMax-M2-REAP-172B-A10B-gguf-q2ks-mixed-AutoRound
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: nvidia/Cosmos-Reason2-2B
Processing GGUF: tencent/HY-MT1.5-7B
Processing GGUF: ethicalabs/Kurtis-EON1
Processing GGUF: LiquidAI/LFM2.5-VL-1.6B-GGUF
  -> Added with 4 quants
Processing GGUF: mradermacher/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC-GGUF
  -> Added with 11 quants
Processing GGUF: GadflyII/GLM-4.6V-NVFP4
Processing GGUF: unsloth/medgemma-1.5-4b-it-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 26 quants
Processing GGUF: DavidAU/Gemma3-27B-it-vl-GLM-4.7-Uncensored-Heretic-Deep-Reasoning
Processing GGUF: unsloth/DeepSeek-OCR-2
Processing GGUF: meituan-longcat/LongCat-Flash-Lite
Processing GGUF: Alibaba-DAMO-Academy/RynnBrain-Nav-8B
Processing GGUF: unsloth/Qwen3-Coder-Next
Processing GGUF: noctrex/Qwen3-Coder-Next-MXFP4_MOE-GGUF
  -> Added with 2 quants
Processing GGUF: GadflyII/Qwen3-Coder-Next-NVFP4
Processing GGUF: OmniDimen/OmniDimen-2-20B-Emotion
Processing GGUF: neuphonic/neutts-nano-spanish
Processing GGUF: Aratako/MioTTS-1.2B
Processing GGUF: inclusionAI/UI-Venus-1.5-30B-A3B
Processing GGUF: embedl/Cosmos-Reason2-2B-W4A16
Processing GGUF: bartowski/huihui-ai_Qwen3-Coder-Next-abliterated-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: mradermacher/Qwen3-Coder-Next-REAP-40B-A3B-i1-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 24 quants
Processing GGUF: DavidAU/Qwen3-30B-A3B-Claude-4.5-Opus-High-Reasoning-2507-ABLITERATED-UNCENSORED-V2
Processing GGUF: loaiabdalslam/Ouroboros-1MContext-Gemma-270m
Processing GGUF: EldritchLabs/Cthulhu-8B-v1.4
Processing GGUF: mlx-community/GLM-5-4bit
Processing GGUF: mradermacher/OpenAI-gpt-oss-20B-Claude-4.5-Opus-Heretic-Uncensored-i1-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 24 quants
Processing GGUF: tacos4me/Step-3.5-Flash-NVFP4
Processing GGUF: noctrex/ZwZ-8B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 8 quants
Processing GGUF: mlx-community/MiniMax-M2.5-3bit
Processing GGUF: huzpsb/MiniMax-M2-her-4b
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: MuXodious/GLM-4.7-Flash-absolute-heresy
Processing GGUF: LightningRodLabs/Golf-Forecaster
Processing GGUF: INC4AI/MiniMax-M2.5-int4-mixed-AutoRound
Processing GGUF: mlx-community/JoyAI-LLM-Flash-4bit-DWQ
Processing GGUF: trillionlabs/Tri-21B-Think-Preview
Processing GGUF: cyankiwi/MiniMax-M2.5-AWQ-4bit
Processing GGUF: heretic-org/XortronCriminalComputingConfig-heretic
Processing GGUF: inferencerlabs/Qwen3.5-397B-A17B-MLX-9bit
Processing GGUF: MuXodious/Nanbeige4.1-3B-absolute-heresy
Processing GGUF: CohereLabs/tiny-aya-earth-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 5 quants
Processing GGUF: mlx-community/Qwen3.5-397B-A17B-nvfp4
Processing GGUF: EliasOenal/MiniMax-M2.5-Hybrid-AWQ-W4A16G128-Attn-fp8_e4m3-KV-fp8_e4m3
Processing GGUF: tomngdev/MiniMax-M2.5-REAP-139B-A10B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: bigscience/bloom
Processing GGUF: llava-hf/llava-1.5-7b-hf
Processing GGUF: BioMistral/BioMistral-7B
Processing GGUF: meta-llama/Meta-Llama-3-8B-Instruct
Processing GGUF: meta-llama/Meta-Llama-3-8B
Processing GGUF: microsoft/Phi-3-mini-4k-instruct
Processing GGUF: aaditya/Llama3-OpenBioLLM-70B
Processing GGUF: lmstudio-community/Mistral-7B-Instruct-v0.3-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 8 quants
Processing GGUF: Lewdiculous/L3-8B-Stheno-v3.2-GGUF-IQ-Imatrix
  -> Added with 12 quants
Processing GGUF: microsoft/Florence-2-base
Processing GGUF: google/gemma-2-9b
Processing GGUF: HuggingFaceTB/SmolLM-135M
Processing GGUF: meta-llama/Llama-3.1-70B
Processing GGUF: meta-llama/Llama-3.1-405B
Processing GGUF: google/gemma-2-2b-it
Processing GGUF: openbmb/MiniCPM-V-2_6
Processing GGUF: Qwen/Qwen2.5-72B-Instruct
Processing GGUF: Qwen/Qwen2.5-3B-Instruct
Processing GGUF: Qwen/Qwen2.5-1.5B-Instruct
Processing GGUF: bartowski/Llama-3.2-3B-Instruct-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 18 quants
Processing GGUF: mav23/Pentest_AI-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 17 quants
Processing GGUF: Qwen/Qwen2.5-Coder-32B-Instruct
Processing GGUF: bartowski/Qwen2.5-Coder-32B-Instruct-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 28 quants
Processing GGUF: Qwen/Qwen2.5-Coder-14B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: OpenSciLM/Llama-3.1_OpenScholar-8B
Processing GGUF: deepseek-ai/DeepSeek-V3
Processing GGUF: mradermacher/DeepSeek-R1-Distill-Qwen-14B-Uncensored-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 11 quants
Processing GGUF: Qwen/Qwen2.5-VL-72B-Instruct
Processing GGUF: bartowski/huihui-ai_QwQ-32B-abliterated-GGUF
  -> Added with 26 quants
Processing GGUF: unsloth/gemma-3-4b-it-GGUF
  -> Added with 26 quants
Processing GGUF: microsoft/bitnet-b1.58-2B-4T-gguf
  -> Added with 1 quants
Processing GGUF: Qwen/Qwen3-1.7B
Processing GGUF: unsloth/Qwen3-14B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 26 quants
Processing GGUF: unsloth/Qwen3-1.7B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 26 quants
Processing GGUF: deepseek-ai/DeepSeek-Prover-V2-671B
Processing GGUF: huihui-ai/Qwen3-4B-abliterated
Processing GGUF: mradermacher/Josiefied-Qwen3-8B-abliterated-v1-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 12 quants
Processing GGUF: Qwen/Qwen3-14B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 5 quants
Processing GGUF: Qwen/Qwen3-1.7B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: Intelligent-Internet/II-Medical-8B
Processing GGUF: DavidAU/Llama-3.2-8X3B-GATED-MOE-NEO-Reasoning-Dark-Champion-uncensored-18.4B-IMAT-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 20 quants
Processing GGUF: mlabonne/gemma-3-12b-it-abliterated-v2-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 6 quants
Processing GGUF: osmosis-ai/Osmosis-Apply-1.7B
  -> Failed to summarize README: Request timed out.
  -> Added with 12 quants
Processing GGUF: unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 26 quants
Processing GGUF: LiquidAI/LFM2-1.2B
Processing GGUF: Trendyol/Trendyol-LLM-8B-T1
Processing GGUF: unsloth/GLM-4.5-Air-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: unsloth/Qwen3-4B-Instruct-2507-GGUF
  -> Added with 26 quants
Processing GGUF: ByteDance-Seed/Seed-OSS-36B-Instruct
Processing GGUF: microsoft/VibeVoice-1.5B
Processing GGUF: apple/FastVLM-0.5B
Processing GGUF: stepfun-ai/Step-Audio-2-mini
Processing GGUF: swiss-ai/Apertus-8B-2509
Processing GGUF: moonshotai/Kimi-K2-Instruct-0905
Processing GGUF: NobodyExistsOnTheInternet/K3-Q4-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: neuphonic/neutts-air
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: openai/gpt-oss-safeguard-120b
Processing GGUF: Qwen/Qwen3-VL-235B-A22B-Thinking
Processing GGUF: neuphonic/neutts-air-q4-gguf
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: vngrs-ai/Kumru-2B
Processing GGUF: deepseek-ai/DeepSeek-V3.2-Exp
Processing GGUF: Qwen/Qwen3-VL-30B-A3B-Thinking
Processing GGUF: Qwen/Qwen3-VL-30B-A3B-Instruct-FP8
Processing GGUF: DragonLLM/Llama-Open-Finance-8B
Processing GGUF: Qwen/Qwen3-VL-8B-Instruct-FP8
Processing GGUF: nanonets/Nanonets-OCR2-3B
Processing GGUF: Phil2Sat/Qwen-Image-Edit-Rapid-AIO-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 74 quants
Processing GGUF: rafacost/DreamOmni2-7.6B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 12 quants
Processing GGUF: Qwen/Qwen3-VL-32B-Thinking
Processing GGUF: lightonai/LightOnOCR-1B-1025
Processing GGUF: QuantTrio/Qwen3-VL-32B-Instruct-AWQ
Processing GGUF: shiviktech/Trident
Processing GGUF: TeichAI/Qwen3-14B-Claude-Sonnet-4.5-Reasoning-Distill-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 4 quants
Processing GGUF: fdtn-ai/Foundation-Sec-8B-Reasoning
Processing GGUF: baidu/ERNIE-4.5-VL-28B-A3B-Thinking
Processing GGUF: speakleash/Bielik-11B-v3.0-Instruct
Processing GGUF: cerebras/MiniMax-M2-REAP-172B-A10B
Processing GGUF: jinaai/jina-vlm
Processing GGUF: Zyphra/ZAYA1-reasoning-base
Processing GGUF: DavidAU/Qwen3-0.6B-heretic-abliterated-uncensored
Processing GGUF: TeichAI/Qwen3-4B-Thinking-2507-Claude-4.5-Opus-High-Reasoning-Distill-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 6 quants
Processing GGUF: nvidia/Qwen3-Nemotron-235B-A22B-GenRM
Processing GGUF: EssentialAI/rnj-1-instruct-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-FP8
Processing GGUF: zai-org/GLM-4.6V
Processing GGUF: zai-org/AutoGLM-Phone-9B-Multilingual
Processing GGUF: nvidia/Qwen3-Next-80B-A3B-Instruct-NVFP4
Processing GGUF: MultiverseComputingCAI/HyperNova-60B
Processing GGUF: mratsim/MiniMax-M2.1-FP8-INT4-AWQ
Processing GGUF: LiquidAI/LFM2-2.6B-Transcript
Processing GGUF: stepfun-ai/Step3-VL-10B
Processing GGUF: DavidAU/Gemma-3-27b-it-Gemini-Deep-Reasoning
Processing GGUF: ByteDance-Seed/Stable-DiffCoder-8B-Base
Processing GGUF: ByteDance-Seed/Stable-DiffCoder-8B-Instruct
Processing GGUF: BennyDaBall/Qwen3-4b-Z-Image-Engineer-V2.5
  -> Added with 6 quants
Processing GGUF: lmstudio-community/GLM-4.7-Flash-MLX-4bit
Processing GGUF: MuXodious/GLM-4.7-Flash-impotent-heresy
Processing GGUF: bartowski/TheDrummer_Skyfall-31B-v4.1-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: cerebras/GLM-4.7-Flash-REAP-23B-A3B
Processing GGUF: tencent/Youtu-VL-4B-Instruct
Processing GGUF: koute/GLM-4.7-Flash-Derestricted
Processing GGUF: arcee-ai/Trinity-Large-Preview
Processing GGUF: Zhayr1/BitMamba-2-1B
Processing GGUF: tiiuae/Falcon-H1R-7B-FP8
Processing GGUF: Alibaba-DAMO-Academy/RynnBrain-8B
Processing GGUF: PRIME-RL/P1-VL-30B-A3B
Processing GGUF: unsloth/Qwen3-Coder-Next-FP8-Dynamic
Processing GGUF: bullpoint/Qwen3-Coder-Next-AWQ-4bit
Processing GGUF: Alibaba-DAMO-Academy/RynnBrain-Plan-30B-A3B
Processing GGUF: Andycurrent/gemma-3-12b-it-uncensored-GGUF
  -> Added with 8 quants
Processing GGUF: hkust-nlp/drkernel-8b
Processing GGUF: MBZUAI/MedMO-4B
Processing GGUF: Applied-Innovation-Center/Karnak
Processing GGUF: Aratako/MioTTS-0.6B
Processing GGUF: Aratako/MioTTS-0.1B
Processing GGUF: ortegaalfredo/MechaEpstein-8000-GGUF
  -> Added with 1 quants
Processing GGUF: nivvis/Step-3.5-Flash-REAP-128B-A11B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: DavidAU/gemma-3-12b-it-vl-Kimi-V2-Heretic-Uncensored-Thinking
Processing GGUF: DavidAU/gemma-3-12b-it-vl-Gemini-3-Pro-Preview-Heretic-Uncensored-Thinking
Processing GGUF: jinaai/jina-embeddings-v5-text-small-clustering
  -> Failed to summarize README: Request timed out.
  -> Added with 14 quants
Processing GGUF: noctrex/Qwen3-Coder-Next-REAP-48B-A3B-MXFP4_MOE-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: TeichAI/LFM2.5-1.2B-Thinking-Pony-Alpha-Distill
Processing GGUF: yanolja/YanoljaNEXT-EEVE-Rosetta-7B-2602
Processing GGUF: inferencerlabs/GLM-5-MLX-4.8bit
Processing GGUF: lm-provers/QED-Nano-SFT
Processing GGUF: LightningRodLabs/Trump-Forecaster
Processing GGUF: prithivMLmods/Nanbeige4.1-3B-f32-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 4 quants
Processing GGUF: prithivMLmods/Qwen3-VL-8B-Instruct-Unredacted-MAX
Processing GGUF: marksverdhei/MiniMax-M2.5-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 4 quants
Processing GGUF: Ex0bit/MiniMax-M2.5-PRISM-LITE
  -> Failed to summarize README: Request timed out.
  -> Added with 2 quants
Processing GGUF: noctrex/MiniMax-M2.5-MXFP4_MOE-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: prithivMLmods/Qwen3-VL-4B-Instruct-Unredacted-MAX
Processing GGUF: prithivMLmods/Qwen3-VL-4B-Instruct-Unredacted-MAX-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 6 quants
Processing GGUF: mradermacher/GLM-4.7-Flash-absolute-heresy-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 11 quants
Processing GGUF: syvai/plapre-pico
  -> Failed to summarize README: Request timed out.
  -> Added with 5 quants
Processing GGUF: Guilherme34/Firefly-V3
Processing GGUF: mradermacher/Qwen3-30B-A3B-Gemini-Pro-High-Reasoning-2507-ABLITERATED-UNCENSORED-i1-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 24 quants
Processing GGUF: mlx-community/Qwen3.5-397B-A17B-4bit
Processing GGUF: ShayanCyan/phi4-multimodal-quantisized-gguf
  -> Failed to summarize README: Request timed out.
  -> Added with 2 quants
Processing GGUF: Andycurrent/Gemma-3-1B-it-GLM-4.7-Flash-Heretic-Uncensored-Thinking_GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 7 quants
Processing GGUF: BennyDaBall/MiniMax-M2.5-REAP-139B-A10B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: EleutherAI/gpt-neo-1.3B
Processing GGUF: microsoft/trocr-large-handwritten
Processing GGUF: mrzlab630/lora-alpaca-trading-candles
Processing GGUF: mistralai/Mistral-7B-v0.1
Processing GGUF: liuhaotian/llava-v1.5-7b
Processing GGUF: epfl-llm/meditron-7b
Processing GGUF: microsoft/phi-2
Processing GGUF: BlouseJury/Mistral-7B-Discord-0.1
Processing GGUF: s3nh/UTENA-7B-NSFW-V2-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 5 quants
Processed 105 GGUF models from page 1
Reached end of available models.

=== Processing pinned GGUF models ===
Processing pinned GGUF: janhq/Jan-v3-4B-base-instruct-gguf
  -> Added pinned GGUF model
Processing pinned GGUF: janhq/Jan-v2-VL-med-gguf
  -> Added pinned GGUF model
Processing pinned GGUF: janhq/Jan-v2-VL-high-gguf
  -> Added pinned GGUF model
Processing pinned GGUF: unsloth/Olmo-3-7B-Instruct-GGUF
  -> Added pinned GGUF model
Processing pinned GGUF: unsloth/Olmo-3-7B-Think-GGUF
  -> Added pinned GGUF model
Processing pinned GGUF: unsloth/Olmo-3-32B-Think-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing pinned GGUF: Menlo/Jan-nano-128k-gguf
  -> Added pinned GGUF model

Total GGUF models: 111

=== Fetching MLX models from HuggingFace API ===
Fetching models from author: mlx-community
Found 100 models from mlx-community
Processing MLX: mlx-community/Kimi-K2.5
  -> Added with 182 safetensors files
Processing MLX: mlx-community/gpt-oss-20b-MXFP4-Q8
  -> Added with 3 safetensors files
Processing MLX: mlx-community/gemma-3-4b-it-qat-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/parakeet-tdt-0.6b-v2
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Devstral-Small-2-24B-Instruct-2512-4bit
  -> Added with 3 safetensors files
Processing MLX: mlx-community/parakeet-tdt-0.6b-v3
  -> Added with 1 safetensors files
Processing MLX: mlx-community/gemma-3-12b-it-qat-4bit
  -> Added with 2 safetensors files
Processing MLX: mlx-community/gemma-3-27b-it-qat-4bit
  -> Added with 4 safetensors files
Processing MLX: mlx-community/Llama-3.2-1B-Instruct-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Llama-3.2-3B-Instruct-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen3-0.6B-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/gemma-3-1b-it-qat-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/GLM-4.7-Flash-4bit
  -> Added with 4 safetensors files
Processing MLX: mlx-community/Meta-Llama-3.1-8B-Instruct-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen3-30B-A3B-4bit
  -> Added with 4 safetensors files
Processing MLX: mlx-community/GLM-4.7-Flash-8bit
  -> Added with 7 safetensors files
Processing MLX: mlx-community/MiniMax-M2.1-8bit
  -> Added with 47 safetensors files
Processing MLX: mlx-community/Kimi-K2-Thinking
  -> Added with 182 safetensors files
Processing MLX: mlx-community/Llama-3.3-70B-Instruct-4bit
  -> Added with 8 safetensors files
Processing MLX: mlx-community/GLM-4.7-Flash-6bit
  -> Added with 5 safetensors files
Processing MLX: mlx-community/Kimi-K2-Instruct-4bit
  -> Added with 180 safetensors files
Processing MLX: mlx-community/MiniMax-M2.1-3bit
  -> Added with 19 safetensors files
Processing MLX: mlx-community/GLM-4.7-4bit
  -> Added with 39 safetensors files
Processing MLX: mlx-community/gpt-oss-120b-MXFP4-Q8
  -> Added with 13 safetensors files
Processing MLX: mlx-community/Meta-Llama-3.1-8B-Instruct-8bit
  -> Added with 2 safetensors files
Processing MLX: mlx-community/Llama-3.3-70B-Instruct-8bit
  -> Added with 15 safetensors files
Processing MLX: mlx-community/GLM-4.7-Flash-5bit
  -> Added with 4 safetensors files
Processing MLX: mlx-community/DeepSeek-V3.1-4bit
  -> Added with 88 safetensors files
Processing MLX: mlx-community/Qwen3-Next-80B-A3B-Instruct-4bit
  -> Added with 9 safetensors files
Processing MLX: mlx-community/Llama-3.2-3B-Instruct-8bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/GLM-4.7-8bit-gs32
  -> Added with 90 safetensors files
Processing MLX: mlx-community/Qwen3-Coder-480B-A35B-Instruct-4bit
  -> Added with 62 safetensors files
Processing MLX: mlx-community/Qwen3-0.6B-8bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen3-Next-80B-A3B-Instruct-8bit
  -> Added with 17 safetensors files
Processing MLX: mlx-community/GLM-4.7-6bit
  -> Added with 54 safetensors files
Processing MLX: mlx-community/Qwen3-Next-80B-A3B-Thinking-4bit
  -> Added with 9 safetensors files
Processing MLX: mlx-community/Qwen3-235B-A22B-Instruct-2507-8bit
  -> Added with 48 safetensors files
Processing MLX: mlx-community/Qwen3-Next-80B-A3B-Thinking-8bit
  -> Added with 17 safetensors files
Processing MLX: mlx-community/Meta-Llama-3.1-70B-Instruct-4bit
  -> Added with 8 safetensors files
Processing MLX: mlx-community/DeepSeek-V3.1-8bit
  -> Added with 175 safetensors files
Processing MLX: mlx-community/GLM-4.5-Air-8bit
  -> Added with 23 safetensors files
Processing MLX: mlx-community/GLM-4.5-Air-bf16
  -> Added with 46 safetensors files
Processing MLX: mlx-community/Qwen3-Coder-480B-A35B-Instruct-8bit
  -> Added with 125 safetensors files
Processing MLX: mlx-community/Qwen3-30B-A3B-8bit
  -> Added with 7 safetensors files
Processing MLX: mlx-community/Qwen3-235B-A22B-Instruct-2507-4bit
  -> Added with 26 safetensors files
Processing MLX: mlx-community/Meta-Llama-3.1-8B-Instruct-bf16
  -> Added with 4 safetensors files
Processing MLX: mlx-community/llama-3.3-70b-instruct-fp16
  -> Added with 28 safetensors files
Processing MLX: mlx-community/Qwen3-1.7B-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/whisper-small-mlx
Processing MLX: mlx-community/Qwen3-4B-Instruct-2507-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen3-TTS-12Hz-0.6B-Base-8bit
  -> Added with 2 safetensors files
Processing MLX: mlx-community/Qwen3-4B-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen3-TTS-12Hz-0.6B-CustomVoice-8bit
  -> Added with 2 safetensors files
Processing MLX: mlx-community/Qwen3-8B-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/gemma-2-2b-it-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen2.5-3B-Instruct-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Ministral-3-3B-Instruct-2512-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen3-Embedding-0.6B-4bit-DWQ
  -> Added with 1 safetensors files
Processing MLX: mlx-community/LFM2.5-VL-1.6B-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen2.5-7B-Instruct-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/whisper-large-v3-turbo
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Mistral-Nemo-Instruct-2407-4bit
  -> Failed to summarize README: Request timed out.
  -> Added with 2 safetensors files
Processing MLX: mlx-community/gemma-3n-E2B-it-lm-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen2.5-1.5B-Instruct-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/gemma-3n-E4B-it-lm-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/translategemma-4b-it-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/MiniMax-M2.1-4bit
  -> Added with 27 safetensors files
Processing MLX: mlx-community/Kokoro-82M-bf16
  -> Added with 55 safetensors files
Processing MLX: mlx-community/Qwen3-VL-4B-Instruct-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/embeddinggemma-300m-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/LFM2.5-1.2B-Thinking-6bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen2.5-0.5B-Instruct-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/gemma-2-9b-it-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/whisper-large-v3-mlx
Processing MLX: mlx-community/Qwen2-VL-2B-Instruct-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen3-VL-2B-Instruct-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen3-TTS-12Hz-1.7B-Base-bf16
  -> Added with 2 safetensors files
Processing MLX: mlx-community/Mistral-7B-Instruct-v0.3-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/LFM2-2.6B-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/multilingual-e5-base-mlx
  -> Failed to summarize README: Request timed out.
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen3-Coder-Next-4bit
  -> Added with 9 safetensors files
Processing MLX: mlx-community/Step-3.5-Flash-4bit
  -> Added with 22 safetensors files
Processing MLX: mlx-community/gemma-3-1b-it-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen3-235B-A22B-4bit
  -> Added with 26 safetensors files
Processing MLX: mlx-community/GLM-OCR-bf16
  -> Failed to summarize README: Request timed out.
  -> Added with 1 safetensors files
Processing MLX: mlx-community/LFM2.5-1.2B-Instruct-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen3.5-397B-A17B-4bit
  -> Failed to summarize README: Request timed out.
  -> Added with 46 safetensors files
Processing MLX: mlx-community/Qwen3-TTS-12Hz-1.7B-VoiceDesign-bf16
  -> Added with 2 safetensors files
Processing MLX: mlx-community/Qwen3.5-397B-A17B-nvfp4
  -> Failed to summarize README: Request timed out.
  -> Added with 46 safetensors files
Processing MLX: mlx-community/Ministral-3-8B-Instruct-2512-4bit
  -> Added with 2 safetensors files
Processing MLX: mlx-community/gpt-oss-20b-MXFP4-Q4
  -> Added with 3 safetensors files
Processing MLX: mlx-community/DeepSeek-R1-Distill-Qwen-1.5B-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/whisper-tiny
Processing MLX: mlx-community/Qwen2.5-VL-3B-Instruct-4bit
  -> Failed to summarize README: Request timed out.
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen3-TTS-12Hz-1.7B-VoiceDesign-8bit
  -> Failed to summarize README: Request timed out.
  -> Added with 2 safetensors files
Processing MLX: mlx-community/Llama-2-7b-chat-mlx
Processing MLX: mlx-community/SmolLM3-3B-4bit
  -> Added with 1 safetensors files
Processing MLX: mlx-community/Qwen3-TTS-12Hz-0.6B-Base-bf16
  -> Failed to summarize README: Request timed out.
  -> Added with 2 safetensors files
Processing MLX: mlx-community/Qwen3-235B-A22B-8bit
  -> Added with 48 safetensors files
Processing MLX: mlx-community/Meta-Llama-3-8B-Instruct-4bit
  -> Added with 1 safetensors files

=== Processing pinned MLX models ===
Processing pinned MLX: mlx-community/Jan-v3-4B-base-instruct-4bit
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-high-4bit-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-high-8bit-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-high-bf16-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-med-4bit-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-med-8bit-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-med-bf16-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-low-4bit-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-low-8bit-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-low-bf16-mlx
  -> Added pinned MLX model
Total MLX models: 106

=== Removing duplicates ===
After dedup: 212 models

=== V2 Catalog Summary ===
Total models: 212
  - GGUF models: 106
  - MLX models: 106
Written to: model_catalog_v2.json

Updated catalog; total now 212 (GGUF: 106, MLX: 106)
