Loaded 216 existing entries from model_catalog_v2.json

=== Fetching GGUF models from HuggingFace API ===
Fetching page 1...
Processing GGUF: Qwen/Qwen3.5-35B-A3B
Processing GGUF: Qwen/Qwen3.5-27B
Processing GGUF: Qwen/Qwen3.5-397B-A17B
Processing GGUF: Qwen/Qwen3.5-122B-A10B
Processing GGUF: unsloth/Qwen3.5-35B-A3B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: zai-org/GLM-5
Processing GGUF: Nanbeige/Nanbeige4.1-3B
Processing GGUF: LocoreMind/LocoOperator-4B
Processing GGUF: MiniMaxAI/MiniMax-M2.5
Processing GGUF: LiquidAI/LFM2-24B-A2B
Processing GGUF: moonshotai/Kimi-K2.5
Processing GGUF: unsloth/Qwen3.5-122B-A10B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: unsloth/Qwen3.5-27B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Qwen/Qwen3-Coder-Next
Processing GGUF: Qwen/Qwen3.5-397B-A17B-FP8
Processing GGUF: Qwen/Qwen3.5-35B-A3B-Base
Processing GGUF: CohereLabs/tiny-aya-global
Processing GGUF: unsloth/Qwen3-Coder-Next-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Fortytwo-Network/Strand-Rust-Coder-14B-v1
Processing GGUF: nvidia/NVIDIA-Nemotron-Nano-9B-v2-Japanese
Processing GGUF: guidelabs/steerling-8b
Processing GGUF: zai-org/GLM-OCR
Processing GGUF: unsloth/Qwen3.5-397B-A17B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: salakash/Minimalism
Processing GGUF: deepseek-ai/DeepSeek-OCR-2
Processing GGUF: nvidia/Qwen3.5-397B-A17B-NVFP4
Processing GGUF: unsloth/GLM-4.7-Flash-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: jdopensource/JoyAI-LLM-Flash
Processing GGUF: zai-org/GLM-4.7-Flash
Processing GGUF: inclusionAI/Ling-2.5-1T
Processing GGUF: Qwen/Qwen3.5-27B-FP8
Processing GGUF: Qwen/Qwen3.5-35B-A3B-FP8
Processing GGUF: unsloth/MiniMax-M2.5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: openai/gpt-oss-120b
Processing GGUF: stepfun-ai/Step-3.5-Flash
Processing GGUF: openai/gpt-oss-20b
Processing GGUF: LiquidAI/LFM2.5-1.2B-Thinking
Processing GGUF: Qwen/Qwen3.5-122B-A10B-FP8
Processing GGUF: lightonai/LightOnOCR-2-1B
Processing GGUF: deepseek-ai/DeepSeek-V3.2
Processing GGUF: Trendyol/Trendyol-LLM-Asure-12B
Processing GGUF: AesSedai/Qwen3.5-35B-A3B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: google/translategemma-4b-it
Processing GGUF: nineninesix/kani-tts-2-en
Processing GGUF: meta-llama/Llama-3.1-8B-Instruct
Processing GGUF: Qwen/Qwen2.5-7B-Instruct
Processing GGUF: google/gemma-3n-E4B-it-litert-lm
Processing GGUF: Qwen/Qwen3-0.6B
Processing GGUF: litert-community/Gemma3-1B-IT
Processing GGUF: google/gemma-3n-E2B-it-litert-lm
Processing GGUF: unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: deepseek-ai/DeepSeek-OCR
Processing GGUF: nvidia/Nemotron-Terminal-32B
Processing GGUF: bartowski/Qwen_Qwen3.5-27B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: heretic-org/Nanbeige4.1-3B-heretic
Processing GGUF: dphn/Dolphin-Mistral-24B-Venice-Edition
Processing GGUF: PaddlePaddle/PaddleOCR-VL-1.5
Processing GGUF: CohereLabs/tiny-aya-base
Processing GGUF: google/gemma-3-27b-it
Processing GGUF: Qwen/Qwen3-8B
Processing GGUF: ZJU-AI4H/Hulu-Med-7B
Processing GGUF: Qwen/Qwen3-VL-8B-Instruct
Processing GGUF: LiquidAI/LFM2.5-VL-1.6B
Processing GGUF: Qwen/Qwen3-4B-Instruct-2507
Processing GGUF: google/medgemma-1.5-4b-it
Processing GGUF: inclusionAI/Ring-2.5-1T
Processing GGUF: byteshape/Devstral-Small-2-24B-Instruct-2512-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 8 quants
Processing GGUF: meta-llama/Llama-3.2-3B-Instruct
Processing GGUF: deepseek-ai/DeepSeek-R1
Processing GGUF: google/gemma-3-4b-it
Processing GGUF: unsloth/GLM-5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: ZJU-AI4H/Hulu-Med-4B
Processing GGUF: LiquidAI/LFM2.5-1.2B-Instruct
Processing GGUF: GitMylo/nsfwvision-qwen3-vl-8b-v3-safetensors
Processing GGUF: GadflyII/Qwen3-Coder-Next-NVFP4
Processing GGUF: AIDC-AI/Ovis2.6-30B-A3B
Processing GGUF: tokyotech-llm/GPT-OSS-Swallow-20B-RL-v0.1
Processing GGUF: meta-llama/Meta-Llama-3-8B
Processing GGUF: Qwen/Qwen2.5-Coder-7B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: cublya/GPT-OSS-Code-Reasoning-20B
Processing GGUF: Qwen/Qwen3-Coder-Next-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: AesSedai/Qwen3.5-122B-A10B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: cyankiwi/Qwen3.5-122B-A10B-AWQ-4bit
Processing GGUF: meta-llama/Llama-3.1-8B
Processing GGUF: google/gemma-3-1b-it
Processing GGUF: LiquidAI/LFM2-8B-A1B
Processing GGUF: Qwen/Qwen3-VL-2B-Instruct
Processing GGUF: p-e-w/gemma-3-12b-it-heretic
Processing GGUF: openbmb/MiniCPM-SALA
Processing GGUF: bknyaz/Qwen3-Coder-Next-REAM
Processing GGUF: cyankiwi/Qwen3.5-35B-A3B-AWQ-4bit
Processing GGUF: coder3101/Qwen3.5-27B-heretic
Processing GGUF: rednote-hilab/dots.ocr
Processing GGUF: deepseek-ai/DeepSeek-V3.2-Exp
Processing GGUF: lightonai/LightOnOCR-1B-1025
Processing GGUF: MBZUAI/MedMO-4B
Processing GGUF: tokyotech-llm/GPT-OSS-Swallow-120B-RL-v0.1
Processing GGUF: nvidia/Nemotron-Terminal-8B
Processing GGUF: Ex0bit/Kimi-K2.5-PRISM-REAP-530B-A32B
Processing GGUF: cerebras/MiniMax-M2.5-REAP-139B-A10B
Processing GGUF: meta-llama/Llama-3.3-70B-Instruct
Processing GGUF: google/medgemma-4b-it
Processing GGUF: Qwen/Qwen3-4B-Thinking-2507
Processing GGUF: microsoft/VibeVoice-1.5B
Processing GGUF: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16
Processing GGUF: tencent/HY-MT1.5-1.8B
Processing GGUF: PrimeIntellect/INTELLECT-3.1
Processing GGUF: teapotai/tinyteapot
Processing GGUF: Qwen/Qwen3-Coder-Next-FP8
Processing GGUF: zai-org/GLM-5-FP8
Processing GGUF: lm-provers/QED-Nano
Processing GGUF: Amshaker/Mobile-O-0.5B-iOS
Processing GGUF: ubergarm/Qwen3.5-397B-A17B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: NoesisLab/Spartacus-1B-Instruct
Processing GGUF: vincentkaufmann/gpt-oss-20b-vision-preview
Processing GGUF: meta-llama/Llama-3.2-1B
Processing GGUF: Qwen/Qwen2.5-VL-3B-Instruct
Processing GGUF: microsoft/bitnet-b1.58-2B-4T
Processing GGUF: Qwen/Qwen3-30B-A3B-Instruct-2507
Processing GGUF: MiniMaxAI/MiniMax-M2.1
Processing GGUF: zai-org/GLM-4.7
Processing GGUF: DMindAI/DMind-3
Processing GGUF: bharatgenai/Param2-17B-A2.4B-Thinking
Processing GGUF: trillionlabs/Tri-21B-Think
Processing GGUF: kristaller486/dots.ocr-1.5
Processing GGUF: z-lab/gpt-oss-20b-DFlash
Processing GGUF: cerebras/MiniMax-M2.5-REAP-172B-A10B
Processing GGUF: mradermacher/Qwen3.5-27B-heretic-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 13 quants
Processing GGUF: TinyLlama/TinyLlama-1.1B-Chat-v1.0
Processing GGUF: sarvamai/sarvam-m
Processing GGUF: UCSB-SURFI/VulnLLM-R-7B
Processing GGUF: Qwen/Qwen3-Next-80B-A3B-Instruct
Processing GGUF: ByteDance/Ouro-2.6B-Thinking
Processing GGUF: nvidia/Nemotron-Orchestrator-8B
Processing GGUF: unsloth/Nemotron-3-Nano-30B-A3B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: google/translategemma-27b-it
Processing GGUF: arcee-ai/Trinity-Large-Preview
Processing GGUF: nvidia/Kimi-K2.5-NVFP4
Processing GGUF: Amshaker/Mobile-O-1.5B
Processing GGUF: CohereLabs/tiny-aya-fire
Processing GGUF: KaraKaraWitch/Golddiamondgold-Paperbliteration-L33-70b
Processing GGUF: MultiverseComputingCAI/Hypernova-60B-2602
Processing GGUF: bartowski/Qwen_Qwen3.5-35B-A3B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: cyankiwi/Qwen3.5-27B-AWQ-BF16-INT4
Processing GGUF: mistralai/Mistral-7B-Instruct-v0.2
Processing GGUF: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
Processing GGUF: google/gemma-3-12b-it
Processing GGUF: Qwen/Qwen3-14B
Processing GGUF: Qwen/Qwen3-Embedding-0.6B
Processing GGUF: Qwen/Qwen3-Embedding-8B
Processing GGUF: Qwen/Qwen3-Coder-30B-A3B-Instruct
Processing GGUF: moonshotai/Kimi-K2-Instruct-0905
Processing GGUF: moondream/moondream3-preview
Processing GGUF: Qwen/Qwen3-VL-4B-Instruct
Processing GGUF: PaddlePaddle/PaddleOCR-VL
Processing GGUF: ArliAI/gpt-oss-120b-Derestricted
Processing GGUF: TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill
Processing GGUF: neuphonic/neutts-nano-german
Processing GGUF: Amshaker/Mobile-O-0.5B
Processing GGUF: Shaligram-Dewangan/Dhi-5B-Base
Processing GGUF: CohereLabs/tiny-aya-water
Processing GGUF: prithivMLmods/Qwen3-VL-8B-Instruct-Unredacted-MAX
Processing GGUF: darkc0de/XORTRON.CriminalComputing.LARGE.2026.3
Processing GGUF: huihui-ai/Huihui-Kimi-K2.5-BF16-abliterated-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: MBZUAI/MedMO-8B-Next
Processing GGUF: cyankiwi/Qwen3.5-27B-AWQ-4bit
Processing GGUF: atbender/Qwen3.5-REAP-212B-A17B-W4A16
Processing GGUF: QuantTrio/Qwen3.5-122B-A10B-AWQ
Processing GGUF: brayniac/Qwen3.5-35B-A3B-heretic
Processing GGUF: meta-llama/Llama-2-7b
Processing GGUF: meta-llama/Llama-2-7b-chat-hf
Processing GGUF: meta-llama/Meta-Llama-3-8B-Instruct
Processing GGUF: google/gemma-2-2b-it
Processing GGUF: Qwen/Qwen2.5-Coder-7B-Instruct
Processing GGUF: Qwen/Qwen2.5-1.5B-Instruct
Processing GGUF: meta-llama/Llama-3.2-1B-Instruct
Processing GGUF: google/gemma-3-12b-it-qat-q4_0-unquantized
Processing GGUF: Qwen/Qwen3-32B
Processing GGUF: google/medgemma-27b-it
Processing GGUF: unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Qwen/Qwen3-30B-A3B-Thinking-2507
Processing GGUF: inference-net/Schematron-3B
Processing GGUF: ytu-ce-cosmos/Turkish-Gemma-9b-T1
Processing GGUF: allenai/olmOCR-2-7B-1025-FP8
Processing GGUF: google/functiongemma-270m-it
Processing GGUF: Qwen/Qwen3-VL-32B-Instruct
Processing GGUF: datalab-to/chandra
Processing GGUF: moonshotai/Kimi-K2-Thinking
Processing GGUF: nvidia/NVIDIA-Nemotron-Parse-v1.1
Processing GGUF: bartowski/kldzj_gpt-oss-120b-heretic-v2-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: deepseek-ai/DeepSeek-V3.2-Speciale
Processing GGUF: nvidia/Qwen3-Next-80B-A3B-Thinking-NVFP4
Processing GGUF: Qwen/Qwen3-VL-Embedding-2B
Processing GGUF: rootsautomation/GutenOCR-3B
Processing GGUF: unsloth/Kimi-K2.5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: meituan-longcat/LongCat-Flash-Lite
Processing GGUF: bullpoint/Qwen3-Coder-Next-AWQ-4bit
Processing GGUF: inclusionAI/UI-Venus-1.5-2B
Processing GGUF: mratsim/MiniMax-M2.5-BF16-INT4-AWQ
Processing GGUF: prithivMLmods/Qwen3-VL-4B-Instruct-Unredacted-MAX
Processing GGUF: LiquidAI/LFM2-24B-A2B-ONNX
Processing GGUF: NexaAI/LFM2-24B-A2B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 7 quants
Processing GGUF: EliasOenal/MiniMax-M2.5-Hybrid-AWQ-W4A16G128-Attn-fp8_e4m3-KV-fp8_e4m3
Processing GGUF: LiquidAI/LFM2-24B-A2B-MLX-8bit
Processing GGUF: bartowski/Qwen_Qwen3.5-122B-A10B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: mlx-community/Qwen3.5-27B-4bit
Processing GGUF: internlm/Spatial-SSRL-3B
Processing GGUF: microsoft/Florence-2-large
Processing GGUF: google/gemma-2-9b-it
Processing GGUF: meta-llama/Llama-3.2-3B
Processing GGUF: sarvamai/sarvam-1
Processing GGUF: deepseek-ai/DeepSeek-R1-Distill-Llama-70B
Processing GGUF: Qwen/Qwen2.5-VL-7B-Instruct
Processing GGUF: meta-llama/Llama-4-Scout-17B-16E-Instruct
Processing GGUF: unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: DeepHat/DeepHat-V1-7B
Processing GGUF: Qwen/Qwen3-4B
Processing GGUF: meta-llama/Llama-Prompt-Guard-2-86M
Processing GGUF: google/medgemma-27b-text-it
Processing GGUF: sarvamai/sarvam-translate
Processing GGUF: unsloth/Qwen3-30B-A3B-Thinking-2507-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: PleIAs/Baguettotron
Processing GGUF: jinaai/jina-vlm
Processing GGUF: ServiceNow-AI/Apriel-1.6-15b-Thinker
Processing GGUF: DavidAU/Llama3.3-8B-Instruct-Thinking-Claude-4.5-Opus-High-Reasoning
Processing GGUF: DMindAI/DMind-3-mini
Processing GGUF: google/translategemma-12b-it
Processing GGUF: tokyotech-llm/GPT-OSS-Swallow-20B-SFT-v0.1
Processing GGUF: tokyotech-llm/Qwen3-Swallow-30B-A3B-RL-v0.2
Processing GGUF: lovedheart/Qwen3-Coder-Next-REAP-40B-A3B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: MBZUAI/MedMO-8B
Processing GGUF: Aratako/MioTTS-0.1B
Processing GGUF: bartowski/huihui-ai_Qwen3-Coder-Next-abliterated-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: TeichAI/LFM2.5-1.2B-Thinking-Pony-Alpha-Distill
Processing GGUF: arcee-ai/Trinity-Large-Preview-W4A16
Processing GGUF: ubergarm/MiniMax-M2.5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: nvidia/music-flamingo-think-2601-hf
Processing GGUF: cyankiwi/Qwen3-Coder-Next-REAM-AWQ-4bit
Processing GGUF: DarkArtsForge/Magistaroth-24B-v1
Processing GGUF: 0xSero/Kimi-K2.5-PRISM-REAP-72
Processing GGUF: embedl/Cosmos-Reason2-2B-W4A16-Edge2
Processing GGUF: mmnga-o/Qwen3.5-REAP-212B-A17B-gguf
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: unsloth/Qwen3.5-35B-A3B-Base
Processing GGUF: lmstudio-community/Qwen3.5-35B-A3B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 3 quants
Processing GGUF: noctrex/Qwen3.5-122B-A10B-MXFP4_MOE-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: ValiantLabs/Qwen3.5-27B-Esper3.1
Processing GGUF: QuantTrio/Qwen3.5-35B-A3B-AWQ
Processing GGUF: tvall43/Qwen3.5-35B-A3B-heretic-mxfp4-gguf
  -> Failed to summarize README: Request timed out.
  -> Added with 3 quants
Processing GGUF: mradermacher/Qwen3.5-35B-A3B-heretic-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 11 quants
Processing GGUF: meta-llama/Llama-3.1-405B
Processing GGUF: meta-llama/Prompt-Guard-86M
Processing GGUF: Qwen/Qwen2.5-14B-Instruct
Processing GGUF: Qwen/Qwen2.5-32B-Instruct
Processing GGUF: Qwen/Qwen2.5-Coder-32B-Instruct
Processing GGUF: DavidAU/Maximizing-Model-Performance-All-Quants-Types-And-Full-Precision-by-Samplers_Parameters
Processing GGUF: deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
Processing GGUF: humain-ai/ALLaM-7B-Instruct-preview
Processing GGUF: GSAI-ML/LLaDA-8B-Instruct
Processing GGUF: meta-llama/Llama-Guard-4-12B
Processing GGUF: google/gemma-3n-E4B-it
Processing GGUF: LiquidAI/LFM2-350M
Processing GGUF: google/gemma-3-270m
Processing GGUF: NousResearch/Hermes-4-14B
Processing GGUF: allenai/Olmo-3-1025-7B
Processing GGUF: ibm-granite/granite-4.0-h-small
Processing GGUF: tencent/HunyuanImage-3.0
Processing GGUF: deepseek-ai/DeepSeek-V3.2-Exp-Base
Processing GGUF: Qwen/Qwen3-VL-30B-A3B-Instruct
Processing GGUF: huihui-ai/Huihui-Qwen3-VL-8B-Instruct-abliterated
Processing GGUF: kenpath/svara-tts-v1
Processing GGUF: Nanbeige/Nanbeige4-3B-Base
Processing GGUF: EssentialAI/rnj-1
Processing GGUF: p-e-w/Qwen3-4B-Instruct-2507-heretic
Processing GGUF: p-e-w/gpt-oss-20b-heretic
Processing GGUF: arcee-ai/Trinity-Nano-Preview
Processing GGUF: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-FP8
Processing GGUF: zai-org/AutoGLM-Phone-9B
Processing GGUF: nvidia/Qwen3-Next-80B-A3B-Instruct-NVFP4
Processing GGUF: nvidia/Cosmos-Reason2-8B
Processing GGUF: nvidia/Cosmos-Reason2-2B
Processing GGUF: allenai/Molmo2-8B
Processing GGUF: XiaomiMiMo/MiMo-V2-Flash
Processing GGUF: DMindAI/DMind-3-nano
Processing GGUF: unsloth/GLM-4.7-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Alibaba-Apsara/DASD-4B-Thinking
Processing GGUF: allura-forge/Llama-3.3-8B-Instruct
Processing GGUF: tencent/Youtu-LLM-2B
Processing GGUF: tokyotech-llm/Qwen3-Swallow-8B-SFT-v0.2
Processing GGUF: Qwen/Qwen3-VL-Embedding-8B
Processing GGUF: stepfun-ai/Step-Audio-R1.1
Processing GGUF: meituan-longcat/LongCat-Flash-Thinking-2601
Processing GGUF: cerebras/GLM-4.7-Flash-REAP-23B-A3B
Processing GGUF: Qwen/Qwen3-Coder-Next-Base
Processing GGUF: cyberagent/CAT-Translate-1.4b
Processing GGUF: GadflyII/GLM-4.7-Flash-MTP-NVFP4
Processing GGUF: unsloth/GLM-OCR
Processing GGUF: nineninesix/kani-tts-2-pt
Processing GGUF: huihui-ai/Huihui-Qwen3-Coder-Next-abliterated
Processing GGUF: inclusionAI/LLaDA2.1-mini
Processing GGUF: Aratako/MioTTS-2.6B
Processing GGUF: embedl/Cosmos-Reason2-2B-W4A16
Processing GGUF: Xlnk/ruvltra-claude-code
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: OccultAI/Morpheus-8B-v1
Processing GGUF: CohereLabs/tiny-aya-earth
Processing GGUF: ubergarm/GLM-5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: LiquidAI/LFM2-24B-A2B-MLX-4bit
Processing GGUF: tomngdev/MiniMax-M2.5-REAP-139B-A10B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Aimin12/Qwen3-4B-Thinking-2507-Distill-Claude-Opus-4.6-Reasoning-Abliterated
Processing GGUF: mmnga-o/GPT-OSS-Swallow-20B-RL-v0.1-gguf
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: cyankiwi/Qwen3-Coder-Next-AWQ-8bit
Processing GGUF: mmnga-o/GPT-OSS-Swallow-120B-RL-v0.1-gguf
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Naphula/Meme-Trix-MoE-14B-A8B-v1
Processing GGUF: prithivMLmods/Qwen2.5-VL-32B-Instruct-Unredacted-MAX
Processing GGUF: lokahq/Trinity-Mini-DrugProt-Think
Processing GGUF: Madras1/Qwen2.5-1.5B-Instruct-reasoning-merged
Processing GGUF: OpenMOSE/Qwen3.5-REAP-212B-A17B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: unsloth/Qwen3.5-35B-A3B
Processing GGUF: unsloth/Qwen3.5-27B
Processing GGUF: lmstudio-community/Qwen3.5-27B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 3 quants
Processing GGUF: PicoKittens/PicoMistral-23M
Processing GGUF: cerebras/Step-3.5-Flash-REAP-149B-A11B
Processing GGUF: cerebras/Step-3.5-Flash-REAP-121B-A11B
Processing GGUF: cyankiwi/Qwen3.5-35B-A3B-AWQ-8bit
Processing GGUF: zerdovzad/Nord-AI
Processing GGUF: Salesforce/blip-image-captioning-base
Processing GGUF: bigcode/starcoder
Processing GGUF: meta-llama/Llama-2-7b-hf
Processing GGUF: deepseek-ai/deepseek-coder-6.7b-instruct
Processing GGUF: meta-llama/LlamaGuard-7b
Processing GGUF: Qwen/Qwen1.5-MoE-A2.7B-Chat
Processing GGUF: microsoft/Phi-3-mini-4k-instruct
Processing GGUF: deepseek-ai/DeepSeek-V2-Lite
Processing GGUF: dphn/dolphin-2.9.3-mistral-7B-32k
Processing GGUF: google/gemma-2-2b
Processing GGUF: meta-llama/Llama-3.1-70B-Instruct
Processing GGUF: NousResearch/Hermes-3-Llama-3.1-8B
Processing GGUF: Qwen/Qwen2-VL-7B-Instruct
Processing GGUF: Qwen/Qwen2.5-0.5B
Processing GGUF: Qwen/Qwen2.5-0.5B-Instruct
Processing GGUF: Qwen/Qwen2.5-72B-Instruct
Processing GGUF: Qwen/Qwen2.5-3B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Qwen/Qwen2.5-7B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Qwen/Qwen2.5-14B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: meta-llama/Llama-3.2-11B-Vision-Instruct
Processing GGUF: ai4bharat/indic-parler-tts
Processing GGUF: HuggingFaceTB/SmolLM2-1.7B-Instruct
Processing GGUF: Qwen/Qwen2.5-Coder-14B
Processing GGUF: dphn/Dolphin3.0-Llama3.1-8B
Processing GGUF: bartowski/DeepSeek-R1-Distill-Qwen-32B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: microsoft/Phi-4-multimodal-instruct
Processing GGUF: Qwen/QwQ-32B
Processing GGUF: mlabonne/gemma-3-27b-it-abliterated
Processing GGUF: canopylabs/orpheus-3b-0.1-ft
Processing GGUF: meta-llama/Llama-4-Maverick-17B-128E-Instruct
Processing GGUF: ByteDance-Seed/UI-TARS-1.5-7B
Processing GGUF: Qwen/Qwen3-1.7B
Processing GGUF: Qwen/Qwen3-30B-A3B
Processing GGUF: Qwen/Qwen3-0.6B-Base
Processing GGUF: unsloth/Qwen3-8B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 25 quants
Processing GGUF: Qwen/Qwen3-4B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 5 quants
Processing GGUF: Qwen/Qwen3-Reranker-0.6B
Processing GGUF: Qwen/Qwen3-Embedding-0.6B-GGUF
Processing GGUF: google/gemma-3n-E2B-it
Processing GGUF: moonshotai/Kimi-VL-A3B-Thinking-2506
Processing GGUF: microsoft/Phi-tiny-MoE-instruct
Processing GGUF: Trendyol/Trendyol-LLM-8B-T1
Processing GGUF: trillionlabs/Tri-21B
Processing GGUF: Qwen/Qwen3-Coder-480B-A35B-Instruct
Processing GGUF: unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: numind/NuMarkdown-8B-Thinking
Processing GGUF: Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8
Processing GGUF: unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: unsloth/GLM-4.5-Air-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Qwen/Qwen3-4B-Instruct-2507-FP8
Processing GGUF: unsloth/Qwen3-4B-Thinking-2507-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 27 quants
Processing GGUF: CohereLabs/command-a-reasoning-08-2025
Processing GGUF: nvidia/NVIDIA-Nemotron-Nano-9B-v2
Processing GGUF: Qwen/Qwen3-Next-80B-A3B-Thinking
Processing GGUF: nvidia/Qwen3-32B-NVFP4
Processing GGUF: opendatalab/MinerU2.5-2509-1.2B
Processing GGUF: openai/gpt-oss-safeguard-20b
Processing GGUF: Qwen/Qwen3-Next-80B-A3B-Instruct-FP8
Processing GGUF: Qwen/Qwen3-Next-80B-A3B-Thinking-FP8
Processing GGUF: LiquidAI/LFM2-2.6B
Processing GGUF: nineninesix/kani-tts-370m
Processing GGUF: nota-ai/ERGO-7B
Processing GGUF: Qwen/Qwen3-VL-8B-Instruct-FP8
Processing GGUF: FlareRebellion/WeirdCompound-v1.7-24b
Processing GGUF: ByteDance/Ouro-2.6B
Processing GGUF: moonshotai/Kimi-Linear-48B-A3B-Instruct
Processing GGUF: fdtn-ai/Foundation-Sec-8B-Reasoning
Processing GGUF: huihui-ai/Huihui-Qwen3-VL-30B-A3B-Thinking-abliterated
Processing GGUF: Cannae-AI/MedicalLlama3.2-vision-11B-IT
Processing GGUF: TeichAI/Qwen3-30B-A3B-Thinking-2507-Claude-4.5-Sonnet-High-Reasoning-Distill-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: allenai/Olmo-3-7B-Think
Processing GGUF: neuphonic/neutts-nano
Processing GGUF: internlm/Spatial-SSRL-Qwen3VL-4B
Processing GGUF: deepseek-ai/DeepSeek-Math-V2
Processing GGUF: zai-org/GLM-4.6V
Processing GGUF: mradermacher/Qwen3-4B-Thinking-2507-Claude-4.5-Opus-High-Reasoning-Distill-Heretic-Abliterated-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 12 quants
Processing GGUF: TeichAI/Qwen3-14B-Claude-4.5-Opus-High-Reasoning-Distill
Processing GGUF: nvidia/Nemotron-Cascade-8B
Processing GGUF: SebastianBodza/MiraToffel_miraTTS_german
Processing GGUF: tencent/HY-MT1.5-1.8B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 3 quants
Processing GGUF: MultiverseComputingCAI/HyperNova-60B
Processing GGUF: LiquidAI/LFM2.5-1.2B-JP
Processing GGUF: LiquidAI/LFM2.5-1.2B-Base
Processing GGUF: voyageai/voyage-4-nano
Processing GGUF: LiquidAI/LFM2.5-Audio-1.5B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 9 quants
Processing GGUF: Qwen/Qwen3-VL-Reranker-8B
Processing GGUF: DavidAU/Mistral-Nemo-2407-12B-Thinking-Claude-Gemini-GPT5.2-Uncensored-HERETIC
Processing GGUF: bakrianoo/arabic-legal-documents-ocr-1.0
Processing GGUF: openbmb/AgentCPM-Report
Processing GGUF: janhq/Jan-v3-4B-base-instruct
Processing GGUF: mlx-community/GLM-4.7-Flash-8bit
Processing GGUF: cyankiwi/GLM-4.7-Flash-AWQ-4bit
Processing GGUF: huihui-ai/Huihui-GLM-4.7-Flash-abliterated
Processing GGUF: mlx-community/GLM-OCR-bf16
Processing GGUF: inferencerlabs/Qwen3-Coder-Next-MLX-9bit
Processing GGUF: lovedheart/Qwen3-Coder-Next-REAP-48B-A3B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Kilinskiy/Step-3.5-Flash-Ablitirated
Processing GGUF: OmniDimen/OmniDimen-2-20B-Emotion
Processing GGUF: Applied-Innovation-Center/Karnak
Processing GGUF: bartowski/stepfun-ai_Step-3.5-Flash-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: MuXodious/gpt-oss-20b-RichardErkhov-heresy
Processing GGUF: Intel/Qwen3-Coder-Next-int4-AutoRound
Processing GGUF: AudioVisual-Caption/ASID-Captioner-7B
Processing GGUF: Ex0bit/Step-3.5-Flash-PRISM-PRO-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: ysong21/entropy-v1-fp8
Processing GGUF: chhao/Weak-Driven-Learning
Processing GGUF: p-e-w/Qwen3-8B-heretic
Processing GGUF: yanolja/YanoljaNEXT-EEVE-Rosetta-7B-2602
Processing GGUF: mlx-community/Nanbeige4.1-3B-8bit
Processing GGUF: inclusionAI/ZwZ-8B
Processing GGUF: inclusionAI/ZwZ-4B
Processing GGUF: andrevp/MiniCPM-o-4_5-MLX-4bit
Processing GGUF: AesSedai/MiniMax-M2.5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: p-e-w/Qwen3-4B-Instruct-2507-heretic-v2
Processing GGUF: p-e-w/Qwen3-4B-Instruct-2507-heretic-v3-quantized-processing
Processing GGUF: MuXodious/Goetia-24B-v1.3-absolute-heresy
Processing GGUF: clarkkitchen22/Pokemon-Red-Qwen3-80B
Processing GGUF: Intel/MiniMax-M2.5-int4-AutoRound
Processing GGUF: QuantTrio/MiniMax-M2.5-AWQ
Processing GGUF: ggml-org/Qwen3-Coder-Next-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: heretic-org/XortronCriminalComputingConfig-heretic
Processing GGUF: mlx-community/Qwen3.5-397B-A17B-4bit
Processing GGUF: MuXodious/Luna-7B-A4B-absolute-heresy
Processing GGUF: AesSedai/Qwen3.5-397B-A17B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: mratsim/MiniMax-M2.5-FP8-INT4-AWQ
Processing GGUF: cashxout/Qwen3-30B-A3B-Claude-4.5-Opus-High-Reasoning-2507-ABLITERATED-UNCENSORED-V2
Processing GGUF: bartowski/Qwen_Qwen3.5-397B-A17B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: vincentzed-hf/Qwen3.5-397B-A17B-NVFP4
Processing GGUF: puwaer/Qwen3-Next-80B-A3B-Thinking-GRPO-Uncensored
Processing GGUF: mradermacher/Qwen3-4B-Thinking-2509-Genius-Coder-AI-Full-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 12 quants
Processing GGUF: nvidia/Nemotron-Terminal-14B
Processing GGUF: jinaai/jina-embeddings-v5-text-small-retrieval-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 14 quants
Processing GGUF: LiquidAI/LFM2-24B-A2B-MLX-6bit
Processing GGUF: DavidAU/ERNIE-21B-A3B-Thinking-Gemini-3-Pro-High-Reasoning-V2
Processing GGUF: skyblanket/GLM-5-abliterated
Processing GGUF: heretic-org/gemma-3-4b-it-heretic
Processed 18 GGUF models from page 1
Reached end of available models.

=== Processing pinned GGUF models ===
Processing pinned GGUF: janhq/Jan-v3-4B-base-instruct-gguf
  -> Added pinned GGUF model
Processing pinned GGUF: janhq/Jan-v2-VL-med-gguf
  -> Added pinned GGUF model
Processing pinned GGUF: janhq/Jan-v2-VL-high-gguf
  -> Added pinned GGUF model
Processing pinned GGUF: janhq/Qwen3.5-35B-A3B-GGUF
  -> Added pinned GGUF model
Processing pinned GGUF: unsloth/Olmo-3-7B-Instruct-GGUF
  -> Added pinned GGUF model
Processing pinned GGUF: unsloth/Olmo-3-7B-Think-GGUF
  -> Added pinned GGUF model
Processing pinned GGUF: unsloth/Olmo-3-32B-Think-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing pinned GGUF: Menlo/Jan-nano-128k-gguf
  -> Added pinned GGUF model

Total GGUF models: 117

=== Fetching MLX models from HuggingFace API ===
Fetching models from author: mlx-community
Found 100 models from mlx-community
Processing MLX: mlx-community/whisper-small-mlx
Processing MLX: mlx-community/whisper-large-v3-mlx
Processing MLX: mlx-community/whisper-medium-mlx
Processing MLX: mlx-community/Llama-2-7b-chat-mlx

=== Processing pinned MLX models ===
Processing pinned MLX: mlx-community/Jan-v3-4B-base-instruct-4bit
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-high-4bit-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-high-8bit-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-high-bf16-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-med-4bit-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-med-8bit-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-med-bf16-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-low-4bit-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-low-8bit-mlx
  -> Added pinned MLX model
Processing pinned MLX: janhq/Jan-v2-VL-low-bf16-mlx
  -> Added pinned MLX model
Total MLX models: 106

=== Removing duplicates ===
After dedup: 215 models

=== V2 Catalog Summary ===
Total models: 215
  - GGUF models: 109
  - MLX models: 106
Written to: model_catalog_v2.json

Updated catalog; total now 215 (GGUF: 109, MLX: 106)
