Loaded 184 existing entries from model_catalog_v2.json

=== Fetching GGUF models from HuggingFace API ===
Fetching page 1...
Processing GGUF: zai-org/GLM-OCR
Processing GGUF: moonshotai/Kimi-K2.5
Processing GGUF: Qwen/Qwen3-Coder-Next
Processing GGUF: zai-org/GLM-5
Processing GGUF: stepfun-ai/Step-3.5-Flash
Processing GGUF: unsloth/Qwen3-Coder-Next-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: internlm/Intern-S1-Pro
Processing GGUF: inference-net/Schematron-3B
Processing GGUF: Qwen/Qwen3-Coder-Next-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Nanbeige/Nanbeige4.1-3B
Processing GGUF: zai-org/GLM-4.7-Flash
Processing GGUF: openbmb/MiniCPM-SALA
Processing GGUF: UCSB-SURFI/VulnLLM-R-7B
Processing GGUF: FutureMa/Eva-4B-V2
Processing GGUF: deepseek-ai/DeepSeek-OCR-2
Processing GGUF: PaddlePaddle/PaddleOCR-VL-1.5
Processing GGUF: ytu-ce-cosmos/Turkish-Gemma-9b-T1
Processing GGUF: stepfun-ai/Step-3.5-Flash-GGUF-Q4_K_S
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: meta-llama/Llama-3.1-8B-Instruct
Processing GGUF: Qwen/Qwen3-Coder-Next-FP8
Processing GGUF: openai/gpt-oss-20b
Processing GGUF: MiniMaxAI/MiniMax-M2.1
Processing GGUF: Qwen/Qwen3-Coder-Next-Base
Processing GGUF: unsloth/GLM-4.7-Flash-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: zai-org/GLM-4.7
Processing GGUF: lightonai/LightOnOCR-2-1B
Processing GGUF: openai/gpt-oss-120b
Processing GGUF: trillionlabs/gWorld-8B
Processing GGUF: inclusionAI/LLaDA2.1-mini
Processing GGUF: Qwen/Qwen3-VL-8B-Instruct
Processing GGUF: unsloth/Kimi-K2.5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-NVFP4
Processing GGUF: lovedheart/Qwen3-Coder-Next-REAP-48B-A3B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: google/medgemma-1.5-4b-it
Processing GGUF: unsloth/GLM-5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: zai-org/GLM-5-FP8
Processing GGUF: Qwen/Qwen3-0.6B
Processing GGUF: meituan-longcat/LongCat-Flash-Lite
Processing GGUF: inclusionAI/LLaDA2.1-flash
Processing GGUF: ACE-Step/acestep-5Hz-lm-4B
Processing GGUF: nvidia/Kimi-K2.5-NVFP4
Processing GGUF: LGAI-EXAONE/EXAONE-4.0-1.2B
Processing GGUF: unsloth/Qwen3-Coder-Next-FP8-Dynamic
Processing GGUF: google/gemma-3-4b-it
Processing GGUF: Qwen/Qwen3-8B
Processing GGUF: TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill
Processing GGUF: LiquidAI/LFM2.5-1.2B-Instruct
Processing GGUF: Qwen/Qwen3-4B-Instruct-2507
Processing GGUF: voyageai/voyage-4-nano
Processing GGUF: google/translategemma-4b-it
Processing GGUF: google/functiongemma-270m-it
Processing GGUF: deepseek-ai/DeepSeek-V3.2
Processing GGUF: arcee-ai/Trinity-Large-Preview
Processing GGUF: Hcompany/Holo2-235B-A22B
Processing GGUF: Qwen/Qwen3-Coder-30B-A3B-Instruct
Processing GGUF: unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: trillionlabs/gWorld-32B
Processing GGUF: huihui-ai/Huihui-Qwen3-Coder-Next-abliterated
Processing GGUF: meta-llama/Llama-3.2-3B-Instruct
Processing GGUF: google/gemma-3n-E4B-it-litert-lm
Processing GGUF: ubergarm/Step-3.5-Flash-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Qwen/Qwen2.5-7B-Instruct
Processing GGUF: numind/NuMarkdown-8B-Thinking
Processing GGUF: unsloth/gpt-oss-20b-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 16 quants
Processing GGUF: LiquidAI/LFM2.5-1.2B-Thinking
Processing GGUF: tencent/Youtu-VL-4B-Instruct
Processing GGUF: concavity-ai/superlinear-exp-v0.1
Processing GGUF: deepseek-ai/DeepSeek-OCR
Processing GGUF: stepfun-ai/Step-3.5-Flash-FP8
Processing GGUF: microsoft/bitnet-b1.58-2B-4T
Processing GGUF: google/gemma-3n-E2B-it-litert-lm
Processing GGUF: nvidia/Cosmos-Reason2-8B
Processing GGUF: Qwen/Qwen3-VL-Embedding-2B
Processing GGUF: stepfun-ai/Step3-VL-10B
Processing GGUF: bakrianoo/arabic-legal-documents-ocr-1.0
Processing GGUF: Qwen/Qwen2.5-Coder-7B-Instruct
Processing GGUF: google/gemma-3-27b-it
Processing GGUF: Qwen/Qwen3-Embedding-8B
Processing GGUF: Qwen/Qwen3-VL-2B-Instruct
Processing GGUF: Qwen/Qwen3-VL-Embedding-8B
Processing GGUF: deepseek-ai/DeepSeek-R1
Processing GGUF: PaddlePaddle/PaddleOCR-VL
Processing GGUF: fdtn-ai/Foundation-Sec-8B-Reasoning
Processing GGUF: nvidia/music-flamingo-2601-hf
Processing GGUF: LiquidAI/LFM2.5-VL-1.6B
Processing GGUF: SicariusSicariiStuff/Assistant_Pepe_8B
Processing GGUF: inclusionAI/UI-Venus-1.5-8B
Processing GGUF: meta-llama/Llama-3.2-1B
Processing GGUF: litert-community/Gemma3-1B-IT
Processing GGUF: google/medgemma-4b-it
Processing GGUF: openbmb/MiniCPM-V-4_5
Processing GGUF: moonshotai/Kimi-K2-Thinking
Processing GGUF: nvidia/Qwen3-Next-80B-A3B-Thinking-NVFP4
Processing GGUF: google/translategemma-27b-it
Processing GGUF: koute/GLM-4.7-Flash-Derestricted
Processing GGUF: unsloth/GLM-OCR
Processing GGUF: inclusionAI/UI-Venus-1.5-30B-A3B
Processing GGUF: meta-llama/Llama-3.1-8B
Processing GGUF: meta-llama/Llama-3.2-1B-Instruct
Processing GGUF: meta-llama/Llama-3.3-70B-Instruct
Processing GGUF: p-e-w/gemma-3-12b-it-heretic
Processing GGUF: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16
Processing GGUF: ekwek/Soprano-1.1-80M
Processing GGUF: inclusionAI/UI-Venus-1.5-2B
Processing GGUF: meta-llama/Meta-Llama-3-8B
Processing GGUF: ByteDance-Seed/UI-TARS-1.5-7B
Processing GGUF: ibm-granite/granite-docling-258M
Processing GGUF: Alibaba-Apsara/DASD-4B-Thinking
Processing GGUF: unsloth/MiniMax-M2.1-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: unsloth/Qwen3-Coder-Next
Processing GGUF: GadflyII/Qwen3-Coder-Next-NVFP4
Processing GGUF: Qwen/Qwen3-32B
Processing GGUF: Qwen/Qwen3-Embedding-0.6B
Processing GGUF: dphn/Dolphin-Mistral-24B-Venice-Edition
Processing GGUF: rednote-hilab/dots.ocr
Processing GGUF: microsoft/VibeVoice-1.5B
Processing GGUF: cyankiwi/Qwen3-Coder-Next-AWQ-4bit
Processing GGUF: Aratako/MioTTS-2.6B
Processing GGUF: google/medgemma-27b-it
Processing GGUF: Qwen/Qwen3-30B-A3B-Instruct-2507
Processing GGUF: Qwen/Qwen3-VL-4B-Instruct
Processing GGUF: datalab-to/chandra
Processing GGUF: ibm-granite/granite-vision-3.3-2b-chart2csv-preview
Processing GGUF: DavidAU/gemma-3-12b-it-vl-GLM-4.7-Flash-Heretic-Uncensored-Thinking
Processing GGUF: lovedheart/Qwen3-Coder-Next-REAP-40B-A3B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: unsloth/GLM-5
Processing GGUF: Qwen/Qwen2.5-1.5B-Instruct
Processing GGUF: google/gemma-3-1b-it
Processing GGUF: inference-net/Schematron-8B
Processing GGUF: Qwen/Qwen3-Next-80B-A3B-Instruct
Processing GGUF: huihui-ai/Huihui-Qwen3-VL-8B-Instruct-abliterated
Processing GGUF: Nanbeige/Nanbeige4-3B-Thinking-2511
Processing GGUF: zai-org/GLM-4.6V-Flash
Processing GGUF: unsloth/Nemotron-3-Nano-30B-A3B-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: cerebras/MiniMax-M2.1-REAP-139B-A10B
Processing GGUF: ChengyuDu0123/HER-32B
Processing GGUF: Alibaba-DAMO-Academy/RynnBrain-2B
Processing GGUF: google/gemma-2b-it
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: dphn/Dolphin3.0-Llama3.1-8B
Processing GGUF: deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
Processing GGUF: LiquidAI/LFM2-350M
Processing GGUF: moonshotai/Kimi-Linear-48B-A3B-Instruct
Processing GGUF: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-FP8
Processing GGUF: unsloth/GLM-4.7-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Qwen/Qwen3-VL-Reranker-2B
Processing GGUF: unsloth/DeepSeek-V3.2-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: bartowski/Qwen_Qwen3-Coder-Next-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: bartowski/moonshotai_Kimi-Linear-48B-A3B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Aratako/MioTTS-0.1B
Processing GGUF: mistralai/Mistral-7B-Instruct-v0.2
Processing GGUF: Qwen/Qwen2.5-0.5B-Instruct
Processing GGUF: Qwen/Qwen2.5-Coder-7B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Qwen/Qwen2.5-VL-3B-Instruct
Processing GGUF: Qwen/Qwen2.5-VL-7B-Instruct
Processing GGUF: google/gemma-3-12b-it
Processing GGUF: Qwen/Qwen3-1.7B
Processing GGUF: HuggingFaceTB/SmolLM3-3B
Processing GGUF: zai-org/GLM-4.5-Air
Processing GGUF: Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8
Processing GGUF: Qwen/Qwen3-4B-Thinking-2507
Processing GGUF: Qwen/Qwen3-VL-235B-A22B-Thinking
Processing GGUF: tencent/HunyuanImage-3.0
Processing GGUF: maya-research/maya1
Processing GGUF: neuphonic/neutts-nano
Processing GGUF: deepseek-ai/DeepSeek-V3.2-Speciale
Processing GGUF: ServiceNow-AI/Apriel-1.6-15b-Thinker
Processing GGUF: XiaomiMiMo/MiMo-V2-Flash
Processing GGUF: tiiuae/Falcon-H1-Tiny-R-90M
Processing GGUF: trillionlabs/Trida-7B
Processing GGUF: ACE-Step/acestep-5Hz-lm-0.6B
Processing GGUF: unsloth/DeepSeek-OCR-2
Processing GGUF: mlx-community/Kimi-K2.5
Processing GGUF: stepfun-ai/Step3-VL-10B-FP8
Processing GGUF: mlx-community/GLM-OCR-bf16
Processing GGUF: yuliang03181/ConceptLM_Llama3.1_8B
Processing GGUF: microsoft/X-Reasoner-7B
Processing GGUF: mlx-community/Qwen3-Coder-Next-8bit
Processing GGUF: lkevincc0/Step-3.5-Flash-REAP-128B-A11B
Processing GGUF: meta-llama/Llama-2-7b-chat-hf
Processing GGUF: TinyLlama/TinyLlama-1.1B-Chat-v1.0
Processing GGUF: google/paligemma-3b-pt-224
Processing GGUF: Qwen/Qwen2.5-3B-Instruct
Processing GGUF: Qwen/Qwen2.5-Coder-14B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
Processing GGUF: microsoft/Phi-4-multimodal-instruct
Processing GGUF: meta-llama/Llama-4-Scout-17B-16E-Instruct
Processing GGUF: Qwen/Qwen3-14B
Processing GGUF: Qwen/Qwen3-0.6B-Base
Processing GGUF: darkc0de/XortronCriminalComputingConfig
Processing GGUF: fancyfeast/llama-joycaption-beta-one-hf-llava
Processing GGUF: Qwen/Qwen3-Embedding-4B
Processing GGUF: sarvamai/sarvam-translate
Processing GGUF: google/gemma-3n-E2B-it
Processing GGUF: Qwen/Qwen3-235B-A22B-Instruct-2507
Processing GGUF: Qwen/Qwen3-Coder-480B-A35B-Instruct
Processing GGUF: unsloth/gpt-oss-120b-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: facebook/DepthLM
Processing GGUF: Qwen/Qwen3-VL-32B-Instruct
Processing GGUF: MiniMaxAI/MiniMax-M2
Processing GGUF: inclusionAI/LLaDA2.0-flash
Processing GGUF: nvidia/Nemotron-Orchestrator-8B
Processing GGUF: ArliAI/gpt-oss-120b-Derestricted
Processing GGUF: tencent/HY-MT1.5-1.8B
Processing GGUF: DarkArtsForge/Asmodeus-24B-v1
Processing GGUF: miromind-ai/MiroThinker-v1.5-30B
Processing GGUF: z-lab/Qwen3-4B-DFlash-b16
Processing GGUF: openbmb/AgentCPM-Explore
Processing GGUF: tiiuae/Falcon-H1-Tiny-90M-Instruct
Processing GGUF: Naphula/Goetia-24B-v1.3
Processing GGUF: NeuroSenko/Qwen3-Coder-Next-exl3
Processing GGUF: bartowski/stepfun-ai_Step-3.5-Flash-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: vikhyatk/moondream2
Processing GGUF: meta-llama/Meta-Llama-3-8B-Instruct
Processing GGUF: google/gemma-2-2b-it
Processing GGUF: microsoft/Phi-3.5-mini-instruct
Processing GGUF: Qwen/Qwen2.5-72B-Instruct
Processing GGUF: Qwen/Qwen2.5-7B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: meta-llama/Llama-3.2-3B
Processing GGUF: jinaai/ReaderLM-v2
Processing GGUF: microsoft/Phi-4-mini-instruct
Processing GGUF: google/gemma-3-12b-it-qat-q4_0-unquantized
Processing GGUF: Qwen/Qwen3-4B
Processing GGUF: moonshotai/Kimi-K2-Instruct
Processing GGUF: google/gemma-3-270m-it
Processing GGUF: google/gemma-3-270m
Processing GGUF: internlm/Intern-S1-mini
Processing GGUF: apple/FastVLM-0.5B
Processing GGUF: Qwen/Qwen3-VL-235B-A22B-Instruct
Processing GGUF: tiiuae/Falcon-H1R-7B
Processing GGUF: inclusionAI/LLaDA2.0-mini
Processing GGUF: allenai/Olmo-3.1-32B-Think
Processing GGUF: utter-project/EuroMoE-2.6B-A0.6B-Instruct-2512
Processing GGUF: zai-org/GLM-4.7-FP8
Processing GGUF: FunAudioLLM/Fun-Audio-Chat-8B
Processing GGUF: Qwen/Qwen3-VL-Reranker-8B
Processing GGUF: z-lab/Qwen3-Coder-30B-A3B-DFlash
Processing GGUF: google/translategemma-12b-it
Processing GGUF: mlx-community/GLM-4.7-Flash-4bit
Processing GGUF: GadflyII/GLM-4.7-Flash-NVFP4
Processing GGUF: AesSedai/Kimi-K2.5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: ChengyuDu0123/HER-RM-32B
Processing GGUF: yasserrmd/GLM4.7-Distill-LFM2.5-1.2B
Processing GGUF: zakarth/violet-1b4-chat
Processing GGUF: mlx-community/Step-3.5-Flash-4bit
Processing GGUF: togethercomputer/Aurora-Spec-Qwen3-Coder-Next-FP8
Processing GGUF: DavidAU/OpenAI-gpt-oss-20B-Claude-4.5-Opus-Heretic-Uncensored
Processing GGUF: Aratako/MioTTS-1.7B
Processing GGUF: ubergarm/Kimi-K2.5-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: yanolja/YanoljaNEXT-EEVE-Rosetta-7B-2602
Processing GGUF: openai-community/gpt2
Processing GGUF: Salesforce/blip-image-captioning-large
Processing GGUF: mistralai/Mistral-7B-v0.1
Processing GGUF: xai-org/grok-1
Processing GGUF: microsoft/Phi-3-mini-4k-instruct
Processing GGUF: microsoft/Florence-2-large
Processing GGUF: google/gemma-2-9b-it
Processing GGUF: meta-llama/Prompt-Guard-86M
Processing GGUF: Qwen/Qwen2.5-3B
Processing GGUF: ai4bharat/indic-parler-tts
Processing GGUF: Qwen/Qwen2.5-Coder-32B-Instruct
Processing GGUF: OpenSciLM/Llama-3.1_OpenScholar-8B
Processing GGUF: mlabonne/gemma-3-27b-it-abliterated
Processing GGUF: deepseek-ai/DeepSeek-R1-0528-Qwen3-8B
Processing GGUF: ggml-org/gpt-oss-20b-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: Qwen/Qwen3-Next-80B-A3B-Thinking
Processing GGUF: Qwen/Qwen3-VL-30B-A3B-Thinking
Processing GGUF: quwsarohi/NanoAgent-135M
Processing GGUF: Qwen/Qwen3-VL-8B-Thinking
Processing GGUF: General-Medical-AI/UniMedVL
Processing GGUF: ByteDance/Ouro-1.4B
Processing GGUF: ZJU-AI4H/Hulu-Med-4B
Processing GGUF: unsloth/Qwen3-Next-80B-A3B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: utter-project/EuroLLM-22B-Instruct-2512
Processing GGUF: nvidia/Qwen3-Next-80B-A3B-Instruct-NVFP4
Processing GGUF: allenai/Molmo2-8B
Processing GGUF: Tongyi-MAI/MAI-UI-8B
Processing GGUF: mratsim/MiniMax-M2.1-FP8-INT4-AWQ
Processing GGUF: haykgrigorian/TimeCapsuleLLM-v2-llama-1.2B
Processing GGUF: DavidAU/LFM2.5-1.2B-Instruct-Thinking-Claude-High-Reasoning
Processing GGUF: FutureMa/Eva-4B
Processing GGUF: openbmb/AgentCPM-Report
Processing GGUF: huihui-ai/Huihui-GLM-4.7-Flash-abliterated
Processing GGUF: arcee-ai/Trinity-Large-TrueBase
Processing GGUF: Alibaba-DAMO-Academy/RynnBrain-Nav-8B
Processing GGUF: Alibaba-DAMO-Academy/RynnBrain-8B
Processing GGUF: Alibaba-DAMO-Academy/RynnBrain-30B-A3B
Processing GGUF: NbAiLab/borealis-27b-instruct-preview
Processing GGUF: distil-labs/distil-ai-slop-detector-gemma
Processing GGUF: cyberagent/CAT-Translate-1.4b
Processing GGUF: unsloth/Qwen3-Coder-Next-FP8
Processing GGUF: mlx-community/Qwen3-Coder-Next-4bit
Processing GGUF: gss1147/Gemma-3-Prompt-Coder-270m-it-Uncensored
Processing GGUF: Aratako/MioTTS-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 24 quants
Processing GGUF: tsukemono/neuTTS-JP-150m
Processing GGUF: FPHam/Regency-Aghast-27b-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 2 quants
Processing GGUF: Edge-Quant/Nanbeige4.1-3B-Q4_K_M-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: bigscience/bloom
Processing GGUF: bigcode/starcoder2-15b
Processing GGUF: sophosympatheia/Midnight-Miqu-70B-v1.5
Processing GGUF: CohereLabs/c4ai-command-r-plus
Processing GGUF: google/gemma-2-2b
Processing GGUF: inflatebot/MN-12B-Mag-Mell-R1
Processing GGUF: Qwen/Qwen2.5-32B-Instruct
Processing GGUF: HuggingFaceTB/SmolLM2-135M
Processing GGUF: deepseek-ai/DeepSeek-V3
Processing GGUF: HuggingFaceTB/SmolVLM-256M-Instruct
Processing GGUF: reducto/RolmOCR
Processing GGUF: Qwen/Qwen3-30B-A3B
Processing GGUF: unsloth/Qwen3-4B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 26 quants
Processing GGUF: Goekdeniz-Guelmez/Josiefied-Qwen3-8B-abliterated-v1
Processing GGUF: Qwen/Qwen3-0.6B-MLX-4bit
Processing GGUF: deepseek-ai/DeepSeek-R1-0528
Processing GGUF: Qwen/Qwen3-Reranker-0.6B
Processing GGUF: google/gemma-3n-E4B-it
Processing GGUF: zai-org/GLM-4.1V-9B-Thinking
Processing GGUF: internlm/Intern-S1
Processing GGUF: Qwen/Qwen3-30B-A3B-Instruct-2507-FP8
Processing GGUF: Qwen/Qwen3-30B-A3B-Thinking-2507
Processing GGUF: ggml-org/gpt-oss-120b-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: moonshotai/Kimi-K2-Instruct-0905
Processing GGUF: moondream/moondream3-preview
Processing GGUF: Qwen/Qwen3Guard-Gen-8B
Processing GGUF: deepseek-ai/DeepSeek-V3.2-Exp
Processing GGUF: Qwen/Qwen3-VL-235B-A22B-Instruct-FP8
Processing GGUF: DragonLLM/Llama-Open-Finance-8B
Processing GGUF: Qwen/Qwen3-VL-4B-Thinking
Processing GGUF: google/t5gemma-2-270m-270m
Processing GGUF: Nanbeige/Nanbeige4-3B-Base
Processing GGUF: nvidia/NVIDIA-Nemotron-Parse-v1.1
Processing GGUF: unsloth/Qwen3-Next-80B-A3B-Thinking-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: Qwen/Qwen3-Next-80B-A3B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: allenai/Olmo-3.1-32B-Instruct
Processing GGUF: browser-use/bu-30b-a3b-preview
Processing GGUF: LGAI-EXAONE/K-EXAONE-236B-A23B
Processing GGUF: skt/A.X-K1
Processing GGUF: LiquidAI/LFM2.5-1.2B-Base
Processing GGUF: LLM360/K2-Think-V2
Processing GGUF: baichuan-inc/Baichuan-M3-235B
Processing GGUF: ByteDance-Seed/Stable-DiffCoder-8B-Instruct
Processing GGUF: huihui-ai/Huihui-Step3-VL-10B-abliterated
Processing GGUF: janhq/Jan-v3-4B-base-instruct
Processing GGUF: cyankiwi/GLM-4.7-Flash-AWQ-4bit
Processing GGUF: unsloth/GLM-4.7-Flash-FP8-Dynamic
Processing GGUF: nota-ai/Solar-Open-100B-NotaMoEQuant-Int4
Processing GGUF: DavidAU/Gemma3-27B-it-vl-GLM-4.7-Uncensored-Heretic-Deep-Reasoning
Processing GGUF: inferencerlabs/Kimi-K2.5-MLX-3.6bit
Processing GGUF: arcee-ai/Trinity-Large-Base
Processing GGUF: MuXodious/RimDialogue-3B-v1-absolute-heresy
Processing GGUF: Ostrakon/Ostrakon-VL-8B
Processing GGUF: GAIR/daVinci-Agency
Processing GGUF: unsloth/Qwen3-Coder-Next-Base
Processing GGUF: DavidAU/gemma-3-12b-it-vl-Polaris-GLM-4.7-Flash-VAR-Thinking-Instruct-Heretic-Uncensored
Processing GGUF: EZCon/GLM-OCR-4bit-g32-mxfp4-mixed_4_8-mlx
Processing GGUF: hkust-nlp/drkernel-14b
Processing GGUF: nyuuzyou/BadApple-LLaMA-nano
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: bartowski/zerofata_MS3.2-PaintedFantasy-v4-24B-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 27 quants
Processing GGUF: AesSedai/Step-3.5-Flash-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: DavidAU/OpenAI-gpt-oss-20B-GPT5.1-5.2-DISTILL-Heretic-Uncensored-MXFP4
Processing GGUF: WokeAI/Tankie-NB-3B-SFT-v1
Processing GGUF: openai-community/gpt2-large
Processing GGUF: microsoft/trocr-large-handwritten
Processing GGUF: meta-llama/Llama-2-7b-hf
Processing GGUF: BioMistral/BioMistral-7B
Processing GGUF: AI4Chem/ChemLLM-7B-Chat-1_5-DPO
Processing GGUF: aaditya/Llama3-OpenBioLLM-8B
Processing GGUF: microsoft/Phi-3-mini-128k-instruct
Processing GGUF: failspy/llama-3-70B-Instruct-abliterated
Processing GGUF: QuantFactory/NeuralDaredevil-8B-abliterated-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 14 quants
Processing GGUF: Sao10K/L3-8B-Stheno-v3.2
Processing GGUF: deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct
Processing GGUF: meta-llama/Llama-3.1-70B
Processing GGUF: unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit
Processing GGUF: MarinaraSpaghetti/NemoMix-Unleashed-12B
Processing GGUF: Qwen/Qwen2.5-0.5B
Processing GGUF: Qwen/Qwen2.5-14B-Instruct
Processing GGUF: Qwen/Qwen2.5-3B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: AiCloser/Qwen2.5-32B-AGI
Processing GGUF: bartowski/Llama-3.2-1B-Instruct-GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 18 quants
Processing GGUF: sarvamai/sarvam-1
Processing GGUF: HuggingFaceTB/SmolLM2-360M
Processing GGUF: HuggingFaceTB/SmolLM2-1.7B-Instruct
Processing GGUF: Qwen/Qwen2.5-Coder-32B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: unsloth/Llama-3.3-70B-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
Processing GGUF: AlicanKiraz0/Cybersecurity-BaronLLM_Offensive_Security_LLM_Q6_K_GGUF
  -> Failed to summarize README: Request timed out.
  -> Added with 1 quants
Processing GGUF: ByteDance-Seed/UI-TARS-7B-DPO
Processing GGUF: ubaitur5/Ministral-3b-instruct-Q4-mlx
Processing GGUF: Qwen/Qwen2.5-VL-72B-Instruct
Processing GGUF: ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8
  -> Failed to summarize README: Request timed out.
  -> Added with 7 quants
Processing GGUF: huihui-ai/DeepSeek-V3-abliterated
Processing GGUF: unsloth/gemma-3-27b-it-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing GGUF: canopylabs/orpheus-3b-0.1-ft
Processing GGUF: meta-llama/Llama-4-Maverick-17B-128E-Instruct
Processing GGUF: unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processed 13 GGUF models from page 1
Reached end of available models.

=== Processing pinned GGUF models ===
Pinned model janhq/Jan-v3-4B-base-instruct-gguf already in list
Processing pinned GGUF: janhq/Jan-v2-VL-med-gguf
  -> Added pinned GGUF model
Processing pinned GGUF: janhq/Jan-v2-VL-high-gguf
  -> Added pinned GGUF model
Processing pinned GGUF: unsloth/Olmo-3-7B-Instruct-GGUF
  -> Added pinned GGUF model
Processing pinned GGUF: unsloth/Olmo-3-7B-Think-GGUF
  -> Added pinned GGUF model
Processing pinned GGUF: unsloth/Olmo-3-32B-Think-GGUF
  -> Repository contains multi-part GGUF files, skipping
Processing pinned GGUF: Menlo/Jan-nano-128k-gguf
  -> Failed to summarize README: Request timed out.
  -> Added pinned GGUF model

Total GGUF models: 95

=== Fetching MLX models from HuggingFace API ===
Found 100 MLX models
Processing MLX: sentence-transformers/all-MiniLM-L6-v2
  -> Added with 1 safetensors files
Processing MLX: google-bert/bert-base-uncased
  -> Added with 1 safetensors files
Processing MLX: google/electra-base-discriminator
Processing MLX: timm/mobilenetv3_small_100.lamb_in1k
  -> Added with 1 safetensors files
Processing MLX: sentence-transformers/all-mpnet-base-v2
  -> Added with 1 safetensors files
Processing MLX: FacebookAI/roberta-large
  -> Added with 1 safetensors files
Processing MLX: FacebookAI/xlm-roberta-base
  -> Added with 1 safetensors files
Processing MLX: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
  -> Added with 1 safetensors files
Processing MLX: laion/clap-htsat-fused
  -> Added with 1 safetensors files
Processing MLX: openai/clip-vit-base-patch32
Processing MLX: pyannote/wespeaker-voxceleb-resnet34-LM
Processing MLX: colbert-ir/colbertv2.0
  -> Added with 1 safetensors files
Processing MLX: pyannote/segmentation-3.0
Processing MLX: BAAI/bge-m3
Processing MLX: pyannote/speaker-diarization-3.1
Processing MLX: Bingsu/adetailer
Processing MLX: FacebookAI/roberta-base
  -> Added with 1 safetensors files
Processing MLX: openai/clip-vit-large-patch14
  -> Added with 1 safetensors files
Processing MLX: openai-community/gpt2
  -> Added with 1 safetensors files
Processing MLX: cross-encoder/ms-marco-MiniLM-L6-v2
  -> Added with 1 safetensors files
Processing MLX: facebook/contriever
Processing MLX: coqui/XTTS-v2
Processing MLX: distilbert/distilbert-base-uncased
  -> Added with 1 safetensors files
Processing MLX: openai/whisper-large-v3
  -> Added with 3 safetensors files
Processing MLX: hexgrad/Kokoro-82M
Processing MLX: sentence-transformers/paraphrase-multilingual-mpnet-base-v2
  -> Added with 1 safetensors files
Processing MLX: FacebookAI/xlm-roberta-large
  -> Added with 1 safetensors files
Processing MLX: jinaai/jina-embeddings-v3
  -> Failed to summarize README: Request timed out.
  -> Added with 1 safetensors files
Processing MLX: cardiffnlp/twitter-roberta-base-sentiment-latest
Processing MLX: timm/resnet50.a1_in1k
  -> Added with 1 safetensors files
Processing MLX: BAAI/bge-small-en-v1.5
  -> Added with 1 safetensors files
Processing MLX: BAAI/bge-large-en-v1.5
  -> Added with 1 safetensors files
Processing MLX: sentence-transformers/multi-qa-mpnet-base-dot-v1
  -> Added with 1 safetensors files
Processing MLX: timm/mobilenetv3_large_100.ra_in1k
  -> Added with 1 safetensors files
Processing MLX: google-bert/bert-base-multilingual-uncased
  -> Added with 1 safetensors files
Processing MLX: jonatasgrosman/wav2vec2-large-xlsr-53-russian
Processing MLX: facebook/opt-125m
Processing MLX: distilbert/distilbert-base-uncased-finetuned-sst-2-english
  -> Added with 1 safetensors files
Processing MLX: sentence-transformers/LaBSE
  -> Added with 2 safetensors files
Processing MLX: autogluon/chronos-2
  -> Failed to summarize README: Request timed out.
  -> Added with 1 safetensors files
Processing MLX: BAAI/bge-base-en-v1.5
  -> Added with 1 safetensors files
Processing MLX: google/vit-base-patch16-224
  -> Added with 1 safetensors files
Processing MLX: openai/clip-vit-large-patch14-336
Processing MLX: intfloat/multilingual-e5-large
  -> Added with 1 safetensors files
Processing MLX: emilyalsentzer/Bio_ClinicalBERT
Processing MLX: facebook/esmfold_v1
Processing MLX: facebook/bart-large-mnli
  -> Added with 1 safetensors files
Processing MLX: sentence-transformers/all-MiniLM-L12-v2
  -> Added with 1 safetensors files
Processing MLX: argmaxinc/whisperkit-coreml
Processing MLX: sentence-transformers/paraphrase-MiniLM-L6-v2
  -> Added with 1 safetensors files
Processing MLX: ProsusAI/finbert
Processing MLX: google-bert/bert-base-multilingual-cased
  -> Added with 1 safetensors files
Processing MLX: facebook/w2v-bert-2.0
  -> Added with 1 safetensors files
Processing MLX: facebook/bart-large-cnn
  -> Added with 1 safetensors files
Processing MLX: google-t5/t5-small
  -> Added with 1 safetensors files
Processing MLX: jonatasgrosman/wav2vec2-large-xlsr-53-portuguese
Processing MLX: openai/clip-vit-base-patch16

=== Processing pinned MLX models ===
Processing pinned MLX: mlx-community/Jan-v3-4B-base-instruct-4bit
  -> Added pinned MLX model
Total MLX models: 81

=== Removing duplicates ===
After dedup: 173 models

=== V2 Catalog Summary ===
Total models: 173
  - GGUF models: 93
  - MLX models: 80
Written to: model_catalog_v2.json

Updated catalog; total now 173 (GGUF: 93, MLX: 80)
